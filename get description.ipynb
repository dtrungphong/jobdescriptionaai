{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a18a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8ad9b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = 'data-02-06'\n",
    "list_jd = os.listdir(source_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b75822ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_jd_work_path = []\n",
    "for jd in list_jd:\n",
    "    file = os.listdir(os.path.join(source_dir,jd))[1]\n",
    "    list_jd_work_path.append(os.path.join(source_dir,jd,file)) # đọc ra đường dẫn của các file html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f3ac517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(soup, txt):\n",
    "    txt = txt.lower()\n",
    "    if txt not in soup.getText().lower():\n",
    "        return \"\"\n",
    "    for i in range(len(soup.find_all('div'))):\n",
    "        \n",
    "        if (txt in (soup.find_all('div')[i].getText().lower()) ):\n",
    "            if len(solve(soup.find_all('div')[i],txt).split(' '))>8:\n",
    "                return solve(soup.find_all('div')[i],txt)\n",
    "            return soup.getText().lower()\n",
    "    return soup.getText().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3839279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data-02-06/860/data.html'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_jd_work_path[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "530722b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-02-06/1670/data.html\n"
     ]
    }
   ],
   "source": [
    "with open(list_jd_work_path[7],'r') as f:\n",
    "    print(list_jd_work_path[7])\n",
    "    soup = BeautifulSoup(f,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d97f4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\nmô tả công việc\\n\\n\\n                                    - xây dựng database khách hàng, quản lý chất lượng\\n- thiết kế, xây dựng và khởi chạy các quy trình xuất, chuyển đổi và tải dữ liệu mới\\n- phụ trách nghiên cứu các công cụ để phát triển tính năng cho phần mềm dữ liệu hỗ trợ công việc/ kỹ năng kiến thức về phân tích\\n- phối hợp với đội cntt nội bộ để làm rõ các yêu cầu về kiến trúc tích hợp dữ liệu\\n- khai thác, phân tích và xử lý từ dữ liệu nguồn để tổng hợp về kho dữ liệu\\n- triển khai và quản lý công việc, chi phí theo kế hoạch crm đã xây dựng\\n                                \\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = (solve(soup,'mô tả công việc'))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a4a2534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = text[text.find('mô tả công việc'.lower()):text.find('yêu cầu ứng viên'.lower())]\n",
    "text = text.replace(tmp,'')\n",
    "tmp = text[text.find('yêu cầu ứng viên'.lower()):text.find('\\xa0'.lower())]\n",
    "text.find('\\xa0'.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5dd6946b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yêu cầu ứng viên\n",
      "- tốt nghiệp đại học ngành kinh tế, phân tích dữ liệu, công nghệ thông tin, hệ thống thông tin.- ưu tiên ứng viên có kinh nghiệm làm việc thực tế.- ưu tiên ứng viên có kinh nghiệm đã sử dụng hoặc triển khai các giải pháp bi, excel nâng cao, phân tích tài chính, bsc/kpi- kỹ năng phân tích yêu cầu dữ liệu, tư duy, học hỏi nhanh- có kinh nghiệm xây dựng dashboard, làm việc với tableau bi, power bi.- sử dụng tốt microsoft office word, excel- tiếng anh đọc hiểu bắt buộc, có khả năng giao tiếp cơ bản là một lợi thế\n"
     ]
    }
   ],
   "source": [
    "# tmp = text.splitlines()\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ae1c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 'mô tả công việc'\n",
    "t = t.lower()\n",
    "soup = soup.find_all('div')[0]\n",
    "for i in range(len(soup.find_all('div'))):\n",
    "        if (t in (soup.find_all('div')[i].getText().lower()) ):\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1568e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bf58b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    descrip = ['Mô tả công việc', 'Chi tiết công việc', 'Description' , 'Responsi']\n",
    "    require = ['Job Require', 'yêu cầu công việc', 'yêu cầu ứng viên', 'kinh nghiệm', 'bằng cấp', 'experience', 'qualification']\n",
    "    for i in range (len(list_jd_work_path)):\n",
    "        print(\"================================================\")\n",
    "        print(list_jd_work_path[i])\n",
    "        with open(list_jd_work_path[i],'r') as f:\n",
    "            soup = BeautifulSoup(f,'html.parser')\n",
    "            text = \"\"\n",
    "            for j in range(len(descrip)):\n",
    "                text = (solve(soup,descrip[j]))\n",
    "                if(text !=''):\n",
    "                    tmp1=''\n",
    "                    tmp2=''\n",
    "                    for k in range(len(require)):\n",
    "                        if(text.find(require[k].lower())!= -1):\n",
    "                            tmp1 = text[text.find(descrip[j].lower()):text.find(require[k].lower())]\n",
    "                            text = text.replace(tmp1,'')\n",
    "                            tmp2 = text[text.find(require[k].lower()):text.find('\\xa0'.lower())]\n",
    "                            break\n",
    "                    if tmp1=='':\n",
    "                        tmp1 = text[text.find(descrip[j].lower()):-1]\n",
    "                    \n",
    "                    print(tmp1)\n",
    "                    print('-----------------------------------------------')\n",
    "                    print(tmp2)\n",
    "                    data.append([list_jd_work_path[i],tmp1,tmp2])\n",
    "                    break\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c52bf694",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "data-02-06/2121/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "work on data collection systems/ crm (sales system)/underwriting system/management\n",
      "information system (mis), data analytics and other strategies that optimize statistical efficiency and quality.\n",
      "regularly monitor the sales, collection, underwriting, loan products portfolios to ensure delivering highest portfolio performance.\n",
      "analyse sales, collection and underwriting performance records/kpi, interpret results of overall and recommend promotion or change of conditions of loan products if any.\n",
      "coordinate with other related functions to implement strategic changes in sales/collection/und operation, including technical development with it department.\n",
      "strong knowledge of microsoft access, sql, excel and analysis tools such as power query (mquery), power bi for collecting, analysing, evaluating and reporting data in order to increase sales productivity\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "- education level, certification: university degree in computer science, marketing analytics,\n",
      "business, statistics or other related studies; or equivalent work experience\n",
      "- experience:\n",
      "\n",
      "3+ years' experience in similar or equivalent position\n",
      "experience and knowledge of consumer financing industry and collection as a preferred.\n",
      "strong analytical skills with ability to deliver insightful ideas, excited to draw findings from figures.\n",
      "\n",
      "- individual characteristics:\n",
      "\n",
      "good interpersonal, communication and presentation skills.\n",
      "proactive, responsible, attention to detail and a good team player.\n",
      "fluency in written and spoken english\n",
      "\t\n",
      "================================================\n",
      "data-02-06/2860/data.html\n",
      "responsible for driving strategic planning process, facilitating organizational alignment, and overseeing the development and execution of the company's strategic plans. \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2537/data.html\n",
      "mô tả công việc\n",
      "- tham gia vào các dự án triển khai datawarehouse và bi- khảo sát khách hàng để lấy yêu cầu nghiệp vụ, nguồn dữ liệu cần thiết cho nhu cầu báo cáo- mô hình hóa, phân tích dữ liệu phục vụ cho báo cáo và thực hiện phân tích dữ liệu- phân tích yêu cầu và thiết kế dashboard.- phân tích đánh giá các yêu cầu của bài toán của doanh nghiệp và tư vấn giải pháp tối ưu bằng dữ liệu và công nghệ bi- ứng dụng các công cụ bi để xây dựng các dashboard, báo cáo thông minh, trực quan: tableau, power bi.- đào tạo, hướng dẫn người dùng sử dụng dashboard, báo cáo.- thực hiện các nhiệm vụ khác theo phân công của cấp quản lý. \n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "- tốt nghiệp đại học ngành kinh tế, phân tích dữ liệu, công nghệ thông tin, hệ thống thông tin.- ưu tiên ứng viên có kinh nghiệm làm việc thực tế.- ưu tiên ứng viên có kinh nghiệm đã sử dụng hoặc triển khai các giải pháp bi, excel nâng cao, phân tích tài chính, bsc/kpi- kỹ năng phân tích yêu cầu dữ liệu, tư duy, học hỏi nhanh- có kinh nghiệm xây dựng dashboard, làm việc với tableau bi, power bi.- sử dụng tốt microsoft office word, excel- tiếng anh đọc hiểu bắt buộc, có khả năng giao tiếp cơ bản là một lợi thế\n",
      "================================================\n",
      "data-02-06/2727/data.html\n",
      "mô tả công việc\n",
      "chịu trách nhiệm trích xuất và lưu trữ dữ liệu toàn hệ thống (sql, aws, sap);thực hiện các báo cáo định kỳ hàng tuần, hàng tháng gửi cho ban tổng giám đốc và trưởng các bộ phận;phối hợp với các bộ phận liên quan (kinh doanh, kho vận, đặt hàng, ngành hàng,...) để đưa ra các nhận định về kết quả báo cáo;xác định các vấn đề từ các báo cáo và đề xuất giải pháp;đảm bảo thời gian cung cấp các báo cáo tuần, tháng về tình hình tiêu thụ, tồn kho, ngành hàng theo thời gian quy định.thời gian làm việc: 08h00 - 17h00, thứ 2 đến thứ 7 (nghỉ luân phiên thứ 7/tháng)địa chỉ làm việc: 391b trần hưng đạo, phường cầu kho, quận 1, tp.hcm\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "1. trình độ:có kiến thức cơ bản về supply chain/ logistics và ngành bán lẻ;nắm được các phương pháp & công cụ thống kê phân tích;tốt nghiệp đại học các chuyên ngành toán thống kê/thống kê kinh tế/ thống kê kinh doanh/kinh tế lượng/ khoa học dữ liệu/ khoa học máy tính/logictics & chuỗi cung ứng/ quản trị kinh doanh2. kinh nghiệm: ưu tiên ứng viên có đam mê phân tích dữ liệu và kinh nghiệm làm việc từ dưới 06 tháng – 01 năm.3. kỹ năng:kỹ năng tư duy logic, có hệ thống, trực quan hóa dữ liệu;kỹ năng excel nâng cao (vba, sql, access);kỹ năng lập kế hoạch và quản lý công việc;kỹ năng giao tiếp tốt và khả năng thuyết trình;kỹ năng giải quyết vấn đề;kỹ năng tổ chức, tổng hợp và phân tích dữ liệu: dashboard (qlik hoặc powerbi hoặc tableau), xử lý & phân tích dữ liệu (alteryx, sql, r hoặc python là một lợi thế).4. thái độ/phẩm chất: nhạy bén, linh hoạt, khéo léo, có trách nhiệm, ham học hỏi, dấn thân.\n",
      "quyền lợi\n",
      "lương thỏa thuận và nhận đúng hạn;thưởng thâm niên, thưởng tháng 13;được hỗ trợ cơm trưa tại công ty;chỗ ở nội trú cho các nhân sự ở xaxem xét tăng lương 1 lần/năm;bhxh, bhyt, bhtn đầy đủ theo luật;tham gia bảo hiểm bảo việt (thời gian làm việc chính thức đủ 8 tháng);nghỉ phép thường niên, lễ, tết theo quy định;tham gia teambuilding, các hoạt động nội bộ và các hoạt động cộng đồng do công ty tổ chức;được đào tạo bài bản về các kiến thức, kỹ năng cho công việc & kỹ năng đời sống (sức khỏe, dinh dưỡng,...);cơ hội thăng tiến công bằng, không giới hạn phòng ban;làm việc với các nhân sự dày dặn kinh nghiệm trong ngành giày chỉ có ở thương hiệu quốc dân “biti's - nâng niu bàn chân việt”;có cơ hội tham gia dự án hạnh phúc happy biti's để hiểu hơn về chính mình, hiểu & kết nối với người khác, kết nối với thiên nhiên;môi trường làm việc được chia sẻ, được lắng nghe và được tôn trọng;được nhận học bổng \"nâng niu tài năng việt\" cho con em có thành tích học tập tốt.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "hết hạn nộp đơn\n",
      "\n",
      "================================================\n",
      "data-02-06/860/data.html\n",
      "descriptionkiotviet wishes to transfer a massive power of technology to every business model in vietnam and southeast asia through our simple and effective solutions. kiotviet is committed itself to creating efficient, convenient products for micro, small and medium-size businesses. in over 10 years, with more than 1000 people who form kiotviet in present, we understand that our members of all time are the foundation of kiotviet nowadays and a launchpad for reaching a better kiotviet in the future. kiotviet is committed to creating a work environment that shares success, shares responsibilities.we are looking for some developers to join our product team. joining us, you will have a chance to build the first marketplace in vietnam with so much technology challenge. as a developer, you will be involved in building products to enable an excellent \n",
      "-----------------------------------------------\n",
      "experience.what you will do:design the architecture, implement and maintain the data pipelines that are scalable and reliable for kiotviet data platform.design and implement data warehouse, datamarts to meet the need of querying data and perform descriptive and predictive analytics.collect, process, store and analyze our ever-growing customer data.participate in design and implement new generation of our data platform to help push our stakeholders take advantage from data faster.build high-performance, mission critical apis to allow various customer-facing and internal services to query data, perform analytics.brainstorm, discuss with various experts from other departments to develop data products that serve various customer-facing problems and how data will help push our business further.skillsdata structuresdata warehousingbig datarequirementyou must be strong in data structures and algorithms and have a good knowledge in data analysis.deep understanding of data warehouse concepts and practices.you should be experienced building a data warehouse on cloud platform such a google bigquery.possess an in-depth understanding of the data management.you should be experienced in big data processing framework like apache spark.you should be proficient in one or more of the following programming languages: java / scala / python.eager to learn and willing trial and error several times.experienced in manipulating, processing and extracting data from various source systems; working familiarity with relational databases is a plus.experience with cloud platforms such as google cloud platform is a plus.\n",
      "================================================\n",
      "data-02-06/2337/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "phát triển hệ thống cameraai phục vụ các bài toán nhận diện, định danh người, theo dõi, tìm kiếm hàng hóa, đọc địa chỉ, biển số nhà;tham gia xây dựng và làm chủ giải pháp vision ứng dụng trong các bài toán đọc ảnh ra văn bản;tham gia xây dựng và triển khai các giải pháp nhận diện xe, biển số xe, các loại phương tiện sử dụng trong kho;tham gia trực kĩ thuật vận hành các dịch vụ vision, giải quyết sự cố do vận hành, deploy code;theo dõi, giám sát chất lượng các dịch vụ vision;lên kế hoạch bảo trì, nâng cấp các dịch vụ vision về quy mô cũng như tính sẵn sàng của dịch vụ;phối hợp với các team đảm bảo vận hành ổn định hệ thống ekyc, chấm công điểm danh;thời gian làm việc: 9:00 – 18:30; thứ hai – thứ sáu và hai ngày thứ bảy trong tháng luân phiên;địa chỉ: toà nhà ghtk, đường phạm hùng, phường mễ trì, quận nam từ liêm, hà nội.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "tốt nghiệp chuyên ngành liên quan: công nghệ thông tin, điện tử viễn thông, tự động hóa;có tối thiểu 4 năm kinh nghiệm trở lên về lập trình ai trên các thiết bị main board như jetson devices, raspberry pi;có kiến thức về lập trình ai trên các dòng chip arm, hisilicon, rockchip là 1 lợi thế;làm việc thành thạo với các giao thức tcp/ip, mqtt, http,…các mô trình giao tiếp với số lượng lớn client;có kinh nghiệm lập trình driver giao tiếp scanner, các giải pháp vision xử lý ảnh, làm việc với máy xray kiểm soát hàng hoá là một lợi thế;đọc, hiểu tài liệu kỹ thuật tốt;chủ động, sáng tạo, nhiệt tình và có trách nhiệm trong công việc;biết lắng nghe, kiên trì học hỏi, cẩn thận và tỉ mỉ và có khả năng làm việc với cường độ cao;sẵn sàng làm việc over-time khi có yêu cầu;có khả năng làm việc độc lập và làm việc theo nhóm.\n",
      "quyền lợi\n",
      "lương từ junior đến senior: 500$ – 2000$ net (đánh giá tăng lương theo năng lực định kỳ);bảo hiểm sức khỏe cao cấp generali;môi trường làm việc trẻ trung, năng động;làm việc cùng đội ngũ công nghệ giỏi chuyên môn, có cơ hội để phát huy tối đa năng lực của bản thân;liên tục được đào tạo về kiến thức, kỹ năng liên quan đến các lĩnh vực hoạt động của công ty;được cung cấp đầy đủ phương tiện làm việc theo yêu cầu của tính chất công việc;các hoạt động tập thể, giải trí đa dạng (clb bóng đá, game, bi lắc, …); sự kiện team-building hàng năm;được đảm bảo đầy đủ các chế độ phúc lợi theo quy định của pháp luật hiện hành và của công ty;thưởng tết nguyên đán, tết dương lịch, ngày lễ khác và thưởng thành tích nổi bật.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 31/07/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/1871/data.html\n",
      "responsibilities:assembling large, complex sets of data that meet non-functional and functional business requirementsbuilding analytical tools to utilize the data pipeline, providing actionable insight into key business performance metrics including operational efficiency and customer acquisitionidentifying, designing, and implementing internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processesworks closely with all business units to develop strategy for long term data platform architecture.ii. \n",
      "-----------------------------------------------\n",
      "job requirements:university degree in computer science, engineering and/or a technically oriented field2 years of experience with flink/spark, databricks2 years of experience with azure (dp200 and/or dp201, dp203 certification acts as a plus)passionate about analytics machine learning technology & applications and eager to learnenglish communicationknowledge of big data technologies, such as spark, hadoop/mapreduceknowledge of azure services like storage account, azure databricks etc.good knowledge of sql and excellent coding skillsworking knowledge of various ml/dl applications such as keras, tensorflow, python scikit learn and rself-development, communication, problem-solving skills.open-minded, multi-tasking, teamwork, flexible and interest to learn new things\n",
      "\n",
      "================================================\n",
      "data-02-06/1670/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "                                    - xây dựng database khách hàng, quản lý chất lượng\n",
      "- thiết kế, xây dựng và khởi chạy các quy trình xuất, chuyển đổi và tải dữ liệu mới\n",
      "- phụ trách nghiên cứu các công cụ để phát triển tính năng cho phần mềm dữ liệu hỗ trợ công việc/ kỹ năng kiến thức về phân tích\n",
      "- phối hợp với đội cntt nội bộ để làm rõ các yêu cầu về kiến trúc tích hợp dữ liệu\n",
      "- khai thác, phân tích và xử lý từ dữ liệu nguồn để tổng hợp về kho dữ liệu\n",
      "- triển khai và quản lý công việc, chi phí theo kế hoạch crm đã xây dựng\n",
      "                                \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3017/data.html\n",
      "responsible “tribe of intrapreneurs” that is passionately dedicated to renew the travel industry and while doing so reinvent the ways how businesses stay, work and pay.\n",
      "\n",
      "our entrepreneurial driven environment of full ownership and execution focus offers you the playground to contribute to a greater mission, while growing personally and professionally throughout this unique journey. you will continuously learn from a radical culture of retrospectives and continuous improvement and actively contribute to making business life better, smarter and more sustainable.\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3128/data.html\n",
      "responsibility will be to design and build our data infrastructure and develop features that leverage the power of data to deliver value to our customers. your daily tasks will encompass a wide range of activities, including but not limited to:\n",
      "\n",
      "developing and implementing data-driven solutions: utilize your expertise to solve complex business problems by developing and implementing data-driven solutions.\n",
      "analyzing large datasets: dive into extensive datasets, identify trends, and extract meaningful insights that can guide decision-making processes.\n",
      "designing experiments and measuring impact: design and conduct experiments to measure the impact of product changes, analyzing the results to gain valuable insights.\n",
      "building predictive models: apply your knowledge of machine learning algorithms to develop accurate and robust predictive models.\n",
      "collaborating with cross-functional teams: work closely with cross-functional teams to ensure successful implementation of data science projects, fostering collaboration and communication.\n",
      "integrating data science into products: collaborate with software engineers to seamlessly integrate data science methodologies and solutions into our products.\n",
      "researching new technologies and techniques: stay updated on the latest technologies and techniques in the field of data science, actively researching and proposing innovative ideas to enhance existing processes.\n",
      "monitoring and improving model performance: continuously monitor the performance of models in production and propose improvements to optimize their effectiveness.\n",
      "staying current with industry trends: stay abreast of industry trends and best practices in data science, proactively applying this knowledge to enhance our data-driven strategies.\n",
      "mentoring and providing technical guidance: share your expertise and mentor junior team members, offering technical guidance and support as they develop their skills.\n",
      "\n",
      "what you should have\n",
      "\n",
      "bachelor’s degree or higher in computer science, mathematics, statistics, or engineering (or a related field).\n",
      "proven experience in applying machine learning techniques to large datasets.\n",
      "demonstrated experience in developing, building, and delivering machine learning models to production.\n",
      "experience with nlp/llm is a plus.\n",
      "experience with investing & trading in the stock market is a plus.\n",
      "\n",
      "we offer a competitive compensation package and a dynamic work environment that encourages innovation and professional growth. join our team and contribute to the cutting-edge work we do in leveraging data to drive business success.\n",
      " benefits\n",
      "\n",
      "attractive income.\n",
      "monthly/annual bonuses, 13th-month bonus.\n",
      "12 days for annual leave and 03-day bonus leave for each 12 working months.\n",
      "team building activities, holidays with the company.\n",
      "open working space.\n",
      "every 6-months performance review.\n",
      "approach the environment of a fintech startup, grant admissions to many departments within the company: product-design, product development, growth, operations.\n",
      "learn, experience, and get close contact with experts in investment and finance.\n",
      "propose ideas freely, permission to make trials, and fail.\n",
      "other benefits as per required from the labor code.\n",
      "\n",
      "how to apply1\n",
      "\n",
      "hotline: 0944 511 091 (ms. thanh huyen).\n",
      "\n",
      "contact information\n",
      "\n",
      "head office: capital building, 58 kim ma street, ba dinh district, hanoi capital\n",
      "hcm branch: bitexco nam long building, 63a vo van tan street, district 3, hochiminh city\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1589/data.html\n",
      "responsibility, and good english\n",
      "\n",
      "\n",
      "general information\n",
      "\n",
      "\n",
      "level: junior-middletype of the position: full-time permanent cluster: it craft (autobiz)working time: 9:00 am - 6:00 pm (flexible - hybrid working)working location: f-central; 16a le hong phong, ward 12, dist. 10, hcmcmonthly salary: up to 1000$other benefits: 13th-month salarytet bonustrade union giftslunch served right at the pantry premium healthcare packageannual healthcare checkup at the international clinicfree training classes with diverse topics the innovative salary review process22 leaves per year (12al+10sl)laptop policy if anyparking-freeonsite opportunities to france upon client’s request\n",
      "\n",
      "-----------------------------------------------\n",
      "experience with linux os, bash scriptfamiliar with crawling data from the websiteexperienced in sql, and mysql databases.experienced in python/javascript/bash scriptingdata mining or have an interest in data scienceteamwork spirit, responsibility, and good english\n",
      "\n",
      "\n",
      "general information\n",
      "\n",
      "\n",
      "level: junior-middletype of the position: full-time permanent\n",
      "================================================\n",
      "data-02-06/2743/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description\n",
      "\n",
      "\n",
      "life at agoda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "all teams\n",
      "contentcustomer \n",
      "-----------------------------------------------\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "business intelligence developer (bangkok based, relocation provided)\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "================================================\n",
      "data-02-06/2920/data.html\n",
      "description\n",
      "\n",
      "we are looking for for data/back-end engineer(python, fastapi, scrapying, sql).we are a vietnam-based software development company working with global clients on various projects.through our outsourcing projects, we also provide talented developers like yourself with opportunities for work at international firms.we do not outsource our developers, rather, we invite them into one shared office that serves many regular corporate clients.enhance your skills and value in a developer-friendly environment, through projects with global companies.you will be working on the product: cigro cigro is a data integration solution for e-commerce companies that provides all stages of data storage, pre-processing, and visualization from various platformcigro accomplishment:\n",
      "got invested from prominent unicorn founders (socar, zigzag, sendbird etc) and vcs (springcamp, schmidt, synergy ib, tab angel)\n",
      "record 10x growth last 12 months in sales and our client includes big names in d2c, media commerce fields.\n",
      "\n",
      "handle big data and can develop data engineering career (prefect, bigquery, postgresql, stack).\n",
      "\n",
      "job responsibilities\n",
      "\n",
      "crawling & scraping data using python\n",
      "\n",
      "\n",
      "web service development using python, fast api, sql\n",
      "\n",
      "plan/design data architectures that fit business strategies\n",
      "\n",
      "\n",
      "your skills and experience\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "job requirements\n",
      "\n",
      "1+ years experience with python asynchronous programming. ( fresher accepted. )\n",
      "\n",
      "advanced experience with sql\n",
      "\n",
      "\n",
      "upper-intermediate\n",
      "================================================\n",
      "data-02-06/2424/data.html\n",
      "================================================\n",
      "data-02-06/2990/data.html\n",
      "responsibilities\n",
      "\n",
      "provide hw manufacturing i.e. data and analysis that is needed to build hw costing tool.\n",
      "provide hw material consumption and processing cost across hw supply base, report findings, and propose aligned standards.\n",
      "measure product complexity and productivity that can be a base to build up hw costing tool \n",
      "support special projects as directed\n",
      "travel to manufacturing locations as needed\n",
      "\n",
      " \n",
      "dimensions\n",
      "reports to sr. manager, strategic costing. interacts with:\n",
      "\n",
      "hardwear rms (raw material supplier)\n",
      "hardwear management team\n",
      "\n",
      " \n",
      "education & \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2550/data.html\n",
      "================================================\n",
      "data-02-06/3022/data.html\n",
      "chi tiết công việc junior financial planning and analysis executive  tại công ty cổ phần galaxy pla\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1897/data.html\n",
      "mô tả công việc- analyze and organize raw data \n",
      "- build data systems and pipelines\n",
      "- evaluate business needs and objectives\n",
      "- interpret trends and patterns\n",
      "- conduct complex data analysis and report on results\n",
      "- prepare data for prescriptive and predictive modeling\n",
      "- build algorithms and prototypes\n",
      "- combine raw information from different sources\n",
      "- explore ways to enhance data quality and reliability\n",
      "- identify opportunities for data acquisition\n",
      "- develop analytical tools and programs\n",
      "- collaborate with data scientists and architects on several projects\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên- previous experience as a data engineer or in a similar role\n",
      "- technical expertise with data models, data mining, and segmentation techniques\n",
      "- knowledge of programming languages \n",
      "================================================\n",
      "data-02-06/145/data.html\n",
      "mô tả công việc\n",
      "- đo lường số liệu bán từng dòng sản phẩm để đưa ra tỷ trọng đặt hàng - đo lường dòng sản phẩm bán chậm, bán chạy và đưa ra đề xuất - xây dựng bảng tỷ lệ chia hàng, phân bổ đến hệ thống cửa hàng- đảm bảo tồn kho an toàn cho từng cửa hàng và luân chuyển hàng hóa trong hệ thống - dự trữ hàng hóa cửa hàng khai trương - dự đoán xu hướng bán của nhóm hàng phụ trách- quản lý, theo dõi các chương trình khuyến mãi- kết hợp cùng giám đốc vùng xây dựng kế hoạch bán\n",
      "yêu cầu: \n",
      "- nam/nữ (23 - 35t), tốt nghiệp cao đẳng, đại học chuyên ngành kinh tế, tài chính- tối thiểu 1 năm \n",
      "-----------------------------------------------\n",
      "kinh nghiệm tại các vị trí tương đương- thành thạo excel, biết sql là một lợi thế- có kỹ năng tổng hợp và phân tích số liệu- nhanh nhẹn, trung thực, trách nhiệm, cầu tiến - ưu tiên đã từng làm giám sát bán hàng, vận đơn, cửa hàng trưởng, ngành hàng trong các chuỗi bán lẻ lớn\n",
      "địa điểm làm việc\n",
      "bạn có thể lựa chọn làm tại 1 trong các văn phòng- trụ sở chính yody: đường an định, p. việt hòa, tp. hải dương (maps)- với ứng viên tại hà nội, bạn sẽ di chuyển về hải dương làm việc (yody hỗ trợ xe đưa đón hà nội - hải dương hoặc sắp xếp nơi ở miễn phí tại hải dương)\n",
      "quyền lợi:\n",
      "– thu nhập: 15 – 20 triệu (lương + thưởng doanh thu đơn hàng sản phẩm phụ trách)– thưởng cuối năm: 1-2 tháng thu nhập, thưởng theo doanh thu, thưởng các ngày lễ, tết+ cung cấp thiết bị làm việc+ phụ cấp ăn trưa miễn phí tại công ty.+ nghỉ chủ nhật, năm có 12 ngày nghỉ phép+ đóng bảo hiểm khi chính thức theo quy định+ được tổ chức sinh nhật, du lịch 1-2 lần/năm, hưởng các chính sách đãi ngộ đặc biệt từ công ty\n",
      "================================================\n",
      "data-02-06/2758/data.html\n",
      "mô tả công việc:\n",
      "- tham gia xây dựng cơ chế đánh giá, nguyên tắc lựa chọn dịch vụ áp dụng cho các hệ thống dịch chuyển lên cloud (clouding service matrix).\n",
      "- tham gia xây dựng phương pháp/quy trình và thực hiện lập ngân sách chi phí hạ tầng trên cloud.\n",
      "- tham gia xây dựng và thực hiện báo cáo định kỳ và dự báo sử dụng chi phí cloud.\n",
      "- tham gia xây dựng cơ chế cảnh báo, xử lý với các trường hợp vượt ngân sách xây dựng ban đầu.\n",
      "- xây dựng báo cáo phân bổ chi phí cloud đến từng hệ thống, khối trong ngân hàng\n",
      "- phân tích thực trạng, đánh giá, đề xuất với ban lãnh đạo các cơ hội tối ưu chi phí cloud\n",
      "- thực hiện các công việc khác theo phân công của giám đốc khối tài chính/trưởng phòng.\n",
      "                                                                                   \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/767/data.html\n",
      "mô tả công việc –...\n",
      "                            \n",
      "apply for this job\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1867/data.html\n",
      "mô tả công việc\n",
      "create and maintain optimal data pipeline architecture,assemble large, complex data sets that meet functional/non-functional business requirements.identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using sql and aws ‘big data’ technologies.build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.work with stakeholders including the executive, product, data and design teams to assist with data-related technical issues and support their data infrastructure needs.keep our data separated and secure across national boundaries through multiple data centers and aws regions.create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.work with data and analytics experts to strive for greater functionality in our data systems.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "advanced working sql knowledge and experience working with relational databases, query authoring (sql) as well as working familiarity with a variety of databases.experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.strong analytic skills related to working with unstructured datasets.build processes supporting data transformation, data structures,…a successful history of manipulating, processing and extracting value from large disconnected datasets.working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.strong project management and organizational skills.experience supporting and working with cross-functional teams in a dynamic environment.having 2+ years of experience in a data engineer role, who has attained a graduate degree in computer science, statistics, informatics, information systems or another quantitative field. they should also have experience using the following software/tools:experience with big data tools: hadoop, spark, kafka, etc.experience with relational sql and nosql databases, including postgres and mongodbexperience with data pipeline and workflow management tools: azkaban, luigi, airflow, etc.experience with aws cloud services: ec2, emr, rds, redshiftexperience with stream-processing systems: storm, spark-streaming, etc.experience with object-oriented/object function scripting languages: python, java, c++, scala, etc.\n",
      "quyền lợi\n",
      "professional work environment:\n",
      "================================================\n",
      "data-02-06/2886/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "                                                                                            - develop and propose product strategy and business planning to company management. lead the product development functions, including new product development, product pricing, profitability testing, regulatory filing, and product implementation, product performance monitoring, and audit. ensure that marketability and profitability of the products and support the business development of the company. keep abreast with and understand the implication of changes in regulation and accounting standards.\n",
      "\n",
      "- calculate insurance premiums and participate in developing wordings, terms & conditions of insurance and reinsurance products; verify the premium based on statistics, ensure the economic and technical feasibility of the product and the company's solvency; evaluate the difference between the charging assumptions and the actual implementation of each product on annual basis.\n",
      "\n",
      "- develop and manage the system of valuation for statutory reserves and for internal purposes complying with the local regulations and company policies.\n",
      "\n",
      "- participate in the separation of equity and insurance premiums in accordance with the law.\n",
      "\n",
      "- evaluate the company's solvency and verify the solvency report and submit to competent authority in accordance with law.\n",
      "\n",
      "- prepare regular report to bod and the members' council on the current financial situation and forecast the future financial situation of the company; situation of the company's investment activities\n",
      "\n",
      "- evaluate reinsurance programs and reinsurance contracts before submitting them to the board of directors and board of members for approval.\n",
      "\n",
      "- forecasting the financial position of the company on the basis of assessing arising risks, proposing measures to ensure the financial safety of the company.\n",
      "\n",
      "- other tasks as assigned.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1710/data.html\n",
      "mô tả công việc\n",
      "chứng khoán an bình (abs) là thành viên thuộc tập đoàn geleximco với hơn 16 năm kinh nghiệm trong lĩnh vực tài chính và đầu tư. với hơn 150 nhân viên đang làm việc tại hơn 10 tỉnh thành trên toàn quốc và đang tiếp tục tăng trưởng mạnh mẽ trong năm 2022.\n",
      "abs hướng đến trở thành nền tảng đầu tư hiệu quả và tin cậy, dễ dàng tiếp cận cho cả các nhà đầu tư chuyên nghiệp và các nhà đầu tư mới với lượng sản phẩm đầu tư đa dạng từ chứng khoán, trái phiếu, quỹ đầu tư.\n",
      "với mong muốn đầu tư hệ thống công nghệ tốt nhất, trở thành một trong các công ty tài chính hàng đầu, abs đang tìm kiếm vị trí thực tập sinh developer để xây dựng các sản phẩm công nghệ tài chính về đầu tư tại việt nam.\n",
      "1. được đào tạo và làm việc với các chuyên gia về web, backend, mobile, data science…\n",
      "2. lập trình back end phát triển phần mềm cho các dự án sản phẩm cntt trên nền web / mobile: tích hợp với các hệ thống hỗ trợ khác như crm, dwh, các hệ thống trao đổi thông tin, gửi nhận thông tin, hệ thống bảo mật, phân quyền, quản lý định danh…\n",
      "3. tìm hiểu các công nghệ mới nhất và ứng dụng cho hệ thống hiện tại.\n",
      "4. công nghệ chúng tôi đang sử dụng:\n",
      "– kiến trúc: microservices\n",
      "– ngôn ngữ lập trình: java, spring boot, dotnet core, nodejs, react, flutter\n",
      "– message broker: kafka, rabbitmq\n",
      "– cơ sở dữ liệu: oracle, redis, mongodb\n",
      "– công nghệ xử lý realtime: apache flink, kafka\n",
      "– công nghệ triển khai vận hành: docker, vmware, jenkins, ansible, elasticsearch, elastic apm, wso2 api manager.\n",
      " \n",
      "ii. \n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "– đang là sinh viên năm 3 hoặc năm cuối chuyên ngành cntt hoặc hiểu biết tương đương, muốn có môi trường học tập và phát triển thực tế.\n",
      "– kỹ năng giao tiếp tốt, cởi mở, thân thiện, làm việc nhóm hiệu quả.\n",
      "– có hiểu biết về các ngôn ngữ / nền tảng sau: spring, spring boot, spring mvc, .net, nodejs, react, vue, angular, go\n",
      "– khả năng nắm bắt, yêu thích nghiên cứu công nghệ mới.\n",
      "\n",
      "================================================\n",
      "data-02-06/2634/data.html\n",
      "descriptions\n",
      "\n",
      "responsible for industrialization, deployment and functional maintenance of data products/solutions, including digital products, business intelligence, and machine learning use cases.\n",
      "collaborate with other member and user to build data pipelines.\n",
      "responsible for quality checking and testing.\n",
      "collaboratively work to solve research problems.\n",
      "develop new algorithms and computational tools to solve research problems.\n",
      "review research code created by other team members.\n",
      "write technical documentation and reports.\n",
      "continue learning new technologies, introducing existing products, improving product experience, and creating more value.\n",
      "\n",
      "ii. skill and experience\n",
      "\n",
      "at least 1 year experiences in data engineer.\n",
      "demonstrable experience in web application development (building of api driven interfaces).\n",
      "ability to program with python is required.\n",
      "good knowledge in data warehouse, etl, data pipeline.\n",
      "proficiency in sql.\n",
      "exposure to emerging open-source technologies is preferred.\n",
      "good number sense, logical thinking, problem-solving and communication skills.\n",
      "have teamwork skills, work independently and self-study.\n",
      "experience with data pipeline and workflow management tools: airflow, etc.\n",
      "experience with big data tools: spark, kafka, etc.\n",
      "experience with oracle.\n",
      "\n",
      "iii. why you will love joining us?\n",
      "for you to join\n",
      "\n",
      "financial well-being: a competitive salary with 13th month salary, annual performance bonus and a variety of allowances.\n",
      "salary review: annually or on excellent performance.\n",
      "activities: company trips, team-building, and other customized monthly bonding events.\n",
      "annual leaves: 16 days off and 01 birthday leave per year.\n",
      "healthcare: annual health check, insurance according to labor law and extra pti insurance package.\n",
      "working environment: dynamic, friendly environments with working time flexibility (mon-fri), and other perks include snacks, coffee, and healthy food provided daily suited for hardworking, fun, and team collaboration.\n",
      "\n",
      "for you to grow\n",
      "\n",
      "ambition: we are now keeping on with our hyper growth to multicategory, multichannel, multimarket, and expanding into the world largest e-commerce enabler. hence, there will continuously be opportunities to challenge yourself, learn new skills and knowledge. \n",
      "challenges: your voice can always be heard as we embrace the eagerness of learning and sharing. you can be your own boss and create your own value with the ability to take initiative and make decisions in all aspects of work.\n",
      "chances: be led and coached by experienced and inspirational leaders and participate in various training courses where you can enlarge your knowledge and experience in the e-commerce and supply chain industry.\n",
      "\n",
      "for you to stay\n",
      "\n",
      "people: having a headquarter in the us and an operation office in vietnam, our team is young and highly motivated. you will be working with and alongside members having experiences from international corporations or high profile from vietnam that share the same passion and dedication.\n",
      "culture: our working environment is humble, collaborative and 100% healthy. we promote exchange & speak out, you can receive transparent and supportive feedback so you can perform the best.\n",
      "career path: provide you a great career path, open to rotating for your better understanding of the company and contribute across many of our functions.\n",
      "\n",
      "and much more, join us and let yourself explore other fantastic things!\n",
      "-----------------------------------------------\n",
      "experience in the e-commerce industry.\n",
      "we are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end-to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\n",
      "i. job descriptions\n",
      "\n",
      "responsible for industrialization, deployment and functional maintenance of data products/solutions, including digital products, business intelligence, and machine learning use cases.\n",
      "collaborate with other member and user to build data pipelines.\n",
      "responsible for quality checking and testing.\n",
      "collaboratively work to solve research problems.\n",
      "develop new algorithms and computational tools to solve research problems.\n",
      "review research code created by other team members.\n",
      "write technical documentation and reports.\n",
      "continue learning new technologies, introducing existing products, improving product experience, and creating more value.\n",
      "\n",
      "ii. skill and experience\n",
      "\n",
      "at least 1 year experiences in data engineer.\n",
      "demonstrable experience in web application development (building of api driven interfaces).\n",
      "ability to program with python is required.\n",
      "good knowledge in data warehouse, etl, data pipeline.\n",
      "proficiency in sql.\n",
      "exposure to emerging open-source technologies is preferred.\n",
      "good number sense, logical thinking, problem-solving and communication skills.\n",
      "have teamwork skills, work independently and self-study.\n",
      "experience with data pipeline and workflow management tools: airflow, etc.\n",
      "experience with big data tools: spark, kafka, etc.\n",
      "experience with oracle.\n",
      "\n",
      "iii. why you will love joining us?\n",
      "for you to join\n",
      "\n",
      "financial well-being: a competitive salary with 13th month salary, annual performance bonus and a variety of allowances.\n",
      "salary review: annually or on excellent performance.\n",
      "activities: company trips, team-building, and other customized monthly bonding events.\n",
      "annual leaves: 16 days off and 01 birthday leave per year.\n",
      "healthcare: annual health check, insurance according to labor law and extra pti insurance package.\n",
      "working environment: dynamic, friendly environments with working time flexibility (mon-fri), and other perks include snacks, coffee, and healthy food provided daily suited for hardworking, fun, and team collaboration.\n",
      "\n",
      "for you to grow\n",
      "\n",
      "ambition: we are now keeping on with our hyper growth to multicategory, multichannel, multimarket, and expanding into the world largest e-commerce enabler. hence, there will continuously be opportunities to challenge yourself, learn new skills and knowledge.\n",
      "================================================\n",
      "data-02-06/1121/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responsible for the assigned tasks;\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1160/data.html\n",
      "responsible for the entire customer lifecycle. typically a data driven role, a growth strategy manager will create tests and experiments to positively influence customer acquisition, customer conversion, customer retention and customer lifetime value for taptap and our business partners.\n",
      "what you will be responsible for:\n",
      "\n",
      " build and lead the growth team to drive prioritization, strategy, and focus on solutions to solve user problems across different channels, including our brand partners’ and taptap’s own channels. you will be collaborating with the marketing & product teams on a daily basis.\n",
      "discover growth opportunities for taptap and our partners from funnel conversion rates and user \n",
      "-----------------------------------------------\n",
      "experience by exploring offline & online transaction data, customer activity within apps and actual customer insights.\n",
      "maintain rigor in analytical excellence in terms of data analytics, a/b test design, and appropriate statistical tests across the product funnel from acquisition, adoption, retention to monetization.\n",
      "liaise with other analytical chapters such as data science, data engineering, etc, to ensure that initiatives are aligned and data integrity standards are adhered to.\n",
      "analyze our complex and ever-growing data, present insights, and propose strategic options to senior management to drive business decisions.\n",
      "test and validate solutions through proper experimentation process.\n",
      "importantly, using data to identify growth opportunities and problem solve so as to achieve business goals with metrics such as adoption rate, gmv, mau, & cohort retention.\n",
      "\n",
      "you will have the following skills and experience:\n",
      "this role requires a person who is data driven, a growth marketer will create tests and experiments to positively influence customer acquisition, customer conversion, customer retention and customer lifetime value.\n",
      "================================================\n",
      "data-02-06/720/data.html\n",
      "responsibilitiesbe in charge of analyzing data for department qa .define and execute the digital testing strategy to identify risks and drive the testing coverage within the audit cycle to assess internal control activity, operational efficiencies and compliance with selected policies, procedures and regulations.review the business process maps for each audit to identify the key automated business controls and critical data elements, and whether there are control gaps in the end to end flow.train and coach staff in tools and methods for performing effective and efficient audits, reviews and special projects.work with product owners and it stakeholders to prioritize backlogs, deliver solutions through environments and into production.lead and provide estimates, formalize release plans, and implementation schedules/dependencies.innovate to improve future processes and deployments.develop a method to identify fake failimplement the method into actual operations to detect fake failenable ops to track fake fail rateset up data model to test scan compliance auditreport and find the root cause for the problem.propose solutionsdevelop a tool to identify wrong dim weight behaviors compared to dimweight sopbring the method into actual operations to detect wrong behaviors in the dim/weight process.apply a systematic, risk-focused, disciplined, and balanced approach to evaluate and improve the effectiveness and efficiency of processes, internal controls, risk management and governance processes.drive innovation and technological improvements that support the activities of internal audit such as data analytics, process and data mining. set up data model to test scan compliance auditreport and find the root cause for the problem.propose solutionsto plan and execute initiative projects, together with cross-departments. training and coaching junior audit team members and likely to have wider coaching and people management responsibilities.assist in the identification, selection, and implementation of tools, technologies, and practices that support the overall qa processmanage external contracts and suppliers where required\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2178/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "design, develop and enhancement big data systems such as data warehouse, data lake\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "designing and develop big data applications\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "creating data processing frameworks\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "extracting data and isolating data clusters\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "doing poc & present about big data solutions for new project\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "troubleshooting application bugs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "maintaining the data security\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "develop and update technical documentation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "develop testing scripts and analyzing results\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1008/data.html\n",
      "================================================\n",
      "data-02-06/2068/data.html\n",
      "mô tả công việc\n",
      " 1. support and coordinate with other department to develop system for tracking sell out/ display/ sell-thru/ incentive settlement (nds, e-warranty, gtm, aqua psi )2. make sure that system is running stable and full fill data from internally to get market situation internal sales performance, trade insights, market trend, competitor’s activities3. support manager to conduct... \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2381/data.html\n",
      "mô tả công việc:\n",
      "\n",
      "lập trình bằng python, r và sql.\n",
      "xử lý các dữ liệu căn bản.\n",
      "\n",
      "\n",
      "xây dựng các ml model để giải quyết các bài toán thực tế\n",
      "\n",
      "3.yêu cầu\n",
      "\n",
      "tốt nghiệp chuyên ngành công nghệ thông tin\n",
      "đã có \n",
      "-----------------------------------------------\n",
      "kinh nghiệm xây dựng ml model và các kỹ thuật liên quan như k-fold cross-validation.\n",
      "có thể xây dựng các mô hình bằng tensorflow hoặc pytorch.\n",
      "có kinh nghiệm với data visualisation bằng bằng biểu đồ sử dụng python, r hoặc một bi dashboard bất kỳ (tableau, powerbi).\n",
      "\n",
      "\n",
      "có kinh nghiệm ứng dụng ml model vào các bài toán thực tế.\n",
      "sử dụng thành thạo một ml platform bất kỳ là một lợi thế (mlflow, kubeflow, azure machine learning, vertex ai).\n",
      "làm việc hiệu quả với các thành viên trong nhóm phát triển sản phẩm và hoàn thành các mục tiêu chung đã được đặt ra trong các giai đoạn cụ thể.\n",
      "================================================\n",
      "data-02-06/2717/data.html\n",
      "mô tả công việc\n",
      "• tham gia dự án thực tế về data science, ai, machine learning trong lĩnh vực tài chính, viễn thông, ngân hàng, bảo hiểm, v.v..• tham gia các dự án phân tích dữ liệu & hành vi người dùng trên hệ thống để hiểu được insight• nghiên cứu các mô hình ml & dl cơ bản áp dụng cho các bài toán trong lĩnh vực tài chính, viễn thông, ngân hàng, bảo hiểm v.v..\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "• trình độ đại học trở lên, học chuyên ngành công nghệ thông tin, hệ thống thông tin hoặc các chuyên ngành liên quan tại các trường đại học công nghệ, đại học công nghiệp, học viện bưu chính viễn thông, đại học bách khoa v,v...• biết sử dụng các công cụ tableau; ngôn ngữ truy vấn sql, python …• có kiến thức cơ bản về các mô hình học máy• có kĩ năng làm việc nhóm và độc lập.• nhanh nhẹn, ham học hỏi, chủ động, thẳng thắn và có tinh thần trách nhiệm cao\n",
      "quyền lợi\n",
      "• nhân viên lương cứng 8 - 12 triệu theo năng lực.• sau khi ký hợp đồng chính thức sẽ được hưởng chế độ thưởng theo quy định công ty.nghỉ phép 12 ngày/năm, nghỉ ốm/nghỉ chế độ thai sản/hiếu hỉ… theo quy định pháp luật lao động, bảo hiểm xã hội• du lịch hàng năm, teambuilding, event.• được tài trợ, tham gia các khóa đào tạo kỹ năng, chuyên môn hàng năm, thi lấy chứng chỉ để phục vụ cho công việc.• review đánh giá công việc 2 lần/ năm;• có khả năng phát triển bản thân, định hướng phát triển công việc lâu dài;• môi trường trẻ, năng động, chuyên nghiệp, được khuyến khích sáng tạo và phát triển các ý tưởng mới, sếp trẻ tâm lý, đồng nghiệp thân thiện, văn hóa trao đổi thẳng thắn, cởi mở trên tinh thần hỗ trợ cùng phát triển;• học hỏi kinh nghiệm trực tiếp từ các senior, chuyên gia giàu kinh nghiệm;\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 07/06/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/1706/data.html\n",
      "mô tả công việc:\n",
      "kiotviet wishes to transfer a massive power of technology to every business model in vietnam and southeast asia through our simple and effective solutions. kiotviet is committed itself to creating efficient, convenient products for micro, small and medium-size businesses. in over 10 years, with more than 1000 people who form kiotviet in present, we understand that our members of all time are the foundation of kiotviet nowadays and a launchpad for reaching a better kiotviet in the future. kiotviet is committed to creating a work environment that shares success, shares responsibilities.\n",
      " we are looking for some developers to join our product team. joining us, you will have a chance to build the first marketplace in vietnam with so much technology challenge. as a developer, you will be involved in building products to enable an excellent \n",
      "-----------------------------------------------\n",
      "experience.\n",
      "what you will do:\n",
      "- design the architecture, implement and maintain the data pipelines that are scalable and reliable for kiotviet data platform.\n",
      "- design and implement data warehouse, datamarts to meet the need of querying data and perform descriptive and predictive analytics.\n",
      "- collect, process, store and analyze our ever-growing customer data.\n",
      "- participate in design and implement new generation of our data platform to help push our stakeholders take advantage from data faster.\n",
      "- build high-performance, mission critical apis to allow various customer-facing and internal services to query data, perform analytics.\n",
      "- brainstorm, discuss with various experts from other departments to develop data products that serve various customer-facing problems and how data will help push our business further.\n",
      "================================================\n",
      "data-02-06/1908/data.html\n",
      "================================================\n",
      "data-02-06/2261/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "\n",
      "                                    căn cứ vào đơn hàng của phòng kinh doanh, căn cứ vào lượng hàng tồn kho, căn cứ theo năng suất của từng phân xưởng, căn cứ vào tình trạng hoạt động của thiết bị máy móc… để lập kế hoạch sản xuất/ gia công cho từng bộ phận, từng công đoạn đảm bảo sản xuất ra lượng hàng theo yêu cầu, đúng thời gian.\n",
      "lập kế hoạch giao hàng. theo dõi kế hoạch giao hàng đảm bảo đúng tiến độ.\n",
      "chuyển kế hoạch sản xuất cho phòng sản xuất và kh vật tư. giám sát, theo dõi, lập báo cáo tiến độ sản xuất hàng ngày, tuần, tháng, quý, năm.\n",
      "theo sát tiến độ sản xuất để kịp tiến độ xuất hàng; đôn đốc các bộ phận thực hiện đúng tiến độ. báo cáo sự việc phát sinh (nhân sự, nguyên vật liệu, máy móc…) ảnh hưởng đến kh sản xuất và đề xuất giải pháp xử lý với tbp kế hoạch, phòng kinh doanh và các phòng ban liên quan.\n",
      "thống kê và phân tích dữ liệu sản xuất (sản lượng, năng suất, chất lượng, định mức nguyên vật liệu, tỷ lệ phế liệu sản xuất, hiệu suất máy móc… ), đưa ra đánh giá và đề xuất phương pháp khắc phục, cải tiến.\n",
      "chủ động thiết lập mối quan hệ chặt chẽ với các bộ phận, đảm bảo nguồn thông tin luôn xuyên suốt trong việc thực hiện đơn hàng, là đầu mối kết nối với các bộ phận liên quan với phòng kế hoạch và sản xuất để giải quyết các vấn đề phát sinh trong sx.\n",
      "phối hợp cùng phòng kinh doanh thực hiện đúng quy trình đặt hàng và giao hàng hợp lý, dựa trên nguyên tắc đảm bảo về chất lượng; thường xuyên kiểm tra, xác nhận về lịch booking của khách hàng vào nhận hàng hoá.\n",
      "thống kê, đánh giá biến động hàng tồn kho, phân rõ trách nhiệm xử lý hàng hóa, bán thành phẩm tồn kho, cập nhật tình trạng tồn kho theo định kỳ.\n",
      "thực hiện các công việc khác theo sự phân công của cấp quản lý.\n",
      "                                \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/703/data.html\n",
      "mô tả công việc\n",
      "\n",
      "xây dựng / tích hợp phần mềm và thuật toán để lập kế hoạch đường đi, lập kế hoạch hành vi và điều khiển phương tiện\n",
      "phát triển / thực hiện / đánh giá / triển khai các thuật toán trong lập kế hoạch chuyển động của rô bốt, xe tự hành (ví dụ: a*, dijkstra ), mô hình xe và chuyển động học\n",
      "\n",
      "yêu cầu\n",
      "\n",
      "có \n",
      "-----------------------------------------------\n",
      "kinh nghiệm học tăng cường , học giám sát (reinforcement learning , supervised learning)\n",
      "[lợi thế] kiến thức về ros1/ros2\n",
      "làm việc trong môi trường linux\n",
      "khả năng làm việc nhóm và làm việc độc lập tốt.\n",
      "yêu thích/ mong muốn làm về xe tự lái ở việt nam là một lợi thế\n",
      "\n",
      "quyền lợi\n",
      "\n",
      "\n",
      "lương: trợ cấp (2.000.000 – 4.000.000 vnđ).\n",
      "tham gia các hoạt động học tập, đào tạo trong và ngoài công ty.\n",
      "nghỉ thứ 7, chủ nhật + 12 ngày phép/ năm\n",
      "câu lạc bộ và nhiều hoạt động văn hóa – thể thao – nghệ thuật được công ty tài trợ hoặc hỗ trợ.\n",
      "đảm bảo sức khỏe: khám sức khỏe định kỳ, hỗ trợ mua bảo hiểm sức khỏe chất lượng cao…\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/3092/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            1. performance management & analytics:\n",
      "• issue-focus analysis: perform data analytics to identify trends & underlying patterns & provide recommendations to support business decision making.\n",
      "• lead the design and implementation of analytics projects/ data sharing/ analytics exercises within ops division.\n",
      "• advise project owners/managers performance management methods, conduct post-launch evaluation for strategic & critical functional projects and initiatives/process.\n",
      "• conducts kpi assessment for the division and underlying departments.\n",
      "• lead the design and implementation of unit cost model within ops division\n",
      "\n",
      "2. dashboards/ report/ warehouse/ data services:\n",
      "• design, manage & review periodic report/ dashboard (monthly, weekly, daily…) and provide data services to ad-hoc requests to support the division head and stakeholders of the division.\n",
      "• continuously & actively identify areas of potential improvement/ simplification/ automation and implement these changes for dashboards/ reports/ warehouse/ data services to enhance operations & team productivity, capacity.\n",
      "• be the pic from ops team to work with relevant stakeholders (bi center, data analytics & insight, it, etc.) regarding operations data rules, data extraction, data mart.\n",
      "\n",
      "3. team management & development\n",
      "• ensure all team members are motivated, challenged by proper task allocation, talent\n",
      "identification & development, coaching & mentoring, team engagement activities.\n",
      "\n",
      "4. stakeholder management\n",
      "• deliver satisfactory stakeholder management & influencing, maintaining good relationship with other department & divisions: departments in ops, bi center, it, business departments, project management office, finance,…\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2846/data.html\n",
      "mô tả công việc\n",
      "-khảo sát hiện trạng và đánh giá các nhu cầu của các đơn vị/ bộ phận nghiệp vụ về việc khai thác dữ liệu, xây dựng báo cáo; thực hiện tư vấn và phân tích nhu cầu khai thác dữ liệu từ các đơn vị/ bộ phận nghiệp vụ trong ngân hàng; chuyển hóa các yêu cầu nghiệp vụ thành các yêu cầu về dữ liệu, hệ thống và công cụ hỗ trợ khai thác dữ liệu; phối hợp với các đơn vị phát triển, đưa ra kiến trúc khai thác dữ liệu để cung cấp sản phẩm phù hợp cho đơn vị/ bộ phận nghiệp vụ-tìm hiểu, đề xuất các cải tiến nâng cao hiệu quả, rút ngắn thời gian tạo lập báo cáo và truy xuất dữ liệu tại các đơn vị nghiệp vụ trên toàn hàng mà trọng tâm là phát triển kỹ năng tự khai thác dữ liệu (data self-service) tại  khối nghiệp vụ cụ thể.-quản lý danh mục dịch vụ báo cáo, trong đó xác định chủ sở hữu của các báo cáo, đơn vị/ bộ phận nghiệp vụ hiện đang sử dụng các báo cáo, cũng như tần suất, mục đích sử dụng dịch vụ dữ liệu.-phối hợp với các bộ phận phát triển báo cáo quản trị từ đó thu thập thông tin nguồn dữ liệu cho các báo cáo thuộc danh mục quản lý-tìm hiểu và đánh giá, đề xuất giải pháp quản lý tập trung danh mục báo cáo, logic mapping báo cáo.-thu thập nhu cầu về dữ liệu để xây dựng dashboard; thiết kế và phối hợp cùng các đơn vị phát triển để hiện thực hóa các dashboard trên nền tảng dữ liệu tập trung; hỗ trợ các đơn vị sử dụng công cụ bi khai thác dữ liệu từ kho dữ liệu\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "-có kinh nghiệm tối thiểu 01 năm làm việc trong các tổ chức tín dụng, tài chính hoặc ngân hàng;-có kiến thức nền tảng tốt về hệ quản trị cơ sở dữ liệu và mô hình hóa dữ liệu;-sử dụng thành thạo ít nhất một công cụ bi (power bi, tableau) để trực quan hóa dữ liệu;-cẩn thận, tỉ mỉ, làm việc tốt dưới áp lực;-ưu tiên các ứng viên có kinh nghiệm tham gia triển khai các dự án về báo cáo, dữ liệu tại các công ty tài chính/ngân hàng thương mại;-ưu tiên các ứng viên có hiểu biết về phương pháp agile, đã tham gia trong hoạt động thực tế hoạt động theo mô hình scrum team-ưu tiên các ứng viên đã có kinh nghiệm làm ba, phân tích kinh doanh, mis cho phát triển báo cáo tại các ngân hàng/tổ chức tài chính;-có kỹ năng, tư duy lập trình và sử dụng tốt ít nhất một ngôn ngữ lập trình ứng dụng là một lợi thế;-kỹ năng ngôn ngữ và diễn đạt văn bản tốt; sử dụng thành thạo tiếng việt và có khả năng giao tiếp bằng tiếng anh.\n",
      "quyền lợi\n",
      "quyền lợi• thời gian làm việc: t2-t6, nghỉ t7 và cn• lương hấp dẫn (mức lương & thưởng cạnh tranh)• phụ cấp tăng ca, thưởng dự án, thưởng vượt chỉ tiêu, thưởng tháng lương thứ 13,...• được công ty thực hiện đầy đủ nghĩa vụ về bảo hiểm; thai sản, con nhỏ, cưới hỏi, sinh nhật,...• được tham gia các hoạt động teambuilding, du lịch, các hoạt động thể thao, các hoạt động xây dựng tinh thần đồng đội.• định kỳ xét tăng lương 2 lần/năm hoặc đột xuất theo đánh giá.đặc biệt:• thử việc 100% lương• bảo hiểm sức khoẻ mic, chương trình vay ưu đãi đối với cbnv...• thưởng theo kết quả kinh doanh hàng năm của công ty (thường được thưởng 2 tháng lương) .• được cử tham gia các khóa đào tạo mới, đào tạo nâng cao phù hợp với năng lực và nguyện vọng.• môi trường chuyên nghiệp sử dụng phương pháp scrum và agile vào quản lý phát triển sản phẩm\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 30/06/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2212/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "                                    - xây dựng kế hoạch kinh doanh trên cơ sở ngân sách của khối ngân hàng bán lẻ.\n",
      "- xây dựng kế hoạch ngân sách theo nhóm các hạn mục chi phí ( chi phí thương hiệu, chi phí nhân sự, chi phí kinh doanh, chi phí truyền thông,...) từ đó áp dụng các mô hình quản trị doanh thu, chi phí hiệu quả.\n",
      "- quản trị kế hoạch kinh doanh và ngân sách đã xây dựng, bám sát và có kiến nghị kịp thời với hoạt động kinh doanh.\n",
      "- đề xuất, phụ trách, tham gia các dự án nâng cao năng lực/chất lượng dịch vụ quản trị của khối bán lẻ (mis, kpi, cải tiến giao dịch tại quầy…)\n",
      "- tổng hợp tham mưu và quản trị các hạn mục, sáng kiến nằm trong chiến lược bán lẻ.\n",
      "- thực hiện các công việc khác theo yêu cầu của cấp lãnh đạo.\n",
      "                                \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1612/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "hỗ trợ các đơn vị kinh doanh trong việc kiểm soát dữ liệu đầu vào và chuẩn hóa hệ thống dữ liệu hiện tại\n",
      "hỗ trợ các đơn vị kinh doanh trong việc xây dựng các quy tắc chuẩn hóa, so khớp, hợp nhất\n",
      "phụ trách cấu hình lên tool quản lý dữ liệu chủ các quy tắc chuẩn hóa, so khớp, hợp nhất.\n",
      "vận hành và quản trị hệ thống quản lý dữ liệu chủ mdm\n",
      "phụ trách khai thác dữ liệu từ hệ thống quản lý dữ liệu chủ (nếu có)\n",
      "thiết kế các dashboard giám sát cldl dữ liệu chủ\n",
      "báo cáo theo dõi hệ thống định kỳ\n",
      "thực hiện các công việc theo sự phân công của lãnh đạo phòng\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2163/data.html\n",
      "descriptionthe bosch group is a leading global supplier of technology and services. it employs roughly 394,500 associates worldwide (as of december 31, 2020). according to preliminary figures, the company generated sales of 71.6 billion euros in 2020. its operations are divided into four business sectors: mobility solutions, industrial technology, consumer goods, and energy and building technology.the bosch group comprises robert bosch gmbh and its roughly 440 subsidiaries and regional companies in some 60 countries. if its sales and service partners are included, then bosch is represented in roughly 126 locations. this worldwide development, manufacturing, and sales network is the foundation for further growth.rbvh - robert bosch engineering and business solutions vietnam company limited is 100% owned subsidiary of robert bosch gmbh. \n",
      "rbvh has started its operations from 19th october, 2010 at e-town2 in hcmc. this engineering development center will be engaged in developing embedded systems and software, mechanical design and simulation, and will provide it (sap consulting, java development….) and business services (finance and accounting, economics, purchasing, logistics, translations japanese-english-japanese, information security ) solutions to the bosch group of companies globally. job descriptionwork with and coordinate between software development teams in the organizationconvert machine learning (ml) models into apis to enhance their functionalitydesigning ml systems, as well as artificial intelligence (ai) software to automate certain predictive models and tasks.test and deploy ai software and models on embedded deviceskeeping documentation of the ml processes.use ai to empower the organization through r&d projects in the automotive fieldsqualificationsbachelor’s or master's degree in computer science/ computer vision/ mechatronics/ information technology or related fieldstwo or more years of \n",
      "-----------------------------------------------\n",
      "experience in applying ai/ml/computer vision/ nlp to practical and comprehensive technology solutionsexperience with programming languages such as c++, pythonexperience with one of standard ml frameworks such as pytorch, tensorflow, or kerashands-on knowledge of basic ml/dl algorithms, object-oriented programmingproficient at englishpreferred skillsexperience with innovation acceleratorsbasic knowledge in statistics and mathematics, including probability, linear algebraexperience with ai/ml model deploying on embedded systems/ familiarity with cloud computing environments is a plusgood communication and analytical thinking skillsadditional informationjoin a dynamic english-speaking multi-culture working environmentfurthermore, we also offer you internship allowance during the internship program1 day of birthday leave + 1 day of full-paid leave/ per monthmotivating benefits of trade union activities, team building and company tripopportunity to work in global projects of fast developing company and being a part of the innovation team contributing initiative ideas to the hi-tech worldengage\n",
      "================================================\n",
      "data-02-06/2147/data.html\n",
      "================================================\n",
      "data-02-06/2605/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            we are looking for an inspirational, dynamic, and vibrant data analyst to join our forward-thinking admin team that supports core application database (including the isams management system, school buddy, hr system). the candidate is responsible for the overall management and administration to ensure the data integrity of core applications and works closely with the ict team to verify applications availability to minimise operation disruption.\n",
      "\n",
      "who are westlink international school?\n",
      "\n",
      "opening in august 2022, westlink international school (wis) is part of a growing number of schools worldwide owned by the international schools partnership (isp). it benefits from the insights, practices, and resources of a network of 60 schools in 16 countries around the world, to ensure all children \n",
      "-----------------------------------------------\n",
      "experience amazing learning.\n",
      "\n",
      "job description:\n",
      "\n",
      "•\tdata management – responsible for data gathering, processing, ensuring data structures are adequate and report design and administration as required. \n",
      "•\tcore applications development – responsible to work with relevant departments to define requirements for system integration in the schools. working closely with it team and school leaders in isams development plan;liaising with all stakeholders to develop and present the proposed development plan to school leaders.\n",
      "•\ttraining – planning, coordinating, and conducting core applications specific training for teaching and non-teaching staff for the school to maximise the user experience of the system, as necessary.\n",
      "•\tsupport – being the primary contact with isams support; with it team in maintaining users and user accounts, troubleshooting issues to do with the isams system and the use of it.\n",
      "•\treview – monitoring the effectiveness of the isams implementation and adoption and providing feedback regularly for informed planning.\n",
      "•\tother - comply with regional ict hardware and software procurement process and technology standard. accountable to support the implementation of a disaster recovery plan compliant with regional standards. \n",
      "•\tworking with regional it team and management heads to identify process improvement opportunities, propose system modifications, and devise data governance strategies. \n",
      "•\tmaintains a proficient level of knowledge of the data reporting and collection requirements of school leadership team and other requirements including the schools code of conduct\n",
      "•\tticket and escalation management \n",
      "•\tadhere to school, region, group policies and procedures\n",
      "•\tcoordinate with it team (collaboration with it team on daily operation) \n",
      "•\tdocument knowledgebase, change requests, and project resource.\n",
      "•\tflexible with regard to working hours and available on occasion to work outside of normal hours in response to support demands of the school and regional office. \n",
      "•\tactive participation in new infrastructure initiatives that could help our schools improve efficiencies.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "================================================\n",
      "data-02-06/858/data.html\n",
      "description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "view all jobs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "view our website\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about the companyglobal fashion group (gfg) is the leading fashion and lifestyle retail destination in asia pacific, latin america and cis. we connect over 10,000 global, local and own brands to a market of more than one billion consumers through four established e-commerce platforms: the iconic, zalora, dafiti and lamoda.through an inspiring and seamless customer \n",
      "-----------------------------------------------\n",
      "experience enabled by our own technology ecosystem and operational infrastructure, we are setting the benchmark in online fashion & lifestyle in our markets, and our vision is to be the #1 online destination for fashion & lifestyle in growth markets.\n",
      "================================================\n",
      "data-02-06/1838/data.html\n",
      "description: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1901/data.html\n",
      "================================================\n",
      "data-02-06/2559/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description\n",
      "\n",
      "                                                                                            no.269\n",
      "- manage databases throughout various environments for the product lifecycle, from testing to systems that are mission-critical in production.\n",
      "- construct and manage database servers and procedures, including system health and performance monitoring, to ensure high levels of performance, availability, and security.\n",
      "- provide final problem settlement by independently analyzing, resolving, and correcting problems in real time.\n",
      "- work productively in a team setting as well as individually with little supervision.\n",
      "- establish and carry out processes to manage database configuration for the environments in which they operate as well as the databases themselves.\n",
      "- designing and documenting procedures and processes will help other team members handle our database environments consistently.\n",
      "- help the team improve the ability to manage our oracle database infrastructure on oracle cloud by helping to adopt automation methods and technologies.\n",
      "- develop sound judgment and problem-solving abilities to identify problems, offer solutions, and clearly explain those solutions. independently manages another's tasks while working.\n",
      "- proven track record of implementing technologies with broad-reaching effects\n",
      "- execute routine, daily tasks related to data replication, sql tuning, application tuning, creating database objects, and data modeling as a database administrator.\n",
      "- leadership \n",
      "-----------------------------------------------\n",
      "experience in technology that will help with updates and developments\n",
      "- required availability for off-shift employment and rotational on-call duties\n",
      "                                                                                    \n",
      "read full job descriptions\n",
      "================================================\n",
      "data-02-06/2828/data.html\n",
      "mô tả công việc\n",
      " • tham gia dự án thực tế về trong lĩnh vực tài chính, viễn thông, ngân hàng, bảo hiểm, v.v..• vận hành, triển khai các job etl, tổng hợp dữ liệu và xuất dữ liệu theo yêu cầu.• xây dựng & triển khai các hệ thống data warehouse, data mart và data lake cho các dự án thực tế.• tham gia và triển khai các dịch vụ sử dụng các công nghệ bigdata: hadoop, spark, … \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2616/data.html\n",
      "================================================\n",
      "data-02-06/789/data.html\n",
      "description \n",
      "\n",
      "requirements:\n",
      "+ proven \n",
      "-----------------------------------------------\n",
      "experience as a bi developer (industry experience is preferred).\n",
      "+ background in data warehouse design.\n",
      "+ in-depth understanding of database management systems.\n",
      "+ deep knowledge of sql queries,web programming (node js, python is a bonus).\n",
      "+ experience about google bigquery, google bigtable.\n",
      "+ analytical mind with a problem-solving aptitude.\n",
      "qualifications:\n",
      "+ bsc/ba in computer science, engineering or relevant field\n",
      "skills:\n",
      "+ knowledge about database architecture, sql, web programming, linux server.\n",
      "+ ability to take instruction and work to deadlines\n",
      "+ troubleshooting skill, strong logic thinking, solve problems creatively and effectively\n",
      "+ management/leadership\n",
      "+ intermediate english.\n",
      "\n",
      "================================================\n",
      "data-02-06/2535/data.html\n",
      "mô tả công việc\n",
      "- chạy các đầu mục báo cáo, phân tích về danh mục khách hàng - báo cáo các chỉ số tác nghiệp của các team - tham gia phân bổ danh sách khách hàng đến các team - tham gia đề xuất kpis dịch vụ khách hàngvà tính toán tỷ lệ hoàn thành kpis- chịu trách nhiệm báo cáo, phân tích chuyên đề theo định kỳ hoặc theo phát sinh thực tế- hoàn thành các công việc khác theo yêu cầu của quản lý\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "- sử dụng tốt một trong các phần mềm thống kê/ xây dựng mô hình/ quản lý dữ\n",
      "================================================\n",
      "data-02-06/646/data.html\n",
      "mô tả công việc\n",
      "\n",
      "1. nhận chỉ tiêu bán hàng của công ty, lên kế hoạch thúc đẩy doanh thu, triển khai thực hiện đảm bảo đạt chỉ tiêu được giao.\n",
      "2. đào tạo, hướng dẫn các chính sách chương trình của acs tới các đại lý, nhân viên đại lý hợp tác với acs việt nam.\n",
      "3. lên lịch đi tuyến hàng tuần đến các đại lý để chăm sóc, trao đổi, nắm bắt các thông tin bán hàng tại đại lý kịp thời.\n",
      "4. tìm kiếm và phát triển thị trường, mở mới các đại lý phù hợp để mở rộng hợp tác.\n",
      "5. hỗ trợ đại lý xử lý các vấn đề liên quan đến chương trình, chính sách của acs.\n",
      "6. triển khai trưng bày hình ảnh posm của acs trong đại lý.\n",
      "7. sắp xếp lịch làm việc cho nhân viên tư vấn, giám sát việc hoàn thành chỉ tiêu được giao. hỗ trợ nhân viên xử lý các vướng mắc trong công việc.\n",
      "8. báo cáo kết quả bán hàng hàng tuần, hàng tháng và các vấn đề tại thị trường, chính sách của đối thủ cho cấp trên. tìm hiểu và báo cáo nguyên nhân\n",
      "dẫn đến doanh số giảm/tăng, đề xuất giải pháp khắc phục.\n",
      "9. tìm hiểu chương trình, kế hoạch của đối thủ cạnh tranh\n",
      "10. thực hiện các công việc khác được cấp trên giao.\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "1.tuân thủ đúng các quy định của công ty\n",
      "2. quản lý nhân viên\n",
      "3. triển khai chính xác chương trình, chính sách tới các đối tác hợp tác .\n",
      "4. hoàn thành chỉ tiêu doanh thu được giao.\n",
      "- giới tính: nam, nữ (ưu tiêu nam)\n",
      "- tuổi: < 35\n",
      "\n",
      "================================================\n",
      "data-02-06/360/data.html\n",
      "responsibilities\n",
      "ensure smooth setup of pre-trade processes\n",
      "monitoring daily live trading for various financial instruments/markets\n",
      "perform risk management for portfolio trading activities\n",
      "provide insight/analysis of the trading behaviors and portfolio performance\n",
      "improve the trade monitoring and operation process\n",
      "requirements\n",
      "knowledge of the financial markets and trading\n",
      "proficient in python, bash, sql\n",
      "sharp-minded with the ability to think ahead for potential problems\n",
      "advanced analytic and problem-solving skills\n",
      "quick learner with attention to details\n",
      "good communication skills and teamwork spirit\n",
      "\n",
      "** the following are bonuses\n",
      "\n",
      "linux \n",
      "-----------------------------------------------\n",
      "experience\n",
      "knowledge/experience in risk management and portfolio management\n",
      "benefitssalary range: up to usd 2,000 gros\n",
      "================================================\n",
      "data-02-06/2141/data.html\n",
      "description\n",
      "\n",
      "participating in asilla's products and building projects in the computer vision sector using deep learning technology. asilla's products are the core technology in video analysis, including anomaly detection and multiple-camera tracking.specifically:\n",
      "building deep learning, machine learning models in action recognition, and video analysis.\n",
      "analyzing and processing images and video data to prepare for the training process.\n",
      "integrating ai models into application systems.\n",
      "optimizing the performance of the application systems.\n",
      "\n",
      "\n",
      "your skills and \n",
      "-----------------------------------------------\n",
      "experience\n",
      "\n",
      "\n",
      "university degree in it or equivalent.\n",
      "proficient with frameworks: pytorch, tensorflow\n",
      "proficient in python, c/c++ programming languages\n",
      "at least 2,5 years of experience working as an ai engineer, ai researcher, or data scientist position.\n",
      "experience working with jetson nvidia devices is a plus.\n",
      "good logical thinking skills, hard working and responsible at work.\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "\n",
      "competitive salary: up to $2500\n",
      "14 months' salary a year\n",
      "opportunity to receive bonus shares.\n",
      "to fully participate in the regimes prescribed by the state such as social insurance, health insurance, unemployment insurance, and annual leave.\n",
      "be trained and work directly with experienced experts in the field of ai.\n",
      "have the opportunity to do challenging things, develop your full potential\n",
      "participate in team building, travel 2-3 times/year.\n",
      "enjoy full benefits (happiness, birthday...);\n",
      "young, comfortable working environment, dynamic startup spirit.\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2722/data.html\n",
      "mô tả công việc\n",
      "- phân tích các yêu cầu chức năng và tạo lên phương án kỹ thuật cho sản phẩm; - lập kế hoạch và điều phối nguồn lực kỹ thuật triển khai; - hướng dẫn triển khai kỹ thuật và đào tạo cho thành viên trong nhóm; - luôn cập nhật các công nghệ mới; - xử lý các vấn đề kỹ thuật và các vấn đề phát sinh trong quá trình triển khai kỹ thuật.- báo cáo công việc, tiến độ với trưởng phòng/cấp trên.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "- có kiến thức về ai/bigdata. kinh nghiệm trên 2 năm- bằng cử nhân hoặc thạc sĩ về khoa học máy tính, kỹ thuật phần mềm hoặc công nghệ thông tin.- hơn 2 năm kinh nghiệm trong các lĩnh vực ai/ml, bigdata.- đã từng thiết kế và triển khai một hệ thống ai hoàn chỉnh từ thu thập dữ liệu đến đào tạo.- kinh nghiệm thực tế trong việc xây dựng, khắc phục sự cố và cung cấp các mô hình ai/ml, bigdata- thành thạo python và các thuật toán tensorflow\n",
      "quyền lợi\n",
      "- lương được xem xét, đánh giá tăng định kỳ một năm 2 lần.- thưởng cuối năm và thưởng các ngày lễ tết.- thời gian làm việc: từ 8h00 - 17h00 (nghỉ trưa 1 tiếng) - từ thứ 2 đến thứ 6\n",
      "================================================\n",
      "data-02-06/2089/data.html\n",
      "================================================\n",
      "data-02-06/2328/data.html\n",
      "description\n",
      "\n",
      "• provide leadership and guidance to coach, motivate, and lead team members to their optimum performance levels and career development.• work closely with other engineers to develop new products• work on extensions of existing products• suggest and implement improvements on current products• plan, design, develop, manage, document, test, deploy, and support new and existing modules• resolve issues proactively to deliver high quality products\n",
      "\n",
      "your skills and \n",
      "-----------------------------------------------\n",
      "experience\n",
      "\n",
      "• strong postgres experience• maintain and modify existing data sets, data loads, documentation, policies, procedures, and other data solutions• create, design, and develop data models for multiple applications• design and implement etl procedures for intake of data from multiple applications in data warehouse• carry out monitoring, tuning, and database performance analysis• design, implement and maintain analytics and business intelligence platform architecture for data warehouse• perform the design and extension of data marts, meta data, and data models• prepare various code designs and ensure efficient implementation of the same• evaluate all codes and ensure the quality of all project deliverables• knowledge of shell scripting is a plus\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "panasonic r&d center vietnam was established in april 2007, is a company specializing in r&d of panasonic group in vietnam with the aim of enhancing r&d activities in the field of digital home appliances, automation, mobility in vietnam, providing r&d services for software solutions in today's hottest fields such as ai, cloud, iot in a chain of r&d centers of worldwide corporations\n",
      "================================================\n",
      "data-02-06/3125/data.html\n",
      "================================================\n",
      "data-02-06/2723/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "• research and develop ai/deep learning/machine learning applications for various business (automotive, security, iot, … etc).• experience in development and optimization of ai/deep learning/machine learning into embedded system such as jetson tx board, fpga board, arm board, dsp board is a big plus.• experience a professional environment with diverse projects\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "• vietnamese nationality.• last year of university/university.• good programming skill in one of languages c/c++/python.• familiar with computer vision/machine learning/deep learning or graphic programming (2d & 3d, opengl, pointcloud, etc)• experiences with common frameworks (opencv, caffe, tensor flow, etc).• software design skill (uml, object oriented design) is a plus\n",
      "quyền lợi\n",
      "1. career path developmentclearly defined long-term multi-career roadmap;unlimited development & training opportunities (language training, technical training, soft-skill training, on-job training, etc.)oversea business trips (japan, china, singapore, us, mexico, eu, etc.)2. work-life balanceflexible working time that supports work-life balance (core time: 9:00-16:00; 5 days from monday - friday/ week)flexible lunch time;additional special holiday3. wellnesswell-protected with 24/7 personal accident and medical care insurance;well-designed annual health check-up program;4. activitiesteam-building activities; birthday party; year-end party; sport day/ family daysummer vacation (trip to famous tourist spots domestic/ overseas,…)5. cash benefitsattractive and competitive salary & bonus package depend on abilities, performance and competenciesdiversified allowance scheme6. physical environmentgrade a office with creative workplace and open space.well-equipped facilities/ devices and professional working platforms. application submission\n",
      "cách thức ứng tuyển\n",
      "\n",
      "hết hạn nộp đơn\n",
      "\n",
      "================================================\n",
      "data-02-06/2954/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- nhập và theo dõi, thống kê tất cả các số liệu về hàng hóa, sản phẩm, các số liệu phát sinh trong từng khâu sản xuất  - tổng hợp số lượng hàng hóa nhập xuất, hàng tồn kho theo mỗi ngày và tổng hợp cả trong tháng  - đảm bảo sự trung thực về các khía cạnh kế toán, số liệu được thực hiện chính xác, cập nhật và đúng hạn  - làm báo cáo sản xuất hàng ngày, tháng. - thống kê (hàng ngày) chi tiết tất cả các số liệu đầu vào quá trình sản xuất phát sinh như: nguyên phụ liệu, thứ phẩm tái chế, tất cả các thành phẩm nhập kho… từ đó kiểm tra định mức sử dụng, tỷ lệ hao hụt… - thực hiện báo cáo tổng kết các số liệu đã được thống kê, theo dõi và ghi lại sự cố bất thường tại nhà máy; theo dõi đôn đốc tiến độ sản xuất và giao hàng* quyền lợi- xem xét tăng lương hàng năm. - phúc lợi: quy định của công ty (lễ/tết/bảo hiểm 24/7) - được tạo điều kiện phát huy năng lực bản thân và cơ hội thăng tiến lên các vị trí quản lý cao hơn.\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1927/data.html\n",
      "================================================\n",
      "data-02-06/1983/data.html\n",
      "mô tả công việc\n",
      " - responsible for developing business insights and trends using data visualization techniques and tools such as dashboards and reports- data exploration and preparation, data collection and integration to facilitate data analysis- developing data models for the purpose of data analysis- because ssi is still building up its data analytic practice, the role must also cover the related roles of data engineer at times.- this role would be suitable for someone who is already working with data with future ambitions of becoming a data scientist- for the data science roleidentifying relevant data sources for business needs- collecting structured and unstructured data- sourcing missing data- organizing data into usable formats- building predictive models- building machine learning algorithms- enhancing the data collection process- processing, cleansing & verifying of data- analysing data for trends and patterns and to find answers to specific questions- setting up data infrastructure- develop, implement and maintain databases- assess quality of data and remove or clean data- generating information and insights from data sets and identifying trends and patterns- preparing reports for executive and project teams- create visualisations of data \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3021/data.html\n",
      "chi tiết công việc data scientist tại công ty cổ phần galaxy pla\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2397/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- finance partnering activities including analysis involving- performance analysis and reporting including reporting of customer analysis/trends and dhl’s fleets & network- ensure the compliance with group finance and accounting policies and reporting deadlines- weekly validate invoices for payment purpose- prepare monthly accrual revenue, cost - support ccm in p&l review - ensure compliance with the company policies.- ensure complete the tasks accurately and timely. - other tasks to support finance team if any- being finance partner for other departments. - maintain an effective interface with other functions, operations.-  proactive in learning and sharing knowledge with other team member to build a strong finance team.\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1314/data.html\n",
      "================================================\n",
      "data-02-06/2517/data.html\n",
      "description\n",
      "enabled\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sap as service provider\n",
      "we use the following session cookies, which are all required to enable the website to function:\"route\" is used for session stickiness\"careersitecompanyid\" is used to send the request to the correct data center\"jsessionid\" is placed on the visitor's device during the session so the server can identify the visitor\"load balancer cookie\" (actual cookie name may vary)  prevents a visitor from bouncing from one instance to another\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2787/data.html\n",
      "description\n",
      "\n",
      "\n",
      "take the initiative to organize business unit within the organization to gather and combine the necessary business-related data.\n",
      "use data to analyze, assess, and pinpoint areas for improvement in the present business processes.\n",
      "collaborate with other teams to meet business requirements.\n",
      "define specific business requirements and work with the appropriate data team members to translate these into technological requirements.\n",
      "verifying provided data schema.\n",
      "doing data extraction, transformation as carpla’s standards\n",
      "extracting, transforming, and onboarding data\n",
      "data analysis and quality assurance for your product\n",
      "leading, guiding, mentoring other team members\n",
      "\n",
      "\n",
      "your skills and experience\n",
      "\n",
      "\n",
      "bachelor’s degree in engineering, computer science (or equivalent experience)\n",
      "at least 6 months of relevant experience as a data analysis\n",
      "3+ years of experience working as business analyst\n",
      "in-depth knowledge of car domain is nice to have.\n",
      "extensive experience working with data analytics and related technologies.\n",
      "demonstrable experience and skills with ms excel and ms powerpoint\n",
      "thorough knowledge of the relevant business units \n",
      "basic knowledge of data management issues\n",
      "significant data quality and metadata management expertise\n",
      "some familiarity with product and project management is desirable.\n",
      "nice to have prior fintech experience.\n",
      "in-depth knowledge of sql (complex join, subqueries, unions,e.g…) and powerbi is nice to have\n",
      "excellent understanding of business architecture ideas and how they're used.\n",
      "excellent written english communication skills\n",
      "ability to move fast and be efficient, making decisions on objective data evidence.\n",
      "ability to work independently.\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "thu nhập- gói thu nhập 14-16 tháng lương/ năm- xét tăng lương theo năng lực và kết quả công việc định kỳ 1 lần/ năm hoặc tăng lương đột xuất theo hiệu quả công việcbảo hiểm và chính sách phúc lợi- chế độ bảo hiểm sức khỏe cho bản thân và người nhà- nghỉ thứ bảy, chủ nhật hàng tuần- du lịch, teambuilding/ dã ngoại định kỳ hàng năm- chế độ mừng sinh con, quà nhân ngày lễ/ tết, quà ngày truyền thống và các chế độ phúc lợi khácchế độ đào tạo- tham gia các khóa đào tạo chuyên môn, nâng cao kỹ năng thực hiện công việc, kỹ năng mềm và thi các chứng chỉ cntt quốc tế miễn phí tại công ty- được tham gia các chương trình đào tạo trước khi bắt đầu công việc và trong quá trình làm việc theo \n",
      "-----------------------------------------------\n",
      "yêu cầu công việc- chính sách phát triển, thăng tiến có lộ trình theo từng vị trí, từng phòng ban- cơ hội tiếp cận với các công nghệ mới nhất: cloud, big data…môi trường làm việc- tham gia các câu lạc bộ của công ty: clb bóng đá, chạy bộ, yoga, gym…- được trang bị laptop, các thiết bị công nghệ hiện đại trong quá trình làm việc- môi trường làm việc hiện đại, năng động, khuyến khích tối đa sự sáng tạo của nhân viên- văn phòng làm việc hạng a, không gian mở, tiêu chuẩn 5 sao\n",
      "\n",
      "================================================\n",
      "data-02-06/2589/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "job descriptionthis role will be responsible for taking business needs from business units and analyzing relevant data to develop answers for the needs or find interesting data trends that could bring business value.take ownership of the data governance project and work with cross departments to facilitate and initiate data solutions.we are building an office in kuala lumpur, malaysia. we prioritize recruiting vietnamese candidates willing to relocate to malaysia with attractive salary offers.work location 1: kuala lumpur, malaysiawork location 2: hanoi, vietnam responsibilities- responsible for developing business insights and trends using data visualization techniques and tools such as dashboards and reports- data exploration and preparation, data collection and integration to facilitate data analysis to solve business problems- developing data models for data analysis- take ownership and lead data projects with internal teams- this role would be suitable for someone who is already working with data with future ambitions of becoming a data scientist- generating information and insights from data sets and identifying trends and patterns- (if possible) building predictive models and handling other advance task\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "requirements- from 2-year experience as a data analyst- fluent in writing & speaking english- familiar with databases & cloud storage (google bigquery, snowflake…)- familiar with visualization tools (tableau, powerbi, looker…)- master of sql and python- having experience in 2 domains (mobile application) and (financial investment) is a great advantage- understand the data needs of different departments (marketing, product, finance…)- understand the scopes of data engineers, data scientists to collaborate and take the lead if needed- have a robust problem-solving mindset. be able to turn a simple question to become a comprehensive data dashboard that detects and solves a business problem- good communication skills. be able to deliver, present and explain the results in an effective way for both technical and non-technical parties\n",
      "quyền lợi\n",
      "benefits- competitive salary with annual salary reviewwork in malaysia: up to 2000 usd with allowanceswork in vietnam: up to 900 usd- an international working environment with friendly, creative colleagues from around the world- an excellent opportunity to grow your career. we encourage you to take the lead, initiate and make decisions- tuition fee sponsorship if you expect to become a data scientist or grow other data skills- enjoy birthday parties and frequent weekend parties and other team-building activities (depending on your work location)\n",
      "cách thức ứng tuyển\n",
      "\n",
      "hết hạn nộp đơn\n",
      "\n",
      "================================================\n",
      "data-02-06/1508/data.html\n",
      "================================================\n",
      "data-02-06/1565/data.html\n",
      "responsibilities\n",
      "requirements\n",
      "what we offer\n",
      "about us\n",
      "additional inforesponsibilities\n",
      "\n",
      "\n",
      "\n",
      "ml system operation (mlops):\n",
      "\n",
      "integrate ml models and ensure consistency in model interfaces and interaction as per product requirements\n",
      "monitor and optimize system performance and resource consumption\n",
      "manage development servers and environments\n",
      "communicate with product team, infrastructure team, engineering team, and data science team to ensure consistency in requirement, development, integration, and deployment\n",
      "optimize and deploy \"tiny\" ml solutions on limited computation power devices such as mobile devices and web platforms\n",
      "\n",
      "ml model development (data science):\n",
      "\n",
      "build ekyc components (fraud detection, face recognition, ocr, object detection), using state-of-the-art methods in computer vision\n",
      "develop computer vision models and provide solutions for acquisition, verification, validation, and fraud detection of user data\n",
      "\n",
      "requirements\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bs or ms in computer science, statistics, mathematics, or related fields\n",
      "3+ years of \n",
      "-----------------------------------------------\n",
      "experience in data science and mlops\n",
      "great communication skills\n",
      "desired engineering skills:\n",
      "================================================\n",
      "data-02-06/2644/data.html\n",
      "description:\n",
      "i. responsibilities\n",
      "– manage master data, including creation, updates, and deletion.\n",
      "– assess the effectiveness and accuracy of data tables in our distributed system.\n",
      "– support the datamart in identifying and revising reporting requirements.\n",
      "– provide quality assurance on the quality and accuracy of data tables.\n",
      "– help develop reports and analysis.\n",
      "– support business analyst by preparing ad-hoc complicated/customized data tables.\n",
      "– serve as an advocate of our data-driven culture.\n",
      "– work with other members (data engineer, business analyst) to implement, integrate and optimize our existing systems.\n",
      "ii. requirements\n",
      "– have bachelor degree in information systems, information management or information technology.\n",
      "– demonstrate competency in handling large data set and relational databases.\n",
      "– have \n",
      "-----------------------------------------------\n",
      "experience in scripting with sql, spark, r/ python.\n",
      "– possess logical thinking, detail-oriented, strong organizational skills, ability to multi-task and work independently under tight deadlines.\n",
      "– work experience as a data analyst is a plus.\n",
      "– work experience in working with distributed system is a plus.\n",
      "iii. benefits \n",
      "– competitive salary: up to $650/month (junior) or upto $2000/month (senior)\n",
      "(negotiable, and periodically reviewed based on your capacity).\n",
      "– truly cares about you and your experience at ghtk – rewards and promotions are available on special occasions.\n",
      "– attractive insurance package – you will be provided with a package of generali premium health insurance, along with other benefits in accordance with vietnam labour law: health insurance, social insurance,…\n",
      "– special and worthy welfare regimes – there are 12 days off per year, 13th-month salary, yearly kick-off & team-building events with various bonding activities at workplace.\n",
      "– amazing culture – our working environment is young and dynamic with many promotion opportunities, creating a sustainable career path.\n",
      "– opportunity to work with the best – we not only hire talents but also collaborative ones.\n",
      "– get maximum support to master operations knowledge with additional leadership skills to meet the job’s requirements.\n",
      "– be empowered, self-determined, and have enough space for self-development in a typical e-logistics environment.\n",
      "iv. other information\n",
      "– time of work: 9:00 am – 6:30 pm. from monday to friday and alternate saturdays.\n",
      "– address: ghtk building, 8 pham hung street, me tri ward, nam tu liem district, ha noi.\n",
      "v. how to apply\n",
      "– to apply for the data analyst position, please send us your cv to email: talent.acquisition@ghtk.co.\n",
      "– subject: da – your name.\n",
      "================================================\n",
      "data-02-06/2615/data.html\n",
      "================================================\n",
      "data-02-06/3122/data.html\n",
      "description\n",
      "\n",
      "\n",
      "team and role introduction: strategic and planning (snp) is one of the key drivers to the success of category execution, campaigns, traffic mechanics, and thereby business target. the role will provide standardized methodology, data reports and insights to commercial teams to realize growth opportunities, address potential setbacks while fostering effective daily operations. responsibilities: • working closely with snp lead to review commercial performances, analyze key impacting factors & deep dive potential areas for growth. • building and maintaining automated dashboards for performance tracking & analysis serving categories’ demand. • owning & managing performances of selected products/ functional areas. this may include but not limited to: deal hunting, assortment building, pricing strategy, tools adoption & investments. • coordinating with multiple internal stakeholders to effectively plan & execute periodic project/ campaign operations • ad-hoc data analysis & powerpoint presentation duties or other responsibilities as required • types of projects include: seller segmentation, seller/user acquisition & retention, reporting standardization, a/b testing & experimentation analysis for optimization. \n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "job requirements\n",
      "\n",
      "\n",
      "requirements/qualifications(must have): • qualifications in business administration/marketing/computer science. • have passion for data analytics, research or project management. • ability to organize & analyze large amount of data to arrive at actionable insights. • effective spoken and written communication skills (both english and vietnamese) with ability to manage multiple stakeholders’ expectations. • experience in excel & power point is required. • experience writing custom queries in sql or other sql-based languages is a plus. • willing and eager to learn. ability to adapt in a fast-moving environment in cross functional and cross-cultural teams. • strong ownership & self-motivated\n",
      "\n",
      "================================================\n",
      "data-02-06/833/data.html\n",
      "================================================\n",
      "data-02-06/1836/data.html\n",
      "description: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2291/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responsibilities: \n",
      "lead the effort to communicate state of the business to stakeholders regularly - enable audiences to understand the reasons behind the trends - and provide insights to drive strategic decisions.\n",
      "conduct exploratory analysis - go deep into the data to develop hypotheses and to answer complex business questions\n",
      "develop tools and automated processes that project the work out to a broader audience. strategize on democratizing data and insights to make analyses easily repeatable and generalizable by other team members in the future\n",
      "ownership of conceptualizing, developing, and maintaining dashboards, visualizations\n",
      "develop analytics frameworks and foundations to enable easy actionable insights and reliable measurement\n",
      "become a data expert in your business domain and own data quality\n",
      "empower the team to answer data questions quickly and easily by building high-quality ground truth data sets\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2380/data.html\n",
      "mô tả công việc:\n",
      "\n",
      "lập trình giao diện dashboard, trực quan hóa dữ liệu, xây dựng báo cáo (trên nền tảng siemens xhq)\n",
      "xây dựng các biễu mẫu báo cáo reporting trên nền tảng microsoft\n",
      "xác định và trình bày các đề xuất để trình bày dữ liệu trực quan dựa trên nhu cầu phân tích dữ liệu của dự án\n",
      "\n",
      "3. yêu cầu:\n",
      "\n",
      "tốt nghiệp chuyên ngành điện - tự động hoá, công nghệ thông tin, cơ điện tử, hoặc các ngành kỹ thuật khác. ưu tiên các trường/ ngành nền tảng it-ot\n",
      "đã có kiến thức/ \n",
      "-----------------------------------------------\n",
      "kinh nghiệm trong việc xây dựng các dashboard, trực quan hóa báo cáo sử dụng các phần mềm khác nhau như: microsoft power bi, tableau, google data studio, google analytics, …\n",
      "kiến thức về các giải pháp phân tích phổ biến như business intelligence và data warehousing\n",
      "có kinh nghiệm về sql queries để xây dựng bộ dữ liệu (dataset)\n",
      "kĩ năng đọc tài liệu tiếng anh và làm việc nhóm.\n",
      "kĩ năng xử lý vấn đề.\n",
      "\n",
      "chấp nhận sinh viên mới ra trường có nền tảng theo yêu cầu\n",
      "4. quyền lợi\n",
      "\n",
      "mức lương: thoả thuận theo năng lực\n",
      "môi trường làm việc đam mê, năng động, sáng tạo, hoà đồng\n",
      "chế độ đãi ngộ tốt\n",
      "thực hiện chế độ theo quy định nhà nước ngay khi kết thúc 02 tháng thử việc.\n",
      "đóng bhxh theo quy định nhà nước\n",
      "thưởng quý,\n",
      "================================================\n",
      "data-02-06/612/data.html\n",
      "description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "view all jobs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "view our website\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about the companyglobal fashion group (gfg) is the leading fashion and lifestyle retail destination in asia pacific, latin america and cis. we connect over 10,000 global, local and own brands to a market of more than one billion consumers through four established e-commerce platforms: the iconic, zalora, dafiti and lamoda.through an inspiring and seamless customer \n",
      "-----------------------------------------------\n",
      "experience enabled by our own technology ecosystem and operational infrastructure, we are setting the benchmark in online fashion & lifestyle in our markets, and our vision is to be the #1 online destination for fashion & lifestyle in growth markets.\n",
      "================================================\n",
      "data-02-06/2140/data.html\n",
      "mô tả công việc\n",
      "•\tkhảo sát hiện trạng và đánh giá các nhu cầu của các đơn vị/ bộ phận nghiệp vụ về việc khai thác dữ liệu, xây dựng báo cáo; thực hiện tư vấn và phân tích nhu cầu khai thác dữ liệu từ các đơn vị/ bộ phận nghiệp vụ trong ngân hàng; chuyển hóa các yêu cầu nghiệp vụ thành các yêu cầu về dữ liệu, hệ thống và công cụ hỗ trợ khai thác dữ liệu; phối hợp với các đơn vị phát triển, đưa ra kiến trúc khai thác dữ liệu để cung cấp sản phẩm phù hợp cho đơn vị/ bộ phận nghiệp vụ\n",
      "•\ttìm hiểu, đề xuất các cải tiến nâng cao hiệu quả, rút ngắn thời gian tạo lập báo cáo và truy xuất dữ liệu tại các đơn vị nghiệp vụ trên toàn hàng mà trọng tâm là phát triển kỹ năng tự khai thác dữ liệu (data self-service) tại  khối nghiệp vụ cụ thể. \n",
      "•\tquản lý danh mục dịch vụ báo cáo, trong đó xác định chủ sở hữu của các báo cáo, đơn vị/ bộ phận nghiệp vụ hiện đang sử dụng các báo cáo, cũng như tần suất, mục đích sử dụng dịch vụ dữ liệu.\n",
      "•\tphối hợp với các bộ phận phát triển báo cáo quản trị từ đó thu thập thông tin nguồn dữ liệu cho các báo cáo thuộc danh mục quản lý\n",
      "•\ttìm hiểu và đánh giá, đề xuất giải pháp quản lý tập trung danh mục báo cáo, logic mapping báo cáo.\n",
      "•\tthu thập nhu cầu về dữ liệu để xây dựng dashboard; thiết kế và phối hợp cùng các đơn vị phát triển để hiện thực hóa các dashboard trên nền tảng dữ liệu tập trung; hỗ trợ các đơn vị sử dụng công cụ bi khai thác dữ liệu từ kho dữ liệu\n",
      "\n",
      "những quyền lợi hấp dẫn khi gia nhập:\n",
      "- nghỉ lễ, nghỉ phép, nghỉ ốm theo quy định\n",
      "- nghỉ sinh nhật\n",
      "- bảo hiểm sức khỏe\n",
      "- lương tháng 13, thưởng tài chính hàng năm\n",
      "- chế độ gắn kết nhân viên (company team building, workshop, events…)\n",
      "- chế độ đào tạo hấp dẫn theo chức danh, theo chương trình của công ty và tập đoàn\n",
      "                                                                                   \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1505/data.html\n",
      "mô tả công việc\n",
      "\n",
      "xây dựng, phát triển các hệ thống lưu trữ, xử lý dữ liệu lớn (big data)xây dựng các giải pháp etl có khả năng mở rộng linh hoạt với độ tin cậy cao, phục vụ cho việc khai thác/ ingest các loại dữ liệu (cấu trúc, lưu lượng, tốc độ) từ nhiều nguồn khác nhauxây dựng, phát triển các công cụ khai thác dữ liệu, quản trị dữ liệuthiết kế chi tiết giải pháp cho các luồng thu thập, chuẩn hóa, làm sạch, làm giàu, lưu trữ, xử lý, phân tích và hiển thị dữ liệu lớnthiết kế chi tiết giải pháp cho các luồng thu thập, chuẩn hóa, làm sạch, làm giàu, lưu trữ, xử lý,phân tích và hiển thị dữ liệu lớnphối hợp, hỗ trợ data scientist trong việc chuyển đổi các mô hình, thuật toán học máy, khai phá dữ liệu thành các bản đặc tả, thiết kế phần mềm đảm bảo chúng có thể được cài đặt, triển khai hiệu quả trên môi trường tính toán phân tán và có khả năng mở rộng tốt khi tập dữ liệu đầu vào tăng trưởng nhanhthiết kế giải pháp và trực tiếp phát triển các module, thư viện có tính chất nền tảng, có khả năng tái sử dụng cao, ảnh hưởng diện rộng\n",
      "\n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2562/data.html\n",
      "descriptions\n",
      "\n",
      "be responsible for strategizing and performing project management techniques to enhance business performance, works closely with stakeholders to perform business partnering, supporting, coordinating & advising\n",
      "comprehend the company r&r structure and collaborate with relevant teams.\n",
      "define, develop and implement the efficient business processes.\n",
      "follow up kpi tracking, measure & feedback\n",
      "analyze corporate & business situations as well as propose solution recommendations to make improvements;\n",
      "plan, design and implement an overall risk management process, prepare alternative options & action plans to decrease risk factors; propose recommendations to optimize company resources & work efficiency.\n",
      "using data for strategic planning, build up reporting system and management dashboard.\n",
      "\n",
      "ii. skill and experience\n",
      "\n",
      "bachelor‘s degree or above in business, finance, or economics or related fields;\n",
      "experiences in corporate development, business partnering, prioritize in the e-commerce or related industry.\n",
      "a deep understanding of business models, market and industry trends affecting the collaboration and productivity sector;\n",
      "excellent in researching, qualitative & quantitative analytical skills;\n",
      "ability to develop trusted relationships externally and internally;\n",
      "be scrappy and an effective cross-functional collaborator;\n",
      "a self-starter who has worked in a fast-paced, quickly evolving environment with multiple partners;\n",
      "have strong presentation and communication skills and the ability to change complex issues into structured frameworks and concrete plans.\n",
      "\n",
      "key competences\n",
      "\n",
      "have strong communication and interpersonal skills;\n",
      "have the ability to analyze business issues and deliver logical conclusions;\n",
      "familiar with data consolidation, process analysis & strategic planning;\n",
      "problem - solving;\n",
      "conflict resolution;\n",
      "hunger for knowledge & strive for continuous improvement.\n",
      "\n",
      "iii. why you will love joining us?\n",
      "for you to join\n",
      "\n",
      "\n",
      "\n",
      "financial well-being: a competitive salary with 13th month salary, annual performance bonus and a variety of allowances.\n",
      "\n",
      "\n",
      "salary review: annually or on excellent performance.\n",
      "\n",
      "\n",
      "activities: company trips, team-building, and other customized monthly bonding events.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "annual leaves: 16 days off and 01 birthday leave per year.\n",
      "\n",
      "\n",
      "healthcare: annual health check, insurance according to labor law and extra pti insurance package.\n",
      "\n",
      "\n",
      "working environment: dynamic, friendly environments with working time flexibility (mon-fri), and other perks include snacks, coffee, and healthy food provided daily suited for hardworking, fun, and team collaboration.\n",
      "\n",
      "\n",
      "for you to grow\n",
      "\n",
      "\n",
      "ambition: we are now keeping on with our hyper growth to multicategory, multichannel, multimarket, and expanding into the world largest e-commerce enabler. hence, there will continuously be opportunities to challenge yourself, learn new skills and knowledge. \n",
      "\n",
      "\n",
      "challenges: your voice can always be heard as we embrace the eagerness of learning and sharing. you can be your own boss and create your own value with the ability to take initiative and make decisions in all aspects of work.\n",
      "\n",
      "\n",
      "chances: be led and coached by experienced and inspirational leaders and participate in various training courses where you can enlarge your knowledge and experience in the e-commerce and supply chain industry.\n",
      "\n",
      "\n",
      "for you to stay\n",
      "\n",
      "\n",
      "people: having a headquarter in the us and an operation office in vietnam, our team is young and highly motivated. you will be working with and alongside members having experiences from international corporations or high profile from vietnam that share the same passion and dedication.\n",
      "\n",
      "\n",
      "culture: our working environment is humble, collaborative and 100% healthy. we promote exchange & speak out, you can receive transparent and supportive feedback so you can perform the best.\n",
      "\n",
      "\n",
      "career path: provide you a great career path, open to rotating for your better understanding of the company and contribute across many of our functions.\n",
      "\n",
      "\n",
      "and much more, join us and let yourself explore other fantastic things!\n",
      "\n",
      "-----------------------------------------------\n",
      "experience in the e-commerce industry.\n",
      "we are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\n",
      "i. job descriptions\n",
      "\n",
      "be responsible for strategizing and performing project management techniques to enhance business performance, works closely with stakeholders to perform business partnering, supporting, coordinating & advising\n",
      "comprehend the company r&r structure and collaborate with relevant teams.\n",
      "define, develop and implement the efficient business processes.\n",
      "follow up kpi tracking, measure & feedback\n",
      "analyze corporate & business situations as well as propose solution recommendations to make improvements;\n",
      "plan, design and implement an overall risk management process, prepare alternative options & action plans to decrease risk factors; propose recommendations to optimize company resources & work efficiency.\n",
      "using data for strategic planning, build up reporting system and management dashboard.\n",
      "\n",
      "ii. skill and experience\n",
      "\n",
      "bachelor‘s degree or above in business, finance, or economics or related fields;\n",
      "experiences in corporate development, business partnering, prioritize in the e-commerce or related industry.\n",
      "a deep understanding of business models, market and industry trends affecting the collaboration and productivity sector;\n",
      "excellent in researching, qualitative & quantitative analytical skills;\n",
      "ability to develop trusted relationships externally and internally;\n",
      "be scrappy and an effective cross-functional collaborator;\n",
      "a self-starter who has worked in a fast-paced, quickly evolving environment with multiple partners;\n",
      "have strong presentation and communication skills and the ability to change complex issues into structured frameworks and concrete plans.\n",
      "\n",
      "key competences\n",
      "\n",
      "have strong communication and interpersonal skills;\n",
      "have the ability to analyze business issues and deliver logical conclusions;\n",
      "familiar with data consolidation, process analysis & strategic planning;\n",
      "problem - solving;\n",
      "conflict resolution;\n",
      "hunger for knowledge & strive for continuous improvement.\n",
      "\n",
      "iii. why you will love joining us?\n",
      "for you to join\n",
      "\n",
      "\n",
      "\n",
      "financial well-being:\n",
      "================================================\n",
      "data-02-06/2732/data.html\n",
      "================================================\n",
      "data-02-06/2982/data.html\n",
      "================================================\n",
      "data-02-06/2371/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "skills required\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "details\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "làm việc tại trụ sở chính của công ty tại yokohama, hoặc trung tâm phát triển yokohama, hoặc văn phòng tại tokyo.\n",
      "[nội dung công việc cụ thể]- thiết kế và xây dựng đường ống dữ liệu- khai thác / báo cáo / vận hành dữ liệu- công việc trực quan hóa và làm sạch dữ liệu- thiết kế và vận hành giám sát dịch vụ- phát triển các công cụ phân tích và các ứng dụng khác.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "required experience / skills detail\n",
      "\n",
      "\n",
      "\n",
      "kỹ năng / \n",
      "-----------------------------------------------\n",
      "kinh nghiệm cần thiết- có hơn 3 năm kinh nghiệm phát triển hệ thống- có kinh nghiệm về c ++, python, scala là một điểm cộng- có kinh nghiệm thao tác sql- người có hứng thú với công việc phân tích dữ liệu.\n",
      "ưu tiên- ứng viên có hơn 2 năm kinh nghiệm thiết kế hệ thống cơ bản- ứng viên có kinh nghiệm sử dụng dwh (gcp bigquery, redshift, v.v.)- ứng viên có kinh nghiệm sử dụng các công cụ phân tích tiếp thị đám mây công cộng như aws, gcp và azure- ứng viên có kinh nghiệm sử dụng công cụ kiểu như là bi- ứng viên có kinh nghiệm hỗ trợ khách hàng - ứng viên muốn tự tạo dữ liệu phân tích của riêng mình ngay từ đầu.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job detail\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job code\n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "position type\n",
      "\n",
      "full-time\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "career level\n",
      "\n",
      "technical / engineer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "education level\n",
      "\n",
      "diploma (3 years)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gender\n",
      "\n",
      "male / female\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "age\n",
      "\n",
      "26 - 40\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job categories\n",
      "\n",
      "\n",
      "it - software\n",
      "\n",
      ", \n",
      "\n",
      "interpreter/ translator (japanese)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "information\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "name:\n",
      "\n",
      "\n",
      "careerlink asia co., ltd.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "千葉県千葉市美浜区中瀬２丁目6番地1 wbgマリブイースト21階\n",
      "\n",
      ", \n",
      "\n",
      "\n",
      ", \n",
      "\n",
      "\n",
      ", \n",
      "\n",
      "japan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "application language:\n",
      "japanese\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "careerlink asia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "https://corp.careerlink.asia/\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "25 - 99 employees\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact: careerlink asia co., ltd.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "khách hàng của công ty careerlink là các công ty it\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "see more\n",
      "\n",
      "\n",
      "\n",
      "see less\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "other jobs from this company\n",
      "\n",
      "|\n",
      "\n",
      "see all\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "kỹ sư phát triển và quản lý dự án trên các nền tảng có quy mô lớn như aws, ci / cd, devops\n",
      "\n",
      "\n",
      "careerlink asia\n",
      "\n",
      "\n",
      "\n",
      "japan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nhân viên sale\n",
      "\n",
      "\n",
      "careerlink asia\n",
      "\n",
      "\n",
      "\n",
      "japan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nhân sự quản lý bộ phận\n",
      "\n",
      "\n",
      "careerlink asia\n",
      "\n",
      "\n",
      "\n",
      "japan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nhân viên lập kế hoạch kinh doanh\n",
      "\n",
      "\n",
      "careerlink asia\n",
      "\n",
      "\n",
      "\n",
      "japan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nhân viên bộ phận quản lý\n",
      "\n",
      "\n",
      "careerlink asia\n",
      "\n",
      "\n",
      "\n",
      "japan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tags\n",
      "\n",
      "\n",
      "\n",
      "japanese n2\n",
      "python developer\n",
      "back-end developer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "share\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "copied\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2948/data.html\n",
      "description\n",
      "\n",
      "\n",
      "life at agoda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "all teams\n",
      "contentcustomer \n",
      "-----------------------------------------------\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "manager, marketing strategy & analytics (bangkok-based, relocation provided)\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "================================================\n",
      "data-02-06/2896/data.html\n",
      "mô tả công việc\n",
      " kiểm soát và quản lý hệ thống master dataphân tách quy trình và làm việc với các phòng ban để thu nhập dữ liệutương tác các phòng ban liên quan về thiết kế form mẫu thu nhập thông tinxác định và sửa đổi các yêu cầu báo cáohỗ trợ các sáng kiến về tính toàn diện và chuẩn hóa dữ liệucác công việc khác được phân công bởi quản lý trực tiếp \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2386/data.html\n",
      "mô tả công việc\n",
      "ownership of designing, developing, building, testing and maintaining our next generation data etl platformchampion the effort to continuously improving the efficiency and flexibility of the platform and servicescreate web/app-based metric reports using standard frameworkspinpoint and clarify key issues that need action, lead the response and articulate results clearly in actionable formshow a strong aptitude for carrying out solutions and translating objectives into a scalable solution that meets end customers’ needs within deadlinestroubleshooting and debugging to optimise the performancetake charge to recommend proactively and deploy methods to improve our data reliability, quality and efficiencysupport ad-hoc data related requests using mysql, s3 and aws redshift\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "bachelor's degree in computer science, software or computer engineering, applied math, physics, statistics, or a related field, preferredat least 3 years of hands-on working experience in data/software engineering in a highly scalable production environment2 years of experience developing data warehouses on snowflake platform, requiredgood knowledge of architecting large-scale data infrastructure in the cloud platform good knowledge of big data technologies like hadoop,hive,spark, redshift aws or other real-time streaminggood knowledge of server-side programming languages (preferably python) and golang.devops experience (devops or gitlab) delivering continuous improvementsdata visualization and dashboarding experience (power bi, tableau, etc.) \n",
      "================================================\n",
      "data-02-06/2771/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            - develop report and dashboard.\n",
      "- evaluate business numbers and provide executive summary to stakeholders.\n",
      "- detect outliers through numbers and response immediately with logical and reasonable actions.\n",
      "- support initiatives for data integrity and normalization.\n",
      "- investigate and reconciles any discrepancies in reports daily.\n",
      "- assist with other reporting or other tasks as needed.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/762/data.html\n",
      "================================================\n",
      "data-02-06/2640/data.html\n",
      "mô tả công việc\n",
      "– nghiên cứu, cài đặt, cải tiến các thuật toán xử lý dữ liệu lớn (big data), mô hình ml/deep\n",
      "learning/ai tiên tiến trên thế giới.\n",
      "– xây dựng các mô hình học máy/trí tuệ nhân tạo để giải quyết các vấn đề nghiệp vụ kinh\n",
      "doanh của ghtk, dựa trên dữ liệu lớn được lưu trên nền tảng bigdata của ghtk.\n",
      "– tham gia xây dựng hệ thống học máy/ai tự động\n",
      "ii. yêu cầu\n",
      "– có kiến nền tảng về xác suất thông kê, đại số và giải tích.\n",
      "– có kiến thức tốt về thuật toán, khai phá dữ liệu, học máy.\n",
      "– có tư duy và kỹ năng lập trình tốt.\n",
      "– có khả năng đọc tài liệu, các bài báo khoa học bằng tiếng anh.\n",
      "– có \n",
      "-----------------------------------------------\n",
      "kinh nghiệm lập trình với java hoặc python, sử dụng các bộ thư viện về khai phá dữ\n",
      "liệu, học máy, học sâu.\n",
      "– có kinh nghiệm làm việc với môi trường bigdata, các thuật toán phân tán sử dụng spark\n",
      "và mapreduce là một lợi thế.\n",
      "iii. quyền lợi\n",
      "– lương fresher đến senior: 500$ – 2000$\n",
      "================================================\n",
      "data-02-06/768/data.html\n",
      "description\n",
      "\n",
      "our client is the first experience platform for communications service providers in saas in the globe who is searching for a qualified candidate to join their firm:\n",
      "\n",
      "lead the development of machine learning algorithms on health/fitness data\n",
      "improve existing machine learning pipeline scalability, usability, and performance\n",
      "work closely with cross-functional teams to tackle challenges around time series data coming from sensors and edge devices\n",
      "connect the gap between r&d and production and collaborate with our product managers, data scientists, and firmware engineers to ensure the delivery of high quality and robust solutions for our users\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "job requirement\n",
      "\n",
      "\n",
      "bs/ms/phd in computer science, electrical engineering, or related technical field\n",
      "at least 3+ years of industry experience in developing ml systems\n",
      "strong programming skills in python\n",
      "proficiency manipulating big data with apache spark (pyspark)\n",
      "experience with leading machine learning product development on time-series data (sensor, iot devices, health/fitness tracking, audio, etc.)\n",
      "strong knowledge in software architecture design, debugging, source control management, testing, performance, scaling, and operations.\n",
      "experience and demonstrated capability to handle challenges with vague or abstract problem definition\n",
      "\n",
      "\n",
      "tagged as: apache spark, computer science, python\n",
      "================================================\n",
      "data-02-06/2283/data.html\n",
      "description\n",
      "\n",
      "phát triển và bảo trì các dự án liên quan đến business intelligence (bi)\n",
      "\n",
      "your skills and \n",
      "-----------------------------------------------\n",
      "experience\n",
      "\n",
      "\n",
      "etl architecture\n",
      "================================================\n",
      "data-02-06/2985/data.html\n",
      "================================================\n",
      "data-02-06/1000/data.html\n",
      "description\n",
      "as a senior client service analyst at iqvia, you will be responsible for providing quality service to the clients and assist them to obtain maximum value from iqvia information products and services.control the data and report generation process, provide guidance and support to internal and external data stakeholdersassure the consistency, integrity, and availability of the data, as well as being a communication channel with our clients, information providers and internal team.analyzes complex queries raised by clients using in-depth understanding of the client and iqvia syndicated offerings (data), ensuring a comprehensive and timely responses provides additional insight and interpretation of the data to enable appropriate resolution of business questions and/or issues, identifies customized solutions independently support meetings and discussions (both internally & externally) related to project work/data analytics  runs standard queries for data extraction verifies data for accuracy and completeness skills & \n",
      "-----------------------------------------------\n",
      "experiencebachelor’s degree with at least 3 years of related experienceexperience in pharmaceutical industry is preferredwell versed in microsoft excel, powerpoint and power biknowledge in sql server is preferredpossess strong analytical and communication skillsiqvia is a leading global provider of advanced analytics, technology solutions and clinical research services to the life sciences industry. we believe in pushing the boundaries of human science and data science to make the biggest impact possible – to help our customers create a healthier world. learn more at https://jobs.iqvia.com\n",
      "\n",
      "apply now\n",
      "save job\n",
      "remove saved job\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "no recently viewed jobs.  view all opportunities.\n",
      "\n",
      "\n",
      "explore location\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "share this job\n",
      "\n",
      "twitter\n",
      "linkedin\n",
      "facebook\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5 ways to grow your career\n",
      "fulfil your career aspirations at iqvia by unlocking access to these five development resources.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "a warm welcome\n",
      "gawel shares his recruitment experience and the warm welcome he received upon joining iqvia.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "how we work\n",
      "we understand life’s complexities so no matter the role, we strive to find the balance of work flexibility so you can succeed both professionally and personally.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "our benefits\n",
      "our integrated benefits programs are designed to meet individuals’ diverse and changing well-being needs.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/3060/data.html\n",
      "================================================\n",
      "data-02-06/396/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "tiếp nhận và giải quyết các yêu cầu hỗ trợ từ phía người dùng cho các hệ thống phần mềm nội bộ wilmarclv (các phần mềm hỗ trợ hoạt động của đội ngũ bán hàng, nhà phân phối)\n",
      "ghi nhận lại các yêu cầu cầu hỗ trợ đã xử lý.\n",
      "tiếp nhận, xử lý, theo dõi và báo cáo kịp thời các lỗi hệ thống (nếu có).\n",
      "triển khai, đào tạo và hỗ trợ người dùng mới sử dụng hệ thống.\n",
      "cài đặt các dữ liệu trên hệ thống (sản phẩm mới, bảng giá, chương trình khuyến mại,…)\n",
      "kiểm thử trên môi trường thử nghiệm khi lỗi được khắc phục hoặc khi có tính năng mới trên hệ thống.\n",
      "soạn thảo các tài liệu hướng dẫn sử dụng.\n",
      "thực hiện cập nhật số liệu báo cáo định kì trên hệ thống cung cấp cho các phòng ban liên quan sử dụng.\n",
      "đề xuất các ý kiến để cải tiến hệ thống. thu thập các yêu cầu nâng cấp hệ thống, phát triển các chức năng mới từ đội ngũ bán hàng\n",
      "thực hiện các báo cáo phân tích và các công việc khác được phân công.\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/838/data.html\n",
      "================================================\n",
      "data-02-06/2970/data.html\n",
      "================================================\n",
      "data-02-06/667/data.html\n",
      "================================================\n",
      "data-02-06/251/data.html\n",
      "descriptionin india, bosch is a leading supplier of technology and services in the areas of mobility solutions, industrial technology, consumer goods, and energy and building technology. additionally, bosch has in india the largest development center outside germany, for end to end engineering and technology solutions. the bosch group operates in india through twelve companies.  bosch set-up its manufacturing operation in 1951, which has grown over the years to include 18 manufacturing sites, and seven development and application centers. bosch group in india employs over 31,000 associates and generated consolidated revenue of about ₨.21,450 crores* (2.66 billion euros) in 2018 of which ₨. 15,824 crores*(1.96 billion euros) from third party. the group in india has close to 18,000 research and development associates.in india, bosch limited is the flagship company of the bosch group. it earned revenue of over ₨. 12,460 crores (1.54 billion euros) in 2018. additional information can be accessed at www.bosch.in.job descriptioncloud analytics & optimization team is responsible to establish and drive cloud analytics capabilities for ccoe with focus on cloud resource utilization, smart reporting (with ai, prediction capabilities), cloud cost optimization & rightsizing initiatives\n",
      "\n",
      "- provide cloud analytics platform to visualize the consumption metrics, cost optimization and for right sizing advise on increasing or decreasing cloud service portfolios (enable data driven decision making)\n",
      "- provide various set of reporting for different use cases requested by our stakeholders and teams\n",
      "- establish necessary frameworks, processes to help collect, process and visualize data from the clouds\n",
      "- support various teams to identify opportunities for optimization of resources based on various data sets\n",
      "- exchange feedback/inputs with other domains and drive continuous improvement initiatives within the domain\n",
      "- setup necessary program dashboards to enable steering of various initiatives/topicsqualificationsqualifications:\n",
      "- personality: analytical and problem-solving skills, ability to find creative solutions, confident in working in a bigger companies organizational structures\n",
      "- working style: committed, focused, structured, team-oriented, capability in balancing interests\n",
      "- \n",
      "-----------------------------------------------\n",
      "experience: proven practical experience with strong analytical skills and knowledge in the context of cloud. optimization and profound hyperscaler / public cloud knowledge is also helpful.\n",
      "\n",
      "================================================\n",
      "data-02-06/1928/data.html\n",
      "================================================\n",
      "data-02-06/2910/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            1. monitor, understand & improve customer \n",
      "-----------------------------------------------\n",
      "experience for assigned customer segments:\n",
      "- define customer journey (stage/ step/ touchpoints/ related functions) based on internal process. it could be - - \n",
      "- end-to-end journey but usually specific parts of journey.\n",
      "- define the key metrics & questionnaire to measure the success of customer experience based on customer journey (nps, transactional nps, csat, ces, customer complaints, business metrics…).\n",
      "- coordinate with relevant departments to collect and track customer experience metrics across end-to-end journey.\n",
      "- regularly monitor the metrics to identify potential problematic touchpoints.\n",
      "- propose & conduct necessary qualitative & quantitative research to confirm customer journey, identify customer’s expectation, customer pain points, drop rate during detected journey then report key findings.\n",
      "- coordinate with process analyst & business stakeholders to define potential root causes for improvement solution design.\n",
      "- recommend & coordinate in enhancement activities (ux/ui revision, product/process improvement, people training,…).\n",
      "\n",
      "2. drive customer centricity culture activities:\n",
      "organize activities for exco/ head/ employee to experience company product & services.\n",
      "coordinate with hr & related functions to organize activities and contests to promote customer centric culture and mindset within the organization.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "================================================\n",
      "data-02-06/2270/data.html\n",
      "================================================\n",
      "data-02-06/2986/data.html\n",
      "responsibilities\n",
      "\n",
      "performs higher level responsibilities involving the consumer aml kyc activities and transaction monitoring\n",
      "research system issues, identifying process improvements, communicating changes and issues to clients, and testing key enhancements.\n",
      "research system and process issues, identifying solutions and communicating procedure exceptions to business partners.\n",
      "tests functional enhancements being implemented by vendors and integrated systems.\n",
      "perform cdd/ name screening as required\n",
      "review/update kyc actives to ensure the latest info is adequate and properly.\n",
      "perform transaction monitoring and report the unusual behavior as applicable\n",
      "produces metrics and reports with accuracy and quality to ibac lead and internal clients.\n",
      "appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency.\n",
      "\n",
      " \n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1069/data.html\n",
      "mô tả công việc:\n",
      "\n",
      "hỗ trợ các đơn vị kinh doanh trong việc kiểm soát dữ liệu đầu vào và chuẩn hóa hệ thống dữ liệu hiện tại\n",
      "hỗ trợ các đơn vị kinh doanh trong việc xây dựng các quy tắc chuẩn hóa, so khớp, hợp nhất\n",
      "phụ trách cấu hình lên tool quản lý dữ liệu chủ các quy tắc chuẩn hóa, so khớp, hợp nhất.\n",
      "vận hành và quản trị hệ thống quản lý dữ liệu chủ mdm\n",
      "phụ trách khai thác dữ liệu từ hệ thống quản lý dữ liệu chủ (nếu có)\n",
      "thiết kế các dashboard giám sát cldl dữ liệu chủ \n",
      "báo cáo theo dõi hệ thống định kỳ\n",
      "thực hiện các công việc theo sự phân công của lãnh đạo phòng\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc:\n",
      " 1/  trình độ học vấn\n",
      "\n",
      "tốt nghiệp từ đại học trở lên chuyên ngành cntt, điện tử viễn thông hoặc các chuyên ngành tương đương\n",
      "\n",
      "2/ kiến thức/ chuyên môn có liên quan\n",
      "\n",
      "hiểu biết về nghiệp vụ ngân hàng là một lợi thế\n",
      "kiến thức và kỹ năng thực tế về thiết kế và truy vấn cơ sở dữ liệu sql server, sql, oracle,...\n",
      "có kiến thức về tiêu chuẩn dữ liệu của các miền dữ liệu trong lĩnh vực ngân hàng như miền dữ liệu khách hàng, sản phẩm tiền gửi, sản phẩm tiền vay…\n",
      "yêu cầu thành thạo ngôn ngữ sql/plsql, sql server\n",
      "\n",
      "3/  các kinh nghiệm liên quan\n",
      "\n",
      "có ít nhất 1 năm kinh nghiệm về phân tích dữ liệu / quản trị dữ liệu / kiểm toán cntt / quản lý siêu dữ liệu.\n",
      "================================================\n",
      "data-02-06/2187/data.html\n",
      "description and thank you in advance if you decide to apply for this position. shortlisted candidates will be contacted within 2 weeks of application, otherwise, we might meet when another chance arises.\n",
      "-----------------------------------------------\n",
      "experience and revenue performance by deep segmentation analysis and proactively develop a timely optimisation plan to maximise sellers' success and revenue performance.possess a hybrid user-focused & data-informed mindset. actively conduct in-depth analysis with big amount of data, research market trends and frequently talk to customers to identify sellers' problems/opportunities; while at the same time work closely with relevant teams to deliver appropriate solutions.work closely with product team to develop product roadmap and play an active role in product development process with product team - from users discovery to solutions ideation, results analysis and optimisation.research on new monetisation schemes and regularly carry out experiments to test new premium packages/features to optimise users’ effectiveness as well as spending.work closely with the go to market specialist to maximise adoption of the product offerings from the target segments.responsible for analysis of sales performance and product/ service effectiveness metrics of the business owner segment who is a reliable seller and qualified by the commercial team.prepare weekly, \n",
      "================================================\n",
      "data-02-06/2324/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      " we are looking for senior data scientists to join our data science team at aiactiv, a newly created company of datviet group. the successful candidate will:\n",
      "\n",
      "\n",
      "work with \n",
      "-----------------------------------------------\n",
      "experienced data scientists and machine learning engineers to build/improve large-scale learning applications (e.g., demographic prediction, churn detection, email campaign optimization, user segmentation, recommender systems, ad optimization, etc).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "work closely with the it team to maintain and improve existing data science applications.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "produce comprehensive and clear documentation\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/933/data.html\n",
      "================================================\n",
      "data-02-06/1571/data.html\n",
      "mô tả công việc\n",
      " \n",
      "responsible for industrialization, deployment, and functional maintenance of data products/solutions, including digital products, business intelligence, and machine learning use cases.\n",
      "collaborate with other members and users to build data pipelines.\n",
      "responsible for quality checking and testing.\n",
      "collaboratively work to solve research problems.\n",
      "develop new algorithms and computational tools to solve research problems.\n",
      "review research code created by other team members.\n",
      "write technical documentation and reports.\n",
      "continue learning new technologies, introducing existing products, improving product \n",
      "-----------------------------------------------\n",
      "experience, and creating more value.\n",
      " \n",
      "================================================\n",
      "data-02-06/2590/data.html\n",
      "mô tả công việc\n",
      "participate in requirements analysis & technical specification in the agile/scrum development process.design, develop, and maintain scalable data pipelines and etl processes to collect, clean, and process large datasets. the system is built on the microservice architecture and deployed kubernetes (use aws eks service) across 3 aws regions globally (us, hk, sg).collaborate with data scientists, analysts, and other stakeholders to understand data requirements and develop data solutions that meet business needs. use bi tools for data analytics, such as grafana, aws quicksight, or excel (google sheets).develop and implement data integration strategies and data transformation logic, ensuring high-quality and accurate data in the data warehouse. use kafka and nifi tech-stack & eco-system to build data flow.optimize and improve the performance, efficiency, and reliability of data pipelines, data models, and data storage solutions. use database or object storage services like postgresql, elasticsearch, redis, and aws s3.monitor and troubleshoot data pipeline issues, ensuring data integrity and timely data delivery. use tools for monitoring logs and issues such as sentry, grafana, or alerts slack.continuously evaluate and implement new technologies, tools, and techniques to enhance data engineering capabilities.document data engineering processes and maintain data dictionaries, ensuring compliance with data governance policies and regulatory requirements. use the atlassian toolset (jira, confluence) or slack to help teams organize, collaborate, and complete work together.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "bachelor's degree in computer science or a related field.4+ years of experience in backend development or data engineering, etl development, or a similar role.experience working with microservice architecture.proficiency one of langue in .net, java, or python for data processing and scripting.experience working with relational databases, such as one of the database types: postgresql, mysql, oracle, or ms sql server.knowledge of working with document databases, such as one the database types: elasticsearch, redis, mongodb, or apache solr.familiarity with data warehousing concepts and cloud-based data storage solutions (e.g., aws, gcp, azure).strong problem-solving skills, attention to detail, and the ability to work independently and as part of a team.excellent communication and collaboration skills, especially in agile culture environment.﻿nice to have:\n",
      "================================================\n",
      "data-02-06/2626/data.html\n",
      "responsibilities (30%)\n",
      "\n",
      "lead a team of data analysts and data engineers, providing guidance and mentorship, and support in their day-to-day activities\n",
      "foster a collaborative and high-performing team culture, promoting knowledge sharing and continuous improvement.\n",
      "identify skill gaps and training needs, and coordinate training programs to enhance the team’s capabilities.\n",
      "proactively identify opportunities for leveraging data and analytics to drive business growth, operational efficiency, and cost savings\n",
      "work closely with clients to understand their needs and align team strategies to expand our support and coverage.\n",
      "\n",
      "\n",
      "business intelligence analyst responsibilities (70%) \n",
      "\n",
      "design and develop reports, dashboards, and visualizations in tableau to present data in a clear and concise manner, tailored to various business needs.\n",
      "ensure data accuracy, reliability, and integrity by implementing robust data governance and quality assurance processes.\n",
      "own the design, development, and maintenance of etls and data pipelines;\n",
      "design, develop, and deploy an automated bi solution using sql server, ssis, cloud technologies (azure, aws, google cloud)  etc.;\n",
      "create and update powerpoint slides used in client meetings, business reviews, etc.;\n",
      "proactively communicate and collaborate with external and internal stakeholders to analyze information needs and functional requirements.\n",
      "identify, troubleshoot, and resolve data and reporting issues;\n",
      "responsible for maintenance, documentation, and enhancements of recurring processes and procedures.\n",
      "\n",
      "\n",
      "\n",
      "what we are looking for\n",
      "\n",
      "bachelor’s degree in mis, information technology, computer science, or other quantitative major. an understanding of basic accounting/finance is a plus;\n",
      "proven \n",
      "-----------------------------------------------\n",
      "experience (3+ years) in business intelligence, data analysis, or a related role, with a track record of successful team leadership.\n",
      "strong knowledge of tableau and able to develop insightful dashboards and reports that drive business decision making and outcomes;\n",
      "intermediate to advanced database, t-sql, data modelling, etl (ssis, azure data factory …) skills;\n",
      "intermediate powerpoint;\n",
      "experience in python, c#, vba is a plus\n",
      "understand data models, database design development, data mining and segmentation techniques.\n",
      "\n",
      "what we offer: we treat people fairly and with dignity, keeping a healthy perspective about life and work and fostering a positive and enjoyable work environment with appealing benefits as below:\n",
      "\n",
      "a competitive monthly salary based on your ability\n",
      "13th month tet bonus & bi-annual performance bonus\n",
      "annual salary review\n",
      "attractive employee awards: employee of year, semi-annual outstanding employee\n",
      "social insurance and healthcare insurance upon vietnam labor code\n",
      "pti insurance package, and annual health check\n",
      "an english-speaking environment\n",
      "an open culture that spurs creativity, innovation, and inclusivity\n",
      "a variety of training courses for your career development\n",
      "diverse activities to foster relationships, including company trips, year-end party, employees’ birthdays\n",
      "an open-space office, a cafeteria, and a range of modern equipment\n",
      "other allowance from referrals and special occasions (weddings, seniority, and new-born baby)\n",
      "\n",
      "work location: our office is located at 9th floor, ree tower, 9 doan van bo, ward 13, district 4\n",
      "working hours\n",
      "working hours can be decided flexibly, however, for the 1st several months it is:\n",
      "mon – fri: 3pm – 6pm (office) & 9pm – 2am (wfh)\n",
      "afterwards, fully remote or shifts like 7pm – 4am or 9pm – 6am can be considered.\n",
      "================================================\n",
      "data-02-06/3099/data.html\n",
      "mô tả công việc\n",
      " \n",
      "phân tích khu vực & địa điểm thương mại để đưa ra dự báo doanh thu của nso (new store open) và các store hiện tại.\n",
      "phân tích các yếu tố tiềm năng để dự báo dự báo doanh thu để đạt được boe\n",
      "làm đánh giá hiệu suất cửa hàng sau khi hoàn thành giai đoạn nso (new store open) của các cửa hàng\n",
      "hỗ trợ lập kế hoạch mở rộng cửa hàng\n",
      "nghiên cứu thị trường hiện tại và thị trường mới để tìm ra các mặt bằng kinh doanh tiềm năng theo khu vực\n",
      "xây dựng cơ sở dữ liệu nội bộ (cơ sở dữ liệu hồ sơ store lưu trữ/cho thuê/…)( store profile/ rent/ …. ).\n",
      "đánh giá hiệu suất cửa hàng hàng tháng / hàng quý.\n",
      "thiết kế và triển khai trực quan hóa (trong công bi) để đáp ứng nhu cầu kinh doanh từ cơ sở dữ liệu quan hệ và các hệ thống nguồn khác.\n",
      "phối hợp chặt chẽ với nhóm kỹ thuật xây dựng và kinh doanh trong việc thu thập và khai thác dữ liệu, tạo ra phân tích thông tin.\n",
      "các dự án phát sinh do trưởng/quản lý trực tiếp phân công.\n",
      " \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2339/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "benefits\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "skills required\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "details\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- tổng hợp dữ liệu thô từ các nguồn, xử lý dữ liệu thô- thực hiện các nghiệp vụ về khai phá dữ liệu, trích xuất đặc trưng để cung cấp thông tin cho quản lý- theo dõi, đánh giá các chỉ tiêu, tiến độ hoàn thành chỉ tiêu của các bộ phận (chủ yếu là bộ phận kinh doanh) để kịp thời báo cáo, báo động cho quản lý- thiết kế các báo cáo, báo động cho các bộ phận liên quan.- thiết kế các form mẫu, biểu mẫu, công cụ.- hỗ trợ trưởng bộ phận các công việc khác khi được yêu cầu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job benefits\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bhxh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "qùa sinh nhật\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tăng lương hàng năm\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lộ trình thăng tiến\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "required experience / skills detail\n",
      "\n",
      "\n",
      "\n",
      "- giới tính: nam/nữ- tốt nghiệp chuyên ngành toán tin, phân tích thống kê, tài chính  - \n",
      "-----------------------------------------------\n",
      "kinh nghiệm 1 năm\n",
      "================================================\n",
      "data-02-06/1281/data.html\n",
      "descriptionleadership role:play a first and foremost leader and founder within the department overseeing all activities of the data analytics and data warehousing departmentslead the recruitment and development of the teamlead initiatives to improve performance across the business, such as: personalizing user experience on the engagement & loyalty mobile app, optimizing analytics efficiency and cost, and optimizing individual department operationwork closely with other departments and stakeholders, including ceo, business, product, finance, marketing, tech, and senior management, to ensure that data-related goals and initiatives are aligned with the organization's overall strategystrategy & analytics: lead the data analytics and data warehousing departments in strategy development with regard to the collection, manipulation, and analysis of data for various business functions/departments such as marketing, sales, and operations, among othersendeavor to create new data-driven approaches for the purpose of generating business insights through data analytics, information visualization, and addressing unanswered business issues in a proactive manner. lead the team in building data governance framework to provide trusted data across functionsin-charge of strategic products including: customer segmentation, personalization engine, antifraud engine etc.keeping up with industry trends and best practices, applying new technologies and techniques to enhance the organization's data strategydata management:oversee and participate in data management activities, including:define, build, and manage the organization's data architecture, including data models, data flows, data integration patterns, data pipelines, data processing, data warehouses, data marts…collect and centralize data from various sources, including internal systems, external partners, and third-party providers.ensure data privacy and security with appropriate policies and security measures.ensure data quality and accuracy with appropriate data quality checks and controls are in place.manage data throughout its lifecycle, from creation to retirement, to optimize its value and minimize risks.recommendation/ml:extend existing ml libraries and frameworks;lead the design and development of machine learning and deep learning systems;enhance implementing appropriate ml algorithms.\n",
      "-----------------------------------------------\n",
      "job requirementbachelor’s degree or above in data science, computer science, information technology,\n",
      "================================================\n",
      "data-02-06/2350/data.html\n",
      "descriptionsfor unilever to remain competitive in the future, the business needs to continue on the path to become data intelligent. the data & analytics team will persevere to make unilever data intelligent, powering key decisions with data, insights, advanced analytics and ai. our ambition is to enable democratization of data, information and insights as a completely agile organization that builds fantastic careers for our people and is accountable for delivering great work that maximizes impact and delivers growth. this data & analytics function endeavours to create clear accountabilities for all aspects of data strategy, data management, information management, analytics, and insights. we are accountable for impact of solutions, maintaining market relevance and minimising unnecessary overlaps in analytics products, ensuring simplicity and that our solutions better meet the needs of our users. our 5 strategies to achieve this are: accelerate & simplify access to relevant data, information and insightsbuild in-house, leading-edge data, information, insights & analytics capability lead the data & insights culture and careers to empower employees across unilever rapidly embed analytics products, solutions and services to drive growthadvance information automation at scale the data scientist is an exciting role in the data science team in seaa as part of the data science centre of excellence (coe). this team focus on supporting global product (data & analytics) development aiming at maximizing business performance by creating/embedding core data science models into the product engine in a fully automated/scalable fashion. currently, the team is supporting a major product expansion, targeting at landing in > 10 countries within next year. the team also works directly with the market (sea) on innovative project using cutting edge technology/ machine learning model. this role has a strong global presence while is also deeply connected with the data and analytics community in the region. we are looking for someone good at comprehending the big picture while having deep technical skills to provide systematic data science solutions to challenging real-live problem. leading user engagement and data science activity in regular product deployment cycle: pre-deployment engagement, market customization, testing + bau monitoring.own the data science road map for the product and leading the development with/without 3rd parties support, coordinating data science related tasks with other tech teams (mlops, solution factory etc).direct engagement for innovative project initiatives, lead the conversation, solution design and development for mvps.data science capability development\n",
      "-----------------------------------------------\n",
      "job requirements:involved in the full cycle of data science product development + deployment, with strong presence in the project.substantial tech experience in all tech aspects of data science work, eda, modelling, testing, bau monitoring.experience with fmcgexperience working with/managing 3rd partiesworking with partners from tech product/platform (ms azure, gcp etc)research for new methodology (from application point of view), writing white papers, product evaluationunilever is an organisation committed to equity, inclusion and diversity to drive our business results and create a better future, every day, for our diverse employees, global consumers, partners, and communities. we believe a diverse workforce allows us to match our growth ambitions and drive inclusion across the business. at unilever we are interested in every individual bringing their ‘whole self’ to work and this includes you! thus if you require any support or access requirements, we encourage you to advise us at the time of your application so that we can support you through your recruitment journey.\n",
      "================================================\n",
      "data-02-06/3078/data.html\n",
      "mô tả công việc\n",
      " we are looking for a highly skilled deep learning engineer to join our team and contribute to the development of our ai system. as a deep learning engineer, you will be responsible for developing, implementing, and optimizing deep learning models and algorithms for object detection, tracking, and face recognition.\n",
      "responsibilities:\n",
      "\n",
      "\n",
      "develop, train, and optimize deep learning models and algorithms for object detection, tracking, and face recognition using state-of-the-art techniques and frameworks (e.g., tensorflow, pytorch).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "design and implement data preprocessing, augmentation, and validation pipelines to ensure the quality and reliability of the training data.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "collaborate with other engineers and data scientists to develop and integrate deep learning models and algorithms into the ai camera system.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "optimize the performance and efficiency of the deep learning models and algorithms through techniques such as pruning, quantization, and compression.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "evaluate and benchmark the performance of the deep learning models and algorithms using appropriate metrics and datasets.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "keep up-to-date with the latest research and advancements in deep learning and computer vision.\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/172/data.html\n",
      "================================================\n",
      "data-02-06/2172/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      " execution:\n",
      "\n",
      "working closely with the cross-functional departments (sales, marketing) in order to monitor the actual expenditures vs budget/ forecast. ensure the expenditures are properly reported and budget are monitored; deviations should be alerted to budget owner and management on time for decision-making.\n",
      "working closely with the accounting team in order to ensure relevant expenditures are properly reported. identify, by reviewing and challenging the accounting records, discrepancies in reporting in order to correct the reports.\n",
      "process monthly closing activities (accruals, provide posting entry to accounting team, ensure spending reported correctly & adequately), p&l management.\n",
      "review contracts related to trade & advertising & promotion expenses with related to assessment on financial & operational risk.\n",
      "control, calculate supply-chain cost efficiency.\n",
      "ensure master data quality and all reports deliverables are accurate, transparent and timely.\n",
      "calculate production cost (e.g. release standard cost, new product cost) and evaluate impact of cost deviation.\n",
      "\n",
      "management:\n",
      "\n",
      "provide financial assessment on trade activities & mkt activities.\n",
      "manage monthly rolling forecast & annual budget in conjunction.\n",
      "provide ad-hoc report or analysis required by management team.\n",
      "support the budget owners by monitoring their budget vs actual, provide informative & supportive analysis to help on management’s decision making.\n",
      "design and implement necessary control tool and process in order to ensure the accuracy of reports.\n",
      "deliver, on monthly basis, the management reports (with full explanation & analysis) by channel, by distributor, by brand.\n",
      " \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/248/data.html\n",
      "descriptionthe bosch group is a leading global supplier of technology and services. in 2013, its roughly 281,000 associates generated sales of 46.4 billion euros. since the beginning of 2013, its operations have been divided into four business sectors: automotive technology, industrial technology, consumer goods, and energy and building technology. the bosch group comprises robert bosch gmbh and its roughly 360 subsidiaries and regional companies in some 50 countries. if its sales and service partners are included, then bosch is represented in roughly 150 countries. this worldwide development, manufacturing, and sales network is the foundation for further growthrbvh - robert bosch engineering and business solutions vietnam company limited is 100% owned subsidiary of robert bosch gmbh. rbvh has started its operations from 19th october, 2010 at e-town2 in hcmc. this engineering development center will be engaged in developing embedded systems and software, mechanical design and simulation, and will provide it (sap consulting, java development….) and business services (finance and accounting, economics, purchasing, logistics, translations japanese-english-japanese, information security ) solutions to the bosch group of companies globally. job descriptionwork closely with internal stakeholders and external clients to understand, analyze technical requirements.analyze data & build visualizations and reportsanalyze & develop queries to collect data from different data sourcesbe responsible for developing, deploying and supporting ms sql server bi solutions utilizing integration services (ssis) and reporting services (ssrs).build fact and dimension tables to support analytical and reporting models.be tasked with building dimensional models and data marts to support reporting and analysis.qualificationsat least 3 years of \n",
      "-----------------------------------------------\n",
      "experience in edw bi development, including microsoft sql server reporting services (ssrs) and integration services (ssis).experience in building self-serve reporting, including parameterized reports with drill-down capabilitiesthe environment consists of microsoft sql server databases (versions 2012, 2014 and 2016).experience with t-sql is required (writing optimizing stored procedures, packages and queries).ability to work independently and good team playergood english communication skillhandle multiple assignmentadditional information\n",
      "================================================\n",
      "data-02-06/2438/data.html\n",
      "responsibilities: \n",
      "configure and maintain database servers and processes, including monitoring of system health and performance, to ensure high levels of performance, availability, and security\n",
      "refine and automate regular processes, track issues, and document changes\n",
      "support cross department for migrating, deploying database changes.\n",
      "involve into composing and training course related to database\n",
      "interview external resources for the account when necessary\n",
      "assist developers with complex query tuning and schema refinement\n",
      "participate and improve the data base services recovery plan\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2428/data.html\n",
      "responsibilities:planning and reporting:lead weekly/monthly sales reporting on key business metrics (sales productivity, revenue per province, customer numbers etc)lead weekly/monthly sales planning to forecast revenue, performance and sales of key fmcg categories/skussupport the area sales managers with the right reports and metrics to identify areas to improvementanalysis and leading projects:conduct analysis on business metrics to identify areas to improvelead large scale projects to improve performance and sales productivitylaunch new sales tools across the nation and ensure proper roll-out (e.g. dms)sales operations & admin:manage administrative affairs (e.g. commissions, onboarding)lead process improvement projects to streamline sales operation\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3041/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            1.\tlead the implementation of designing, developing & providing on-going management of data warehouse, data migration, business intelligence systems;\n",
      "2.\tensure the availability of current, accurate, and complete data required to support business planning and informed decision-making;\n",
      "3.\tlead all the data warehouse activities that ensure all data sources is ready for business use;\n",
      "4.\tengaging with stakeholders to identify bi initiatives and form bi projects accordingly (with clear scope, project team, budget, and timeline for securing stakeholder alignment and management);\n",
      "5.\tpartner & collaborate within a business units/divisions, acting as liaison between the business units/divisions and the dci division to assure the data & information support business unit/divisions needs;\n",
      "6.\tassist r&d team to prove and delivery the outcome which contribute to the company revenue;\n",
      "7.\tassist to build, develop and maintain the data pipeline of our strategic big data platform, data lake serving for management needs, business operations of the bank and comply with data governance;\n",
      "8.\tassist the data analysis pipeline with insight generating to support business decision-making, as well as support on-going projects of improvements;\n",
      "9.\twork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions;\n",
      "10.\tinvolve in hiring, develop and lead a high performing da teams; mentoring, coaching and guiding professionals to help develop the top talent data pipeline within dci division.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2024/data.html\n",
      "================================================\n",
      "data-02-06/1860/data.html\n",
      "mô tả công việc\n",
      " - tiếp nhận hồ sơ, hình ảnh, tài liệu, yêu cầu từ khách hàng.\n",
      "- xử lý thông tin, tìm kiếm, trích lọc chính xác thông theo yêu cầu của khách hàng.\n",
      "- nhập các thông tin đã trích lọc được lên hệ thống của khách hàng.\n",
      "- báo cáo công việc theo yêu cầu của đội trưởng.\n",
      "- thực hiện các công việc khác theo sự phân công của đội trưởng. \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1522/data.html\n",
      "================================================\n",
      "data-02-06/2587/data.html\n",
      "mô tả công việc\n",
      "\n",
      "tpf group is an international business recognized for innovation, brand management, merchandise concept development, manufacturing and technology solutions. we comprise two individual, dynamic businesses:\n",
      "\n",
      "tpf think: an integrated marketing communications agency with omnichannel expertise and capabilities.\n",
      "\n",
      "tpf sports: a specialised services provider to top tier sporting clubs and organisations.\n",
      "built on a foundation of almost three decades of experience, tpf group has helped some of the world’s most influential brands to achieve their marketing goals.\n",
      "perform database administrator duty include maintaining adherence to a data management policy and ensuring all databases run efficiently and securely.\n",
      "provide database solutions to an agile software development process and enhance existing products and tools.\n",
      "review sql codes and provide support to the sql developers.\n",
      "improving database performance by means of optimising database design, sql query tuning and/or other techniques.\n",
      "documenting database structure and record database structure changes.\n",
      "maintaining database files and backups securely – according to policies in best practise.\n",
      "monitoring and maintaining database scheduled job.\n",
      "working with deployment team to identify database server baseline.\n",
      "monitoring the performance of database server ensuring the server is always working efficiently.\n",
      "participating in team meetings to discuss and suggest solutions for system development and improvements.\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "knowledge and experience:\n",
      "bachelor’s degree in computer science or equivalent with a minimum of\n",
      "================================================\n",
      "data-02-06/654/data.html\n",
      "mô tả công việc\n",
      "\n",
      "- lập kế hoạch ngân sách\n",
      "\n",
      "tổ chức triển khai lập kế hoạch ngân sách/kế hoạch kinh doanh miền theo từng năm tài chính\n",
      "tổng hợp và thẩm định bộ kế hoạch\n",
      "triển khai bộ khns/khkd theo phê duyệt của miền xuyên suốt năm, theo dõi tiến độ triển khai, đảm bảo kiểm soát các hạng mục thực hiện nằm trogn khns đã được phê duyệt\n",
      "\n",
      "- phân tích tài chính\n",
      "\n",
      "phân tích các chỉ số kinh doanh & lập báo cáo nhằm mục tiêu đánh giá hiệu quả về hoạt động kinh doanh từng nhãn hàng\n",
      "tương tác với các quản lý điều hành/quản lý khu vực về báo cáo tài chính định kỳ, action plan cho những nhà hàng có vấn đề về budget, kinh doanh không hiệu quả.\n",
      "phân tích đối chiếu tình hình kinh doanh và thị trường, xu hướng thực tế để đánh giá và cảnh báo rủi ro;\n",
      "tập hợp, phân tích chi phí đầu tư, nhượng quyền. phân tích các business mode;\n",
      "phân tích hiệu quả thực hiện chương trình khuyến mãi;\n",
      "lập các mô hình phân tích để tư vấn phương án tối ưu chi phí.\n",
      "\n",
      "yêu cầu\n",
      "\n",
      "tốt nghiệp đại học chuyên ngành kế toán / kiểm toán / tài chính hoặc chuyên ngành liên quan;\n",
      "\n",
      "-----------------------------------------------\n",
      "kinh nghiệm hơn 04 năm về chuyên môn phân tích hoạt động kinh doanh. ưu tiên ứng viên có kinh nghiệm làm việc trong mô hình chuỗi nhà hàng f&b, chuỗi cửa hàng bán lẻ retails, fmcg, …;\n",
      "tổ chức & phân tích dữ liệu tốt. sử dụng tốt các công cụ về dữ liệu và phân tích dữ liệu (power bi, power query, data studio, …);\n",
      "có kỹ năng thực hiện phân tích và tổ chức các báo cáo về tài chính, kết quả hoạt động kinh doanh chính xác và có thể đưa ra các nhìn nhận, đánh giá và góp ý hiệu quả;\n",
      "tính cách trung thực, ý thức bảo mật thông tin số liệu tốt;\n",
      "tư duy tốt về kinh doanh và nắm bắt tốt xu hướng kinh doanh của ngành/ thị trường;\n",
      "thái độ tích cực và có tinh thần đồng đội tốt. tinh thần trách nhiệm cao và chịu được áp lực công việc.\n",
      "\n",
      "phúc lợi\n",
      "\n",
      "lương thỏa thuận theo năng lực;\n",
      "thời gian làm việc: thứ 2 - thứ 6, 8h30 - 17h30;\n",
      "công ty cung cấp đầy đủ trang thiết bị làm việc cần thiết như desktop / laptop;\n",
      "lương tháng 13 + thưởng theo kết quả hoạt động kinh doanh;\n",
      "giảm giá trên tổng hóa đơn khi dùng bữa tại các nhà hàng thuộc hệ thống của golden gate;\n",
      "môi trường trẻ trung, năng động. nhiều cơ hội phát triển;\n",
      "công ty thường xuyên có các hoạt động: du lịch hằng năm, team building, tiệc cuối năm.\n",
      "\n",
      "================================================\n",
      "data-02-06/1006/data.html\n",
      "descriptiondaily routine workflow:customer care process and scenario building;automation report and measurable techniques;optimizing daily tasks;customer loyalty program:connecting merchants and partners;cooperating with internal teams and other departments (bi, operations, finance,...);building and implementing loyalty projects: rfm, cjm, gamification,...;data analysis:gathering and analyzing behavioral data of customers;using customer insights to identify core value customers (beneficial customers);controlling and ensuring finance (budget, c/r,cps);product development.\n",
      "-----------------------------------------------\n",
      "job requirementprofessional skills:good communication, understanding customer psychology;ability to work under pressure and finish on time;proficient in ms word, excel, powerpoint;proficient in sql or python is a great advantage;planning & strategy skills,\n",
      "================================================\n",
      "data-02-06/2497/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- tổng hợp và phân tích số liệu liên quan đến ngành hàng, marketing, doanh số sell in/out, vận hành ... và lập báo cáo hàng tuần/tháng. - phối hợp với đội sale, marketing và ngành hàng để tổng hợp số liệu bán hàng và các chỉ số liên quan. - thiết kế các bảng biểu và báo cáo nội bộ phù hợp với yêu cầu của quản lý. - cập nhật thường xuyên thông tin tài chính cho các quản lý liên quan để hỗ trợ ra quyết định kinh doanh. - thường xuyên kiểm soát, đôn đốc các quản lý nh về tiến độ thực hiện doanh số.- báo cáo bgd về tình hình thực hiện doanh số và đưa ra các giải pháp tài chính phục vụ cho việc ra quyết định. - xây dựng, đề xuất và quản trị các báo cáo kinh doanh, vận hành và kpi trên dashboard và excel.- phát triển các danh mục báo cáo phân tích kinh doanh, hiệu quả kinh doanh, hàng tồn kho, đánh giá tình hình sản xuất và kinh doanh sản phẩm nhằm theo dõi, phát triển dòng sản phẩm. - chủ động đưa ra các phương pháp phân tích, xác định số liệu cần lấy và thực hiện lấy số liệu, viết các báo cáo phân tích, đưa ra nhận định và đề xuất tới các bộ phận\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2105/data.html\n",
      "================================================\n",
      "data-02-06/1010/data.html\n",
      "================================================\n",
      "data-02-06/2602/data.html\n",
      "================================================\n",
      "data-02-06/3077/data.html\n",
      "mô tả công việc\n",
      " •conduct data analysis to identify trends and insights to support decision-making\n",
      "•develop and maintain business reports to provide key performance indicators (kpis) and insights to stakeholders\n",
      "• work with stakeholders to gather requirements for new reports and dashboards\n",
      "• collaborate with cross-functional teams to identify and implement process improvements based on insights from data analysis\n",
      "• identify areas for cost optimization and provide recommendations to reduce expenses based on data insights\n",
      "• conduct market research to identify opportunities for business growth and report findings to management\n",
      "• analyze customer data to identify opportunities for increased customer satisfaction and report findings to management\n",
      "• assist in the development of business cases for new products and services based on data analysis\n",
      "• ensure data accuracy and integrity by regularly monitoring data quality\n",
      "• provide ad-hoc analysis as needed to support business decision-making \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/770/data.html\n",
      "responsibilities\n",
      "\n",
      "design, implement and maintain data storages, data processing pipelines, tools, provide basic quality of data and data services\n",
      "participate in system design on team level\n",
      "make technical design and architecture decisions that are simple enough and efficient\n",
      "provide support for operations of the developed systems\n",
      "collaborate with other stakeholders (product managers, project managers, business teams and so on) to apply technology in ways that maximize business value\n",
      "develop practices and flows that improve delivery and quality of systems in the scope of responsibility\n",
      "\n",
      "requirements\n",
      "required skills:\n",
      " \n",
      "\n",
      "6+ years of hands-on backend engineering \n",
      "-----------------------------------------------\n",
      "experience\n",
      "good knowledge of at least one of the programming languages: java or c++\n",
      "strong understanding of algorithms and data structures\n",
      "good understanding of software-hardware performance\n",
      "strong knowledge and experience of software system design\n",
      "ability to understand data - thus, data analytical skills, designing systems based on understanding of data, experience with big data systems\n",
      "\n",
      "preferred qualifications:\n",
      "\n",
      "deep enough understanding of problems from business and product/user perspective; ability to adjust technical solution based on this\n",
      "ability to present things to top management in a clear and concise manner\n",
      "basic understanding of machine learning\n",
      "strong team player with ability to grow capacity of the team via development of team members\n",
      "ability to work smoothly with other stakeholders - product managers, project managers\n",
      "business oriented mindset\n",
      "\n",
      "soft skills:\n",
      "\n",
      "able to analytical thinking and result-orientation\n",
      "good english skills\n",
      "creative thinker and proactive problem solver\n",
      "good communication in both verbal and written\n",
      "well understanding of organizational structure and culture\n",
      "good organizational and time management skills;\n",
      "ability to be adapt quickly to changes\n",
      "\n",
      "---\n",
      "further information will be discussed in the interview!interested candidates, please\n",
      "================================================\n",
      "data-02-06/2126/data.html\n",
      "descriptionengage in the formulation, design and construction of a number of complex real-world industrial ai systemsplan, manage and execute at a fast-pace while maintaining high quality standardsmanage relationships with customers and lead both their ai system development, but also their education in ai system developmentmanage diverse teams of ai engineers, software developers, data scientist and domain experts to effectively complete projects on tight deadlineswork with customers to clear define problem statements and architect scalable solutionsgeneralize customer specific solutions making those tools and capabilities available to all customersdesign and develop ai models to meet project requirementsdesign and develop multi-microservice applications educate customers on the development of ai systems leverage available human expertise in the development of ai systems\n",
      "-----------------------------------------------\n",
      "job requirementmust-have:high proficiency in data management, data analysis and predictive modeling in pythonmachine learning / deep learning work experienceexperience integrating ml models into production systemsgreat-to-have:education or experience in physics or mechanical engineeringnice-to-have:ml ops (aws, k8s, helm)education: master’s degree or higher in computer science, computer engineering, physics or other science/engineering disciplineswhat's on offerawesome colleagueswe will match exceptional talent with exceptional compensation (salary and equity)\n",
      "================================================\n",
      "data-02-06/2242/data.html\n",
      "responsibilities\n",
      "the team\n",
      "on the outside our team resembles most others with a hierarchy, roles and responsibilities. on the inside we operate side by side and in a manner that would be described as flat. we believe in maintaining a safe environment where team members can express strong opinions that are loosely held, and work together to achieve consensus. we rely on each other to collectively deliver the highest quality data to our company and the industry at large.\n",
      "who we are looking for \n",
      "we are looking for a courageous senior data quality analyst to join our team to build new tools, infrastructure, frameworks and services. not only do we design, deploy and operate our organization's data infrastructure, but we are also a product team responsible for delivering data products. we are the “center of excellence” for data quality and lead an education program sharing our core competencies to help our company deliver the most accurate, accessible and up-to-date data in our industry. we believe that data can be beautifully designed, easy to understand and consume, and be user friendly. we just happen to make great data products too. if you also believe this, then we want to meet you.\n",
      "what you will work on \n",
      "you will work with a team on data collection, maintenance, synthesis, integration and publication to our internal services, partners and products. time and attention is placed on our infrastructure to identify and develop solutions that use the best tools and patterns for each engineering challenge. our solutions must be elegant and scalable so that we can quickly incorporate and integrate more datasets into our national backbone of all us residential properties, and extend the breadth and depth of our existing data taxonomy and innovate new high quality data products.\n",
      "key requirements\n",
      "\n",
      "minimum of eight (8) years \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2750/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            job purpose\n",
      "- đảm bảo hạ tầng và hệ thống dữ liệu / báo cáo tài chính luôn sẵn sàng với chất lượng tốt, ổn định phục vụ công tác phân tích và ra quyết định của các đơn vị và ban lãnh đạo\n",
      "- nghiên cứu ứng dụng các giải pháp công nghệ hữu ích vào trong công việc để nâng cao trải nghiệm người dùng và hiệu suất công việc\n",
      "- đảm bảo bộ khung quy định, quy trình quản trị dữ liệu ngân hàng được xây dựng và triển khai hiệu quả\n",
      "- xây dựng đội ngũ nhân sự quản trị dữ liệu\n",
      "các hoạt động chính\n",
      "1. xây dựng khung văn bản:\n",
      "- xây dựng các quy định, quy trình, tiêu chuẩn, mẫu biểu cho công tác phát triển, vận hành hệ thống cơ sở dữ liệu, báo cáo tài chính.\n",
      "2. quản lý vận hành phát triển hệ thống cơ sở dữ liệu:\n",
      "- định hướng, tư vấn và kiểm soát việc phát triển các giải pháp, công cụ khai thác dữ liệu, và hệ thống dữ liệu và báo cáo;\n",
      "- quản lý vận hành hệ thống server, database: tổ chức tối ưu lưu trữ lưu trữ vật lý các databases, datafiles; định kỳ bảo trì hệ thống, sắp xếp dữ liệu đảm bảo hiệu năng ổn định của hệ thống, đảm bảo tính bảo mật.\n",
      "- xây dựng quy chuẩn lập trình, các công cụ, package tiện ích nhằm tối ưu hóa trong việc phát triển dữ liệu; kiểm soát chất lượng, quy trình, quy chuẩn lập trình và có các hỗ trợ/tư vấn kỹ thuật kịp thời cho các thành viên trong team đảm bảo chất lượng đầu ra của dữ liệu.\n",
      "3. quản lý chất lượng dữ liệu\n",
      "- đánh giá hệ thống dữ liệu và các lỗi dữ liệu tiềm ẩn, đưa ra đề xuất chốt kiểm soát, xây dựng lộ trình phát triển các chốt kiểm soát nhằm tối ưu hóa chất lượng dữ liệu;\n",
      "- thực hiện vai trò data steward; quản lý bộ quy tắc chấm điểm chất lượng dữ liệu các yếu tố dữ liệu trọng yếu và các quy tắc phát hiện lỗi dữ liệu;\n",
      "4. lập kế hoạch năng lực\n",
      "- phân tích tình trạng hiện tại về tính sẵn có, khả năng đáp ứng của hệ thống cơ sở dữ liệu tài chính, tốc độ tăng trưởng của hệ thống dữ liệu, số lượng nghiệp vụ phát sinh mới, số lượng user, số lượng yêu cầu xử lý đồng thời (concurrent request) để tiến hành lập kế hoạch năng lực và kế hoạch mua sắm, nâng cấp hệ thống.\n",
      "5. quản lý dự án\n",
      "- tham gia các dự án của ngân hàng có liên quan đến dữ liệu và báo cáo tài chính: kiểm soát tiến độ phần công việc quản trị dữ liệu; phối hợp với khối cntt/ nhà thầu đánh giá yêu cầu thực hiện cũng như các ảnh hưởng liên quan tới số liệu tài chính; rà soát và xác nhận trên tài liệu phân tích nghiệp vụ. tham gia quá trình uat theo kế hoạch;\n",
      "6. quản lý con người\n",
      "- tuyển dụng, đào tạo hướng dẫn các cbnv trong đơn vị để nâng cao kiến thức, \n",
      "-----------------------------------------------\n",
      "kinh nghiệm chuyên môn, kĩ năng của các thành viên; tư vấn và hỗ trợ kịp thời cho các thành viên khi có vướng mắc hoặc phương án xử lý tối ưu trong nhóm;\n",
      "7. khác\n",
      "- đưa ra các đề xuất nhằm nâng cao hiệu quả công việc. thực hiện các công việc khác theo sự phân công của trưởng phòng.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "================================================\n",
      "data-02-06/2514/data.html\n",
      "================================================\n",
      "data-02-06/2427/data.html\n",
      "mô tả công việc\n",
      "\n",
      "cung cấp thông tin chuyên sâu dựa trên dữ liệu cho người dùng bằng cách sử dụng các kỹ thuật khai thác dữ liệu, báo cáo dashboard, thực hiện phân tích thống kê trên các bộ dữ liệu lớn và xây dựng các hệ thống dự đoán chất lượng cao \n",
      "làm việc chặt chẽ với đầu mối nghiệp vụ về dữ liệu, các đơn vị liên quan và cung cấp dữ liệu chuyên sâu cần thiết cho các yêu cầu phân tích, đánh giá.\n",
      "xử lý, vận hành kho dữ liệu đảm bảo chất lượng và tính kịp thời. cung cấp thông tin, dữ liệu quản trị cho các đơn vị theo yêu cầu.\n",
      "\n",
      "\n",
      " xây dựng các mô hình phân tích dữ liệu nhằm mục tiêu tìm ra các cơ hội, tối ưu hệ thống, giải quyết các bài toán nhân sự và kinh doanh thực tế\n",
      " tự động hóa/hỗ trợ tự động hóa các báo cáo định kỳ để nâng cao năng suất lao động\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "trình độ đại học trở lên chuyên ngành toán – tin, công nghệ thông tin, hệ thống thông tin kinh tế\n",
      "có ít nhất 1 năm kinh nghiệm trong ngành cntt, phân tích dữ liệu\n",
      "có khả năng truy vấn, truy xuất dữ liệu (sql, oracle)\n",
      "kỹ năng báo cáo, phân tích sử dụng đa công cụ (excel, tableau, power bi,…)\n",
      "\n",
      "có khả năng phân tích dữ liệu bằng các ngôn ngữ python, r,..)\n",
      "\n",
      "có kiến thức tốt về toán logic, toán thống kê, quản trị kho dữ liệu\n",
      "có kỹ năng làm việc nhóm và giải quyết vấn đề\n",
      "kỹ năng quản lý tổ chức và quản lý công việc\n",
      "kỹ năng quản lý nhân sự\n",
      "kỹ năng đánh giá, phân tích\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/588/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responsibilities\n",
      "working with data engineers to conduct the whole data analytics workstream from eda to build customized predictive modeling use-cases like segmentation, future lifetime customer value, churn prediction, cross-sell prediction…translating data insights into tangible business advice.extracting actionable insights from large customer datasets, and working with csm team to propose strategic/tactical data activation use-cases. presenting research results to clients.implementing customer analytics toolkits/training projects for internal csm/po team.\n",
      "\n",
      "-----------------------------------------------\n",
      "job requirements:\n",
      "b.sc. engineering, computer science, data science, or related majors.solid experience in data analytics specializing in customer data use-cases for a b2c business model: retail, banking, fintech, services, f&b…experiences with supporting business stakeholders with their data-driven marketing/product/cx optimization projects are an advantage\n",
      "================================================\n",
      "data-02-06/1159/data.html\n",
      "responsible for:\n",
      "leadership role:\n",
      "\n",
      "play a first and foremost leader and founder within the department overseeing all activities of the data analytics and data warehousing departments\n",
      "lead the recruitment and development of the team\n",
      "lead initiatives to improve performance across the business, such as: personalizing user \n",
      "-----------------------------------------------\n",
      "experience on the engagement & loyalty mobile app, optimizing analytics efficiency and cost, and optimizing individual department operation\n",
      "work closely with other departments and stakeholders, including ceo, business, product, finance, marketing, tech, and senior management, to ensure that data-related goals and initiatives are aligned with the organization’s overall strategy\n",
      "\n",
      "strategy & analytics:\n",
      "\n",
      "lead the data analytics and data warehousing departments in strategy development with regard to the collection, manipulation, and analysis of data for various business functions/departments such as marketing, sales, and operations, among others\n",
      "endeavor to create new data-driven approaches for the purpose of generating business insights through data analytics, information visualization, and addressing unanswered business issues in a proactive manner.lead the team in building data governance framework to provide trusted data across functions\n",
      "in-charge of strategic products including: customer segmentation, personalization engine, anti-fraud engine etc.\n",
      "keeping up with industry trends and best practices, applying new technologies and techniques to enhance the organization’s data strategy\n",
      "\n",
      "data management:\n",
      "oversee and participate in data management activities, including:\n",
      "\n",
      "define, build, and manage the organization’s data architecture, including data models, data flows, data integration patterns, data pipelines, data processing, data warehouses, data marts…\n",
      "collect and centralize data from various sources, including internal systems, external partners, and third-party providers.\n",
      "ensure data privacy and security with appropriate policies and security measures.\n",
      "ensure data quality and accuracy with appropriate data quality checks and controls are in place.\n",
      "manage data throughout its lifecycle, from creation to retirement, to optimize its value and minimize risks.\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/822/data.html\n",
      "mô tả công việc vị trí data warehouse engineer\n",
      "\n",
      "thiết kế kiến trúc và giải pháp dữ liệu cho data warehouse/data lake\n",
      "tham gia quy trình xây dựng và bảo trì model elt data phục vụ cho nhu cầu report & dashboard, data mining, data modelling\n",
      "phân tích yêu cầu của người dùng, đề xuất phương án biến đổi, làm sạch (data pipeline)\n",
      "tham gia vào thiết kế và phát triển tích hợp các nguồn dữ liệu khác nhau (oracle database, sql server, api, web service, excel…)\n",
      "tối ưu hóa csdl và duy trì nâng cấp các chuẩn kiến trúc của dữ liệu\n",
      "xây dựng các tài liệu thiết kế tổng thể, giải pháp, thiết kế chi tiết, tài liệu giám sát.\n",
      "\n",
      "yêu cầu chung\n",
      "\n",
      "trình độ học vấn: tốt nghiệp đại học các trường chuyên ngành công nghệ thông tin, toán tin, khoa học dữ liệu, …\n",
      "thành thạo về sql và có \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2647/data.html\n",
      "mô tả công việc\n",
      "– xây dựng và ứng dụng các công nghệ về mảng computer vision vào các bài toán antifraud\n",
      "(image recapture v.v.) trong dự án ekyc, ocr và giải quyết các bài toán cụ thể của đơn vị để tối\n",
      "ưu chi phi mang lại giá trị lớn cho ghtk.\n",
      "ii. yêu cầu\n",
      "– có \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/942/data.html\n",
      "================================================\n",
      "data-02-06/2709/data.html\n",
      "mô tả công việc\n",
      "• tham gia dự án thực tế về trong lĩnh vực tài chính, viễn thông, ngân hàng, bảo hiểm, v.v..• vận hành, triển khai các job etl, tổng hợp dữ liệu và xuất dữ liệu theo yêu cầu.• xây dựng & triển khai các hệ thống data warehouse, data mart và data lake cho các dự án thực tế. • tham gia và triển khai các dịch vụ sử dụng các công nghệ bigdata: hadoop, spark, …\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "• trình độ đại học trở lên, học chuyên ngành công nghệ thông tin, hệ thống thông tin hoặc các chuyên ngành liên quan tại các trường đại học công nghệ, đại học công nghiệp, học viện bưu chính viễn thông, đại học bách khoa v,v...• có kinh nghiệm sử dụng ngôn ngữ lập trình python• có kinh nghiệm sử dụng sql• có hiểu biết về elasticsearch, mongodb là một lợi thế• có hiểu biết về airflow, spark là một lợi thế• có kĩ năng làm việc nhóm và độc lập.• nhanh nhẹn, có khả năng tự học tốt và có tinh thần trách nhiệm cao.\n",
      "quyền lợi\n",
      "• nhân viên lương cứng 7 - 12 triệu theo năng lực.• sau khi ký hợp đồng chính thức sẽ được hưởng chế độ thưởng theo quy định công ty.nghỉ phép 12 ngày/năm, nghỉ ốm/nghỉ chế độ thai sản/hiếu hỉ… theo quy định pháp luật lao động, bảo hiểm xã hội• du lịch hàng năm, teambuilding, event.• được tài trợ, tham gia các khóa đào tạo kỹ năng, chuyên môn hàng năm, thi lấy chứng chỉ để phục vụ cho công việc.• review đánh giá công việc 2 lần/ năm;• có khả năng phát triển bản thân, định hướng phát triển công việc lâu dài;• môi trường trẻ, năng động, chuyên nghiệp, được khuyến khích sáng tạo và phát triển các ý tưởng mới, sếp trẻ tâm lý, đồng nghiệp thân thiện, văn hóa trao đổi thẳng thắn, cởi mở trên tinh thần hỗ trợ cùng phát triển;• học hỏi kinh nghiệm trực tiếp từ các senior, chuyên gia giàu kinh nghiệm;\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 07/06/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2057/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            job purpose: identifies and translates business demands/requirements into analytics use cases; manages analytics projects; drives the implementation of solutions across the business and promotes cost effective scaling\n",
      "\n",
      "•articulate analytics propositions to business stakeholders, and collaborate with the business to identify and scope new use case opportunities, defines the mvp and protects projects’ scope \n",
      "•support advanced analytics team by providing clear inputs (e.g. requirements) to them from the business teams; works with analytics teams to confirm assumptions and ensure models and outputs will meet business requirements (alongside the product owner)\n",
      "•lead communication of analytics outputs with executives; act as bridge between management and analytics specialists; share insights with business stakeholders and collects inputs\n",
      "•strategic data driven business partner, supports defining roadmaps, builds the organization-wide analytics capability\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1412/data.html\n",
      "responsibility partnership program how we work \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2885/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "                                                                                            know your customer verification\n",
      "\n",
      "1.developing and implementing data analysis tools and techniques for transaction monitoring.\n",
      "2.analyzing transactional data to detect any suspicious activity or patterns that may indicate money laundering or other financial crimes and recommend appropriate treatments.\n",
      "3. preparing reports and presenting findings to management and other stakeholders.\n",
      "4. collaborating with compliance officers and other stakeholders to ensure compliant with all relevant regulations.\n",
      "5. contribute to the development of re-engineering methods to improve processes, reduce risks, increase controls and/or increase efficiency.\n",
      "\n",
      "team performance\n",
      "\n",
      "1. developing and implementing data analysis tools and techniques for team's performance monitoring.\n",
      "2. creating visualizations and reports to effectively communicate data insights to ops supervisors and management.\n",
      "3. developing and implementing data analysis tools and techniques to improve kyc processes.\"\n",
      "\n",
      "kyc reporting\n",
      "\n",
      "1. provide robust analysis and insight by identifying issue and trends in order to present monthly reports.\n",
      "2. analyzing data to identify potential issue and trends that could impact the kyc operations.\n",
      "3. communicate kyc analysis findings and work with management to come up with recommendations to inform decision making.\n",
      "4. create reports and presentations that summarize kyc findings and recommendations.\n",
      "5. collaborate with management and other departments or teams to ensure consistency and alignment of kyc verification practices.\n",
      "\n",
      "project contribution\n",
      "\n",
      "1. delivers delegated tasks and contributes in accomplishing team projects/ initiatives assigned by the kyc supervisor in order to improve kyc systems and processes.\n",
      "\n",
      "development\n",
      "\n",
      "1. participate in required compliance trainings in order to satisfy regulatory and business partner's requirements.\n",
      "2.behavioral and pattern analytics\n",
      "3. conduct research to stay informed on industry trends and emerging risks that could impact the organization.\n",
      "4. to promote risk awareness culture within the company.\"\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2931/data.html\n",
      "description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "skills required\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "details\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- chịu trách nhiệm thực hiện/chuẩn bị các báo cáo quản trị, báo cáo ngân sách / to be responsible for preparing management reports and budgeting reports.- thực hiện phân tích các báo cáo quản trị hàng tháng để tư vấn cho giám đốc tài chính / to analyze monthly management report to give recommendation to cfo.- thực hiện theo dõi và phân tích tình hình thực hiện ngân sách / to monitor budget performance and analysis.- chuẩn bị phương án kinh doanh cho các dự án đầu tư tài sản mới / to prepare business case for new project or capex investment.- thực hiện các công việc khác theo sự phân công của giám đốc tài chính / to do the other jobs under the assignment of cfo\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "required experience / skills detail\n",
      "\n",
      "\n",
      "\n",
      "- tốt nghiệp đại học chuyên ngành về kinh tế, ưu tiên tài chính và kế toán / university graduated of economy especially in finance or accounting- tiếng anh thành thạo (nghe, nói, đọc, viết) / fluency in english (reading, listening, speaking, writing).- trình độ vi tính : sử dụng thành thạo các phần mềm words, excel, power point / computer skills: word, excel, power point.- 1 hoặc 2 năm \n",
      "-----------------------------------------------\n",
      "kinh nghiệm tại vị trí tương đương hoặc kế toán/kiểm toán / have 1 or 2 years of experience in similar position or accounting/auditing.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job detail\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "position type\n",
      "\n",
      "full-time\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "career level\n",
      "\n",
      "staff\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "education level\n",
      "\n",
      "bachelor's degree\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gender\n",
      "\n",
      "male / female\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job categories\n",
      "\n",
      "\n",
      "accounting / audit\n",
      "\n",
      ", \n",
      "\n",
      "finance / investment\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "information\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "name:\n",
      "\n",
      "\n",
      "hcns\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "18 đại lộ bình dương, vĩnh phú\n",
      "\n",
      ", \n",
      "\n",
      "thuan an city\n",
      "\n",
      ", \n",
      "\n",
      "binh duong\n",
      "\n",
      ", \n",
      "\n",
      "viet nam\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- các ứng viên quan tâm vui lòng gửi hồ sơ trực tuyến, gửi kèm file hoặc trực tiếp đến tại công ty.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "application language:\n",
      "vietnamese\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "công ty cổ phần bệnh viện đa khoa quốc tế hạnh phúc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "http://www.hanhphuchospital.com\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "500 - 999 employees\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact: hcns\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bệnh viện quốc tế hạnh phúc cung cấp các tiện nghi và dịch vụ y tế toàn diện trong lĩnh vực chăm sóc sức khỏe với trọng tâm là ngành sản-phụ khoa và nhi khoa.\n",
      "phương châm của hạnh phúc là \"đón mừng cuộc sống\" phản ánh chính xác tinh thần các dịch vụ mà chúng tôi cung cấp.\n",
      "chúng tôi đang tìm kiếm các cá nhân năng động để cùng chia sẻ hoài bão và là một phần của hạnh phúc.\n",
      "gia nhập với chúng tôi, các bạn sẽ có được:\n",
      "- môi trường làm việc thử thách, năng động, chuyên nghiệp\n",
      "- đào tạo phù hợp với yêu cầu công tác\n",
      "- thu nhập hấp dẫn tương xứng với khả năng làm việc\n",
      "- công việc ổn định và cơ hội thăng tiến trong nghề nghiệp\n",
      "- có xe đưa đón nhân viên từ tp hồ chí minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "see more\n",
      "\n",
      "\n",
      "\n",
      "see less\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "other jobs from this company\n",
      "\n",
      "|\n",
      "\n",
      "see all\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[hcm] finance analyst\n",
      "\n",
      "\n",
      "công ty cổ phần bệnh viện đa khoa quốc tế hạnh phúc\n",
      "\n",
      "\n",
      "\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "chuyên viên pháp lý cao cấp\n",
      "\n",
      "\n",
      "công ty cổ phần bệnh viện đa khoa quốc tế hạnh phúc\n",
      "\n",
      "\n",
      "\n",
      "binh duong\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "work location\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "18 đại lộ bình dương, vĩnh phú, thuan an city, binh duong\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tags\n",
      "\n",
      "\n",
      "\n",
      "thuan an town\n",
      "finance\n",
      "phân tích tài chính\n",
      "finance analyst\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "share\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "copied\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/554/data.html\n",
      "================================================\n",
      "data-02-06/682/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "làm việc với các bộ phận liên quan để lấy yêu cầu, đề xuất các kpis cần thiết trong việc xây dựng các trang báo cáo;\n",
      "phối hợp chặt chẽ với team it để thiết kế mô hình dữ liệu - data warehouse;\n",
      "quản lý, trích xuất và xử lý dữ liệu phục vụ cho các phân tích;\n",
      "phân tích và đề xuất thiết kế tính năng cho các báo cáo phục vụ hoạt động quản trị;\n",
      "phụ trách phát triển data marts và reports/dashboards thông minh cho khối;\n",
      "trình bày hiểu biết sâu sắc và đề xuất phương án để nâng cao trải nghiệm sử dụng báo cáo;\n",
      "hỗ trợ ra quyết định cho giám đốc khối;\n",
      "xây dựng, tối ưu hóa và đảm bảo chất lượng dữ liệu;\n",
      "rà soát và tối ưu code sql/plsql;\n",
      "lên kế hoạch, sắp xếp ưu tiên công việc, hoàn thành và bàn giao kết quả công việc đúng thời hạn, etc…\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2543/data.html\n",
      "responsible for key data engineering initiatives spanning our work in product analytics, machine learning and search. \n",
      "here are some examples of projects we have tackled that you may be excited to lead:\n",
      "\n",
      "releasing public data to the wikimedia community and the world at large. our public data offerings are used all over the world by companies and research institutions big and small. a popular example is the wikipedia clickstream (a.k.a. wikipedia's rabbit hole)\n",
      "deploying an anomaly detection system to monitor wikipedia accessibility over the world and detect possible outages (or censorship events)\n",
      "implementing and driving adoption of the data catalog\n",
      "migrating oozie and other bespoke data pipelines to apache airflow and spark 3\n",
      "evangelize privacy conscious ways to compute metrics. privacy is key to the work we do\n",
      "\n",
      "we are a fully remote, internationally distributed team. we see each other in person 1-2 times a year during one of our off-sites (the last few have been in places like berlin, copenhagen and new york) or wikimania, the annual international conference for the wiki community.\n",
      "open to candidates located in timezones utc-8 to utc+2\n",
      "you are responsible for:\n",
      "\n",
      "manage a fully remote, globally-distributed team of data engineers\n",
      "coach and develop the team to meet their individual and collective goals\n",
      "help deliver data services to provide accessible, trusted data for insights, research and product reuse\n",
      "partner closely with other teams and departments across the wikimedia foundation to deliver data solutions\n",
      "work with product and program management to develop and implement the data engineering roadmap in an agile, iterative manner\n",
      "ensure data is available, reliable, consistent, accessible, secure, and available in a timely manner for external and internal stakeholders and in accordance with our privacy policy\n",
      "balance innovation, evolution and addressing technical debt\n",
      "review and advice in code changes and technical decisions made by team\n",
      "help formalize and improve engineering processes \n",
      "develop an inclusive culture that is innovative and collaborative, both within your team and in the broader organization\n",
      "\n",
      "skills and experience:\n",
      "\n",
      "4+ years of engineering management or technical leadership experience\n",
      "experience working with diverse and remote teams\n",
      "experience supporting multiple teams of data analysts\n",
      "knowledge of best practices in the design of data warehouses and data products\n",
      "deep understanding of challenges of delivering data products at scale\n",
      "expert experience working with data engineering tools and frameworks, processes and methodologies \n",
      "experience building data pipelines using tools such as airflow, spark, gobblin, yarn\n",
      "experience with one or more programming languages:python, scala, and java\n",
      "experience with data query and manipulation languages including sql\n",
      "experience with data visualization, preferably superset \n",
      "experience with automated testing and continuous integration\n",
      "solid judgment and ability to prioritize\n",
      "strong customer focus\n",
      "excellent written and verbal communication skills\n",
      "bs or ms degree, preferably in computer science, or equivalent work experience\n",
      "\n",
      "qualities that are important to us:\n",
      "\n",
      "commitment to the mission of the organization and our values\n",
      "commitment to our guiding principles\n",
      "commitment to diversity, equity, and inclusion\n",
      "cross-cultural sensitivity and awareness\n",
      "collaborative working experience\n",
      "\n",
      "about the wikimedia foundation\n",
      "the wikimedia foundation is the nonprofit organization that operates wikipedia and the other wikimedia free knowledge projects. our vision is a world in which every single human can freely share in the sum of all knowledge. we believe that everyone has the potential to contribute something to our shared knowledge, and that everyone should be able to access that knowledge freely. we host wikipedia and the wikimedia projects, build software experiences for reading, contributing, and sharing wikimedia content, support the volunteer communities and partners who make wikimedia possible, and advocate for policies that enable wikimedia and free knowledge to thrive. \n",
      "the wikimedia foundation is a charitable, not-for-profit organization that relies on donations. we receive donations from millions of individuals around the world, with an average donation of about $15. we also receive donations through institutional grants and gifts. the wikimedia foundation is a united states 501(c)(3) tax-exempt organization with offices in san francisco, california, usa.\n",
      "as an equal opportunity employer, the wikimedia foundation values having a diverse workforce and continuously strives to maintain an inclusive and equitable workplace. we encourage people with a diverse range of backgrounds to apply. we do not discriminate against any person based upon their race, traits historically associated with race, religion, color, national origin, sex, pregnancy or related medical conditions, parental status, sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, or any other legally protected characteristics.\n",
      "the wikimedia foundation is a remote-first organization with staff members including contractors based in more than 50 countries. salaries at the wikimedia foundation are set in a way that is competitive, equitable, and consistent with our values and culture. the anticipated annual pay range of this position for applicants based within the united states is us$ 136,761  to us$ 217,146  with multiple individualized factors, including cost of living in the location, being the determinants of the offered pay. for applicants located outside of the us, the pay range will be adjusted to the country of hire. we neither ask for nor take into consideration the salary history of applicants. the compensation for a successful applicant will be based on their skills, experience and location. \n",
      "all applicants can reach out to their recruiter to understand more about the specific pay range for their location during the interview process.\n",
      "if you are a qualified applicant requiring assistance or an accommodation to complete any step of the application process due to a disability, you may contact us at recruiting@wikimedia.org or +1 (415) 839-6885.\n",
      "more information\n",
      "u.s. benefits & perkswikimedia foundationapplicant privacy policynews from across the wikimedia movementblogwikimedia 2030our commitment to equitythis is wikimedia foundation facts matterour projectsour tech stack\n",
      "-----------------------------------------------\n",
      "experienced engineering manager to join the data engineering team. at the wikimedia foundation, we operate the world’s largest collaborative project: a top ten website, reaching a billion people globally every month, while incorporating the values of privacy, transparency and community that are so important to our users.\n",
      "working closely with other technology and product teams, as well as our community of contributors and readers, you will help deliver the next generation of data usage, analysis and access across all wikimedia projects.\n",
      "this role is responsible for key data engineering initiatives spanning our work in product analytics, machine learning and search.\n",
      "================================================\n",
      "data-02-06/143/data.html\n",
      "mô tả công việc\n",
      "- xây dựng các data models, pipelines trên cơ sở hạ tầng đám mây, sử dụng sql / javascript / python- khai thác dữ liệu, xây dựng, cập nhật và duy trì các báo cáo, số liệu quan trọng để theo dõi hiệu quả hoạt động kinh doanh- sở hữu và cải tiến các chỉ số phân tích đầu cuối nâng cao, từ trích xuất dữ liệu đến phân tích và trình bày những kiến thức chuyên sâu, nắm bắt xu hướng và sự bất thường trên thị trường để trả lời các câu hỏi quan trọng định hướng phát triển của doanh nghiệp- phối hợp cùng với nhóm data engineer, đảm bảo chất lượng dữ liệu ở mức cao để phục vụ như nguồn thông tin hữu ích cho toàn tổ chức- làm việc với nhóm quản lý và sản phẩm để tạo danh sách ưu tiên các nhu cầu cho từng phân khúc kinh doanh để hiểu và giúp họ tìm ra thông tin chi tiết từ dữ liệu- tham gia vào quá trình phát triển sản phẩm bằng cách tư vấn cho nhóm sản phẩm và cntt với các yêu cầu về số liệu và dữ liệu có liên quan- xác định và đề xuất các cách mới để tiết kiệm chi phí bằng cách hợp lý hóa các quy trình kinh doanh- thời gian làm việc: 8h-17h, nghỉ các chủ nhật\n",
      "yêu cầu\n",
      "- có ít nhất 01 năm \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1642/data.html\n",
      "================================================\n",
      "data-02-06/2586/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "be a member of a dedicated team\n",
      "program new scripts to crawl new sites, new strategies to overcome technical difficulties (ip blocked, encrypted data,..)\n",
      "keep on optimizing crawling process\n",
      "design and implement a web app about real estate\n",
      "communicate with clients on innovations or improvements.\n",
      "research machine learning model, visualize data (language, number)\n",
      "other works according to project requirements\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "\n",
      "at least 2+ years using linux os, bash script\n",
      "familiar with\n",
      "================================================\n",
      "data-02-06/835/data.html\n",
      "================================================\n",
      "data-02-06/1830/data.html\n",
      "================================================\n",
      "data-02-06/2967/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "build, release, and manage the configuration of all production systems,manage a continuous integration and deployment methodology for server-based technologieswork alongside architecture and engineering teams to design and implement any scalable software servicesensure necessary system security by using best in class cloud security solutionsstay current with new technology options and vendor products, evaluating which ones would be a good fit for the companyimplement continuous integration/continuous delivery (ci/cd) pipelines when necessaryrecommend process and architecture improvementstroubleshoot the system and solve problems across all platform and application domains.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "6 months experience using awsexperience designing and building web environments on aws, which includes working with services like (ec2, s3, route53, lambda, cloudwatch,…)experience building and maintaining cloud-native applicationsa solid background in linux/unix and windows server system administrationexperience using devops tools in a cloud environment, such as ansible, artifactory, docker, github, jenkins, kubernetes, maven, and sonar qubeexperience using monitoring solutions like cloudwatch, zabbix, grafanaan understanding of writing infrastructure-as-code (iac), using tools like cloudformation or terraformknowledge of one or more of the most-used programming languages like python, bash shell, power shell\n",
      "quyền lợi\n",
      "highly competitive salary and bonus, plus several additional benefitsearnings up to 13 months salary/year (including salary and bonus)consider periodic salary increasesopportunity to work on challenging projectsjoin insurance according to vietnamese labor law (social insurance, health insurance, unemployment insurance)\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 24/06/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2461/data.html\n",
      "descriptionthe bosch group is a leading global supplier of technology and services. in 2013, its roughly 281,000 associates generated sales of 46.4 billion euros. since the beginning of 2013, its operations have been divided into four business sectors: automotive technology, industrial technology, consumer goods, and energy and building technology. the bosch group comprises robert bosch gmbh and its roughly 360 subsidiaries and regional companies in some 50 countries. if its sales and service partners are included, then bosch is represented in roughly 150 countries. this worldwide development, manufacturing, and sales network is the foundation for further growthbgsv - bosch global software technologies vietnam company limited is 100% owned subsidiary of robert bosch gmbh. bgsv has started its operations from 19th october, 2010 at e-town2 in hcmc. this engineering development center will be engaged in developing embedded systems and software, mechanical design and simulation, and will provide it (sap consulting, java development….) and business services (finance and accounting, economics, purchasing, logistics, translations japanese-english-japanese, information security ) solutions to the bosch group of companies globally. job descriptionbusiness enhancement by combining various aspects of business management and information technology in order to fully integrate computer science and businessbe part of financial related tools/systems development from planning to actual with good logic and financial background/insightsbe the champion in data analysis/data science with good visualization in power bi or any other developed platformbe a part of internal process/tools management, development and harmonization by working with various stakeholders within bgsv as well as central team in germany/indiadevelop automated/ dashboard reporting to transform data into valuable insights and real-time analysisbuild and ensure internal control system is operate effectivelyother tasks as required by manager from time to time\n",
      "-----------------------------------------------\n",
      "qualificationsbachelor’s degree in accounting/finance/business informaticsat least 4 years in same or similar roleacquire strong analytical (quantitative as well as qualitative) skills including building models, prior data miningfamiliar with microsoft excel, power bi, sap and all other financial systemsself-starter with the ability to streamline functions and passion to learn and growmust possess excellent communication and presentation skills in english and vietnamese, and be comfortable interacting with executive-level managementwork and collaborate well with team-matesadditional informationwhy\n",
      "================================================\n",
      "data-02-06/845/data.html\n",
      "descriptionreporting to the head of operation you will be responsible for:* the role:this role requires the candidate to develop a strong grasp of the data available across daily cs operation such as kpis of cs team/ cs project (chatbot/automation system/ etc.) to assist the wider commercial & partnerships team in planning and executionassist the wider team with the use of data analytics to explore growth areas, drive impact for different initiatives and improve merchant-partner performance* operation â daily tasks:understanding the flow and logic of developing & building intent for chatbot, from tech's documentsmonitoring, evaluating, recording, and fixing errors during rolling out/launching a chatbot on a new storemonitoring, training (updating the ai) for chatbot during official operation* development - project-based tasks:working with internal cs agents to build up the knowledgebase - faqs for chatbot effectivelybuilding and expanding new bots for new stores, based on existing knowledgebase & intent scenariosassist the team with ad-hoc tasks assigned by line manage\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2773/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            1. quản lý bán hàng:\n",
      "- quản lý và theo dõi tốc độ bán hàng của nhân viên bán hàng (theo sku/ brand/...)\n",
      "- theo dõi tình hình pos / kho hàng trên thị trường\n",
      "- hỗ trợ trưởng nhóm kinh doanh và nhân viên kinh doanh trong việc cải thiện hiệu suất bán hàng\n",
      "\n",
      "2. quản lý thương hiệu:\n",
      "- theo dõi và quản lý chỉ số tăng trưởng của từng nhãn hiệu được phân công\n",
      "- lập kế hoạch phát triển doanh số, độ phủ, tốc độ bán hàng, tồn kho và trưng bày của từng nhãn hiệu\n",
      "- lập kế hoạch phát triển nhãn hiệu mới theo từng giai đoạn\n",
      "\n",
      "3. lập kế hoạch\n",
      "- đưa ra mục tiêu doanh số, mục tiêu tăng trưởng của các lĩnh vực phù hợp\n",
      "- xây dựng kế hoạch phát triển thị trường, đề ra mục tiêu và phương hướng cụ thể\n",
      "- xây dựng kế hoạch phát triển thương hiệu mới\n",
      "- xây dựng kế hoạch theo yêu cầu phát sinh của cấp trên\n",
      "\n",
      "4. báo cáo\n",
      "- thực hiện các báo cáo theo yêu cầu của cấp trên\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2927/data.html\n",
      "mô tả công việccoordinate, analyze daily, weekly and monthly reports on operational activities for the management team (excel, power bi..)assist in analyzing cost related reports & find opportunities to minimize/exploit costs;monthly analyze p&l and follow-up actual results in comparison with budget/targetother tasks as assigned by direct managers.\n",
      "-----------------------------------------------\n",
      "experience in the e-commerce industry.we are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end-to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.mô tả công việccoordinate, analyze daily, weekly and monthly reports on operational activities for the management team (excel, power bi..)assist in analyzing cost related reports & find opportunities to minimize/exploit costs;monthly analyze p&l and follow-up actual results in comparison with budget/targetother tasks as assigned by direct managers.\n",
      "================================================\n",
      "data-02-06/2755/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi tiết công việc demand planning specialist tại công ty con cưng (concung.com)\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1172/data.html\n",
      "responsibilities: \n",
      "\n",
      "\n",
      "support brand, marketing and communication business\n",
      "\n",
      "\n",
      "support quality and management of the internal and/or external communications initiatives to support communications\n",
      "\n",
      "\n",
      "preparation, implementation & evaluation of event plan; ensure marketing campaign efficiency and effectiveness to reach the defined brand goals\n",
      "\n",
      "\n",
      "develop relevant content & coordinate with business team and other stakeholders to communicate and acquire adequate resources to ensure effectiveness of outputs\n",
      "\n",
      "\n",
      "conduct market researches & update business intelligence\n",
      "\n",
      "\n",
      "​\n",
      "apply now \n",
      "email your cv to recruitment@cel-consulting.com \n",
      "or apply online at\n",
      "​\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2558/data.html\n",
      "description\n",
      "\n",
      "                                                                                            1. xây dựng và vận hành kho dữ liệu:\n",
      "- làm việc với các team erp, software, các đối tác và phòng ban chức năng để xác định luồng đi và ý nghĩa của dữ liệu\n",
      "- thiết kế các phương án thu thập dữ liệu, các tiêu chuẩn thu thập, đảm bảo việc thu thập và ghi nhận dữ liệu đúng và phù hợp cho việc khai thác/ ứng dụng.\n",
      "- thực hiện các công việc etl, tạo và quản lí các nguồn kết nối với kho dữ liệu\n",
      "- làm việc với các team phân tích để thiết kế những bộ dữ liệu phù hợp cho hệ thống báo cáo\n",
      "- cập nhật những thay đổi trong các bộ dữ liệu theo quá trình chuyển đổi của business và các nhu cầu khai thác\n",
      "- xây dựng các tài liệu liên quan đến kiến trúc và định nghĩa dữ liệu\n",
      "\n",
      "2. cải tiến, nâng cấp hiệu suất của kho dữ liệu:\n",
      "- xây dựng những kiến trúc dữ liệu phù hợp với nhu cầu từ các đội phân tích, khoa học dữ liệu, học máy và người dùng\n",
      "- làm việc với các team kỹ thuật công nghệ để cải thiện hạ tầng, môi trường kho dữ liệu,  tư vấn và xây dựng những giải pháp để dữ liệu có thể được lưu trữ nhiều hơn, đa dạng hơn, truy vấn nhanh hơn và tiết kiệm chi phí\n",
      "- nắm bắt chi phí và khả năng đáp ứng của kho dữ liệu, liên tục theo dõi, cảnh báo và xử lí nhanh nhất có thể khi có sự cố phát sinh để đảm bảo hệ thống báo cáo và các sản phẩm dữ liệu khác hoạt động trơn tru hiệu quả\n",
      "\n",
      "3) minh bạch và an toàn dữ liệu:\n",
      "- xây dựng và quản lí các kết nối vào và ra từ kho dữ liệu\n",
      "- đảm bảo các kết nối được ổn định và an toàn\n",
      "- theo dõi và cảnh báo nếu có bất kì vấn đề gì khiến dữ liệu có thể bị sai lệch, lấy cắp, dùng sai mục đích\n",
      "                                                                                    \n",
      "read full job descriptions\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2792/data.html\n",
      "description\n",
      "\n",
      "essential duties:\n",
      "consult the ceo and execute the data-driven strategy to achieve the business objectives.\n",
      "build/lead bi team to fit the strategic plan.\n",
      "has worked directly for a ceo\n",
      "support design & build data warehouse.\n",
      "directly working with the us manager to deliver tasks.\n",
      "interpret data with regard to financials / operations / inventory\n",
      "design, validate/test, and maintain the report system to fit all requirements.\n",
      "present the report/findings (in english) to stakeholders\n",
      "active working with stakeholders to propose new ideas – execute the ideas to help the business achieve the overall goal\n",
      "\n",
      "\n",
      "your skills and \n",
      "-----------------------------------------------\n",
      "experience\n",
      "\n",
      "qualifications/experience:\n",
      "5+ years’ experience as a data analyst or business intelligence analyst.\n",
      "proficient use of microsoft sql.\n",
      "proficient use of power bi.\n",
      "perfect english skills.\n",
      "have a good understanding of the data warehouse\n",
      "excellent presentation and data visualization skills.\n",
      "excellent communication skills.\n",
      "degree in data science / data analysis / mathematics is a plus.\n",
      "knowledge about the process of a production company is a plus.\n",
      "has worked with an investment company is a plus\n",
      "worked in us market or used to study in us is a plus\n",
      "================================================\n",
      "data-02-06/2188/data.html\n",
      "description\n",
      "\n",
      "\n",
      "life at agoda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "all teams\n",
      "contentcustomer \n",
      "-----------------------------------------------\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "analyst/senior analyst (flights team, bangkok-based, relocation provided)\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "================================================\n",
      "data-02-06/1934/data.html\n",
      "responsibilities: \n",
      "building a cloud sourcing system that pulls data from tens of thousands tables on-premises, and hundreds of data source systems (rdbms, file server, kafka,...) designing change data capture method for each source system\n",
      "designing and implementing a big data management system by leveraging lambda/delta/kappa architecture concept\n",
      "implementing data replication/projection lag from techcombank on-premises to techcombank data lake on cloud in real-time processing or batch model with high performance - scalable aws services like kinesis, firehose, glue (spark), lambda,...\n",
      "serving analytics data of ten million techcombank customers to other techcombank internal teams, providing hundreds of millions of data elements daily through high throughput, low latency protocols (websocket, message queue, rest, graphql,...)\n",
      "collaborating with the data architect team on regular basis to design/review data models, and application architectures \n",
      "maintaining software clean architecture, clean code, and high quality. participating in code reviews, pair programming, mob programming, and coaching other members\n",
      "providing data features infrastructure to empower ml engineering in various bank businesses\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/790/data.html\n",
      "description:\n",
      "– planning, studying, and collecting data to determine costs of business activity such as raw material purchases, inventory and labor\n",
      "– analyzing data collected and recording results\n",
      "– analyzing changes in product design, raw materials, manufacturing methods or services provided, to determine effects on cost\n",
      "– analyzing actual manufacturing costs and preparing periodic reports comparing standard costs to actual production costs\n",
      "– recording cost information for use in controlling expenditures\n",
      "– making estimates of new and proposed product costs\n",
      "– maintaining cost accounting system \n",
      "requirements:\n",
      "– proven 3 years work \n",
      "-----------------------------------------------\n",
      "experience as a cost accountant, cost analyst, accountant or similar role\n",
      "================================================\n",
      "data-02-06/1202/data.html\n",
      "================================================\n",
      "data-02-06/668/data.html\n",
      "================================================\n",
      "data-02-06/3044/data.html\n",
      "description\n",
      "\n",
      "\n",
      "work with the scrum master, po and team lead, to understand the backlog and priorities that need to be delivered to support business needs\n",
      "work with business to under their needs and how we can add value by creating and delivering data products that meet their needs\n",
      "apply your deep skills and \n",
      "-----------------------------------------------\n",
      "experience in modern data platforms, its components and their purpose in the overall ecosystem and architecture\n",
      "apply your knowledge and experience to engineer data from its raw elements from source systems into a useable format for business to derive insights\n",
      "apply your experience in modern data modelling techniques\n",
      "apply the right mindset, attitude and willingness to learn, grow not only one self, but also help grow others.\n",
      "================================================\n",
      "data-02-06/2888/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- khai thác dữ liệu, xây dựng, cập nhật và duy trì các báo cáo, số liệu quan trọng để theo dõi hiệu quả hoạt động kinh doanh\n",
      "- tiếp nhận và xử lý các yêu cầu về phân tích số liệu\n",
      "- khai thác dữ liệu đã thu thập được, đưa ra phân tích, lý do và dự đoán tình huống, xu thế trong tương lai\n",
      "- thu thập, phân tích và cải tiến các chỉ số phân tích từ trích xuất dữ liệu đến phân tích và trình bày những kiến thức chuyên sâu, nắm bắt xu hướng và sự bất thường trên thị trường để trả lời các câu hỏi quan trọng định hướng phát triển của công ty.\n",
      "- tổng hợp các nhu cầu từ end-user hoặc tự nhận diện nhu cầu dựa trên dữ liệu, từ đó thực hiện các phân tích dữ liệu để đưa ra insight.\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2670/data.html\n",
      "================================================\n",
      "data-02-06/1730/data.html\n",
      "mô tả công việc\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "- develop and maintain scalable and reliable data pipelines to ingest data from a variety of different data sources into data lake, ensure right data format and  adhere to data quality standards, assure the downstream users can get the data quickly\n",
      "- develop and maintain highly scalable and extensible big data platform which enables collection, storage, modeling, and analysis of massive data sets from numerous channels. define and maintain data pipeline, data structure, data format to enable business solution\n",
      "- develop and enable big data and batch/real-time analytical solutions that leverage emerging technologies.\n",
      "- works in a team to build next-generation hadoop data lake and analytics applications on a group of core hadoop technologies\n",
      "- evaluate new technologies and products, and research to identify opportunities that impact business strategy, business requirements and performance that can accelerate access to data.\n",
      "- work with advanced analytics team to plan and execute high-impact actionable insight generation through big data advanced analytics including predictive analytics, advanced machine learning technologies that reduce cost and improve analytics speed to insight by accelerating the pace of big data innovation at acb.\n",
      "- ensure proper configuration management and change controls are implemented during code migration.\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1923/data.html\n",
      "================================================\n",
      "data-02-06/1954/data.html\n",
      "mô tả công việc\n",
      "\n",
      "• tiếp nhận yêu cầu từ các phòng ban/ quản lý trực tiếp về phát triển báo cáo/số liệu\n",
      "• thu thập dữ liệu từ các hệ thống nội bộ/bên ngoài về data warehouse bằng công cụ odi hoặc phát triển các giải pháp tích hợp\n",
      "• trực xử lý cuối ngày trên hệ thống data warehouse theo qui trình\n",
      "• thực hiện báo cáo trên công cụ obiee (sẽ được đào tạo)\n",
      "• tham gia phát triển, tự động hóa các báo cáo\n",
      "• hỗ trợ user kiểm tra số liệu\n",
      "• cung cấp số liệu cho user\n",
      "• tìm hiểu và ứng dụng các công cụ về lĩnh vực tích hợp dữ liệu...\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "trình độ học vấn: tốt nghiệp đai học chuyên ngành công nghệ thông tin, khoa học máy tính…\n",
      "kinh nghiệm:\n",
      "• ít nhất 1 năm kinh nghiệm ở vị trí tương đương\n",
      "• có kỹ năng viết sql, pl/sql\n",
      "• có kiến thức cơ bản về hệ quản trị cơ sở dữ liệu: oracle, sql server, my sql…\n",
      "• nắm vững kiến thức về: data warehouse, oracle database, bigdata... thành thạo pl/sql và các công cụ tích hợp dữ liệu elt\n",
      "• có khả năng đọc hiểu tài liệu tiếng anh chuyên ngành\n",
      "\n",
      "================================================\n",
      "data-02-06/1716/data.html\n",
      "responsibilitiesthe fundamental quantitative researchers develop trading ideas using fundamental and quantitative analysis. a mixed background of finance, programming and statistics is preferred for this position.requirements\n",
      "recent master’s/ph.d. from finance, accounting, economics, or a related field. bachelor’s degree with exceptional performance will also be considered\n",
      "strong background in mathematics\n",
      "possess a strong interest in financial markets\n",
      "advanced quantitative, analytical, and problem-solving skills\n",
      "having some industry or quant research \n",
      "-----------------------------------------------\n",
      "experience in work/internship/project is preferred\n",
      "detail-oriented\n",
      "\n",
      "** following will be plus points:\n",
      "\n",
      "experience with linux\n",
      "solid programming skills in python or c++\n",
      "benefitssalary range: up to usd 3,500 gros\n",
      "================================================\n",
      "data-02-06/482/data.html\n",
      "responsibilityfaq blog  contact us\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/91/data.html\n",
      "responsibilitieshonest and straight-forward can-do attitude  ability to work overtimebachelor’s or master’s degree in operations / logistics / mathematics, economics, computer science, information management or statistics it / programing english with toiec 600+ or ielts 4.5\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3053/data.html\n",
      "================================================\n",
      "data-02-06/2652/data.html\n",
      "responsibilities\n",
      "lead the development of machine learning algorithms on health/fitness data\n",
      "improve existing machine learning pipeline scalability, usability, and performance\n",
      "work closely with cross-functional teams to tackle challenges around time series data coming from sensors and edge devices\n",
      "connect the gap between r&amp;d and production and collaborate with our product managers, data scientists, and firmware engineers to ensure the delivery of high-quality and robust solutions for our users\n",
      "requirements\n",
      "bs/ms/phd in computer science, electrical engineering, or related technical field\n",
      "3+ years of industry \n",
      "-----------------------------------------------\n",
      "experience in developing ml systems\n",
      "strong programming skills in python\n",
      "proficiency in manipulating big data with apache spark (pyspark)\n",
      "experience with leading machine learning product development on time-series data (sensor, iot devices, health/fitness tracking, audio, etc.)\n",
      "strong knowledge of software architecture design, debugging, source control management, \n",
      "================================================\n",
      "data-02-06/3164/data.html\n",
      "================================================\n",
      "data-02-06/2715/data.html\n",
      "mô tả công việc\n",
      "- theo dõi, phân tích dữ liệu người dùng từ hệ thống của công ty\n",
      "- đánh giá các chỉ số sản phẩm, đưa ra các giải pháp cải thiện sản phẩm\n",
      "- phối hợp với các bộ phận liên quan đưa giải pháp tối ưu nhất cho sản phẩm\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "- sinh viên năm 3, năm 4 khối ngành kinh tế hoặc cntt\n",
      "- tuy duy tốt, nhanh nhạy về số liệu\n",
      "- có khả năng đọc hiểu và phân tích dữ liệu, đưa ra kết luận và giải pháp thông qua các báo cáo\n",
      "- có khả năng làm việc độc lập và trong nhóm, cẩn thận và chính xác trong công việc.\n",
      "- có khả năng giao tiếp tốt, đưa ra ý kiến và thuyết phục được người khác.\n",
      "- có kinh nghiệm làm việc với game là một lợi thế.\n",
      "quyền lợi\n",
      "- hỗ trợ lương thực tập 4.000.000 vnđ/ tháng tùy theo năng lực\n",
      "- thời gian thực tập 2 - 4 tháng - tùy vào năng lực của ứng viên\n",
      "- cam kết cơ hội trở thành nhân viên chính thức sau 2 - 4 tháng thực tập nếu đáp ứng đủ tiêu chí\n",
      "- môi trường làm việc vô cùng thoải mái, sáng tạo, năng động.\n",
      "- được hỗ trợ dấu thực tập nếu ứng viên cần\n",
      "- được tham gia các dự án đang chạy của công ty\n",
      "- được cầm tay chỉ việc, đào tạo kỹ năng và kinh nghiệm làm việc thực tế\n",
      "- hưởng đầy đủ các trợ cấp khác như đi lại, gửi xe như 1 nhân viên chính thức\n",
      "- ăn uống miễn phí đồ ăn, thức uống trong văn phòng\n",
      "- thưởng liên tục: tết âm, tết dương, 8/3, 30/4-1/5, 1/6, trung thu, giữa năm, 2/9, 20/10, giáng sinh.\n",
      "- thời gian làm việc: 7h/ngày (sáng: 9:00 - 12:00, chiều: 13:00 - 17:30, nghỉ giữa chiều 15:00 - 15:30)\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 30/06/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/1747/data.html\n",
      "================================================\n",
      "data-02-06/3104/data.html\n",
      "mô tả công việc\n",
      "phân tích các chỉ số tài chính để cảnh báo về các rủi ro về tài chính (nếu có).tổng hợp thông tin, theo dõi, phân tích và gửi cảnh báo về tình hình thực hiện kế hoạch kinh doanh của các bộ phận.thẩm định hiệu quả kinh doanh các hợp đồng, dự án.theo dõi, phân tích và gửi cảnh báo về tình hình thực hiện kế hoạch kinh doanh hợp đồng dự án.phối hợp với các bộ phận tham gia kiểm soát tài chính tại công ty.hỗ trợ việc xây dựng các định mức chi phí, đo lường hiệu quả của công ty, công ty con  và theo loại hợp đồng, dự án.\n",
      " \n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viêntốt nghiệp đại học trở lên chuyên ngành tài chính, kiểm toán, kinh tế,…có ít nhất 2 năm kinh nghiệm làm công việc tương tự tại hoặc làm cho các công ty kiểm toán (big4).đã học hoặc hoàn thành các chứng chỉ về lĩnh vực tài chính, kiểm toán như: acca, cpa, cfa là lợi thế.tiếng anh giao tiếp khá, nắm được tiếng anh chuyên ngành.nhanh nhẹn, chăm chỉ, tinh thần trách nhiệm cao trong công việc.\n",
      "================================================\n",
      "data-02-06/2854/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      " responsibilitiesdevelop software systems that utilize machine learning and artificial intelligencedesign and implement algorithms and models for data analysis and predictionuse a variety of programming languages such as python, java, or c++work with machine learning frameworks like tensorflow, pytorch, or scikit-learnanalyze, design, and implement software systems that integrate components of aiensure that software systems are scalable, secure, and performantcollaborate with other team members to identify and resolve issues related to software development and integrationkeep up-to-date with the latest trends and techniques in the field of ai and machine learningfollow given procedures and instructions to produce well-designed, testable and clean code \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2711/data.html\n",
      "================================================\n",
      "data-02-06/2545/data.html\n",
      "mô tả công việc\n",
      "- thu thập, tổng hợp, xử lý dữ liệu về kết quả kinh doanh (doanh thu/chi phí) để cung cấp thông tin phục vụ công tác lập báo cáo quản trị nội bộ phục vụ ban lãnh đạo, các khối kinh doanh, các đơn vị kinh doanh, xây dựng kế hoạch và phân tích kinh doanh;- phân tích các lĩnh vực kinh doanh của tập đoàn (phân tích ngành) để đánh giá đầy đủ, khách quan các cơ hội, thách thức, các xu hướng và định vị tập đoàn.- phân tích chi tiết và toàn diện năng lực nội tại của tập đoàn, đánh giá năng suất và hiệu quả, lợi thế cạnh tranh và các điểm yếu (việc phân tích được thực hiện theo các mảng hoạt động kinh doanh và theo các kênh phân phối).- phân tích, đánh giá việc sử dụng các nguồn lực tài chính của tập đoàn để đưa các đề xuất nhằm tối ưu hoá việc huy động và sử dụng các nguồn lực tài chính và quản lý rủi ro cho các mảng kinh doanh và đầu tư của tập đoàn.- phân tích, đánh giá doanh thu, chi phí từ các mảng hoạt động kinh doanh, từ các kênh phân phối, các điểm bán hàng và từ các bộ phận benefit/cost nhằm đưa ra các đề xuất nhằm tối ưu hoá doanh thu, giảm thiểu chi phí phí vận hành, phát hiện ra các cơ hội kinh doanh và tăng các chỉ số sinh lời.- tham gia xây dựng, giao, điều chỉnh, theo dõi, đánh giá thực hiện kế hoạch kinh doanh của toàn hệ thống và của các đơn vị- chủ động đề xuất xây dựng, cải tiến, hiện đại hóa hệ thống báo cáo, hệ thống quản trị cơ sở dữ liệu tập trung của toàn hệ thống và các chương trình phần mềm, ứng dụng phục vụ công tác lập kế hoạch và báo cáo quản trị;thực hiện các công việc khác theo yêu cầu của các cấp lãnh đạo.\n",
      "yêu cầu ứng viên\n",
      "tối thiểu 5 năm kinh nghiệm ở vị trí tương đương, đặc biệt là có kinh nghiệm trong mảng xử lý, tổng hợp dữ liệu, lập báo cáo quản trị, phân tích tài chính doanh nghiệp, phân tích kinh doanh tại các tập đoàn/doanh nghiệp kinh doanh đa ngành, có cơ sở dữ liệu khách hàng và mạng lưới phân phối lớn.tốt nghiệp đại học hệ chính quy trở lên, chuyên ngành kinh tế, quản trị kinh doanh hoặc các ngành có liên quan;am hiểu về lĩnh vực kinh doanh, phân tích số liệu;có tư duy phân tích, tổng hợp, logic;tư duy nhạy bén trong kinh doanh;khả năng tổ chức, quản lý công việc & thời gian. \n",
      "quyền lợi\n",
      "lương chính:- lương thỏa thuận theo năng lực và kinh nghiệm thực tế của ứng viên và các loại phụ cấp theo \n",
      "-----------------------------------------------\n",
      "yêu cầu công việc…;- lương tháng 13 bằng từ 1-3 tháng lương thỏa thuận.thưởng:- thưởng định kỳ theo kết quả kinh doanh chung của tập đoàn theo quý và theo năm;- thưởng đột xuất theo chương trình chung của tập đoàn;- thưởng đột xuất theo thành tích đặc biệt và hoặc các sáng kiến cải tiến trong công việc.chế độ đãi ngộ khác:- được hưởng đầy đủ các chế độ phúc lợi cơ bản theo quy định của nhà nước ngay sau kết thúc thời gian thử việc bao gồm bhxh, bhyt, bhtn, chế độ khám sức khỏe định kỳ...;- được hưởng đầy đủ các chế độ phúc lợi động viên cho bản thân và người thân theo quy định chung của tập đoàn như chế độ thăm hỏi; mừng các ngày lễ trong năm; mừng ngày thành lập tập đoàn; hiếu - hỉ…;- được hưởng đầy đủ các chế độ phúc lợi nâng cao (dành cho cấp quản lý) như: mừng danh hiệu quản lý cuối năm, bảo hiểm sức khỏe cho bản thân và người thân; chăm sóc sức khỏe (tập thể thao, tập gym…); hỗ trợ đi lại; hỗ trợ mua sắm và sử dụng dịch vụ ưu đãi;- được tham gia các hoạt động ngoại khóa, văn hóa đoàn thể hấp dẫn dành cho cbnv;- môi trường làm việc chuyên nghiệp, nhân văn, văn hóa và thân thiện.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 30/06/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/884/data.html\n",
      "responsible for maintenance, documentation, and enhancements of recurring processes and procedures.\n",
      "\n",
      "what we are looking for: \n",
      "\n",
      "bachelor’s degree in computer science, business analytics, data analytics, business intelligence, or a related field required;\n",
      "advanced sql knowledge and \n",
      "-----------------------------------------------\n",
      "experience (stored procedures, function, trigger…) and understanding of data warehousing and data modeling;\n",
      "experienced with business intelligence tools such as microsoft bi stack (e.g., ssis, ssrs, and ssas, azure data warehouse), tableau;\n",
      "intermediate c# or other programming languages;\n",
      "advanced knowledge of data systems and the ability to transform and shape large usable data sets.\n",
      "\n",
      "work behavior\n",
      "\n",
      "ability to lead, plan and manage in an entrepreneurial, team-oriented environment;\n",
      "highly organized with strong project management skills, and drive to meet organizational objectives; ability to manage multiple projects on interrelated timelines;\n",
      "strong written and verbal communication skills;\n",
      "demonstrate experience in getting things done in dynamic, entrepreneurial environment;\n",
      "demonstrate a high attention-to-detail in the analysis and reporting of data.\n",
      "\n",
      "what we offer: we treat people fairly and with dignity, keeping a healthy perspective about life and work and fostering a positive and enjoyable work environment with appealing benefits as below:\n",
      "\n",
      "a competitive monthly salary based on your ability\n",
      "13th month tet bonus & bi-annual performance bonus\n",
      "annual salary review\n",
      "attractive employee awards: employee of year, semi-annual outstanding employee\n",
      "social insurance and healthcare insurance upon vietnam labor code\n",
      "pvi insurance package, and annual health check\n",
      "an english-speaking environment\n",
      "an open culture that spurs creativity, innovation, and inclusivity\n",
      "a variety of training courses for your career development\n",
      "diverse activities to foster relationships, including company trips, year-end party, employees’ birthdays\n",
      "an open-space office, a cafeteria, and a range of modern equipment\n",
      "other allowance from referrals and special occasions (weddings, seniority, and new-born baby)\n",
      "\n",
      "work location\n",
      "ree tower, 9 doan van bo street, ward 13, district 4, hcmc\n",
      "working hours\n",
      "mon – fri: 3pm – 6pm (office) & 9pm – 2am (wfh)\n",
      "================================================\n",
      "data-02-06/2541/data.html\n",
      "================================================\n",
      "data-02-06/2305/data.html\n",
      "responsibility  \n",
      " \n",
      "leadership    \n",
      "\n",
      " \n",
      "leadership overview  \n",
      " \n",
      "board of directors  \n",
      " \n",
      "executive team  \n",
      " \n",
      " \n",
      "culture & values    \n",
      "\n",
      " \n",
      "culture & values overview  \n",
      " \n",
      "code of conduct & compliance  \n",
      " \n",
      " \n",
      "diversity & inclusion  \n",
      " \n",
      "policies & positions  \n",
      " \n",
      "business development & licensing  \n",
      " \n",
      "suppliers    \n",
      "\n",
      " \n",
      "suppliers overview  \n",
      " \n",
      "supplier registration  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "research    \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "research overview  \n",
      " \n",
      "covid-19  \n",
      " \n",
      "areas of focus    \n",
      "\n",
      " \n",
      "oncology  \n",
      " \n",
      "vaccines  \n",
      " \n",
      "infectious diseases  \n",
      " \n",
      "cardio-metabolic diseases  \n",
      " \n",
      " \n",
      "pipeline  \n",
      " \n",
      "discovery & development  \n",
      " \n",
      "product patents  \n",
      " \n",
      " \n",
      " \n",
      "patients    \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "patients overview  \n",
      " \n",
      "patient & treatment education  \n",
      " \n",
      " \n",
      " \n",
      "\n",
      "                careers \n",
      "                  \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "                careers \n",
      "                \n",
      " \n",
      "\n",
      "                search jobs \n",
      "                \n",
      " \n",
      "\n",
      "                our divisions \n",
      "                  \n",
      "\n",
      " \n",
      "\n",
      "                  research laboratories \n",
      "                  \n",
      " \n",
      "\n",
      "                  research & development \n",
      "                  \n",
      " \n",
      "\n",
      "                  manufacturing & supply \n",
      "                  \n",
      " \n",
      "\n",
      "                  human health \n",
      "                  \n",
      " \n",
      "\n",
      "                  animal health \n",
      "                  \n",
      " \n",
      "\n",
      "                  global support functions \n",
      "                  \n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "                student opportunities \n",
      "                \n",
      " \n",
      "\n",
      "                compensation & benefits \n",
      "                \n",
      " \n",
      "\n",
      "               how we hire \n",
      "                \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "                usa, canada & puerto rico careers \n",
      "                \n",
      " \n",
      "\n",
      "                talent community \n",
      "                \n",
      " \n",
      " \n",
      "\n",
      "                blog \n",
      "                \n",
      " \n",
      "events  \n",
      " \n",
      " \n",
      " \n",
      "media    \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "media overview  \n",
      " \n",
      "company fact sheet  \n",
      " \n",
      " \n",
      "\n",
      " \n",
      "\n",
      "                careers \n",
      "                \n",
      " \n",
      "\n",
      "                search jobs \n",
      "                \n",
      " \n",
      "\n",
      "                our divisions \n",
      "                  \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "                  research laboratories \n",
      "                  \n",
      " \n",
      "\n",
      "                  research & development \n",
      "                  \n",
      " \n",
      "\n",
      "                  manufacturing & supply \n",
      "                  \n",
      " \n",
      "\n",
      "                  human health \n",
      "                  \n",
      " \n",
      "\n",
      "                  animal health \n",
      "                  \n",
      " \n",
      "\n",
      "                  global support functions \n",
      "                  \n",
      " \n",
      " \n",
      " \n",
      "\n",
      "            ebrg \n",
      "            \n",
      " \n",
      "\n",
      "            therapeutic areas \n",
      "              \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "              careers in oncology \n",
      "              \n",
      " \n",
      "\n",
      "              careers in cardiovascular \n",
      "              \n",
      " \n",
      "\n",
      "              careers in vaccines \n",
      "              \n",
      " \n",
      "\n",
      "              careers in infectious diseases \n",
      "              \n",
      " \n",
      " \n",
      " \n",
      "\n",
      "                compensation & benefits \n",
      "                \n",
      " \n",
      "\n",
      "                student opportunities \n",
      "                \n",
      " \n",
      "\n",
      "               how we hire \n",
      "                \n",
      " \n",
      "\n",
      "                usa, canada & puerto rico careers \n",
      "                \n",
      " \n",
      "\n",
      "                blog \n",
      "                \n",
      " \n",
      "events  \n",
      " \n",
      "\n",
      "                talent community \n",
      "                \n",
      "\n",
      " \n",
      "contact us  \n",
      " \n",
      "worldwide \n",
      "see our worldwide locations and country contact information.   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2576/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "                                                                                            performance monitoring and analytics:\n",
      "•\tdevelop reporting and dashboards to keep track of business performance, monitoring performance: main kpis: orders, revenue, gross profit, engagement, visitor, roi,..\n",
      "•\tmaintain dashboard and update if any change in datasources.\n",
      "•\tprovide comercial monthly report merchandise and marketing reports.\n",
      "•\tanalyse promotion campagin and give reccomendation for improve the performance\n",
      " ad-hoc analysis and business intelligence tool building to support business performance: customer segmentation, cohort analysis, cross selling opportunities etc.\n",
      "•\tleverage applications data to analyses user behavior.\n",
      "•\tpropose and deploy customer-based promotion.\n",
      "•\tmanage digital marketing team to optimise digital ads performance on social network ( fb, gg)\n",
      "•\tincharge to provide and verify incentive report with hr team.\n",
      "\n",
      "database and process enhancement:\n",
      "•\tenhance processes for commercial team connected with data team regarding to the ensuring a performing and accurate database.\n",
      "•\tcowork with data engineer and thirrd party bi to ensure all metric provided is correct, tracking, finding and give solution to fix bugs if any.\n",
      "•\tdevelop and propose project to enhance business process.\n",
      "•\ttake the lead to initiate and manage proposed projects\n",
      "•\tbe proactive in understanding business’s needs, connect and coordinate with other stakeholders (category, marketing, tech) to deliver proposed solutions\n",
      "•\ta key player in identifying and working with others to develop automated solutions and enhancements to drive business.\n",
      "\n",
      "planing and budgeting & others:\n",
      "•\tyearly targets setting and projection with commercial directors and catergory managers.\n",
      "•\tcontrol and propose marketing monthly budget.\n",
      "•\tgathers business intelligence from a variety of sources including company data, industry and field reports, public information, or purchased sources.\n",
      "•\tassesses market strategies by analysing related products, markets, or trends.\n",
      "•\tcompiles business intelligence or trends to support actionable recommendations.\n",
      "•\tperforms other related duties as assigned.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/879/data.html\n",
      "mô tả công việc- xây dựng cấu trúc data và tập hợp data từ nhiều nguồn của doanh nghiệp- phân tích dữ liệu trên bằng bảng số liệu, biểu đồ, bản đồ và đề xuất các hình thức minh họa hợp lý khác- xây dựng hệ thống các báo cáo đa chiều về thị trường, khách hàng, đối thủ, marketing và quản trị nội bộ- đưa ra đánh giá và cảnh báo từ báo cáo phân tích\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc- tốt nghiệp đại học các ngành về phân tích thông tin, toán, khoa học máy tính, thống kê.- có ít nhất 01 năm kinh nghiệm trong lĩnh vực data analyst hoặc business analyst- kỹ năng phân tích tốt.- có tư duy logic có hệ thống, có kỹ năng giải quyết vấn đề, làm việc có tổ chức và tư duy dựa trên dữ liệu- yêu thích tìm hiểu các kỹ thuật khai thác dữ liệu mới cũng như tìm hiểu các điểm nổi bật của dữ liệu- thành thạo ngôn ngữ lập trình phân tích dữ liệu: sql hoặc r hoặc python.quyền lợi- thu nhập từ 25trđ/tháng trở lên- thưởng tháng lương 13 cùng chế độ phúc lợi hấp dẫn- hưởng đầy đủ các chế độ theo luật lao động: nghỉ lễ tết, nghỉ phép, bhxh- tăng lương định kỳ hàng năm và theo hiệu quả công việc- tham gia bảo hiểm sức khỏe- ưu đãi mua hàng nội bộthông tin liên hệ công ty:ms giang– phòng hành chính nhân sựđịa chỉ: tầng 17, tòa nhà 319 bqp, số 63 lê văn lương, phường trung hòa, cầu giấy, hà nội.email: hanhchinhnhansu@elmich.vnsđt:0931.569.633\n",
      "================================================\n",
      "data-02-06/2978/data.html\n",
      "================================================\n",
      "data-02-06/1596/data.html\n",
      "================================================\n",
      "data-02-06/3110/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            responsibilities:\n",
      "•\texecute mid-long term material supply strategy. \n",
      "•\tstabilize demand flow from sharkninja to oem and sub suppliers.\n",
      "•\tensure sub suppliers capacity/ resource fully supportive to oem demand.\n",
      "•\tset up ctb (clear to build) visibility from oem.\n",
      "•\tmanage factories critical components shortage. \n",
      "•\thandle buy/sell process of most critical parts. \n",
      "•\tmanage material allocation on shared constraints. \n",
      "•\tassess new sub suppliers\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/424/data.html\n",
      "responsibilities\n",
      "requirements\n",
      "what we offer\n",
      "about us\n",
      "additional inforesponsibilities\n",
      "\n",
      "\n",
      "\n",
      "we are looking for qualified mlops engineer for the ekyc project, who will help us build up our digital identity verification products.\n",
      "your primary focus will be:\n",
      "\n",
      "developing and managing the backend system which encapsulates and provides control flow of various ml models.\n",
      "developing ml models and implementing novel solutions for various problems including fraud detection, face matching, ocr in computer vision.\n",
      "act as interfaces between product team, engineering team and data science team to ensure smooth integration of ml solutions.\n",
      "integrate ml models and ensure consistency in model interfaces and interaction as per product requirements.\n",
      "monitor and optimize system performance and resource consumption.\n",
      "manage development servers and environments.\n",
      "communicate with the product team, infrastructure team, engineering team and data science team to ensure consistency in requirement, development, integration, and deployment.\n",
      "optimize and deploy \"tiny\" ml solutions on limited computation power devices such as mobile devices and web platforms.\n",
      "having an opportunity to learn from production across many nations.\n",
      "this position reports to the lead data scientist.\n",
      "\n",
      "(optional) have an opportunity to work under supervision of an \n",
      "-----------------------------------------------\n",
      "experienced data scientist to:\n",
      "\n",
      "build ekyc components (face recognition, ocr, object detection, fraud detection), using state-of-the-art methods\n",
      "develop ml models and provide solutions for acquisition, verification, validation, and fraud detection of user data\n",
      "\n",
      "requirements\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bs or ms in computer science or related fields\n",
      "2+ years of experience in data science and mlops\n",
      "must be proficient in software design and software development.\n",
      "must be proficient in python, scripting language. experience with other programming languages (c++, java, javascript ...) is a plus\n",
      "must be proficient in linux system, version control system (git), virtualization and sw packaging tool (docker)\n",
      "great communication skills\n",
      "desired skills:\n",
      "\n",
      "\n",
      "\n",
      "experience with ml framework: tensorflow, pytorch, mxnet, onnx.\n",
      "experience with managing data science and computer vision toolkit, such as jupyterhub, opencv... is a plus\n",
      "experience with working with databases and query language is a plus.\n",
      "familiar with mlops concept and toolkit is a plus\n",
      "basic understanding of machine learning techniques and algorithms\n",
      "bs/ms in computer science with focus on machine learning is a plus\n",
      "\n",
      "\n",
      "what we offer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "competitive compensation package, including 13th-month salary and performance bonuses\n",
      "comprehensive health care coverage for you and your dependents\n",
      "generous leave policies, including annual leave, sick leave, and flexible work hours\n",
      "convenient central district 1 office location, next to a future metro station\n",
      "onsite lunch with multiple options, including vegetarian\n",
      "grab for work allowance and fully equipped workstations\n",
      "fun and engaging team building activities, sponsored sports clubs, and happy hour every thursday\n",
      "unlimited free coffee, tea, snacks, and fruit to keep you energized\n",
      "an opportunity to make a social impact by helping to democratize credit access in emerging markets.\n",
      "\n",
      "about us\n",
      "\n",
      "\n",
      "\n",
      "we are an ai fintech company specialized in assessing credit profiles of consumers in emerging markets combining pioneering ai with large alternative data sources. in 2020 we reached our ambitious milestone of credit profiling 1 billion consumers spanning 4 countries - vietnam, indonesia, india & the philippines - and building a platform for the wider industry and the financial services industry, in particular, to provide the \"un & under\" served access to credit. at the core of this initiative has been our strict and unwavering adherence to the norms of consumer data privacy and consumer data rights.\n",
      "but we're not satisfied as we embark on the next leg of our journey to deliver 100 million credit lines to consumers in the markets where we operate. although this goal is ambitious, we truly believe that by harnessing the power of ai & big data we can deliver financial access at an unprecedented scale.\n",
      "as a firm, we're audacious problem-solvers motivated by our impact on society. we deeply espouse the values of ownership - of our actions and initiatives, integrity in all we do, and agility in execution.\n",
      "we place great importance on doing what is right, what is best, and what is innovative. if you are smart, driven, and want to make a difference in the world with the most advance and fascinating technology, come join our team. we can satisfy your desire to explore new territory and give you the runway to really make an impact.\n",
      "================================================\n",
      "data-02-06/1785/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "collaborate with cross-functional teams, including product management, engineering, and data science, to gather requirements and define product features and functionality.\n",
      "conduct thorough analysis of customer needs and market trends to identify opportunities for improvement and innovation.\n",
      "translate business requirements into clear and comprehensive user stories, use cases, and functional specifications.\n",
      "develop and maintain documentation, including process flows, data models, and other relevant documentation.\n",
      "conduct regular user research and feedback sessions to understand user behavior, preferences, and pain points, and use insights to drive product improvements.\n",
      "conduct data analysis to identify patterns, trends, and opportunities for optimization.\n",
      "collaborate with ui/ux designers to ensure seamless user \n",
      "-----------------------------------------------\n",
      "experience and user interface design.\n",
      "stay up-to-date with the latest industry trends, technologies, and best practices related to self-service bi and saas solutions.\n",
      "\n",
      "================================================\n",
      "data-02-06/1386/data.html\n",
      "================================================\n",
      "data-02-06/1243/data.html\n",
      "responsibilities:\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tthis is a development project. as a hadoop big data engineer, you will operate and monitor scalable and resilient data platform based on hadoop ecosystem to address the business requirements: \n",
      "– engineer reliable data pipelines for sourcing, processing, transforming, enriching and storing data in different ways, using data platform infrastructure effectively\n",
      "– ingest and transform data sets from a variety of data sources\n",
      "– focus on ingesting, storing, processing, and analyzing large datasets\n",
      "– create scalable, high-performance web services for tracking data\n",
      "– using java (spring boot framework) for development tasks\n",
      "\n",
      "requirements: \n",
      "\t\t\t\t\t\t\t\t\t\t\tmust have requirements:\n",
      "– must have 3+ years of experience at a similar role\n",
      "– having hands on experience in hadoop ecosystem (on-prem) including spark, hdfs, mapreduce, yarn, …\n",
      "– good in programming language python.\n",
      "– experience in monitoring large-scale data processing job (batch-processing, stream processing)\n",
      "– having a background of software developing on java spring boot\n",
      "good to have:\n",
      "– experience with hadoop distributions such as cloudera, hortonworks, comparison and feasibility\n",
      "– experience with data warehouse and data management: data quality, data integration\n",
      "– experience in etl, sql and nosql database\n",
      "– experience with sre, patching & automation: kubernetes or docker & containerization\n",
      "– experience working with big data in a cloud environment\n",
      "– experience in data api\n",
      "– good to have architecture knowledge or experience\n",
      "preferred language for application: english\n",
      "\n",
      "-----------------------------------------------\n",
      "experience range: from 3 years\n",
      "job location: hanoi, hcmc\n",
      "duty & responsibilities:\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tthis is a development project. as a hadoop big data engineer, you will operate and monitor scalable and resilient data platform based on hadoop ecosystem to address the business requirements: \n",
      "– engineer reliable data pipelines for sourcing, processing, transforming, enriching and storing data in different ways, using data platform infrastructure effectively\n",
      "– ingest and transform data sets from a variety of data sources\n",
      "– focus on ingesting, storing, processing, and analyzing large datasets\n",
      "– create scalable, high-performance web services for tracking data\n",
      "– using java (spring boot framework) for development tasks\n",
      "\n",
      "requirements: \n",
      "\t\t\t\t\t\t\t\t\t\t\tmust have requirements:\n",
      "– must have 3+ years of experience at a similar role\n",
      "– having hands on experience in hadoop ecosystem (on-prem) including spark, hdfs, mapreduce, yarn, …\n",
      "– good in programming language python.\n",
      "– experience in monitoring large-scale data processing job (batch-processing, stream processing)\n",
      "– having a background of software developing on java spring boot\n",
      "good to have:\n",
      "– experience with hadoop distributions such as cloudera, hortonworks, comparison and feasibility\n",
      "– experience with data warehouse and data management: data quality, data integration\n",
      "– experience in etl, sql and nosql database\n",
      "– experience with sre, patching & automation: kubernetes or docker & containerization\n",
      "– experience working with big data in a cloud environment\n",
      "– experience in data api\n",
      "– good to have architecture knowledge or experience\n",
      "preferred language for application: english\n",
      "\n",
      "================================================\n",
      "data-02-06/2240/data.html\n",
      "responsibilities\n",
      "\n",
      "combine raw data from different sources and integrate into a central datalake then a data warehouse\n",
      "build the data system and pipeline using airflow or similar tools\n",
      "identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\n",
      "explore ways to enhance data quality, pipeline stability and reliability\n",
      "develop analytical tools and programs using bi tools like pendoai, logi analytics, etc.\n",
      "conduct complex data analysis and report on requests and visualize the data for stakeholders\n",
      "prepare data for prescriptive and predictive modeling\n",
      "collaborate with data scientists and architects\n",
      "\n",
      "key requirements\n",
      "\n",
      "bachelor’s degree in computer science, engineering, or a related field\n",
      "at least 3 years of working as a data engineer or in a similar role\n",
      "technical expertise with data models, analysis, pipeline architecture, etl/elt and segmentation techniques\n",
      "have strong knowledge of python and its data engineering library like numpy, pytorch, etc.\n",
      "have strong knowledge of sql query and relational model design\n",
      "have strong knowledge of nosql databases and their architecture\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2784/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- tham gia vào các dự án xây dựng sản phẩm số hóa với khách hang là nhật bản.- nghiên cứu và phát triển các giải pháp trong lĩnh vực computer vision sử dụng kỹ thuật machine learning & deep learning.- nghiên cứu, tìm hiểu, tối ưu giải thuật xử lý ảnh và thị giác máy tính- crawling dữ liệu cần thiết cho từng bài toán cụ thể- phân tích dữ liệu: nghiên cứu dữ liệu thô. sử dụng các công cụ phân tích dữ liệu và lập trình để xử lý các mô hình dự báo, phân tích rủi ro và gợi ý giải pháp- công việc trao đổi thêm khi phỏng vấn\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1903/data.html\n",
      "mô tả công việc\n",
      "\n",
      "responsibilities\n",
      "lead the effort to communicate state of the business to stakeholders regularly - enable audiences to understand the reasons behind the trends - and provide insights to drive strategic decisions.\n",
      "conduct exploratory analysis - go deep into the data to develop hypotheses and to answer complex business questions\n",
      "develop tools and automated processes that project the work out to a broader audience. strategize on democratizing data and insights to make analyses easily repeatable and generalizable by other team members in the future\n",
      "ownership of conceptualizing, developing, and maintaining dashboards, visualizations and predictive analysis with machine learning models.\n",
      "develop analytics frameworks and foundations to enable easy actionable insights and reliable measurement\n",
      "become a data expert in your business domain and own data quality\n",
      "empower the team to answer data questions quickly and easily by building high-quality ground truth data sets\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "individual skills\n",
      "good communication skill and business understanding with abilities to drive cross-functional team\n",
      "proactive problem solver, eye for detail, process driven\n",
      "agile trained, can elicit user stories, draw process diagrams\n",
      "data modelling experience\n",
      "good understanding of data management - data lineage, meta data, data quality, data governance\n",
      "analytics experience\n",
      "1.5+ years experience in similar role, experience in distribution / last mile delivery/ fulfillment services is preferable\n",
      "sql and data analysis\n",
      "strong analytical skills with the ability to collect, organize, analyze, model, and interpret data\n",
      "experience with an etl framework like airflow, nifi\n",
      "proficient in visualization tools: power bi, tableau, superset, data studio ect.\n",
      "experience with python\n",
      "\n",
      "\n",
      "tại sao bạn sẽ yêu thích làm việc tại đây\n",
      "\n",
      "benefit\n",
      "================================================\n",
      "data-02-06/1773/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      " - tham gia tìm hiểu và cập nhật thông tin thị trường:+ tìm hiểu & liên tục cập nhật các thông tin thị trường (sản phẩm, giá cả, innovation), nhu cầu người tiêu dùng, thông tin đối thủ.tham gia tổng hợp và phân tích các dữ liệu kinh doanh và dữ liệu nghiên cứu thị trường thuộc bộ phận bi (theo dự án food hiện hành)- hỗ trợ quản lý và thực thi các dự án bi - nghiên cứu thị trường và người tiêu dùng (theo dự án food hiện hành):+ phối hợp với các phòng ban liên quan lên kế hoạch và triển khai các dự án nghiên cứu thị trường, người tiêu dùng & đối thủ.+ tham gia làm việc với các agencies thực hiện dự án xuyên suốt các giai đoạn dự án (tóm tắt mục tiêu dự án, đấu thầu, thiết kế nghiên cứu, thực thi dự án & báo cáo kết quả) theo nhiệm vụ được quản lý trực tiếp phân bổ.+ hỗ trợ thực thi dự án, phân tích & báo cáo kết quả các khảo sát nội bộ khi có yêu cầu.- tham gia đánh giá tình hình triển khai các chương trình trưng bày, khuyến mãi & quảng bá thương hiệu tại các kênh mt, gt & meatshop (commercial audit)+ tiến hành đánh giá thực thi triển khai bán hàng/ quảng bá tại các khu vực thực địa+ phối hợp với các phòng ban liên quan lên kế hoạch đánh giá & cập nhật các chương trình triển khai bán hàng theo tháng.+ tổng hợp dữ liệu, phân tích & báo cáo kết quả- quản lý các dự án thử & đánh giá sản phẩm nội bộ: lên kế hoạch đánh giá sản phẩm, phương pháp đánh giá sản phẩm, kết nối các chuyên gia đánh giá cảm quan nội bộ, xử lý & phân tích dữ liệu, báo cáo.- hỗ trợ xây dựng kiến thức và năng lực phân tích dữ liệu cho bộ phận bi và các cộng sự nội bộ. \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1236/data.html\n",
      "mô tả công việc: \n",
      "        \n",
      "\n",
      "trách nhiệm chính\n",
      " - xây dựng giải pháp và lập trình các tầng xử lý trên hệ thống mis bao gồm: data warehouse, data model, bi  \n",
      " - tích hợp tất cả các nguồn dữ liệu từ các hệ thống ứng dụng vào data warehouse \n",
      " - hỗ trợ các đơn vị nghiệp vụ ngân hàng khi có nhu cầu khai thác dữ liệu từ hệ thống mis/dw. \n",
      " - thực hiện phân tích các mô hình dữ liệu, dự đoán, dự báo, báo cáo phân tích,..  \n",
      " - báo cáo định kỳ theo quy định hoặc theo yêu cầu của cấp quản lý trực tiếp. \n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "1. bằng cấp/chứng chỉ:\n",
      "================================================\n",
      "data-02-06/882/data.html\n",
      "descriptions\n",
      "\n",
      "develop and deliver action-oriented, insightful analytics presentations that provide consultative directions to key stakeholders;\n",
      "consolidate data from multiple sources including sales, supply chain, operations, marketing, and source databases to create integrated views that can be used to drive decision making;\n",
      "leverage bi tools and other software applications to develop data models, conduct data analyzing and visualizing in dashboards and reports\n",
      "work with/or build several large and complex databases.\n",
      "\n",
      "ii. skill and experience\n",
      "\n",
      "at least 3-5 years’ experience in business intelligence or relevant role;\n",
      "bachelor’s degree and above in statistics, business, data analytics, and other related fields;\n",
      "strong in sql skills;\n",
      "having knowledge in design data warehouse architecture;\n",
      "have experience in using python is a big plus;\n",
      "ability to demonstrate a high level of verbal and written (both english and vietnamese) to coordinate with internal stakeholders across departments;\n",
      "be opened minded, think out of the box and willing to do attitude;\n",
      "experience in business intelligence in e-commerce/fintech companies is a plus;\n",
      "having knowledge in finance, logistics, operation or marketing is a plus;\n",
      "entrepreneurial spirit and start-up mindset.\n",
      "\n",
      "iii. why you will love joining us?\n",
      "for you to join\n",
      "\n",
      "\n",
      "\n",
      "financial well-being: a competitive salary with 13th month salary, annual performance bonus and a variety of allowances.\n",
      "\n",
      "\n",
      "salary review: annually or on excellent performance.\n",
      "\n",
      "\n",
      "activities: company trips, team-building, and other customized monthly bonding events.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "annual leaves: 16 days off and 01 birthday leave per year.\n",
      "\n",
      "\n",
      "healthcare: annual health check, insurance according to labor law and extra pti insurance package.\n",
      "\n",
      "\n",
      "working environment: dynamic, friendly environments with working time flexibility (mon-fri), and other perks include snacks, coffee, and healthy food provided daily suited for hardworking, fun, and team collaboration.\n",
      "\n",
      "\n",
      "for you to grow\n",
      "\n",
      "\n",
      "ambition: we are now keeping on with our hyper growth to multicategory, multichannel, multimarket, and expanding into the world largest e-commerce enabler. hence, there will continuously be opportunities to challenge yourself, learn new skills and knowledge. \n",
      "\n",
      "\n",
      "challenges: your voice can always be heard as we embrace the eagerness of learning and sharing. you can be your own boss and create your own value with the ability to take initiative and make decisions in all aspects of work.\n",
      "\n",
      "\n",
      "chances: be led and coached by experienced and inspirational leaders and participate in various training courses where you can enlarge your knowledge and experience in the e-commerce and supply chain industry.\n",
      "\n",
      "\n",
      "for you to stay\n",
      "\n",
      "\n",
      "people: having a headquarter in the us and an operation office in vietnam, our team is young and highly motivated. you will be working with and alongside members having experiences from international corporations or high profile from vietnam that share the same passion and dedication.\n",
      "\n",
      "\n",
      "culture: our working environment is humble, collaborative and 100% healthy. we promote exchange & speak out, you can receive transparent and supportive feedback so you can perform the best.\n",
      "\n",
      "\n",
      "career path: provide you a great career path, open to rotating for your better understanding of the company and contribute across many of our functions.\n",
      "\n",
      "\n",
      "and much more, join us and let yourself explore other fantastic things!\n",
      "\n",
      "-----------------------------------------------\n",
      "experience in the e-commerce industry.\n",
      "we are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\n",
      "i. job descriptions\n",
      "\n",
      "develop and deliver action-oriented, insightful analytics presentations that provide consultative directions to key stakeholders;\n",
      "consolidate data from multiple sources including sales, supply chain, operations, marketing, and source databases to create integrated views that can be used to drive decision making;\n",
      "leverage bi tools and other software applications to develop data models, conduct data analyzing and visualizing in dashboards and reports\n",
      "work with/or build several large and complex databases.\n",
      "\n",
      "ii. skill and experience\n",
      "\n",
      "at least 3-5 years’ experience in business intelligence or relevant role;\n",
      "bachelor’s degree and above in statistics, business, data analytics, and other related fields;\n",
      "strong in sql skills;\n",
      "having knowledge in design data warehouse architecture;\n",
      "have experience in using python is a big plus;\n",
      "ability to demonstrate a high level of verbal and written (both english and vietnamese) to coordinate with internal stakeholders across departments;\n",
      "be opened minded, think out of the box and willing to do attitude;\n",
      "experience in business intelligence in e-commerce/fintech companies is a plus;\n",
      "having knowledge in finance, logistics, operation or marketing is a plus;\n",
      "entrepreneurial spirit and start-up mindset.\n",
      "\n",
      "iii. why you will love joining us?\n",
      "for you to join\n",
      "\n",
      "\n",
      "\n",
      "financial well-being:\n",
      "================================================\n",
      "data-02-06/131/data.html\n",
      "================================================\n",
      "data-02-06/1711/data.html\n",
      "mô tả công việc\n",
      "\n",
      "tích hợp dữ liệu\n",
      "thu thập và tích hợp dữ liệu và thông tin từ nhiều nguồn khác nhau về dwh, mô hình hóa phục vụ các bài toán phân tích chuyên sâu.\n",
      "hợp tác với các bên liên quan trong giải pháp cntt/dữ liệu và các bộ phận khác trong việc xác định các nguồn dữ liệu để đáp ứng các yêu cầu về thông tin và khả năng phân tích nhằm giải quyết các nhu cầu kinh doanh\n",
      "tự động hóa và duy trì luồng dữ liệu về dwh.\n",
      "\n",
      " \n",
      "ii. \n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "kiến thức cần có:\n",
      "\n",
      "hệ điều hành: ubuntu server, window server\n",
      "ngôn ngữ lập trình: python, java\n",
      "cơ sở dữ liệu: on-premes: oracle, postgres, mysql (nosql is a plus)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "học vấn: tốt nghiệp đh trở lên 1 trong số các chuyên ngành: computer science, engineering, mathematics hoặc các chuyên ngành có liên quan\n",
      "kiến thức tốt về: datawarehousing, cấu trúc dữ liệu và giải thuật, etl, elt\n",
      "có các kinh nghiệm làm việc sau đây là lợi thế:\n",
      "\n",
      "có kinh nghiệm trong việc thiết kế và xây dựng data models, quy trình etl và elt dữ liệu từ nguồn về dwh, tối ưu hóa luồng dữ liệu\n",
      "kinh nghiệm làm việc theo mô hình agile và scrum\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/1192/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responsible for analyzing and interpreting data. the candidate will use their analytical skills and business acumen to provide insights and recommendations to vp of digital+ before communicating them to the team in vietnam.\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/672/data.html\n",
      "mô tả công việc:\n",
      "\n",
      "-  thiết kế chi tiết giải pháp cho các luồng thu thập, chuẩn hóa, làm sạch, làm giàu, lưu trữ, xử lý, phân tích và hiển thị dữ liệu lớn\n",
      "-  xây dựng các giải pháp etl có khả năng mở rộng linh hoạt với độ tin cậy cao, phục vụ cho việc khai thác các loại dữ liệu (cấu trúc, lưu lượng, tốc độ) từ nhiều nguồn khác nhau\n",
      "-  thiết kế về lưu trữ, backup dữ liệu\n",
      "-  xây dựng, phát triển các công cụ khai thác dữ liệu, quản trị dữ liệu\n",
      "-  làm báo cáo số liệu theo yêu cầu\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "-\n",
      "================================================\n",
      "data-02-06/1061/data.html\n",
      "================================================\n",
      "data-02-06/2325/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "building and optimizing ‘big data’ data pipelines, architectures and data sets;\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "design, develop, and maintain data pipelines, warehouses, datalake.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "build the data products that technical users will depend on for business intelligence and ad-hoc access.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "work side by side with our data science to build and automate data pipeline, data etl, etc. on distributed data processing platform such as spark.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "prepare data inputs for a generic blueprint \"model builder\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "build production data pipeline for daily etl and model retraining\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "end-to-end data processing, troubleshooting, and problem diagnosis.\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2786/data.html\n",
      "mô tả công việc\n",
      "our data scientist team is looking for a young and talented data scientist. the ideal candidate is adept at using state-of-art machine learning and data mining techniques, statistical analysis, and building high-quality prediction systems integrated with our products.in this role, you will discover the information hidden in vast amounts of data, and make more intelligent decisions to deliver even better products. the product’s growth with the scale of data creates a big opportunity and challenge for you to innovate using next-generation technologies (ai and machine learning). last but not least, you will work with our best data engineering, and data analysis to support you in your career-building path. job descriptionapply statistical and machine learning models to cốc cốc productmine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques, and business strategies;implement appropriate machine learning algorithms and turn them into microservices in our production environments.research the optimization solution for ad networkresearch the optimization solution for ad network;contribute to ad network core logic (improving algorithm and ad optimization);perform analysis and design the hypothesis to optimize ad networks user experiences, revenue generation, ad targeting, and other business outcomes.exploratory data analysiscollect and analyze data from our products, market;prepare reports that interpret our user behaviors, marketing trends, and product features;utilize analytic tools and implement scripts to test your proposal hypothesis.key points that make this position different and interesting:solve challenging practical problems with huge amounts of data to handle, serving millions of our users;participate in building models in our powerful gpu cluster;participate in product development following the scrum model and agile activities;professional, dynamic working environment, where you can develop yourself through internal seminars, and courses; we have a bookshelf in our room where you can find there both hardcover and digital versions (once required).\n",
      "yêu cầu ứng viên\n",
      "\n",
      "-----------------------------------------------\n",
      "job requirementsrequired qualifications:1-2 years of working experience as a data scientist or similar role in an it company, university, or research institute;highly analytical with a heavy emphasis on data mining and data visualization (problem formulation, analytical ability, synthesis);experience using statistical computer languages (r, python, slq, etc.) to manipulate data and draw insights from large data sets;experience with statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications;experience with common data machine learning frameworks (tensorflow, scikit-learn, nlp, etc);preferred qualifications:bsc/ba in computer science, engineering, or relevant field; a graduate degree in data science or other quantitative fields is preferred;experience in adverts & advertising network, online marketing;strong communication skills (good english communication skill is a plus);excellent teamwork mindset that can foster teamwork spirit among other members;demonstrating a willingness to learn.\n",
      "quyền lợi\n",
      "hiring processphone screening > home test > onsite interviews > offering.\n",
      "================================================\n",
      "data-02-06/2486/data.html\n",
      "description\n",
      "\n",
      "your tasks will be discussed in more details during the interview.\n",
      "will be trained in techniques using deep learning to handle natural language.\n",
      "\n",
      "2. your skills and \n",
      "-----------------------------------------------\n",
      "experiences\n",
      "\n",
      "either full-time or part-time (minimum 25hs/week but more hours is welcomed).\n",
      "must have a laptop with minimum requirements: 8gb ram, ssd and i3.\n",
      "must have a basic understanding of python, oop (object oriented programming) and database.\n",
      "good logical thinking in programming.\n",
      "show your senior your progress (like test or demo).\n",
      "\n",
      "\n",
      "3. why you’ll love working here\n",
      "\n",
      "will provide support during your job (can discuss more details during the interview).\n",
      "potentially become an official employee with the company benefits.\n",
      "free coffee, tea and cakes.\n",
      "we have these clubs for you to join: football, table football, music, english, media and more.\n",
      "get advices for career development.\n",
      "\n",
      "working hours: morning: 8h30 – 12h00; afternoon: 13h00 – 17h30. (monday to friday).\n",
      "================================================\n",
      "data-02-06/831/data.html\n",
      "================================================\n",
      "data-02-06/849/data.html\n",
      "================================================\n",
      "data-02-06/1366/data.html\n",
      "================================================\n",
      "data-02-06/1891/data.html\n",
      "description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "skills required\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "details\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- thiết kế, xây dựng, quản lý và bảo mật dữ liệu chính. - thu thập yêu cầu, thông tin, thu thập và cập nhật dữ liệu của các nghiệp vụ, quy trình trong doanh nghiệp. từ đó phân tích dữ liệu, chuyển thành thông tin và đưa ra tư vấn về các chỉ số then chốt. - trình bày các nội dung trên bằng bảng số liệu, biểu đồ, bản đồ và đề xuất các hình thức minh hoạ hợp lý khác. - vận hành các tool dữ liệu và tìm insight của dữ liệu. - quản lý và thiết kế môi trường báo cáo, bao gồm nguồn dữ liệu và bảo mật. - thực hiện các công việc khác được bod phân công.* quyền lợi- một môi trường làm việc đầy cảm hứng, mà ở đó chúng ta cùng nhau tạo ra các sản phẩm công nghệ trong tương lai.  - một đội ngũ được định hướng và có các cơ hội nghề nghiệp năng động giúp bạn phát triển cả về cá nhân và nghề nghiệp.  ­- cấu trúc tổ chức phẳng : bạn sẽ được làm việc trong môi trường cởi mở, gần gũi với những người ra quyết định và có khả năng tạo ra sự khác biệt. ­  - tổ chức agile: trọng tâm đặt lên con người, xây dựng tương tác và hỗ trợ giữa các thành viên trong nhóm. những thành viên có năng lực, tương trợ nhau trong công việc sẽ mang đến thành công cho dự án. - văn phòng “mở” và hiện đại: tất cả những gì bạn cần để thư giãn đã có ngay tại văn phòng bao gồm quầy bar, playstation, ghế massage, bida, bi lắc... ­- quan tâm đến đời sống nhân viên: gói bảo hiểm chăm sóc sức khỏe nals care dành riêng cho nalser, giờ làm việc linh hoạt, lớp tiếng anh, lớp yoga, sexy dance, clb âm nhạc ... - chơi hết mình: open talk, team building, company trip, sea game, và các hoạt động khác  - cung cấp thiết bị làm việc macbook. - thu nhập hấp dẫn.  - 20 ngày nghỉ phép hàng năm. - thưởng cuối năm. - check-point ít nhất 2 lần / 1 năm hoặc theo đề xuất của nhân viên. - thời gian làm việc: thứ 2 - thứ 6 (8.00am - 11.30am, 1.00pm - 5.30pm).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "required experience / skills detail\n",
      "\n",
      "\n",
      "\n",
      "- bằng cử nhân về toán học, cntt, thống kê hoặc các lĩnh vực liên quan.- có ít nhất 2 năm \n",
      "-----------------------------------------------\n",
      "kinh nghiệm làm data analyst - phân tích dữ liệu tại một công ty công nghệ.- có kinh nghiệm sử dụng toán học, công cụ trực quan hóa dữ liệu, phân tích kinh doanh và công nghệ chuyển đổi khối lượng lớn dữ liệu phức tạp thành giải pháp.- kỹ năng excel và phân tích dữ liệu tốt bao gồm khả năng sử dụng các công cụ bi.- kỹ năng sử dụng các công cụ visualize để chuyển hóa dữ liệu thành biểu đồ, báo cáo.- kiến thức hoặc kinh nghiệm làm việc về phát triển cơ sở dữ liệu sql.- kỹ năng giải quyết vấn đề và tư duy hoàn thành mục tiêu- có kỹ năng phân tích sắc bén, khả năng thu thập, tổ chức, phân tích và phổ biến lượng lớn thông tin một cách chi tiết và chính xác.- có niềm đam mê với dữ liệu.- cẩn thận, kiên nhẫn, chịu khó, ham học hỏi, có tinh thần trách nhiệm.* ngoài ra:- khả năng code cơ bản để xử lý các mô hình dự báo (predictive models) là lợi thế.- kinh nghiệm với google analytics là một lợi thế.- thành thạo tiếng anh và nghiên cứu tài liệu tiếng anh là một điểm cộng lớn. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job detail\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "position type\n",
      "\n",
      "full-time\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "career level\n",
      "\n",
      "staff\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "education level\n",
      "\n",
      "bachelor's degree\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gender\n",
      "\n",
      "male / female\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job categories\n",
      "\n",
      "\n",
      "it - software\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "information\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "name:\n",
      "\n",
      "\n",
      "phòng nhân sự\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fhome building - 16 ly thuong kiet,  thach thang\n",
      "\n",
      ", \n",
      "\n",
      "hai chau district\n",
      "\n",
      ", \n",
      "\n",
      "da nang\n",
      "\n",
      ", \n",
      "\n",
      "viet nam\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- các ứng viên quan tâm vui lòng gửi hồ sơ trực tuyến, gửi kèm file hoặc trực tiếp đến tại công ty \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "application language:\n",
      "vietnamese\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "công ty cổ phần nal solutions\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "https://nals.vn/\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100 - 499 employees\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact: phòng nhân sự\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nal solutions is a vietnam - japan joint venture software technology company under nal holding. at nals, we bring technology solutions and develop diverse and high-tech products encompassing website development, mobile apps, ai & big data, iot ar/vr.\n",
      "with a board of experienced and skilled technical engineers, a dynamic, enthusiastic, and proactive working environment will always bring quality products and receive certitude from customers. regardless of project type or industry, nals consistently strives to provide comprehensive support from consulting to system development and deliver a great customer experience.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "see more\n",
      "\n",
      "\n",
      "\n",
      "see less\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "other jobs from this company\n",
      "\n",
      "|\n",
      "\n",
      "see all\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python django developer\n",
      "\n",
      "\n",
      "công ty cổ phần nal solutions\n",
      "\n",
      "\n",
      "\n",
      "da nang\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "java developer\n",
      "\n",
      "\n",
      "công ty cổ phần nal solutions\n",
      "\n",
      "\n",
      "\n",
      "da nang\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "php developer\n",
      "\n",
      "\n",
      "công ty cổ phần nal solutions\n",
      "\n",
      "\n",
      "\n",
      "da nang\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "technical leader\n",
      "\n",
      "\n",
      "công ty cổ phần nal solutions\n",
      "\n",
      "\n",
      "\n",
      "da nang\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "process quality assurance (good at japanese)\n",
      "\n",
      "\n",
      "công ty cổ phần nal solutions\n",
      "\n",
      "\n",
      "\n",
      "da nang\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "work location\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fhome building - 16 ly thuong kiet,  thach thang, hai chau district, da nang\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tags\n",
      "\n",
      "\n",
      "\n",
      "hai chau district\n",
      "software\n",
      "it\n",
      "data analyst\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "share\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "copied\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/1878/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responsibilities\n",
      "develop and implement ai models and algorithms. \n",
      "integrate ai solutions into existing systems. \n",
      "collaborate with cross-functional teams to identify business problems and develop ai solutions that meet business requirements. \n",
      "research, evaluate, and propose new ai technologies and trends. \n",
      "continuously learn and keep up with the latest ai trends and technologies. \n",
      "communicate technical concepts to non-technical stakeholders.\n",
      "requirements\n",
      "bachelor's or master's degree in computer science, artificial intelligence, machine learning, or a related field. \n",
      "3+ years of \n",
      "-----------------------------------------------\n",
      "experience in developing ai solutions in a professional setting.\n",
      "================================================\n",
      "data-02-06/269/data.html\n",
      "responsibilities\n",
      "• in charge data/ report improvements by centralising and creating report standard to provide analysis of trends and forecasts and recommend actions.• facilitate productivity improvement by initiating and deploying automated reporting/ forecasting tools.• implement data governance process, that be embedded within the organization’s data creation, management and protection.• to calculating annual premium equivalent (ape) to the right sales channels and prepare reports for management team on daily basis.• support in performing cross-reconciliation of daily business data with other functions (op,mis, dos .etc...)• facilitate the collaboration process with finance, actuarial and other functions to provide mis reports on daily/ weekly/ monthly/ quarterly/ haft-year and yearly reports basis/ad-hoc reports requested by relevant stakeholders.• support in collecting kpi reports submitted by other function then upload into pca’s mi system, such as: new business submission, number of agents, compensation for distribution ..etc..)• support and instruct other departments about finance-related operating manual & systems.• other tasks delegated by line manager.\n",
      "\n",
      "-----------------------------------------------\n",
      "experience requirements\n",
      "• bachelor’s degree in economics, business administration, banking & financeknowledge & skills• at least 03 year experiences of working in insurance/ finance/ banking or equivalent position• must be good knowledge in access, sql & vba. programming language c# (visual studio) is plus• be able to work independently and under pressure to meet the deadline committed in company level• be able to work with details and good analytical skills to deal with large of amount of complex data.• have good english skill (especially speaking and business writing)• possess good communication, problem solving and stakeholder management skills• be careful and responsible.﻿please click the apply button or contact ms tien ngo at +84 359 341 711 or\n",
      "================================================\n",
      "data-02-06/2762/data.html\n",
      "mô tả công việc\n",
      "trở thành thành viên của 1 team đầy nhiệt huyết, tham gia vào các nhiệm vụ: nghiên cứu, thực hiện data visualization, machine learning (models, prediction)trao đổi ý kiến với các thành viên trong team để giải quyết các vấn đề xảy ra trong suốt dự áncác công việc khác được giao trong quá trình làm việc tùy theo yêu cầu từ project\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "sv năm cuối các ngành có liên quan đến data sciencequen thuộc với linux oskiến thức tốt về data mining, data science / machine learninghiểu biết về databases chẳng hạn sql / mysqlkinh nghiệm sử dụng python, pandas, numpy, matplot, sklearn, pyspark or\n",
      "================================================\n",
      "data-02-06/2508/data.html\n",
      "mô tả công việc\n",
      "- lập trình xử lý ảnh, ai deep learning cho các ứng dụng kiểm tra lỗi sản phẩm, đọc mã vạch qr, datamatrix, barcode … , nhận diện kí tự và tích hợp với robot để định vị trí sản phẩm để robot gắp đặt.- setup camera vision , lựa chọn camera, lens, đèn phù hợp để thu được hình ảnh tốt nhất và lên cấu hình vision cho từng bài toán.- lập trình thiết kế phần mềm máy tính, visual studio c++, c sharp, sqlserver,... - lập trình quản lý hệ thống nhà máy, server truyền thông công nghiệp, lưu trữ truy xuất dữ liệu.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "- kinh nghiệm: mới ra trường, \n",
      "================================================\n",
      "data-02-06/3093/data.html\n",
      "description\n",
      "\n",
      "at ahamove, we are always driven by data and recognize it as a fuel for innovation. we collect, analyze and integrate data into every corner of the enterprise. data team is the backbone of our company. just like the “on-demand delivery” segment, our data team provides \"on-demand technologies\" to serve our fast-changing business needs and evolving marketour data team has the power to try many up-to-date solutions, tools and technologies such as cloud services, big data distributed system, machine learning model…currently, we have created different data positions to solve a variety of problems which are fun, challenging and meaningful. we welcome young talents with fresh minds to join us on our way to become a 5-star company. let's grow togetherjob brief\n",
      "maintain & optimize inhouse data infrastructure including databases, etl/elt pipelines\n",
      "work with multiple cloud computing platforms such as gcp, aws, databricks\n",
      "etl/elt big/complex datasets to data marts for multiple departments\n",
      "create benchmark, alert, audit log for data system\n",
      "communicate with stakeholders include product, business users, data analysts and data scientists to solve data related requests\n",
      "\n",
      "\n",
      "your skills and \n",
      "-----------------------------------------------\n",
      "experience\n",
      "\n",
      "\n",
      "bachelor degree in computer science or software engineering\n",
      "specializing in data science or a higher degree is a big plus.\n",
      "at least 02-year-experience in building data platforms and pipelines for analytics.\n",
      "excellence at least 2 programming languages like sql, python, java, scala\n",
      "experience with hadoop, spark\n",
      "experience with cloud services (aws, gcp, azure)\n",
      "\n",
      "experience with different database/data warehouse systems: mongodb, postgresql, bigquery, etc\n",
      "experience with data pipeline and workflow management tools: airflow, cloud composer, dbt, airbyte\n",
      "knowledge of data viz tools like metabase, tableau, looker, etc\n",
      "knowledge of streaming process platform is a plus\n",
      "exposure to emerging open source technologies.\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "benefit\n",
      "competitive salary, 13th-month pay & performance bonus\n",
      "monthly allowance (transportation)\n",
      "annual health check-ups.\n",
      "join training courses and tech sharing\n",
      "open communication with senior engineer & technical leader\n",
      "challenging working environment with attractive domain as logistics\n",
      "comfortable private working area for tech team\n",
      "teambuilding + outing trip\n",
      "our culture\n",
      "we collect, analyze and integrate data into every corner of the enterprise. data team is the backbone of our company. just like the “on-demand delivery” segment, our data team provides \"on-demand technologies\" to serve our fast-changing business needs and evolving market.\n",
      "our data team has the power to try many up-to-date solutions, tools, and technologies such as cloud services, big data distributed systems, machine learning models…\n",
      "currently, we have created different data positions to solve a variety of problems that are fun, challenging, and meaningful.\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/17/data.html\n",
      "descriptionsoftware design.software development.deployment and maintenance.\n",
      "-----------------------------------------------\n",
      "job requirementsat least 3 years of experience in software development.hands-on experience with java, spring, and spring boot is required.having a good understanding of messaging brokers is required.good experience working with typescript and angular.good experience working with web services (restful, soap).good knowledge of git workflow and jenkins is a big plus.passionate about software development.good background in software development processes and best practices.good command of english.effective communication both verbally and non-verbally.positive thinking and attitude in every situation.candidates are vietnamese people.work places : ho chi minh, da nang.benefits and incentivesattractive and high – competitive salarypremium healthcare insurance, annual health check up in the prestige and quality hospitalsannual performance review with high bonus and salary increaseonsite opportunities in the silicon valley and others13th month salaryvietnamese public holiday and special holiday bonuses, personal occasions allowances (birthday, newborn baby, marriage, bereavement, sickness,…)overtime payment\n",
      "================================================\n",
      "data-02-06/3130/data.html\n",
      "description\n",
      "\n",
      "    noventiq is hiring!now we’re looking for sales analyst intern to bring your talent to noventiq vietnam. you’ll be a part of our sales support department.job overview: we're looking for a candidate who will manage organization's data and support senior sales analyst in managing our master dataset, building, and developing reports.what you’ll do:help sales team with crm account management, opportunity management data to support forecasting, pipeline management.be guided to work on reporting dataset to ensure data accuracy, perform financial data reconciliations, analyze data transactions, investigate inconsistencies, adjust any discrepancies for reporting readiness.form close working with sales excellence and peers across company, gaining insights and best practices.other activities related to data analyzing and business processes.profile requirements:entry level, 3rd/4th-year students or fresher to 6 months \n",
      "-----------------------------------------------\n",
      "experienceexperience in office 365 usage and internet browsers.have interests in the position of sales admin/business intelligence/data analyst.ready to learn working with crm and sales financial systems.fluency in microsoft office, especially in excel and bi tools (power bi practice is an advantage).english fluency in speaking and writing.what we offer:working time: mond-fri, flexible working time, wfh is applicable.allowance for full-time internship:\n",
      "================================================\n",
      "data-02-06/2785/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "* finance analyst is responsible for managing a company's resources, analyzing costs, reporting to management and helping executives take the best decisions:- ensure that material and ingredients prices quoted on cost sheets represent good value for money- ensure that the company purchasing systems are loaded with accurate price and material allowance information at key stages in the range development process- provide regular reports on how product costs have changed over time- participate in cost-saving projects, share best practices and cost-saving innovations with other members of the team and initiate price comparisons between different suppliers of the same product- prepares periodic cost reconciliation reports, tracking data such as changing labor and supply costs.- performs other duties as assigned.\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2655/data.html\n",
      "description\n",
      "\n",
      "dedicate time to generating new business and pitching clients\n",
      "develop and work with the team to establish future-facing insights, implications, and recommendations, delivering advice, making recommendations, and identifying and solving problems\n",
      "design, implement, test, deploy, and maintain stable, secure, and scalable data engineering solutions and pipelines in support of data and analytics projects, including integrating new sources of data into our central data warehouse, and moving data out to applications and affiliates.\n",
      "build reports and data visualizations, using data from the data warehouse and other sources.implement and monitor best in class security measures in our data warehouse and analytics environment, with an eye towards the evolving threat landscape.\n",
      "produce scalable, replicable code and engineering solutions that help automate repetitive data management tasks\n",
      "collaborating with our ai & business intelligence teams\n",
      "contributing to a data-driven culture\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3109/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            you want to be an important member of a strong team of other makers who take pride in their work and support each other. as a data analyst, you will be responsible for data analytics, reporting needs, dashboard development, etc. if career growth is important to you, we not only know how to help you with that, it’s what we love to do: https://youtu.be/puqzuwryycu\n",
      "\n",
      "1. data analytics\n",
      "o gather requirements, create detailed plans, and conduct data analysis projects.\n",
      "o centralize data from various platforms to fulfill the requested dashboard\n",
      "o be responsible for tasks related to bi processes: collecting data, creating models, creating data visualizations, and producing reports.\n",
      "o assist the management team in developing and maintaining a dashboard and visualization system for company operation monitoring.\n",
      "o develop a document to help users interpret the data story and data trend to support them in decision–making.\n",
      "\n",
      "2.\ttraining and consulting\n",
      "o\tdevelop and implement a training program to improve the data analytics capacities of the team\n",
      "o\tbe a trainer for the company about bi tools, data analytics methods, statistical tools\n",
      "o\tconsult with data analysis solutions to other departments (employee survey analysis, service metrics analysis, etc.) \n",
      "\n",
      "3.\tothers\n",
      "o\tsupport in implementing the weekly /monthly team reports, including but not limited: quantity, quality, special projects, compliments, complaints, etc. as requested to ensure the more accuracy of the annual reviewing\n",
      "o\tparticipate in technical training, engagement, and career orientation program (connect with and be assigned by direct superior)\n",
      "o\treview and enhance the team’s current processes\n",
      "o\tcomply with the company policies, training programs, and meetings upon request.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1173/data.html\n",
      "responsibilities: \n",
      "\n",
      "\n",
      "support brand, marketing and communication business\n",
      "\n",
      "\n",
      "support quality and management of the internal and/or external communications initiatives to support communications\n",
      "\n",
      "\n",
      "preparation, implementation & evaluation of event plan; ensure marketing campaign efficiency and effectiveness to reach the defined brand goals\n",
      "\n",
      "\n",
      "develop relevant content & coordinate with business team and other stakeholders to communicate and acquire adequate resources to ensure effectiveness of outputs\n",
      "\n",
      "\n",
      "conduct market researches & update business intelligence\n",
      "\n",
      "\n",
      "​\n",
      "apply now \n",
      "email your cv to recruitment@cel-consulting.com \n",
      "or apply online at\n",
      "​\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2402/data.html\n",
      "mô tả công việc\n",
      " \n",
      "\n",
      "contribute to the team’s success by using python 3.7, fastapi and domain-driven design, micro-services to spin up new services and apis (writing and consumption).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "collaborate with product, design and other teams to gain sufficient business understanding to serve the needs of customers and colleagues and to support your team members in delivering solutions.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "balance the trade-offs of delivering sustainable code that provides an excellent customer \n",
      "-----------------------------------------------\n",
      "experience in a fast-paced startup environment.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model good leadership behaviour by engaging in peer to peer feedback and code reviews to foster a healthy, collaborative engineering culture as measured by scrum team health checks.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "use unit test and agile practices to deliver features continuously to production, measured by feedback and daily releases going smoothly.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "embrace a fast paced environment and have a keen interest in data / machine learning tech.\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/1456/data.html\n",
      "responsibility04.one-team spiritbe a pixta-ercompensation & benefitattractive salary with lunch & parking allowance.twice a year performance review with year-end bonus.5 working days a week and 13 paid days off a year.career growthconnect personal growth with business goals.clear career path.flexible team rotation.education & awardfree coursera account.seminars and technical camps.quarterly awards for excellent employees.working atmosphereyoung, transparent & supportive.club: tennis, table tennis, soccer, music...career opportunitieslet's stay in touchhanoi office8th floor, truong thinh building, no.1 phung chi kien street, cau giay district, hanoi, vietnam.recruit.vn@pixta.co.jp(+84) 24 6664 1988 : (+84) 24 6666 1989directio\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1174/data.html\n",
      "responsibilities: \n",
      "\n",
      "\n",
      "support brand, marketing and communication business\n",
      "\n",
      "\n",
      "support quality and management of the internal and/or external communications initiatives to support communications\n",
      "\n",
      "\n",
      "preparation, implementation & evaluation of event plan; ensure marketing campaign efficiency and effectiveness to reach the defined brand goals\n",
      "\n",
      "\n",
      "develop relevant content & coordinate with business team and other stakeholders to communicate and acquire adequate resources to ensure effectiveness of outputs\n",
      "\n",
      "\n",
      "conduct market researches & update business intelligence\n",
      "\n",
      "\n",
      "​\n",
      "apply now \n",
      "email your cv to recruitment@cel-consulting.com \n",
      "or apply online at\n",
      "​\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1593/data.html\n",
      "================================================\n",
      "data-02-06/1445/data.html\n",
      "================================================\n",
      "data-02-06/1902/data.html\n",
      "mô tả công việc\n",
      "\n",
      "this role will be responsible for taking business needs from business units and analyzing relevant data to develop answers for the needs or find interesting data trends that could bring business value.take ownership of the data governance project and work with cross departments to facilitate and initiate data solutions.we are building an office in kuala lumpur, malaysia. we prioritize recruiting vietnamese candidates willing to relocate to malaysia with attractive salary offers.\n",
      "work location 1: kuala lumpur, malaysia\n",
      "work location 2: hanoi, vietnam\n",
      "responsibilities\n",
      "responsible for developing business insights and trends using data visualization techniques and tools such as dashboards and reports\n",
      "data exploration and preparation, data collection and integration to facilitate data analysis to solve business problems\n",
      "developing data models for data analysis\n",
      "take ownership and lead data projects with internal teams\n",
      "this role would be suitable for someone who is already working with data with future ambitions of becoming a data scientist\n",
      "generating information and insights from data sets and identifying trends and patterns\n",
      "(if possible) building predictive models and handling other advance task\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "\n",
      "from 2-year experience as a data analyst\n",
      "fluent in writing & speaking english\n",
      "master of sql and python\n",
      "familiar with databases & cloud storage (google bigquery, snowflake…)\n",
      "familiar with visualization tools (tableau, powerbi, looker…)\n",
      "having experience in 2 domains (mobile application) and (financial investment) is a great advantage\n",
      "understand the data needs of different departments (marketing, product, finance…)\n",
      "understand the scopes of data engineers, data scientists to collaborate and take the lead if needed\n",
      "have a robust problem-solving mindset. be able to turn a simple question to become a comprehensive data dashboard that detects and solves a business problem\n",
      "good communication skills. be able to deliver, present and explain the results in an effective way for both technical and non-technical parties\n",
      "\n",
      "\n",
      "tại sao bạn sẽ yêu thích làm việc tại đây\n",
      "\n",
      "\n",
      "competitive salary with annual salary reviewwork in malaysia: up to 2000 usd with allowanceswork in vietnam: up to 900 usd\n",
      "\n",
      "an international working environment with friendly, creative colleagues from around the world\n",
      "an excellent opportunity to grow your career. we encourage you to take the lead, initiate and make decisions\n",
      "tuition fee sponsorship if you expect to become a data scientist or grow other data skills\n",
      "enjoy birthday parties and frequent weekend parties and other team-building activities (depending on your work location)\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/1883/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "position overview:\n",
      "the customer care centre administrator & analyst is responsible for supporting the alma customer care centre by performing all general and administration functions as well as analyzing of marketing campaigns that include direct mail outbound, owner preview’s, referral previews daily tasks will include lead management and report management.\n",
      "key responsibilities:\n",
      "• provide administrative support including filing, emailing, and other office duties for the alma customer care centre.\n",
      "• update reports or crm, entering tours, tour hooks, nqs and tour results sales results \n",
      "• liaise with customer care centre team regarding dated and open dated package sales.\n",
      "• charge customers credit cards \n",
      "• screen incoming emails and phone calls and action promptly and professionally.\n",
      "• prepare reports and presentations as required.\n",
      "• print and prepare customer care centre production reports and distribute as required.\n",
      "• assist marketing purchase orders and liaise with finance for payment\n",
      "• assist other general office duties.\n",
      "• provide administrative support to customer care centre management team in accordance with directives set from management facilitate the delivery of qualified tours/leads\n",
      "• highly proficient in excel ,word ,powerpoint\n",
      "key performance indicators:\n",
      "performance reviews will be conducted on an annual basis and may require coaching programs to enhance skills and overall productivity.  this position will be measured against the following criteria:\n",
      "• complete all designated tasks, within allocated time frames.\n",
      "• establish and maintain effective working relationships internal stakeholders and corporate suppliers.\n",
      "• treat all company staff and external contacts courteously and respectfully to assist in maintaining a positive company image both within the company and in the public domain.\n",
      "\n",
      "\n",
      "\n",
      "quyền lợi\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- basic salary: 10,000,000 + monthly bonuses and commissions\n",
      "- insurance: health insurance, social insurance, unemployment insurance \n",
      "- annual activities: birthday, holiday/new year bonus, vacation, etc.\n",
      "- training: to participate in basic training courses and improve skills;\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "• proven work experience as a personal assistant/secretary/administrator\n",
      "• knowledge of office management systems and procedures\n",
      "• ms office and english proficiency\n",
      "• outstanding organizational and time management skills\n",
      "• ability to multi-task and prioritize daily workload\n",
      "• excellent verbal and written communications skills\n",
      "• proactive, flexible, and self-motivated\n",
      "• problem-solving skills and can work under high pressure\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/1249/data.html\n",
      "================================================\n",
      "data-02-06/2484/data.html\n",
      "description\n",
      "                \n",
      "about the job\n",
      "\n",
      "maintain and design relational databases to support enterprise application and physical data modelling according to project requirements for data acquisition and security as well as customer-defined deliverables.\n",
      "develop strategies for data modeling, design and implementation to meet stated requirements for metadata management, operation data stores, data lake, data warehouse, data marts and extract transform load environments in batch processing and real-time injection.\n",
      "create and test physical data models for a variety of business data, applications, database structures and metadata tables to meet operational goals for performance and efficiency\n",
      "carrying out day-to-day support for reporting system.\n",
      "\n",
      "about you\n",
      "\n",
      "bachelor or college degree in information technology or equivalent practical work experience\n",
      "2+ years of experience in relevant role\n",
      "proficientwith some of the modern relational databases such as oracle, db2, and sql server\n",
      "hand-on experiences on designing and developing etl solution by using ssis or other etl tools\n",
      "strong in writing t-sql, pl/sql\n",
      "good understanding of data modelling, processing and warehouse techniques\n",
      "skilled at optimizing large complicated sql statements\n",
      "capable of troubleshooting common database issues\n",
      "knowledge at reporting development with microsoft ssis and ssrs\n",
      "analytical thinking\n",
      "good interpersonal and communication skills\n",
      "time management and planning skill\n",
      "\n",
      "equal opportunity \n",
      "amaris consulting is proud to be an equal opportunity workplace. we are committed to promoting diversity within the workforce and creating an inclusive working environment. for this purpose, we welcome applications from all qualified candidates regardless of gender, sexual orientation, race, ethnicity, beliefs, age, marital status, disability or other characteristics.\n",
      "-----------------------------------------------\n",
      "experience. we like to get to know our candidates, challenge them, and be able to give them proper feedback as quickly as possible. here's what our recruitment process looks like:\n",
      "================================================\n",
      "data-02-06/2306/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- tổng hợp, phân tích đánh giá hiệu quả bán hàng hàng tuần/tháng/quý/năm, hiệu quả bán hàng qua các sự kiện, lễ;- phân tích sở thích và nắm bắt tâm lý khách hàng thông qua dữ liệu thu thập,- thu thập thông tin về thị trường và đối thủ cạnh tranh để làm dữ liệu phân tích và báo cáo, nghiên cứu những biến động trong ngành f&b có thể ảnh hưởng tới doanh số với mục đích phục vụ cho việc ra các quyết định chiến lược của công ty,- phát triển và quản lý các công cụ đo lường để tối ưu hóa việc đưa ra quyết định kinh doanh của bgđ- quản lý theo dõi các đơn hàng sale,- phối hợp với team marketing để thực hiện các chương trình kế hoạch sự kiện.- mức thu nhập: lương cứng 10 triệu + các khoản kpi 10%, thưởng tháng 13...\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3057/data.html\n",
      "responsibilities:research projects (inhouse or outsource) • understand the business needs of requesters thoroughly to propose the relevant research scope and approach or evaluate the proposal from vendors to make sure the research can address properly business needs• for annual projects (brand health tracker, benchmarking survey, voice of agency …), work closely and effectively wit related stakeholders (i.e product, branding, agency team etc) to update the local business's needs and provide useful inputs to the questionnaire crafted by outsourced research vendors• work independently to lead and implement internal research projects/ data analytics projects or outsourced research projects, including:➢ collecting internal data from different source for analyzing, questionnaire/ dg design, conduct idi/dg, data analyzing, report writing and provide actionable recommendations for business questions that need sound decision making. ➢ evaluate adjust the proposals made by research agencies so that the final one is produced up to the highest work in terms of timing, budget and quality of deliverables. manage the quality and delivering time of research agency. provide useful and insightful inputs to the work of agencies across the key milestones of project execution (discussion guide development or questionnaire design, topline, reporting)drive insights to actions • organize actionable workshop after obtaining research findings/ data findings so that the information and be shared and bring to actions by different teams• initiate actions to improve customer experience and lead end to end projects to deliver the initiatives improving customer experience across touchpoints.• join cross-function projects to represent voice of customers.ii. \n",
      "-----------------------------------------------\n",
      "job requirements:qualifications:• university/ college degree with marketing/ business majorexperience:• at least 5 years’ experience in market research (2 years' working experience for a market research agency is preferable) and minimum 1 year of working as a ci/ market research manager.job capabilities & behaviors requirements:• execution excellence: take full ownership to resolve difficulties, challenges and deliver the project objectives efficiently with highest standard of quality• working together: work well with different types of people including external research vendors and internal stakeholders; proactively contribute thoughts, ideas in meetings, cross-functional projects• strategic thinking: think a big picture and use good judgment to find hows to approach/ implement one issue/ challenge thoroughly and efficiently• great data analytic skill (i.e either qualitative or quantitative data points)• be a great communicator, both spoken and written english communication\n",
      "\n",
      "================================================\n",
      "data-02-06/3067/data.html\n",
      "================================================\n",
      "data-02-06/2983/data.html\n",
      "description\n",
      "\n",
      "\n",
      "life at agoda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "all teams\n",
      "contentcustomer \n",
      "-----------------------------------------------\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "strategic partnerships – salesforce developer (bangkok- based, relocation provided)\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "================================================\n",
      "data-02-06/1207/data.html\n",
      "================================================\n",
      "data-02-06/766/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description\n",
      "do you want to work at a rapid grow ai-based software company in thailand?\n",
      "\n",
      "about the company: our partner is an ai-based recruitment software company based in bangkok, thailand. its mission is to offer easy-to-use software to empower small, medium, and large companies in their staffing & recruitment transformation.\n",
      "\n",
      "their goal is simple: to provide solutions to the recruitment world’s difficulties and make the entire process simple and enjoyable for recruiters, hiring managers, and candidates alike. globally trusted by thousands of companies in over 130 countries, the company’s growth goes hand in hand with their client’s own. they’re passionate about developing solutions for the changes they encounter and filling the recruitment gap with innovative tech implementation.\n",
      "\n",
      "company location: bangkok, thailand.\n",
      "the company is open to sponsor relocation packages for candidates who are currently not in bangkok.\n",
      "\n",
      "office address: 26/58 orakarn building 16th floor, chidlom alley, phloen chit rd, khwaeng lumphini, khet pathum wan, krung thep maha nakhon 10330\n",
      "\n",
      "responsibilities:\n",
      "\n",
      "– set, define, and own the data science roadmap\n",
      "– build a team of data scientists and mentor junior scientists and engineers\n",
      "– build, maintain and enhance core features of manatal including candidate recommendation engine and cv/resume parsing services\n",
      "– design, prototype, and implement models across several domains. manage each part of a projects life cycle, including ad-hoc exploration, preparation of training data, model development, and production deployment\n",
      "– help define and implement a framework of continual innovation within the ml infrastructure and orchestrate a continuous cycle of learning, inference, and observation\n",
      "– partner with engineers to develop ml pipelines, and maintain high system availability and reliability\n",
      "– utilize methods such as natural language processing, clustering, and dash boarding (among others) to create solutions.\n",
      "\n",
      "interview process\n",
      "– 1st interview\n",
      "– technical take-home test\n",
      "– 2nd interview with cto\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2478/data.html\n",
      "mô tả công việc\n",
      " reporting to the data analytics manager, you will be responsible for:● work closely with all various business units to gather business requirements and prioritize information needs.● design and implement visualizations (in bi tool) in response to business needs from relational databases and other source systems.● acquire data from multiple data sources, understand and maintain the flow of data from sales, commercial, etc.● analyze requirements or concepts and propose viable solutions that bring high value for business and end-users.● work closely with the development team (data engineer, data scientist) to make an automation data report.● review data and dashboard periodically to make sure all reports are up-to-date and accuracy● deliver effective presentations of findings and recommendations to the business user, creating a visual display of quantitative information \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2657/data.html\n",
      "mô tả công việc- sử dụng hệ thống social listening thu thập và xử lý dữ liệu về thương hiệu kh từ đa nguồn \n",
      "(facebook, news, youtube, instagram,…)\n",
      "- thực hiện các báo cáo định kỳ\n",
      "- thực hiện các báo cáo phân tích chuyên sâu các vấn đề kinh tế - xã hội\n",
      "- thực hiện các báo cáo chuyên sâu để nâng cao chiến lược phát triển kinh doanh, thương hiệu, \n",
      "marketing, sales... cho kh\n",
      "- trực tiếp tham gia hỗ trợ các chiến dịch truyền thông, marketing cùng các doanh nghiệp hàng \n",
      "đầu việt nam (vna, viettel, vcb, vpbank,…) trên các nền tảng mxh\n",
      "- trực tiếp tham gia xử lý khủng hoảng truyền thông cho đối tác, dựa trên thống kê và lượng \n",
      "hóa các chỉ sốvề icomm việt nam\n",
      "công ty cp truyền thông và công nghệ icomm việt nam là đơn vị phát triển các sản phẩm công nghệ hàng đầu về dữ liệu lớn và an toàn bảo mật đã và đang triển khai tại các tập đoàn \n",
      "- doanh nghiệp lớn nhất trải dài ở các lĩnh vực: hàng không, viễn thông, tài chính ngân \n",
      "hàng, f&b, năng lượng, bđs, giáo dục,... cũng như các bộ ban ngành và các tỉnh thành  chủ chốt trong cả nước. \n",
      "với hơn 60 sản phẩm phục vụ công tác quản lý nhà nước cũng như các nghiệp vụ đa dạng của  doanh nghiệp, công ty luôn có nguyện vọng đồng hành với những nhân sự có sự đam mê về công nghệ chuyên sâu mang tính đột phá và giải quyết các bài toán thu thập khai thác trên quy  mô dữ liệu siêu lớn\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên- tư duy logic, khả năng sắp xếp, phân tích, giải quyết vấn đề tốt\n",
      "- có khả năng làm việc độc lập, đồng thời có kỹ năng làm việc nhóm\n",
      "- là người chủ động, trách nhiệm, ham học hỏi, tinh thần tích cực\n",
      "- chịu được áp lực tốt trong công việc và sẵn sàng làm ngoài giờ\n",
      "- ưu tiên có kinh nghiệm phân tích dữ liệu hoặc truyền thông/marketing tối thiểu 6 tháng và sử\n",
      "================================================\n",
      "data-02-06/2960/data.html\n",
      "================================================\n",
      "data-02-06/581/data.html\n",
      "responsibilities\n",
      "help make our games even better!use quantitative analysis to understand how the game is played and identify impact and growth opportunitiessupport the game team in their day-to-day needs: facts, ideas, monitoring and assessing impact of design decisionsproactively come up with actionable analyses across game design, monetization strategies, marketing strategiesuse sound analytics to improve our business from marketing to in-game events and offerscollaborate with other scientists and engineers to expand the ways we are using our data to improve our games\n",
      "requirements\n",
      "years of \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/839/data.html\n",
      "================================================\n",
      "data-02-06/2953/data.html\n",
      "description for database engineer at panasonic việt na\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1313/data.html\n",
      "responsibilities\n",
      "requirements\n",
      "what we offer\n",
      "additional infotrusting social is a leading fintech company with a mission to advance data science and technology to deliver financial access for all. our vision is to make universal financial inclusion a reality in southeast asia and india within the next 10 years, transforming the lives of millions of people and promoting economic growth in the region. we are committed to creating an inspiring and dynamic work environment, where employees are empowered to ignite their passion, shape the future of finance, and transform lives across the globe.\n",
      "our credit insights team comprises highly skilled data scientists who stay up to date with the latest developments in data science, machine learning, and ai. we use innovative methods to analyze data and extract insights to enhance our understanding of customers and develop effective financial products.our team creates credit and income scoring models and fraud detection models to identify and prevent fraudulent activities. we also integrate our machine learning model outputs into production for automated decision-making and improved business efficiency.\n",
      "for credit card portfolio management, our mission is to optimize credit line management, credit limit setting, and collections. we utilize our expertise in data science to develop predictive models and analytics that forecast customer behavior and credit risk. additionally, we leverage machine learning and ai techniques to identify patterns and insights in transaction data, customer behavior, and marketing campaigns. by collaborating with other teams, such as product development, marketing, and customer service, we aim to deliver a seamless and personalized customer \n",
      "-----------------------------------------------\n",
      "experience across all touchpoints. ultimately, our goal is to minimize risk and optimize portfolio performance metrics for the benefit of our customers.\n",
      "responsibilities\n",
      "\n",
      "\n",
      "\n",
      "the ideal candidate will have a passion for utilizing data and analytics to optimize portfolio performance. the successful candidate will be responsible for analyzing large datasets, developing predictive models, and generating actionable insights for credit card portfolio management.\n",
      "\n",
      "developing and implementing credit risk models and analytical tools to assess portfolio performance, credit risk, and profitability.\n",
      "analyzing and interpreting data to identify trends, patterns, and insights that drive portfolio management decisions.\n",
      "conducting ad-hoc analysis and data mining to support portfolio optimization and strategy development.\n",
      "collaborating with business stakeholders to understand their needs and requirements, and to develop and implement solutions that meet their needs.\n",
      "creating and maintaining reports and dashboards that provide insights into portfolio performance and key performance indicators (kpis).\n",
      "designing and conducting a/b tests to evaluate the impact of new portfolio strategies and tactics.\n",
      "maintaining up-to-date knowledge of industry trends, best practices, and regulatory requirements related to credit card portfolio management.\n",
      "communicating complex analytical findings and recommendations to non-technical stakeholders, including senior management.\n",
      "mentoring and coaching junior analysts and data scientists on the team.\n",
      "partnering with data engineers and other technical teams to ensure data quality, availability, and scalability.\n",
      "conducting competitive research to stay informed of market trends, customer preferences, and emerging technologies that may impact the credit card portfolio.\n",
      "perform highly complex activities related to financial products, business analysis, and build dashboards for portfolio monitoring.\n",
      "utilize statistical and machine learning techniques to identify patterns and trends in financial data\n",
      "develop and implement data-driven investment strategies that optimize portfolio performance\n",
      "\n",
      "requirements\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2840/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description rockwell automation is hiring!  we are looking for an agreements manager to be based in our vietnam or korea office.  job scope:  develops, evaluates and approves special price requests within defined pricing strategies and models based upon current business and competitive market dynamics to meet customers' needs while providing a profit for the organization. conducts research, considers the competitive environment and monitors the effectiveness of customer pricing strategies. modifies pricing structures as needed to ensure practices do not adversely impact company results or customer satisfaction. partners with key stakeholders to correctly position product portfolio and establish customer pricing programs aligned with product/sales strategy and revenue recognition requirements. projects impact of pricing changes and coordinates implementation of pricing proposals across the organization.  about you:  at least 3 years' \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3027/data.html\n",
      "mô tả công việc\n",
      " \n",
      "a finance intern usually works under the supervision of the business services division\n",
      "management and must follow the accounting or auditing process\n",
      "to collect, understand, process, verify and report accounting related-information to\n",
      "his/her vertical head\n",
      "be given professional analytical and management support work assignments\n",
      "assistance may be required in the preparation of monthly or weekly financial reports\n",
      "develop and utilize spreadsheets, databases and other computer applications\n",
      "manage specialized information, reports, forms dealing with fees, billing, tracking of\n",
      "projects etc\n",
      "enter information into the financial accounting system of the company\n",
      " \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2526/data.html\n",
      "mô tả công việc\n",
      "tìm hiểu về các blockchain network phổ biến hiện tại hỗ trợ smartcontract như eth, bsc, solana, eos…tìm hiểu cách thức vận hành của các blockchaintìm hiểu và đề xuất cách thức chuyển data giữa các chainthực thi giải pháp đề xuất, cải thiện hiệu năng và bảo mật\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "sinh viên năm 3,4,5 hoặc đã tốt nghiệp trong vòng 06 tháng chuyên ngành cntt hoặc tương đương các trường đại học/ cao đẳng. có thể tham gia parttime (20h/tuần).thời gian thực tập: 3- 6 thángcó đam mê và nắm chắc các kiến thức cơ bản lập trìnhcó đam mê tìm hiểu các công nghệ mới, phát triển các sản phẩm mớikhả năng tư duy tốt, chủ động trong công việc, có tinh thần trách nhiệm cao để hoàn thành công việc được giaocó khả năng làm việc teamwork cũng như làm việc độc lập\n",
      "quyền lợi\n",
      "được sự hướng dẫn, dìu dắt từ những người có kinh nghiệm nhiều năm, kỹ năng tốt.được tham gia vào dự án thực tế, quy trình làm việc chuyên nghiệp.có lương hỗ trợ: 2m/tháng\n",
      "================================================\n",
      "data-02-06/3079/data.html\n",
      "mô tả công việc\n",
      "\n",
      "vpbank hiện là một trong những ngân hàng có tốc độ tăng trưởng nhanh nhất tại việt nam, cung cấp đa dạng các dịch vụ và được nhiều khách hàng tin dùng. vpbank đặc biệt chú ý đến việc nâng cao hiệu quả hoạt động qua việc phân tích các dữ liệu kinh doanh.\n",
      "vị trí này đóng vai trò làm việc với các đơn vị kinh doanh và các các phòng/ trung tâm khác trong nội bộ khối quản trị và phân tích dữ liệu (ead) để phân tích các bộ dữ liệu phức tạp, tìm kiếm các hiểu biết sâu sắc về hành vi khách hàng và đưa ra các khuyến nghị tương ứng.\n",
      "1. hỗ trợ quản lý và định hướng phòng khoa học dữ liệu trong việc áp dụng các kỹ thuật phân tích nâng cao, tìm ra hành vi khách hàng, giải quyết các vấn đề kinh doanh thực tế:\n",
      "\n",
      "chủ động triển khai và dẫn dắt các dự án phân tích dữ liệu phục vụ hoạt động kinh doanh\n",
      "áp dụng các kỹ thuật phân tích nâng cao, đưa ra các hiểu biết sâu sắc về hành vi của khách hàng, qua đó giúp giải quyết các vấn đề kinh doanh thực tế.\n",
      "tìm kiếm các hiểu biết sâu sắc về hành vi khách hàng bằng các kỹ thuật khai phá dữ liệu khác nhau\n",
      "phát triển mô hình học máy, giúp các đơn vị kinh doanh dự báo các vấn đề kinh doanh khác nhau như dự báo khách hàng ngừng sử dụng dịch vụ, bán chéo sản phẩm cho khách hàng hiện tại\n",
      "tự động hóa quy trình phân tích\n",
      "hướng dẫn, đào tạo các thành viên trong phòng\n",
      "\n",
      "2. nghiên cứu và học hỏi các kỹ thuật phân tích nâng cao mới\n",
      "\n",
      "nghiên cứu các phương pháp mới trong lĩnh vực phân tích, khai phá dữ liệu và dự báo\n",
      "\n",
      "3. hỗ trợ các phòng/ trung tâm khác trong các bài toán phân tích dữ liệu nâng cao\n",
      "\n",
      "làm việc với các phòng/ trung tâm khác trực thuộc eda cũng như các đơn vị kinh doanh để nắm rõ các vấn đề và thực hiện các phân tích chuyên sâu và dự báo khi cần thiết\n",
      "hỗ trợ đào tạo thành viên khác trong lĩnh vực phân tích dữ liệu\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "yêu cầu công việc\n",
      "\n",
      "tốt nghiệp đại học hoặc cao hơn chuyên nghành toán, thống kê, kinh tế, ngân hàng, tài chính, khoa học máy tính, kỹ thuật phần mềm…\n",
      "tối thiểu 5 năm làm việc trong lĩnh vực phân tích dữ liệu, mô hình học máy, học sâu. ưu tiên các ứng viên có kinh nghiệm tại ngân hàng\n",
      "có hiểu biết sâu sắc và có kinh nghiệm làm việc với các mô hình thống kê, dự báo, các thuật toán học máy, các kỹ thuật phân tích nâng cao\n",
      "thành thạo sql, excel và\n",
      "================================================\n",
      "data-02-06/1145/data.html\n",
      "descriptionkms healthcare is the intersection of world-class technologists and proven healthcare industry expertise.we empower companies to build transformative next-gen technologies to bring about game-changing resolutions to healthcare’s most challenging problems. our solutions ensure improved data exchange while maintaining regulatory compliance and data-driven requirements. we are committed to providing innovative tools and expertise to providers, payers, life sciences, and medical technology vendors in order to help create industry-leading health solutions.at kms healthcare, we leverage technologies to enable a modern way of health service. covering end-to-end product development, we helped numerous u.s. health practices increase health treatment quality, reduce costs, and save people's lives.instead of wishing people good health, join us to make it happen.job descriptiondesign and implement data strategy for current and new data services solutionsinterface with developers, product managers, and product analysts to understand data needscollaborate with architects and application development teams to understand product functionality and design directionprovide input to estimates of quality and quantity of resources required to successfully implement business solutionsresponsible for working as part of application development teams to plan, implement, and test new releases into our production systems environmentassist and oversee the delivery of special projects and enhancements; planning, resourcing and executing with compliance with scrum methodologiesdeliver quality software to production in a consistent and repeatable mannercreate and maintain efficient workflows for software development and deliverymentor other engineers in data engineering design and automated software deliveryprovide mentoring/training for junior members if any.perform other tasks assigned by the leader/ manager.qualificationsgeneral requirements:intermediate level of english level.good for logical thinking and problem solving.ability to self-learn and adapt to new technologies quickly.digital thinker, product mindset, can-do attitude, and adaptable.ability to handle multiple tasks, communicate effectively with team members and management.technical requirements:5+ years of working \n",
      "-----------------------------------------------\n",
      "experience in data engineering, data warehousing, and data streamingstrong experience with sql database.experience with python programing language.experience with\n",
      "================================================\n",
      "data-02-06/2975/data.html\n",
      "================================================\n",
      "data-02-06/3150/data.html\n",
      "description\n",
      "\n",
      "we're a fintech product in viet nam with young people and full of energy. our aim is to optimize product across the entire user journey, identify and create new audiences. we are looking for a senior data scientist to join our data science team. you’ll be part of a team that is disrupting the industry with innovative attribution models and building the future analytics platform to be used by many teams (tech, promotion,..) for user behavior, campaign performance and market insights. you’ll be working on very exciting projects using big data technologies with terabytes of data coming from different source.responsibilities:\n",
      "work with many teams (po, tech, bo) to understand dataflow, cashflow\n",
      "identify problems and propose recommendations\n",
      "focus on bringing statistical depth, analytical insights, and accurate interpretation of data\n",
      "measure system performance and also deeper understand trends by providing insights and recommendations based on large amounts of data from various sources\n",
      "design innovative attribution models to implement valuable metrics and better address system enhancement, user behavior\n",
      "build and maintain visually appealing and engaging dashboards for stakeholders\n",
      "work with data engineers to help define the data standards and requirements helping to ensure our systems are running correctly and efficiently.\n",
      "involve in the development and evolvement of the data architecture\n",
      "support internal training and proper documentation ensuring the successful onboarding of new team members\n",
      "\n",
      "\n",
      "your skills and \n",
      "-----------------------------------------------\n",
      "experience\n",
      "\n",
      "\n",
      "5+ years relevant work experience with large amounts of data\n",
      "education background in machine learning, statistics, math, data science, computer science or other closely related area\n",
      "strong machine learning/statistics background with hands-on experience in academia and/or industry, sourcing, cleaning, manipulating and analyzing large volumes of data\n",
      "experience with open-source machine learning libraries such as numpy, pandas, scikit-learn, distributed/parallel big data processing architecture (e.g., hadoop, spark, mllib) and deep learning framework (e.g., tensorflow, pytorch)\n",
      "understand the business domain (fintech, adtech knowledge is a plus)\n",
      "can plan, prioritize and troubleshoot\n",
      "experience with recommendation systems is a plus\n",
      "experience with data science models in finance domain or crm (e.g., credit scoring, clv, churn, etc) is a plus.\n",
      "================================================\n",
      "data-02-06/826/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responsibilities?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "01. data analysis\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "problem-solving and analytical understanding for statistics and data and infographicstechnical skills and competency in using data analytics software like tableau, powerbi, quicksites, etc.identifying trends and generate insights by conducting routine analyses of datahouse asia’s various datacommunicate key findings to various stakeholders to facilitate data-driven decision-making or storytellingrecognize key metrics and build high-level dashboards to track the progress of the agency’s metrics and its highest-priority initiativesaggregate data from various sources to construct streamlined data pipelines and integrate data from multiple datahouse asia systems into analytical software and create real time dashboards \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "02. operational support\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "provide support as needed to other internal teams when specific projects involving data analysis arisecontinuously strive for ways to improve operational efficiency, develop reports, and maintain spreadsheets/data metrics to monitor, track, and evaluate performanceupdate and maintain agency milestones and metrics, including but not limited to monthly performance management indicatorsresearch data integrity issues and identifying root causes or inconsistencies and required cleanupsupport and provide technical assistance for inquiries and issuestriage and track internal and external data request \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2524/data.html\n",
      "mô tả công việc:- chúng tôi đang tìm kiếm một nhà phân tích dữ liệu kinh doanh dược phẩm có kỹ năng và năng động để tham gia vào nhóm của chúng tôi. ứng viên trúng tuyển sẽ chịu trách nhiệm phân tích và diễn giải các tập dữ liệu phức tạp, cung cấp thông tin chi tiết hữu ích để hỗ trợ các quyết định kinh doanh trong ngành dược phẩm.trách nhiệm công việc:- thu thập, làm sạch và phân tích các bộ dữ liệu lớn từ nhiều nguồn khác nhau, bao gồm số liệu bán hàng, báo cáo nghiên cứu thị trường và phản hồi của khách hàng.- phát triển và duy trì cơ sở dữ liệu, bảng tính và các công cụ khác để tổ chức và phân tích dữ liệu.- sử dụng phần mềm thống kê và phân tích dữ liệu để xác định xu hướng và mẫu trong dữ liệu và chuẩn bị báo cáo cho quản lý.- cộng tác với các nhóm chức năng chéo để hiểu các yêu cầu kinh doanh và phát triển các giải pháp đáp ứng các nhu cầu đó.- giải thích và truyền đạt kết quả dữ liệu cho các bên liên quan phi kỹ thuật một cách rõ ràng và ngắn gọn.- theo dõi các xu hướng của ngành, đối thủ cạnh tranh và các thay đổi về quy định để cung cấp thông tin chuyên sâu về thị trường dược phẩm.- phát triển và thực hiện các chiến lược dựa trên dữ liệu để tối ưu hóa quy trình kinh doanh và tăng lợi nhuận\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2087/data.html\n",
      "================================================\n",
      "data-02-06/1437/data.html\n",
      "================================================\n",
      "data-02-06/1637/data.html\n",
      "================================================\n",
      "data-02-06/2103/data.html\n",
      "mô tả công việc\n",
      "• designing and building scalable data models.• cleaning and transforming data.• develop records management processes and policies• identify areas to increase efficiency and automation of processes• set up and maintain automated data processes• identify, evaluate, and implement external services and tools to support data validation and cleansing• produce and track key performance indicators• develop and support reporting processes• monitor and audit data quality• liaise with internal and external clients to fully understand data content• gather, understand, and document detailed business requirements using appropriate tools and techniques• design and carry out surveys and analyse survey data• manipulate, analyse, and interpret complex data sets relating to the employer's business• prepare reports for internal and external audiences using business analytics reporting tools• create data dashboards, graphs, and visualisations• provide sector and competitor benchmarking• mine and analyse large datasets, draw valid inferences, and present them successfully to management using a reporting tool.• enabling advanced analytics capabilities that provide meaningful business value through easy-to-understand data visualizations.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "• advanced data analytics (azure data factory, data bricks, data lake, hd insights)• sql migration / modernization experience• azure sql database (standalone, elastic pool, serverless, managed instance, hyperscale)• azure synapse analytics• nosql: azure cosmos db, mongodb, cassandra• azure blob storage, azure data lake store• power bi and analysis services• machine learning services/cognitive services• 2+ years’ experience working with bi technologies and tools like microsoft power bi, tableau.• 2 years of experience with azure (da-100 certification acts as a plus)• 3+ years’ using programming languages such as java, dax, mdx, sql, python.• 2+ years’ bi related experience using etl, data warehousing management, data mining, report designer, or development; ability to write complex sql queries against a variety of data sources.• 3+ years’ heterogeneous database management systems like ms sql, oracle, mysql, sap etc. and working knowledge with various data sources like flat files (csv, delimited), web api, xml.• proven ability to build consensus between teams with differing architecture and design viewpoints and perspectives.• good understanding of data and query optimization, query profiling, and query performance monitoring tools and techniques.• experience implementing solutions on multiple hardware platforms and operating systems.• must be self-motivated, responsible, conscientious, and detail oriented. proven ability to follow priorities and timelines.• must have strong analytical and problem-solving skills.• english communication.\n",
      "quyền lợi\n",
      "- 13th month salary, social insurance- opportunity to work on new technologies and tools- opportunity to work with multicultural environment and travel.- performance review and adjust salary twice a year- very attractive remuneration package- a flat hierarchy and a culture of collaboration across all disciplines- modern workplace\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 30/06/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/1980/data.html\n",
      "description for senior datalake engineer at prudential vietnam insuranc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2006/data.html\n",
      "================================================\n",
      "data-02-06/2334/data.html\n",
      "description\n",
      "ai engineer\n",
      "\n",
      "kyanon digital - hcmcitfull-time \n",
      "\n",
      "\n",
      "company profile \n",
      "a vietnam-based tech powerhouse providing world-class digital solutions.\n",
      "established in 2012, kyanon digital is a vietnam-based tech powerhouse having offices in hcmc/vietnam, singapore, and europe. kyanon digital is trusted by international clients for commitment to success and engineering excellence.\n",
      "kyanon digital is focusing 3 main service areas as below:\n",
      "\n",
      "digital consulting\n",
      "digital innovation\n",
      "digital venture\n",
      "\n",
      "you will:\n",
      "\n",
      "convert ai/ml models (computer vision) into apis to enhance functionality so that other applications can access them\n",
      "test and deploy ai/ml software and models\n",
      "optimize ai/ml models for inference in production\n",
      "assist in the development and training of ai/ml model\n",
      "build scalable data pipelines to extract, transform, load and integrate data\n",
      "develop codes and scripts to process structured and unstructured data in real-time or in batches from a variety of data sources\n",
      "optimize existing microservices\n",
      "test data pipelines for scalability and reliability to process high data volume, variety and velocity\n",
      "\n",
      "you should have:\n",
      "\n",
      "bachelor’s degree in computer science, computer engineering, information systems, information engineering, or equivalent\n",
      "at least 2 – 3 years \n",
      "-----------------------------------------------\n",
      "experience in deep learning and machine learning in the area of computer vision\n",
      "experience in building and optimizing microservices, data pipelines, and data sets\n",
      "experience working with cloud infrastructure such as aws, azure or gcp\n",
      "proficient in python programming language\n",
      "knowledge of react js advantageous, but not mandatory\n",
      "experience in restful api service development and familiarity with http / tcp\n",
      "experience in parallel and concurrent computation preferred\n",
      "familiarity with devops container techniques including docker and kubernetes preferred\n",
      "\n",
      "\n",
      "\n",
      "application form\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "upload maximum 1.5mb\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "submit \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/777/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thông tin liên hệ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "phạm vi công việc hỗ trợ trưởng phòng nghiên cứu/ phó tổng giám đốc trong việc phân tích thông tin, duy trì cơ sở dữ liệu và quản lý các báo cáo.\n",
      "\n",
      "\n",
      "chi tiết công việc\n",
      "\n",
      "tham gia vào các dự án khác nhau và đảm nhận vị trí lập trình viên cơ sở dữ liệu / sql cũng như là nhà phát triển hệ thống báo cáo quản trị\n",
      "hỗ trợ trưởng nhóm để cung cấp các báo cáo quản lý kịp thời, phù hợp và chính xác cho nhóm nội bộ và khách hàng\n",
      "hỗ trợ thiết kế và thực hiện các quy trình mới để thu thập dữ liệu và quản lý cơ sở dữ liệu nội bộ\n",
      "cung cấp phân tích nhanh, đặc biệt về các chủ đề kinh doanh khác nhau để ra quyết định quản lý\n",
      "tham gia vào các hoạt động phân tích kinh doanh để thu thập các yêu cầu báo cáo cần thiết\n",
      "phiên dịch các yêu cầu nghiệp vụ thành các thông số kỹ thuật sẽ được sử dụng để triển khai các báo cáo được yêu cầu, được tạo từ nhiều nguồn dữ liệu tiềm năng\n",
      "cung cấp hỗ trợ theo yêu cầu để đảm bảo tính khả dụng và hiệu suất của các báo cáo được phát triển cho cả người dùng bên ngoài và bên trong\n",
      "đảm bảo quản lý cấu hình phù hợp và kiểm soát thay đổi được triển khai cho phạm vi ảnh hưởng của bạn\n",
      "thiết kế và thực hiện các thực tiễn công nghệ, hướng dẫn và quy trình\n",
      "các nhiệm vụ khác được giao bởi người quản lý\n",
      "\n",
      "yêu cầu\n",
      "trình độ học vấn\n",
      "\n",
      "bằng cấp về toán học, kinh tế, khoa học máy tính, quản lý thông tin hoặc thống kê\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "kinh nghiệm\n",
      "\n",
      "kỹ năng giao tiếp, đàm phán và giao tiếp mạnh mẽ, để liên lạc với đồng nghiệp, khách hàng\n",
      "khả năng làm việc với cơ sở dữ liệu và nguồn tài nguyên cntt, khả năng sử dụng phần mềm báo cáo quản trị để thu thập và quản lý thông tin\n",
      "tối thiểu 2 năm kinh nghiệm tại vị trí tương tự\n",
      "tiếng anh thành thạo (cả nói và viết)\n",
      "\n",
      "tính cách\n",
      "\n",
      "chú ý đến chi tiết và hướng đến kết quả\n",
      "kỹ năng viết báo cáo và phân tích mạnh mẽ\n",
      "hiểu các nguyên tắc và thực hành chăm sóc khách hàng\n",
      "kỹ năng giao tiếp, giao tiếp và viết lách tuyệt vời\n",
      "thúc đẩy, năng lực, linh hoạt và sẵn sàng học hỏi\n",
      "kỹ năng tổ chức và quản lý thời gian tuyệt vời với khả năng đa tác vụ\n",
      "khả năng viết báo cáo và thuyết trình tốt\n",
      "khả năng làm việc hiệu quả dưới áp lực\n",
      "sáng tạo, trí tưởng tượng và khả năng sử dụng sáng kiến\n",
      "kỹ năng làm việc nhóm, phân tích và giải quyết vấn đề tốt\n",
      "nhận thức tốt về các hoạt độngkinh doanh và kiến thức tốt về các vấn đề hiện tại\n",
      "\n",
      "để sắp xếp phỏng vấn cùng savills, hãy gửi cv của bạn đến chúng tôi và cho biết vì sao bạn tin tưởng rằng mình sẽ phù hợp với vị trí ứng tuyển.\n",
      "bên cạnh những thông báo tuyển dụng cụ thể, savills việt nam rất chào đón những cá nhân xuất sắc, những người tin rằng mình sẽ thành công tại savills và trên thị trường bất động sản.\n",
      "để ứng tuyển vào các vị trí tuyển dụng của savills, vui lòng email bản cv của bạn đến địa chỉ  careers-hcmc@savills.com.vn\n",
      "ứng tuyển\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2816/data.html\n",
      "================================================\n",
      "data-02-06/2875/data.html\n",
      "================================================\n",
      "data-02-06/2585/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      " trách nhiệm chính\n",
      "chịu trách nhiệm quản lý và theo dõi tiến độ các dự án được phân công.\n",
      "giám sát việc tuân thủ tùy theo yêu cầu từng dự án nhằm đảm bảo chất lượng\n",
      "quản lý việc tiếp nhận yêu cầu và phản hồi từ các phòng ban khác.\n",
      "chịu trách nhiệm phân tích, hỗ trợ xây dựng các chỉ số báo cáo phản ánh đúng thực trạng của hdbank\n",
      "vận hành và xây dựng các hệ thống báo cáo hàng ngày/hàng tuần/hàng tháng.\n",
      " các công việc thực hiện chính\n",
      "thực hiện những phân tích chuyên sâu cho các tất cả các nghiệp vụ và sản phẩm của các khối/phòng/ban thuộc hdbank.\n",
      "phụ trách việc phối hợp chặt chẽ với chuyên viên khoa học dữ liệu và khối/phòng/ban liên quan triển khai mô hình học máy\n",
      "thực hiện các báo cáo trực quan để theo dõi kết quả kinh doanh trên nền tảng công nghệ được hdbank triển khai (powerbi)\n",
      "tiếp nhận và phân tích các yêu cầu từ các đơn vị kinh doanh, nghiên cứu dữ liệu từ datamart để đưa ra đề xuất các chỉ số đo lường phù hợp và thực hiện báo cáo phù hợp với chiến lược kinh doanh từng thời kỳ\n",
      "đóng góp cải tiến và tối ưu hóa quy trình truy xuất dữ liệu, quản lý báo cáo \n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "các yêu cầu về bằng cấp/chứng chỉtốt nghiệp loại khá trở lên chuyên ngành ngân hàng hoặc cntt hoặc các lĩnh vực có liên quanyêu cầu về kinh nghiệm/kiến thức\n",
      "có ít nhất 4 năm kinh nghiệm trong việc xây dựng chỉ số phân tích dữ liệu và thực hiện báo cáo.\n",
      "có 3 - 5 năm kinh nghiệm thực tiễn về\n",
      "================================================\n",
      "data-02-06/1408/data.html\n",
      "================================================\n",
      "data-02-06/1244/data.html\n",
      "responsibilities:\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tas a hadoop big data engineer, you will operate and monitor scalable and resilient data platform based on hadoop ecosystem to address the business requirements:  \n",
      "development tasks (30%)\n",
      "– engineer reliable data pipelines for sourcing, processing, transforming, enriching and storing data in different ways, using data platform infrastructure effectively\n",
      "– ingest and transform data sets from a variety of data sources\n",
      "– focus on ingesting, storing, processing, and analyzing large datasets\n",
      "– create scalable, high-performance web services for tracking data \n",
      "supporting tasks (70%) \n",
      "– provide high operational excellence guaranteeing high availability and platform stability.\n",
      "– technical analysis, trouble shooting and fixing the production incidents, problem tickets and changes\n",
      "– take ownership of (data processing/batch jobs) applications from a support & maintenance perspective\n",
      "– work on small enhancements (analysis, build/test, deployment/release support) \n",
      "\n",
      "requirements: \n",
      "\t\t\t\t\t\t\t\t\t\t\tmust have requirements:\n",
      "– must have 3+ years of experience at a similar role\n",
      "– having hands on experience in hadoop ecosystem (on-prem) including spark, hdfs, mapreduce, yarn, …\n",
      "– good in programming language python\n",
      "– experience in monitoring large-scale data processing job (batch-processing, stream processing)\n",
      "– understanding of sla and meeting timelines for support activities \n",
      "good to have: \n",
      "– experience with hadoop distributions such as cloudera, hortonworks, comparison and feasibility\n",
      "– experience with data warehouse and data management: data quality, data integration\n",
      "– experience in etl, sql and nosql database\n",
      "– experience with sre, patching & automation: kubernetes or docker & containerization\n",
      "– experience working with big data in a cloud environment\n",
      "– experience in backend development using java\n",
      "– experience in data api\n",
      "– good to have architecture knowledge or experience \n",
      "preferred language for application: english\n",
      "\n",
      "-----------------------------------------------\n",
      "experience range: from 3 years\n",
      "job location: hanoi, hcmc\n",
      "duty & responsibilities:\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tas a hadoop big data engineer, you will operate and monitor scalable and resilient data platform based on hadoop ecosystem to address the business requirements:  \n",
      "development tasks (30%)\n",
      "– engineer reliable data pipelines for sourcing, processing, transforming, enriching and storing data in different ways, using data platform infrastructure effectively\n",
      "– ingest and transform data sets from a variety of data sources\n",
      "– focus on ingesting, storing, processing, and analyzing large datasets\n",
      "– create scalable, high-performance web services for tracking data \n",
      "supporting tasks (70%) \n",
      "– provide high operational excellence guaranteeing high availability and platform stability.\n",
      "– technical analysis, trouble shooting and fixing the production incidents, problem tickets and changes\n",
      "– take ownership of (data processing/batch jobs) applications from a support & maintenance perspective\n",
      "– work on small enhancements (analysis, build/test, deployment/release support) \n",
      "\n",
      "requirements: \n",
      "\t\t\t\t\t\t\t\t\t\t\tmust have requirements:\n",
      "– must have 3+ years of experience at a similar role\n",
      "– having hands on experience in hadoop ecosystem (on-prem) including spark, hdfs, mapreduce, yarn, …\n",
      "– good in programming language python\n",
      "– experience in monitoring large-scale data processing job (batch-processing, stream processing)\n",
      "– understanding of sla and meeting timelines for support activities \n",
      "good to have: \n",
      "– experience with hadoop distributions such as cloudera, hortonworks, comparison and feasibility\n",
      "– experience with data warehouse and data management: data quality, data integration\n",
      "– experience in etl, sql and nosql database\n",
      "– experience with sre, patching & automation: kubernetes or docker & containerization\n",
      "– experience working with big data in a cloud environment\n",
      "– experience in backend development using java\n",
      "– experience in data api\n",
      "– good to have architecture knowledge or experience \n",
      "preferred language for application: english\n",
      "\n",
      "================================================\n",
      "data-02-06/2206/data.html\n",
      "descriptionthe bosch group is a leading global supplier of technology and services. in 2013, its roughly 281,000 associates generated sales of 46.4 billion euros. since the beginning of 2013, its operations have been divided into four business sectors: automotive technology, industrial technology, consumer goods, and energy and building technology. the bosch group comprises robert bosch gmbh and its roughly 360 subsidiaries and regional companies in some 50 countries. if its sales and service partners are included, then bosch is represented in roughly 150 countries. this worldwide development, manufacturing, and sales network is the foundation for further growthrbvh - robert bosch engineering and business solutions vietnam company limited is 100% owned subsidiary of robert bosch gmbh. rbvh has started its operations from 19th october, 2010 at e-town2 in hcmc. this engineering development center will be engaged in developing embedded systems and software, mechanical design and simulation, and will provide it (sap consulting, java development….) and business services (finance and accounting, economics, purchasing, logistics, translations japanese-english-japanese, information security ) solutions to the bosch group of companies globally. job descriptionwork closely with the application team in providing the technical research support and development of various artificial intelligence (ai) algorithmsdesign, implement and validate proposed ai algorithms;engage and collaborate with multi-location team (india, germany) to assess the maturity, viability and suitability of different ai research and technologies and their applicability to resolve industry problemsdirect communication, provide solution to global customersqualificationsmaster/ ph.d degree in computer science, engineering, information systems, computer engineering, mathematics, statistics\n",
      "-----------------------------------------------\n",
      "experience in one or more areas of ai, such as machine learning, computer vision, image processing, natural language processinggood understanding of the latest research and technologies in artificial intelligence;experience in programming languages such as python, r, matlab, c++, java;hands-on experience with one or more deep learning frameworks (tensorflow, caffe, theano, pytorch);technical hands-on experience in system integration;communicate technical concepts effectively to non-technical audience;strong communication and documentation skills, adaptable and a team player.additional informationwhy bosch?because we don't just follow trends, we create them.because together we turn ideas into reality, working every day to make the world of tomorrow a better place. do you have high standards when it comes to your job? so do we. at bosch, you will discover more than just work.benefits and career opportunitiesworking in one of the best places to work in vietnamjoin a dynamic and fast growing global company (english-speaking environment)13th-month salary bonus + attractive performance bonus (you'll love it!) + annual performance appraisal100% monthly basic salary and mandatory social insurances in 2-month probationonsite opportunities: short-term and long-term assignments15++ days of annual leave + 1 day of birthday leavepremium health insurance for employee and 02 family membersflexible working timelunch and parking allowancevarious training on hot-trend technologies/ foreign language (english/chinese/japanese) and soft-skillsfitness & sport activities: football, badminton, yoga, aerobicfree in-house entertainment facilities and snackjoin in various team building, company trip, year-end party, tech talks and a lot of charity event\n",
      "================================================\n",
      "data-02-06/674/data.html\n",
      "mô tả công việc\n",
      "\n",
      "– tổng hợp và kiểm soát số liệu định kỳ hằng ngày trên hệ thống erp, các hệ thống báo cáo khác của tập đoàn.\n",
      "– kiểm soát phân tích doanh thu hằng ngày của các đơn vị và các chi phí phát sinh vượt định mức, kế hoạch: chi phí nhân sự, chi phí bán hàng, chi phí mkt, chi phí mua sắm, nhập xuất tồn của vật tư tiêu hao…\n",
      "– phối hợp hỗ trợ và hướng dẫn các đơn vị trong tập đoàn xử lý dữ liệu đầu vào trên erp.\n",
      "– phát hiện các sai sót kịp thời của các bộ phận trong quá trình vận hành hệ thống.\n",
      "– nêu ý kiến cảnh báo đối với các hoạt động/đơn vị có nguy cơ/rủi ro về hiệu quả hoạt động kinh doanh.\n",
      "– lập báo cáo đánh giá kết quả thực hiện quy trình của các đơn vị trong tập đoàn dựa trên số liệu kiểm soát định kỳ.\n",
      "– đề xuất cải tiến biểu mẫu báo cáo tối ưu với hoạt động của tập đoàn phù hợp với mục tiêu quản trị theo từng thời kỳ.\n",
      "– làm việc tại vp chính tại: số 212 kim mã- ba đình- hà nội\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2825/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "                                                                                            main purpose of role:\n",
      "- take on a highly visible role, responsible for partnering with middle & senior-executive level stakeholders to provide them with data driven insights that will drive key strategic business decisions for ani viet nam business. \n",
      "- drive the transformation of data platforms and organization capabilities from predictive to diagnostic to prescriptive analytics.\n",
      "- blend data mining capabilities and a variety of analytical/scientific approaches to translate complex business questions into actionable insight.\n",
      "\n",
      "main responsibilities:\n",
      "- be an ambassador for advanced analytics at comex – ani vn by creating custom insights, recommendations  to meet our business growing and data needs.\n",
      "- contribute to the long-term roadmap for business intelligence’s strategy such as single of truth, standard analysis, predictive and prescriptive analytics models to validate trends and performance correlations.\n",
      "- develop and deliver action-oriented, insightful analytics presentations that provide consultative directions to key stakeholders.\n",
      "- explore and visualize data to provide simplified clarity and understanding.\n",
      "- distill insights from measurements and generate compelling visualizations to tell relevant stories.\n",
      "- coordinates with multiple departments to lead business initiatives from an analytics perspective.\n",
      "- identifies areas of innovation and process improvement across the company.\n",
      "- hypothesis driven problem solving and performs deep-dive analysis to find the root causes analysis (rca).\n",
      "- leverage bi tools and other software applications to develop data models, conduct data mining and enable self-service, data analytics and visualization in dashboards and reports.\n",
      "- develop advanced data analytics methodologies and predictive/simulation models to validate trends.\n",
      "- business intelligence project management.\n",
      "- acts as a coach and mentor to less \n",
      "-----------------------------------------------\n",
      "experienced analysts.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "================================================\n",
      "data-02-06/3011/data.html\n",
      "description\n",
      "\n",
      "responsibilities\n",
      "develop and maintain data pipelines to ingest data from multiple sources to the data lake.\n",
      "design and build data architectures that are optimized for performance and cost.\n",
      "continuously enhance and optimize existing data platform services.\n",
      "communicate with technical and non-technical stakeholders to translate business requirements into data solutions.\n",
      "continuously learn to sharpen fundamental skills, pick up new technologies in the field, and understand what is relevant and when to apply.\n",
      "\n",
      "\n",
      "your skills and \n",
      "-----------------------------------------------\n",
      "experience\n",
      "\n",
      "requirements\n",
      "possession of a solid problem-solving mindset with the support of tools and technologies.\n",
      "minimum three years of working experience in data engineering or jvm-based backend development.\n",
      "efficient coding skills in sql, python, java/scala, and bash scripting.\n",
      "comfortable working with modern data technologies, including spark, airflow, and kafka.\n",
      "good understanding of different types of common data formats and data storage technologies.\n",
      "================================================\n",
      "data-02-06/1818/data.html\n",
      "responsibilities● join ptn global data engineering projects.\n",
      "● collaborate to translate business needs to technical specifications for reporting model design and build.\n",
      "● work in an innovative team to building data models and pipelines to populate data warehouse and data marts with cutting-edge technology.\n",
      "● present information through reports and visualization to visual patterns, interpretation from data\n",
      "● troubleshoot and test the reporting solutions and data integration.\n",
      "● gather and evaluate customers’ feedbacks/comments.\n",
      "● take part in trainings and technical expertise workshops to improve own skill and help others to deepen their domain knowledge.\n",
      "● develop and update precise, traceable and valuable technical documents\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3040/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            - xây dựng kiến trúc, phát triển các công cụ khai thác dữ liệu lớn, xử lý, chuyển đổi dữ liệu lớn và quản trị dữ liệu lớn (big data)\n",
      "-  triển khai và phát triển các ứng dụng, mô hình xử lý dữ liệu trong hệ sinh thái dữ liệu lớn (big data) (hadoop, spark, kafka, …) nhằm đảm bảo cung cấp một nền tảng lưu trữ, xử lý và khai thác dữ liệu đồng nhất, ổn định và hiệu quả cao.\n",
      "-  nghiên cứu và thiết kế các hệ thống bảng biểu, các vùng lưu trữ, các pipeline dữ liệu, các chuẩn nén và phân tầng dữ liệu … phục vụ cung cấp dữ liệu cho nhu cầu khai thác, phân tích của các yêu cầu và dự án triển khai trên hạ tầng big data;\n",
      "- tìm hiểu, phân tích, đánh giá và xử lý các nguồn dữ liệu bán cấu trúc và phi cấu trúc; xây dựng các phương án kết nối dữ liệu đúng logic, nhanh và ổn định\n",
      "- nghiên cứu, phát triển và quy hoạch các hệ thống đồng bộ và xử lý dữ liệu theo thời gian thực (near realtime), data streaming trên các nền tảng oracle, kafka streams,…phục vụ nhu cầu khai thác dữ liệu theo thời gian thực.\n",
      "- nghiên cứu, phát triển và quy hoạch các hệ thống đám mây (google cloud) phục vụ lưu trữ và xử lý dữ liệu để giảm tải cho các hệ thống on-premise.\n",
      "- đánh giá các giải pháp kỹ thuật cũng như kiến trúc của luồng xử lý dữ liệu để đảm bảo đáp ứng các yêu cầu về hiệu năng, mức độ sẵn sàng cao và tính dễ mở rộng\n",
      "- xây dựng và cập nhật các tài liệu liên quan đến thiết kế, triển khai, phát triển và vận hành hệ thống lưu trữ và xử lý dữ liệu lớn\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/840/data.html\n",
      "================================================\n",
      "data-02-06/2594/data.html\n",
      "================================================\n",
      "data-02-06/1945/data.html\n",
      "================================================\n",
      "data-02-06/2726/data.html\n",
      "mô tả công việc\n",
      "khai thác, xây dựng, cập nhật số liệu, dữ liệu để theo dõi hiệu quả hoạt động kinh doanhbáo cáo kết quả kinh doanh định kỳ hàng tuần/tháng/quý theo yêu cầu của trưởng bộ phậnhỗ trợ xây dựng quy trình & phụ trách theo dõi bảo đảm các phòng ban liên quan thực hiện đúng các yêu cầukiểm tra, theo dõi và quản lý các chứng từ liên quan đến chiến dịch: hợp đồng, phụ lục, biên bản nghiệm thu,...thực hiện các công việc khác theo yêu cầu của trưởng bộ phận.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "trình độ học vấn: cao đẳng trở lên chuyên ngành quản trị kinh doanh hoặc các chuyên ngành kinh tế.có ít nhất 6 tháng - 1 năm kinh nghiệm làm việc liên quan đến xử lý, thống kê dữ liệu.sử dụng thành thạo công cụ excel.cẩn thận, chi tiết, chủ động trong công việc, tư duy hệ thống và chịu được áp lực cao.kỹ năng làm việc độc lập.kỹ năng giải quyết vấn đề.kỹ năng giao tiếp và làm việc nhóm.\n",
      "quyền lợi\n",
      "làm việc trong môi trường vui vẻ, cởi mở, tôn trọng lẫn nhau.được đào tạo, tạo điều kiện học hỏi, khẳng định bản thân và thăng tiến.tham gia các hoạt động teambuilding.hưởng các chế độ khác theo quy định của nhà nước.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 09/06/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2520/data.html\n",
      "mô tả công việc\n",
      "- xây dựng và vận hành báo cáo bi cho các team- xây dựng, đề xuất và quản trị các báo cáo kinh doanh, vận hành và kpi trên dashboard và excel- phát triển các danh mục báo cáo phân tích kinh doanh, hiệu quả kinh doanh, hàng tồn kho, đánh giá tình hình sản xuất và kinh doanh sản phẩm nhằm theo dõi, phát triển dòng sản phẩm- chủ động đưa ra các phương pháp phân tích, xác định số liệu cần lấy và thực hiện lấy số liệu, viết các báo cáo phân tích, đưa ra nhận định và đề xuất tới các bộ phận- thời gian làm việc: t2-t7 (8h-17h), nghỉ các chủ nhật\n",
      "yêu cầu \n",
      "- tốt nghiệp đại học (dưới 35 tuổi)- có kiến thức về cấu trúc dữ liệu, cơ sở dữ liệu (sql…), lập trình vba (excel nâng cao), data warehouse, khả năng xây dựng data mart, data model- ít nhất 1 năm \n",
      "-----------------------------------------------\n",
      "kinh nghiệm trong việc làm báo cáo phân tích hiệu quả kinh doanh, phân tích dữ liệu hoặc làm ở vị trí tương tự- có kiến thức về phương pháp luận phân tích dữ liệu toán thống kê và phân tích định lượng. kiến thức chung về hoạt động quản trị kinh doanh, mô hình kinh doanh, kinh tế- giao tiếp tự tin, có tư duy logic, kỹ năng giải quyết vấn đề - tư duy phản biện tốt\n",
      "\n",
      "địa điểm làm việc\n",
      "- trụ sở yody: đường an định, phường việt hoà, tp hải dương- văn phòng hà nội: 90 nguyễn tuân, thanh xuân, hà nội- ứng viên có thể làm việc tại hà nội, 1 tuần về hải dương 2 ngày- có xe đưa đón hà nội - hải dương hoặc sắp xếp nơi ở miễn phí tại hải dương (nếu làm việc cố định tại hải dương)\n",
      "\n",
      "quyền lợi\n",
      "+ thu nhập 20-35 tr/tháng+ thưởng cuối năm: 1 - 3 tháng thu nhập, thưởng theo doanh thu, thưởng các ngày lễ, tết+ nghỉ chủ nhật, năm có 12 ngày nghỉ phép+ đóng bảo hiểm khi chính thức theo quy định+ phụ cấp ăn trưa miễn phí tại công ty+ cung cấp máy tính/thiết bị làm việc+ được tổ chức sinh nhật, du lịch 1-2 lần/năm, hưởng các chính sách đãi ngộ đặc biệt từ công ty+ hỗ trợ xe đưa đón hà nội - hải dương, chỗ ở miễn phí tại hải dương\n",
      "\n",
      "kết nối với yody\n",
      "- hotline/zalo - ms quyên 0344 367 752- email:\n",
      "================================================\n",
      "data-02-06/2286/data.html\n",
      "responsible to accompany virtuos group and glass egg studio for the revolution of integrating ai into 3d game production.\n",
      "responsibilities:\n",
      "1. r&d:\n",
      "a. data\n",
      "work closely with production team to prepare assets in order to synthesize data sets to train our models.assist in data collection suitable for ml projects.\n",
      "b. tools:\n",
      "deliver testing of tools created by the head quarter r&d team.participate in sparring sessions & work with the head quarter r&d team.\n",
      "c. knowledge\n",
      "collaborate with head quarter r&d team to propose and develop new ai-based tools and techniques to improve the efficiency and quality of our digital art production.organize workshops within head quarter r&d team to impart game production expertise.\n",
      "2. production:\n",
      "experiment with how to improve existing workflows and pipelines using cutting-edge ai.deploy ai tools to production team and collect feedback for improvement.participate in guilds to gather potential ideas.investigate the current 3d production workflows and pipelines.work closely with production team to understand clearly the needs.collaborate with head quarter r&d team to propose & develop new ai-based tools.deploy these tools to production team.collect feedback from end users to improve tools more and more convenient and useful.\n",
      "3. market:\n",
      "stay up-to-date with the latest trends and advancements in ai and digital art.research and experiment with different ai algorithms, neural networks, and machine learning techniques (from academia & production) to enhance the creative process.\n",
      "requirements:\n",
      "bachelor’s or master’s degree in computer science, mathematics, statistics, or a related field3+ years of \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2231/data.html\n",
      "mô tả công việc\n",
      "\n",
      " * tham gia vào quá trình phát triển các sản phẩm sốbao gồm phát triển tính năng mới, nâng cấp tính năng, phát hiện và sửa chữa lỗi.\n",
      " * làm việc với các trưởng nhóm, quản lý để thốn\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1743/data.html\n",
      "description\n",
      "                    \n",
      "about the job\n",
      "\n",
      "maintain and design relational databases to support enterprise application and physical data modelling according to project requirements for data acquisition and security as well as customer-defined deliverables.\n",
      "develop strategies for data modeling, design and implementation to meet stated requirements for metadata management, operation data stores, data lake, data warehouse, data marts and extract transform load environments in batch processing and real-time injection.\n",
      "create and test physical data models for a variety of business data, applications, database structures and metadata tables to meet operational goals for performance and efficiency\n",
      "carrying out day-to-day support for reporting system.\n",
      "\n",
      "about you\n",
      "\n",
      "bachelor or college degree in information technology or equivalent practical work \n",
      "-----------------------------------------------\n",
      "experience\n",
      "2+ years of experience in relevant role\n",
      "proficientwith some of the modern relational databases such as oracle, db2, and sql server\n",
      "hand-on experiences on designing and developing etl solution by using ssis or other etl tools\n",
      "strong in writing t-sql, pl/sql\n",
      "good understanding of data modelling, processing and warehouse techniques\n",
      "skilled at optimizing large complicated sql statements\n",
      "capable of troubleshooting common database issues\n",
      "knowledge at reporting development with microsoft ssis and ssrs\n",
      "analytical thinking\n",
      "good interpersonal and communication skills\n",
      "time management and planning skill\n",
      "\n",
      "equal opportunity\n",
      "================================================\n",
      "data-02-06/2058/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "                                                                                            the senior data scientist will be responsible for developing and managing the data science strategy for the company. they will work with stakeholders across the business to identify opportunities to use data to drive decision making. the senior data scientist will also be responsible for building and maintaining a team of data scientists, as well as developing and managing relationships with external partners.\n",
      "\n",
      "•\tformulating, suggesting, and managing data-driven projects which serve business's interests. selecting and employing advanced statistical procedures to obtain actionable insights.\n",
      "•\tbuilds, validates, and improves predictive models. cross-validating models to ensure their generalizability.\n",
      "•\ttailors the analytical approach to the business question. suggesting ways in which insights obtained might be used to inform business strategies.\n",
      "•\tprocesses, cleans and verifies data to support analyses and models.\n",
      "•\ttranslate new innovations intro data driven solutions.\n",
      "•\tcontribute to development of smart digital products (i.e. report, dashboard, model, application).\n",
      "•\tdelegating tasks to data scientists in order to realize the successful completion of projects.\n",
      "•\tmonitoring the performance of data scientists and providing them with practical guidance, as needed.\n",
      "•\tproducing and disseminating non-technical reports that detail the successes and limitations of each project.\n",
      "•\tact as evangelist of data science throughout the opco. staying informed about developments in data science and adjacent fields to ensure that outputs are always relevant.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2919/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            *job purpose : the job holder will support the overall purchasing activities by conducting relevant analysis linked to raw materials, mostly agricultural commodity products used in compound animal feed. in addition, regular internal position reporting will be under ownership of this role, with the opportunity to develop them further. the right candidate will have a keen interest to translate datasets into insights which can impact purchasing decision making.\n",
      "reports to: purchase director asia\n",
      "\n",
      "*research:\n",
      "• conduct desk research on supply and demand related information on the company’s interested raw material, utilizing available public, subscribed data as well as seeking for new source of data and market reports\n",
      "• gather market information and work alongside with purchasers to analyse and understand local market situation and competitor position.\n",
      "• connect to other internal stakeholders like data team, commercial team to validate trends and share data insights.\n",
      "\n",
      "*analysis:\n",
      "• structure data from various internal and external sources\n",
      "• maintain and manage data warehouse for the use of the purchase department\n",
      "• create data insights with power bi\n",
      "• explore and analyse trade data to understand the flow of agricultural raw materials\n",
      "• analyse and assess market situations of raw materials through developing and maintaining local supply and demand analysis\n",
      "\n",
      "*reporting:\n",
      "• take responsibility for consistent weekly reporting on positions and market developments, as well as ad-hoc reporting depending on requirements from the team.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3072/data.html\n",
      "description\n",
      "\n",
      "\n",
      "life at agoda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "all teams\n",
      "contentcustomer \n",
      "-----------------------------------------------\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "senior analyst (supply analytics team, bangkok-based, relocation provided)\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "================================================\n",
      "data-02-06/1920/data.html\n",
      "responsibilities:identifying, designing, and implementing process improvements that include building/re-engineering data models, data architectures, pipelines, and data applicationscontinuously look for data optimization processes and oversee data management, governance, security, and analysisensure data quality and security across every product vertical and related areasdesign, create and launch new data models and pipelines as per needswork towards achieving high performance, operational excellence, accuracy, and reliability of the overall systemmentor and grow data warehouse, data modeling, and data visualization team to correctly establish a data-driven cultureutilize tools and technologies to create data architecture that supports new data initiatives and is useful in next-gen productsensure test-driven products/pipelines that are easily maintainable and reusabledesign and build an infrastructure for extraction, transformation, and loading of data from a wide range of data sourcesoverall build and maintain data foundations that include tools, infrastructure, and pipelines that help the marketing and sales teamincrease automation and build analytic solutions at scale to serve the business requirementsii. \n",
      "-----------------------------------------------\n",
      "job requirements:qualifications \n",
      "================================================\n",
      "data-02-06/2279/data.html\n",
      "responsibilities maintain bau reports/ dashboards for the assigned functions:master the data structures and processing rules for the assigned function(s)prepare & review periodic report/ dashboard (monthly, weekly, daily…) and ad-hoc requests to support the business stakeholders for the assigned functions & ensure data accuracy and timeliness deliveryactively look for areas of potential simplification/ automation and implement these changesverify and document data rules, data dictionary so that it is well-maintained & updatedcontinuously upgrade data processing & visualization skill sets to catch up with new technology, new strategyon project-based (for new requests – dashboard or analysisunderstand the assigned function(s)’ specific goals, challenges & opportunitiesbuild dashboard/ deep-dive analysissupport local/ regional data scientists to build predictive models/ advanced analytics workothers:share knowledge to other team membersother tasks assigned by managersii. \n",
      "-----------------------------------------------\n",
      "job requirements qualificationsdegree in business, mathematics, statistics, engineering, computer science, or other quantitative disciplineexperience min 2-3 years of solid experience in business intelligence/ business analyticsknowledge and skill ability to interpret data and translate them into actionable insightsknowledge of statistical and predictive modeling concepts, machine learning approaches, clustering and classification techniques/ recommendation and optimization algorithms is preferredskilled in sql and excelfamiliarity with one of the programming language r/python is a plusinherently curious about data with a strong desire to keep up to date with the latest developments in analytics and machine learningattention to detailscritical thinkingcan-do attitudedecent communication skills\n",
      "\n",
      "================================================\n",
      "data-02-06/3054/data.html\n",
      "================================================\n",
      "data-02-06/3064/data.html\n",
      "mô tả công việc\n",
      "\n",
      "we are looking for a motivated and talented individual to join our marketing and growth team as a business intelligence intern. this internship provides an excellent opportunity to gain hands-on \n",
      "-----------------------------------------------\n",
      "experience in the field of business intelligence within the fast-paced environment of zalopay. we are seeking someone who is eager to learn, detail-oriented, and passionate about using data to drive marketing strategies and business growth.main responsibilities:1. analytics & insights (40%)use sql and other query language (training will be provided) to retrieve data for analysis/planning.help identify and analyze trends, patterns, and insights through retrieved data.use excel and other visualization tool (training will be provided) to visualize data for communicating between stakeholdershelp the team with developing reports, dashboards, and visualizations to track key performance indicators (kpis) and campaign effectiveness.2. campaign operations (40%)help with documentation for campaign.help setup and organize meeting between cross-functional teams for campaign discussionnote taking between meetings and providing meeting recap afterward.work closely with cross-functional teams to understand business requirements and provide data-backed recommendations.3. planning & forecast (20%)retrieve and utilize historical data to help with campaign planning and forecast.assist the team in forming planning & forecast model to meet target kpis.\n",
      "\n",
      "================================================\n",
      "data-02-06/2638/data.html\n",
      "================================================\n",
      "data-02-06/2643/data.html\n",
      "================================================\n",
      "data-02-06/2607/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "                                                                                            1. make & manage production plan:\n",
      "• make weekly & monthly production plan\n",
      "• adjust production plan based on sales demand & production capacity\n",
      "• keep track of production, sales & delivery situation to timely adjust production plan\n",
      "2. make delivery plan & manage stock at distribution center:\n",
      "• coordinate cargo & ensure safe stock in distribution center\n",
      "• make delivery plan according to peak period\n",
      "• forecast and evaluate high or low inventory situation to take timely measures to avoid shortages or high inventories & incurring costs\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1413/data.html\n",
      "responsibility partnership program how we work \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1579/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "mục đích công việc: chịu trách nhiệm (i) hỗ trợ xây dựng, triển khai cơ sở dữ liệu, báo cáo; (ii) thực hiện báo cáo định kỳ và theo yêu cầu; (iii) phân tích dữ liệu phục vụ công tác quản trị.trách nhiệm công việc:thực hiện các báo định kỳ/đột xuất;\n",
      "phân tích dữ liệu phục vụ công tác quản trị;\n",
      "đóng góp cải tiến việc tự động hóa thu thập và xử lý, dữ liệu;\n",
      "định kỳ kiểm tra dữ liệu từ các hệ thống để đảm bảo tính chính xác của báo cáo;\n",
      "thực hiện các nhiệm vụ khác theo phân công của cấp quản lý.\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc:trình độ cử nhân trở lên, ưu tiên chuyên ngành tài chính, ngân hàng, kinh tế, kế toán, công nghệ thông tin, tin học;\n",
      "tối thiểu 7 năm (chuyên gia)/ 5 năm (chuyên viên cao cấp)/ 3 năm (chuyên viên chính)/ 2 năm (chuyên viên)/ưu tiên có (nhân viên) kinh nghiệm làm việc trong lĩnh vực tài chính, ngân hàng tại các tổ chức dịch vụ tài chính liên quan đến xử lý dữ liệu hệ thống, phân tích dữ liệu, lập báo cáo;\n",
      "tối thiểu 1 năm kinh nghiệm làm việc trong lĩnh vực lập trình vba trên excel: khả năng advance/excellent;\n",
      "kinh nghiệm lập trình và cấu trúc dữ liệu cơ bản;\n",
      "kiến thức sql căn bản;\n",
      "kỹ năng phân tích, quản lý hoạt động và quản lý thời gian tốt; tư duy logic;\n",
      "kỹ năng tiếng anh cơ bản (ưu tiên). \n",
      "\n",
      "\n",
      "\n",
      "chia sẻ công việc này\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tfacebook\n",
      "\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tlinkedin\n",
      "\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2426/data.html\n",
      "descriptionthe bosch group is a leading global supplier of technology and services. in 2013, its roughly 281,000 associates generated sales of 46.4 billion euros. since the beginning of 2013, its operations have been divided into four business sectors: automotive technology, industrial technology, consumer goods, and energy and building technology. \n",
      "the bosch group comprises robert bosch gmbh and its roughly 360 subsidiaries and regional companies in some 50 countries. if its sales and service partners are included, then bosch is represented in roughly 150 countries. this worldwide development, manufacturing, and sales network is the foundation for further growthbgsv – bosch global software technologies company limited (previous name: rbvh - robert bosch engineering and business solutions vietnam company limited) is 100% owned subsidiary of robert bosch gmbh.\n",
      "\n",
      "bgsv has started its operations from 19th october, 2010 at e-town2 in hcmc. this engineering development center will be engaged in developing embedded systems and software, mechanical design and simulation, and will provide it (sap consulting, java development….) and business services (finance and accounting, economics, purchasing, logistics, translations japanese-english-japanese, information security ) solutions to the bosch group of companies globally. job descriptiondesign, develop and enhancement big data systems such as data warehouse, data lakedesigning and develop big data applicationscreating data processing frameworksextracting data and isolating data clustersdoing poc & present about big data solutions for new projecttroubleshooting application bugsmaintaining the data securitydevelop and update technical documentationdevelop testing scripts and analyzing resultsqualificationsat least 5 years of \n",
      "-----------------------------------------------\n",
      "experience in the relevant technologiesbachelor degree in it/ computer science or relevant backgroundexperience in the hadoop ecosystem and its components: hdfs, yarn, mapreduce, apache spark (python/scala), apache sqoop, apache impala, apache avro, apache flume, apache kafkapreferred: having certificate cca175 – spark and hadoop developerdesigned and developed etl processexperienced in unix with scripting experience is preferredshould have strong knowledge on concepts of data warehousing models, data ingestion patterns, data quality and data governanceexperience on the hadoop systems with good understanding and knowledge of hadoop clustergood at english communication skillsadditional informationwhy bosch?because we don't just follow trends, we create them.because together we turn ideas into reality, working every day to make the world of tomorrow a better place. do you have high standards when it comes to your job? so do we. at bosch, you will discover more than just work.benefits and career opportunitiesworking in one of the best places to work in vietnamjoin a dynamic and fast growing global company (english-speaking environment)13th-month salary bonus + attractive performance bonus (you'll love it!) + annual performance appraisal100% monthly basic salary and mandatory social insurances in 2-month probationonsite opportunities: short-term and long-term assignments15++ days of annual leave + 1 day of birthday leavepremium health insurance for employee and 02 family membersflexible working timelunch and parking allowancevarious training on hot-trend technologies/ foreign language (english/chinese/japanese) and soft-skillsfitness & sport activities: football, badminton, yoga, aerobicfree in-house entertainment facilities and snackjoin in various team building, company trip, year-end party, tech talks and a lot of charity event\n",
      "================================================\n",
      "data-02-06/2856/data.html\n",
      "================================================\n",
      "data-02-06/2824/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            job description\n",
      "- read and understand our client’s agreements with their suppliers in english (agreements can be within emails, business contracts, price change forms...)\n",
      "- using excel and some sql, perform analysis on the client’s transactional data (accounts payable, invoice details, purchase orders, sales…)\n",
      "- compare the client’s transactional data with the client’s agreements to validate if all transactions have been paid correctly\n",
      "- identify any historical transactions have some sort of payment error (where the data does not match to the agreement)\n",
      "- create detailed reports in excel to describe and calculate any payment errors identified\n",
      "- discuss your findings by e-mails or im with the overseas project teams and customers located in australia, new zealand, etc.\n",
      "- using our tools and the available data/agreements, attempt to recover the missing monies from our client’s suppliers which would correct & resolve any errors identified\n",
      "- additional processing, transformation, and validation of data may also be required to assist with the analysis, recovery, and resolution of the errors\n",
      "- other assignments by line manager\n",
      "\n",
      "skills:\n",
      "- excellent level of english (written & verbal communication)\n",
      "- detail-oriented, careful manner\n",
      "- good analysis skills, love to work with figures/data\n",
      "- a good team player to effectively work in a dedicated team\n",
      "- able to work under high pressure with good change management skills\n",
      "- good at ms office, especially excel\n",
      "- basic knowledge of sql (preferred by not required)\n",
      "\n",
      "benefits:\n",
      "- 13&14th-month salary payment\n",
      "- 15+ full-paid annual leave\n",
      "- a day off for christmas (25th december)\n",
      "- personal health care\n",
      "- happy hour, company trip\n",
      "- annual health check, training course (sql, python, excel, ....)\n",
      "- parking fee\n",
      "- mid -autumn gift, tet gift, year end party, team building, sport...\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2578/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "                                                                                            •\tassist in identifying and in-depth analysis business needs and system requirements, translating business requirements into functional specifications.\n",
      "•\tconduct feasibility studies on proposed solutions, provide analysis to support the development of business cases\n",
      "•\tconduct analysis on the risk and benefits for the proposed solutions\n",
      "•\tcreating comprehensive, well-thought-out lists of requirements to present to the executives in the corporation\n",
      "•\tanalyze systems and processes to identify enhancement opportunities to resolve system gaps\n",
      "•\tevaluate the ability of an existing system to support proposed changes and identify systems deficiencies and performance gaps\n",
      "•\tpreparing detailed functional specifications for required development activities\n",
      "•\tact as the liaison between users and technical staff throughout the solution implementation cycle\n",
      "•\tdevelop test plans and test cases, document post-test evidence of expected results or defects.\n",
      "•\tcreating data-driven reports in order to reflect the current state of the business’s operations accurately\n",
      "•\teffectively communicate your insights and plans to cross-functional team members and management\n",
      " requirements:\n",
      "•\ta bachelor’s degree in business, computer science or a related field will be required, while an mba will also suffice\n",
      "•\tthe ability to collaborate closely with stakeholders in order to determine solutions that will benefit the business\n",
      "•\tbi tool, data visualization and presentation skills\n",
      "•\tstrong communication skills\n",
      "•\tproject management \n",
      "-----------------------------------------------\n",
      "experience\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "================================================\n",
      "data-02-06/2382/data.html\n",
      "mô tả công việc:\n",
      "\n",
      "hỗ trợ xây dựng cơ sở dữ liệu cho ứng dụng và tích hợp ứng dụng\n",
      "xây dựng cấu trúc cơ sở dữ liệu mới và triển khai ứng dụng\n",
      "lập trình csdl, báo cáo và nâng cấp\n",
      "phát triển, bảo trì và hỗ trợ các chức năng csdl mà công ty đã xây dựng\n",
      "tối ưu và bảo trì csdl đã được xây dựng trước đó, của các dự án cũ\n",
      "thực hiện các tác vụ kiểm thử hiệu năng csdl, xử lý các lỗi\n",
      "phát triển và tối ưu ứng dụng, câu truy vấn, schema\n",
      "hỗ trợ phát triển ứng dụng, debugging, cấu hình, tối ưu hệ thống\n",
      "phát triển và duy trì sql scripts trong microsoft sql server\n",
      "phát triển và duy trì ssrs packages\n",
      "xây dựng chiến lược cho các dữ liệu nâng cấp và tích hợp của ứng dụng giữa các sản phẩm, phiên bản, các nền tảng\n",
      "phân tích mã nguồn của csdl cũ để có phương án tối ưu, cải thiện hiệu suất\n",
      "\n",
      "3. yêu cầu:\n",
      "\n",
      "tốt nghiệp chuyên ngành điện - tự động hoá, công nghệ thông tin, cơ điện tử, hoặc các ngành kỹ thuật khác.ưu tiên các trường/ ngành nền tảng it-ot\n",
      "có \n",
      "-----------------------------------------------\n",
      "kinh nghiệm >1 năm trong việc xây dựng csdl (biết xây dựng trên ms sql là một lợi thế)\n",
      "có kinh nghiệm >1 năm trong xây dựng gói trích xuất dữ liệu (etl/ elt, biết xây dựng trên ms sql là một lợi thế)\n",
      "có kinh nghiệm về sql queries, stored procedures, and functions\n",
      "có kinh nghiệm về xây dựng ssis package\n",
      "kinh nghiệm trong xây dựng reports and dashboards dùng ssrs hoặc các phân mềm khác (lợi thế)\n",
      "có khả năng điều chỉnh và cải thiện hiệu suất hoạt động của hệ thống (indexing, analyzing query execution plans) (lợi thế)\n",
      "kĩ năng làm việc nhóm\n",
      "kĩ năng xử lý vấn đề\n",
      "\n",
      "1-2 năm kinh nghiệm trong lĩnh vực\n",
      "4. quyền lợi:\n",
      "\n",
      "mức lương: thoả thuận theo năng lực\n",
      "môi trường làm việc đam mê, năng động, sáng tạo, hoà đồng\n",
      "chế độ đãi ngộ tốt\n",
      "thực hiện chế độ theo quy định nhà nước ngay khi kết thúc 02 tháng thử việc.\n",
      "đóng bhxh theo quy định nhà nước\n",
      "thưởng quý,\n",
      "================================================\n",
      "data-02-06/2408/data.html\n",
      "================================================\n",
      "data-02-06/2333/data.html\n",
      "================================================\n",
      "data-02-06/2769/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            key accountabilities:\n",
      "•\textraction and generation daily data on time and make sure data consistency to process report, contest and other relative ad hoc.\n",
      "•\tmonitor and control agency sale system to ensure that sale report is accuracy.\n",
      "•\tdeliver reports to agency sale force and managing level as committed schedules. ensure the reports accurate and on time.\n",
      "•\tin charge of answer questions (if any) about agency sale report.\n",
      "•\tto work closely with it teams to update or enhance data to support agency sale\n",
      "•\tcontest calculation\n",
      "•\tanalysis business data and rule contest\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2752/data.html\n",
      "================================================\n",
      "data-02-06/964/data.html\n",
      "description1. end to end commercial responsibility for analytics (aac/instore) in vietnamdrive profitable, accelerated and sustainable revenue growthdrive the sales (penetration driven) strategy based on deep understanding of client needs & priorities. ensure a culture of relentless prospecting into sales routinelaunching of new global products in local market – responsible for go to market strategy for successful new launch of products/ solutions – including but not limited to training, knowledge transfer , development of sales play, client segmentation , marketing cadence and client pitchescreate and leverage new sales initiatives to keep clients and revenue growingensure visibility & accountability to the pipeline, risks & opportunities quarter by quarter, month by month.lead the operating plan & review process for geographic scopeidentify & support large local client growth opportunities and develop engagement plans to maximize the $potentialgrow the business in a sustainable way such as increase multi-year contracts, increase penetration per country/client and achieve a bigger growth on the strategic product2.represent the needs & priorities of vietnam amongst the regional and global product practice leadership community and with other key stakeholdersidentify & prioritize which product solutions to introduce locally– close collaboration with solutions leaders (& p&d team)influence product development roadmaps & prioritization for local markettarget disproportionate attention / sponsorship for vietnam from key stakeholders & practice leadersshare winning approaches, results generation, best practice3.provide strategic direction & clarity to the analytics teams within vietnam as a team leaderaccelerate the analytics playbooks – localize for vnknowledge transfer and training via mindtickle training on existing and new products. ensuring all members in the team understand the new solutions and become the best in their respective practice areas .ground the team in the persona and gift of content go-to-market approach and role model client relationship development with c-level persona targetscommitment to sales force penetration and retentionbe a strong voice in the industry: events / networks / social media outreachbring back & engage teams on key initiatives driven at leadership (l2/3) groupcreate an environment which inspires teams to walk the extra mileensuring that the analytics team in the country are connected to respective product communities within apac and learn & share within this this community4.define the talent / team development plan for vietnam & gain stakeholder buy-in to resource / investment requirementsassess bench-strength of the team within vietnam and what talent movements are required to ensure ‘best athletes’ on the field (tr 1 & 2).develop and groom existing talent – ensure everyone has a clear goals and learning plans.commit to developing a diverse & inclusive team.identify at least one, (outstanding) external succession candidate for self and each key role within the country.ensure that key leaders are engaged in solutions communities across apaccreate and practice culture & environment that talent will flock to (followership)ensure best-in-class working practices with client business partners (cbps), commercial & product leaders, market leaders, delivery coe team & other analytics leadersqualifications7+ years of \n",
      "-----------------------------------------------\n",
      "experience in cpg sales, trade marketing, retailer - key account, merchandising.bachelor's degreeknowledge of sales processes in cpg companies, customers, modern and traditional markets.good knowledge of nielsen iq products, services and data preferreddigital knowledge, salesforceexcellent business english and vietnamese, both verbal and writtenproven sales acumenexcellent problem solving skills, solution oriented and good analytical skillvery good client-facing and communication/presentation skillsfinancial understanding (eg. p&l, ebitda) and how this relates to business successstrong collaboration and networking skillsadditional informationabout niqniq, the world’s leading consumer intelligence company, reveals new pathways to growth for retailers and consumer goods manufacturers. with operations in more than 100 countries, niq delivers the most complete and clear understanding of consumer buying behavior through an advanced business intelligence platform with integrated predictive analytics. niq delivers the full view.\n",
      "================================================\n",
      "data-02-06/2973/data.html\n",
      "================================================\n",
      "data-02-06/2733/data.html\n",
      "================================================\n",
      "data-02-06/509/data.html\n",
      "================================================\n",
      "data-02-06/1982/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      " as a full-time xpon technologies digital/data analytics specialist (google analytics 360) you will:- be a key player in modernising marketing and client \n",
      "-----------------------------------------------\n",
      "experience- utilise our unique partnership with google and your knowledge of ga360 to implement, optimise and analyse performance for our clients- be highly proficient in javascript and sql- have strong communication and presentation skills, including training experience- join a high growth, values-driven company- enjoy flexible/remote working, with the ability to collaborate irl with teams in sydney, wollongong, or brisbane. for the right candidate we will consider other locations, including melbourne.what you will do with usreporting to the head of martech, you will play a key role within xpon technologies as one of our data analytics specialists, where you will liaise with clients, set the strategy, and drive the implementation of their ga 360.you will work closely with our clients to understand their business needs and requirements, and translate these into functional technical solutions across ga 360 and gtm implementations.you will be focused on working with our team to provide the best possible outcomes for our clients, and will:- understand and translate complex business requirements into a functional technical architecture that can be implemented and activated by clients.- implement and manage the delivery of solutions by working collaboratively with google gmp teams, internal teams, and delivery partners.- develop and maintain product knowledge about core competencies of google technologies, and other industry technology solutions.- document the current state of the client's technology and outline systems enhancements needed. serve as technical leader for xpon technologies' clients, with regards to programmatic advertising, analytics, measurement, attribution and marketing activation strategies.- develop deep business partnerships and trusted relationships with both partners and decision-makers at the c-suite level.- conduct effective and efficient troubleshooting, testing and qa analytics implementations.- be involved in weekly one on ones with actions to drive performance.- compile marketing reports and roi analysis.- contribute to strategy documentation and scoping for clients.a day of in the life of this role could include:- conducting discovery/audits to determine the foundation of a client's current set up.- establishing client side stakeholders/owners.- establishing architecture requirements for ga 360.- implementing technical gtm/ga solutions.- briefing internal teams on the solution.- working closely with the client and internal build team to deliver the required insights.- working to establish the right data foundations.- post implementation conducting monthly hygiene checks for ways to improve the data set.- providing ga & gtm training to client teams. \n",
      "================================================\n",
      "data-02-06/1120/data.html\n",
      "================================================\n",
      "data-02-06/2538/data.html\n",
      "mô tả công việc\n",
      "nghiên cứu pháp luật thống kê.xây dựng cơ sở dữ liệu.phân tích dữ liệu thống kêthực hiện các công việc chuyên môn, nghiệp vụ khác theo sự phân công của công ty.(sẽ trao đổi công việc cụ thể tại buổi phỏng vấn)\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "tốt nghiệp đại học trở lên chuyên ngành: thống kê kinh tế- xã hội, tài chính.giao tiếp tốt .có khả năng diễn đạt, thuyết trìnhcó tinh thần trách nhiệm,cẩn thận, trung thực, nhiệt tình trong công việcưu tiên những ứng viên có thành tích học tập giỏi, xuất sắc (chưa có kinh nghiệm sẽ được đào tạo, tư vấn và chia sẻ về nghiệp vụ, kiến thức chuyên môn và kỹ năng mềm).\n",
      "quyền lợi\n",
      "mức lương thỏa thuận theo năng lực,kết quả làm việc.làm việc trong môi trường nghiên cứu, hiện đại, chuyên nghiệp, năng động, bình đẳng, phát huy tối đa khả năng chủ động và sáng tạo;được trang bị đầy đủ trang thiết bị phục vụ công việc;được đóng các chế độ bhyt, bhxh, theo quy định của nhà nước;hưởng các chính sách khen thưởng, phúc lợi theo quy định của công ty.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 07/06/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/370/data.html\n",
      "================================================\n",
      "data-02-06/1119/data.html\n",
      "================================================\n",
      "data-02-06/2654/data.html\n",
      "================================================\n",
      "data-02-06/2383/data.html\n",
      "mô tả công việc:\n",
      "\n",
      "hỗ trợ xây dựng cơ sở dữ liệu cho ứng dụng và tích hợp ứng dụng\n",
      "xây dựng cấu trúc cơ sở dữ liệu mới và triển khai ứng dụng\n",
      "lập trình csdl, báo cáo và nâng cấp\n",
      "phát triển, bảo trì và hỗ trợ các chức năng csdl mà công ty đã xây dựng\n",
      "tối ưu và bảo trì csdl đã được xây dựng trước đó, của các dự án cũ\n",
      "thực hiện các tác vụ kiểm thử hiệu năng csdl, xử lý các lỗi\n",
      "phát triển và tối ưu ứng dụng, câu truy vấn, schema\n",
      "hỗ trợ phát triển ứng dụng, debugging, cấu hình, tối ưu hệ thống\n",
      "phát triển và duy trì sql scripts trong microsoft sql server\n",
      "phát triển và duy trì ssis packages\n",
      "phát triển và duy trì ssrs packages\n",
      "xây dựng chiến lược cho các dữ liệu nâng cấp và tích hợp của ứng dụng giữa các sản phẩm, phiên bản, các nền tảng\n",
      "phân tích mã nguồn của csdl cũ để có phương án tối ưu, cải thiện hiệu suất\n",
      "\n",
      "3. yêu cầu:\n",
      "\n",
      "tốt nghiệp chuyên ngành: điện - tự động hoá, công nghệ thông tin, cơ điện tử, hoặc các ngành kỹ thuật khác.ưu tiên các trường/ ngành nền tảng it-ot\n",
      "đã sử dụng qua các công cụ như: snowflake, tableau, python, r and /or java, sql, pl/sql, and etl/elt\n",
      "có nền tảng kiến thức/ \n",
      "-----------------------------------------------\n",
      "kinh nghiệm trong xây dựng data modeling và xây dựng logical data model (ldm), physical data model (pdm).\n",
      "có nền tảng kiến thức / kinh nghiệm làm việc với mdm tools and implementation\n",
      "có nền tảng kiến thức/ kinh nghiệm làm việc với mdm integration patterns (near realtime, batch)\n",
      "xây dựng báo có dùng ssrs\n",
      "có khả năng lập trình, cấu hình và triển khai trên các nền tảng công nghệ của microsoft.\n",
      "có kĩ năng thực hiện test cases/ automation test là một lợi thế\n",
      "\n",
      "chấp nhận sinh viên mới ra trường có nền tảng theo yêu cầu\n",
      "4. quyền lợi:\n",
      "\n",
      "mức lương: thoả thuận theo năng lực\n",
      "môi trường làm việc đam mê, năng động, sáng tạo, hoà đồng\n",
      "chế độ đãi ngộ tốt\n",
      "thực hiện chế độ theo quy định nhà nước ngay khi kết thúc 02 tháng thử việc.\n",
      "đóng bhxh theo quy định nhà nước\n",
      "thưởng quý,\n",
      "================================================\n",
      "data-02-06/2506/data.html\n",
      "mô tả công việc\n",
      "\n",
      "* xây dựng, theo dõi, phân tích và đánh giá các hoạt động kinh doanh.\n",
      "- 'đánh giá, phân tích và dự báo tiến độ kinh doanh hàng tháng/quý, phân tích tình hình kinh doanh dữ liệu nội bộ & bên ngoài để tìm ra cơ hội tăng trưởng\n",
      "- xây dựng, quản lý và tối ưu ngân sách năm nhằm đảm bảo mục tiêu kinh doanh \n",
      "- kiểm tra, đánh giá các chính sách hỗ trợ bán hàng của đối thủ và nội bộ để làm cơ sở xây dựng các chính sách bán hàng\n",
      "- xây dựng kế hoạch sản lượng, bao phủ theo kênh, theo hệ thống siêu thị, e-com\n",
      "- phối hợp xây dựng kế hoạch và phát triển kinh doanh;  quy hoạch ngành hàng và tìm cơ hội tăng trưởng trong trung hạn\n",
      "- điều phối các hoạt động hỗ trợ của các phòng ban có liên quan để đạt kế hoạch tháng/quý\n",
      "- 'thực hiện các công việc khác theo yêu cầu của quản lý trực tiếp\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "\n",
      "đại học chuyên ngành kinh tế, qtkd, tài chính, marketing;\n",
      "có khả năng phân tích số liệu và thuyết trình;\n",
      "có hiểu biết về nghiên cứu thị trường;\n",
      "có kinh nghiệm làm việc ở vị trí tương đương tối thiểu 3 năm, ưu tiên trong ngành hàng fmcg;\n",
      "tiếng anh và các công cụ microsoft office thành thạo; công cụ phân tích số liệu\n",
      "\n",
      "tổ chức, sắp xếp công việc khoa học; khả năng chịu\n",
      "================================================\n",
      "data-02-06/2603/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            - thực hiện báo cáo (định kỳ/adhoc) theo yêu cầu của các khối/đơn vị kinh doanh theo mảng công việc được giao.\n",
      "- tham gia thực hiện phân tích theo các chuyên đề.\n",
      "- thực hiện các hoạt động xây dựng và cung cấp báo cáo tự động theo nhu cầu đặt hàng của các đơn vị\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2418/data.html\n",
      "================================================\n",
      "data-02-06/1304/data.html\n",
      "responsibilities:...\n",
      "                                \n",
      "apply for this job\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/837/data.html\n",
      "================================================\n",
      "data-02-06/824/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responsibilities\n",
      "\n",
      "responsible for analyzing data, think creatively and develop media plan and strategy to make sure marketing campaign reach the right target audience in the most effective way.\n",
      "liaised directly with the internal team and colleagues to meet business objectives and understand their wants, needs, and objectives and then develop the media plan, what media channel should be used for specific campaigns\n",
      "present innovative strategies to make sure marketing campaigns reach the right target in the most effective way.\n",
      "collecting and analyzing data by the tools with regards to consumer behavior to find certain media with different method\n",
      "devising and recommending strategies and the most appropriate type of media to use, as well as the most effective time spans and location\n",
      "managing budgets and evaluating the campaigns\n",
      "executing and managing digital campaigns using search engine marketing together with social media, programmatic buying and other tracking tools.\n",
      "seek out new media opportunities that fit with the brand and maximizing all opportunities for growth.\n",
      "measure and report performance of media campaigns, gain insight and assess against goals.\n",
      "overseeing the quality of work that gets delivered to the client.\n",
      "talent development by managing the junior team members and be responsible for their delivery & quality of work.\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "job requirements\n",
      "\n",
      "at least 6-8 years of experience related field.\n",
      "skills in strategic planning, logical thinking, problem solving, analytics\n",
      "management skill (better to have)\n",
      "advanced knowledge and mindset of digital marketing\n",
      "trendy & entertainment\n",
      "production knowledge\n",
      "solid experience with sns digital marketing\n",
      "excellence in communication skill\n",
      "outstanding presentation skills.\n",
      "\n",
      "\n",
      "benefits \n",
      "\n",
      "salary: negotiable \n",
      "international, challenging, and friendly working environment\n",
      "salary for 13th month\n",
      "full of social welfare under vietnamese labor law (insurance, annual leave, etc.)\n",
      "annual travel, team building activities, and periodic health check\n",
      "12 annual leave days and 3 paid summer holidays\n",
      "training: trained in soft and technical skills\n",
      "\n",
      "\n",
      "apply online or feel free to contact me directly for more information about this opportunity. due to the high volume of applicants, we regret to inform that only shortlisted candidates will be notified. thank you for your understanding.\n",
      "\n",
      "================================================\n",
      "data-02-06/2029/data.html\n",
      "mô tả công việc\n",
      " \n",
      "key responsibilities- working closely with technology, business partners and data professionals to help design, architect and deploy a new scalable enterprise wide data analytics platform- design, write and deploy high volume data applications to ingest, transform, and store data to be used in models and reporting- analyze and improve efficiency, scalability, reliability and performance of our data platforms and systems infrastructure- design, develop and maintain data pipelines in a devops operating model- design and develop data pipelines catering to both structured and unstructured sources- understand business requirements to develop new data pipelines\n",
      " \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2265/data.html\n",
      "mô tả công việc như sau:\n",
      "\n",
      "thiết kế, phát triển, tối ưu hóa và duy trì kiến ​​trúc dữ liệu và kỹ thuật ống dẫn, đảm bảo tuân thủ các nguyên tắc etl và phù hợp với mục tiêu kinh doanh\n",
      "giải quyết các vấn đề phức tạp về dữ liệu để cung cấp thông tin chi tiết, hỗ trợ đạt mục tiêu kinh doanh\n",
      "xây dựng dữ liệu, hỗ trợ nhóm phân tích và nhà khoa học dữ liệu, nhằm cải thiện năng suất làm việc\n",
      "tư vấn, cố vấn và huấn luyện người khác trong việc phân tích, tiêu chuẩn hóa dữ liệu\n",
      "thúc đẩy văn hóa chia sẻ, tái sử dụng, thiết kế mang tính ổn định và vận hành hiệu quả dữ liệu/giải pháp phân tích\n",
      "chủ trì đánh giá, thực hiện và triển khai các công cụ và quy trình mới trong việc phân tích dữ liệu nhằm cải thiện năng suất làm việc của nhóm\n",
      "xây dựng và đưa ra các kế hoạch truyền thông về khả năng, tiêu chuẩn và quy trình phân tích dữ liệu\n",
      "phối hợp với các chuyên viên phân tích nghiệp vụ và kiến ​​trúc sư giải pháp để phát triển kiến ​​trúc kỹ thuật cho các dự án doanh nghiệp chiến lược và các sáng kiến.\n",
      "tìm hiểu, học hỏi về khoa học máy tính, khoa học dữ liệu, thị giác máy tính, trí tuệ nhân tạo, thống kê và/hoặc toán học ứng dụng\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/973/data.html\n",
      "================================================\n",
      "data-02-06/2225/data.html\n",
      "================================================\n",
      "data-02-06/1053/data.html\n",
      "chi tiết công việc analytics engineer tại joon solution\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/793/data.html\n",
      "description \n",
      "\n",
      "job responsibilities (include, but not limited to the following):\n",
      "– we are seeking phds or \n",
      "-----------------------------------------------\n",
      "experienced researchers in machine learning, expert systems, or artificial\n",
      "– intelligence to apply such technologies toward the development of an expert system that can help research worldwide financial markets. candidates need not have prior knowledge of financial markets, as the new hire will work closely with our highly accomplished quantitative researchers in the financial markets \n",
      "we offer outstanding career opportunities, which include:\n",
      "– competitive financial rewards, relative to performance and position\n",
      "– friendly and collegial working environment\n",
      "– opportunity for promotion and career advancement\n",
      "– opportunity to work with a team of highly accomplished experts in the financial markets to develop a industry frontier machine learning system.\n",
      "job qualifications:\n",
      "– ph.d. or m.s. degree from a top university in machine learning, expert systems, or artificial intelligence\n",
      "– machine learning related working experience at top tier companies.\n",
      "– have on-hand machine learning experience in resolving realistic large scale machine learning projects.\n",
      "– industrial experiences in expert system, game theory, mcts, deep learning related projects are a big plus.\n",
      "– proficient in c++ or python programming; knowledge of database is plus; knowledge of parallel computation is plus.\n",
      "– experience with time-series data analysis is a plus.\n",
      "– have a research scientist mind-set, i.e., be a deep thinker, creative, persevering, smart, a self-starter, etc.\n",
      "– possess good english language skills\n",
      "– have a strong interest in learning about worldwide financial markets\n",
      "– have a strong work ethic\n",
      "position based in hanoi, vietnam.\n",
      "\n",
      "================================================\n",
      "data-02-06/317/data.html\n",
      "responsibility initiatives, including supporting our local communities, advancing equality, and harnessing our technology to protect vulnerable groups. learn more, here\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2388/data.html\n",
      "mô tả công việc\n",
      "\n",
      "we are looking for a data engineer who will work directly with cto and stakeholders to build our financial data platform to support our vision as a data-driven company. the goal is to use data to make informed decisions when developing software product, choosing go-to-market strategy and execute business strategy. he/she will also work with our inhouse data scientist on machine learning & artificial intelligence projects to revolutionize the way vietnamese people trade and invest stocks and securities and bring the maximum values and opportunities for our customers. the ideal candidate should have experience in big data hadoop/spark ecosystem, designing and building scalable data management& data processing platform/data warehouse/data lake at a similar role, including designing data models, collecting data from various sources such as sql/nosql databases, kafka, etc.; transforming raw data to models and building data lake for departmental access. they should have strong background in software engineering, including testing. they must have a proven ability to drive business results with their data-based insights. they must be comfortable working with a wide range of stakeholders and functional teams. the right candidate will have a passion for discovering solutions hidden in large data sets and workingwith stakeholders to improve business outcomes. experiences with power bi (or similar solutions) are preferred, but not required. expertise in finance, banking and stock investing is a huge plus, but not required. must be willing to learn stock investing domain.responsibilities for data engineer\n",
      "work directly with cto to architect and build financial data platform with data from various sources, both inside and outside our company. work directly with data vendors to collect and enrich our financial data platform\n",
      "work directly with our data scientists and investment advisory department to build innovative product features with machine learning and artificial intelligence\n",
      "work with stakeholders throughout the organization to catalog and collect data and identify opportunities for leveraging company data to drive business solutions.\n",
      "mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.\n",
      "develop processes and tools to monitor and analyze data analytics performance and data accuracy.\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "\n",
      "strong problem solving skills with an emphasis on product development.\n",
      "experience working with search engines: elasticsearch, sorl.\n",
      "experience working with machine learning operations (mlops)\n",
      "experience working with and creating data architectures and designing data warehouse\n",
      "experience working with sql / nosql database\n",
      "experience visualizing/presenting data for stakeholders using: ggplot, powerpoint, powerbi, metabase, etc. periscope,\n",
      "excellent written and verbal communication skills for coordinating across teams.\n",
      "a drive to learn and master new technologies and techniques.\n",
      "\n",
      "\n",
      "tại sao bạn sẽ yêu thích làm việc tại đây\n",
      "\n",
      "\n",
      "fastest growing fintech startup with state-of-the-arts technology\n",
      "top notch engineering team\n",
      "competitive salary with regular review and advancement\n",
      "opportunity to take charge of your own works and directly contribute to company products\n",
      "small, young and close-knit team. we move fast, work hard and play hard.\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2582/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "                                                                                            xây dựng và thực hiện các báo cáo số liệu về huy động, cho vay.\n",
      "xây dựng các báo cáo giám sát tăng trưởng tín dụng, huy động của các đvkd.\n",
      "thực hiện các báo cáo phân tích về năng suất lao động của cán bộ bán hàng tại đvkd.\n",
      "phân tích hiệu quả của các chính sách thúc đẩy bán.\n",
      "khai thác dữ liệu và cung cấp số liệu kinh doanh cho các bộ phân có liên quan theo yêu cầu.\n",
      "xây dựng phần mềm và quản trị phần mềm tính toán lợi ích khách hàng đem lại cho ngân hàng.\n",
      "tham gia xây dựng các chương trình quản lý khách hàng nhằm phục vụ công tác báo cáo quản trị, đánh giá kết quả hoạt động kinh doanh đối với khách hàng.\n",
      "tham gia các dự án của ngân hàng xây dựng hệ thống báo cáo về phân tích số liệu, báo cáo quản trị kinh doanh sản phẩm, dịch vụ.\n",
      "thực hiện công việc liên quan đến chính sách lãi suất, phí:\n",
      "xây dựng/điều chỉnh các cơ chế, chính sách lãi suất, phí cho các sản phẩm, dịch vụ.\n",
      "tham mưu/tư vấn cho ban lãnh đạo ngân hàng về việc phê duyệt áp dụng các cơ chế, chính sách ưu đãi liên quan tới lãi suất, phí.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/250/data.html\n",
      "descriptionthe bosch group is a leading global supplier of technology and services. it employs roughly 394,500 associates worldwide (as of december 31, 2020). according to preliminary figures, the company generated sales of 71.6 billion euros in 2020. its operations are divided into four business sectors: mobility solutions, industrial technology, consumer goods, and energy and building technology.the bosch group comprises robert bosch gmbh and its roughly 440 subsidiaries and regional companies in some 60 countries. if its sales and service partners are included, then bosch is represented in roughly 126 locations. this worldwide development, manufacturing, and sales network is the foundation for further growth.bgsv – bosch global software technologies company limited (previous name: rbvh - robert bosch engineering and business solutions vietnam company limited) is 100% owned subsidiary of robert bosch gmbh. bgsv has started its operations from 19th october, 2010 at e-town2 in hcmc. this engineering development center will be engaged in developing embedded systems and software, mechanical design and simulation, and will provide it (sap consulting, java development….) and business services (finance and accounting, economics, purchasing, logistics, translations japanese-english-japanese, information security ) solutions to the bosch group of companies globally. job descriptiondevelop data warehouse and data marts.design reports, dashboards and interactive visualizations.maintaining  large-scale enterprise business intelligence systems.consulting, developing, implementation data warehouse and reports for large customer systems.you'll be trained on: data warehouse building, report and dashboard design, working with could solutions.qualificationsgraduated or going to graduate from computer science, it, management information systems (mis).good database design and programming skill.business intelligence, designed reports, ai knowledge and/or \n",
      "-----------------------------------------------\n",
      "experience will be an advantage.good at english communication.opportunity to working in an international team and global projects.additional informationcommitted 13-month bonus and collaborative yearly performance bonus.15-day annual leave + birthday leave and will be added 1 more every 3 years.meal & parking allowances (60.000 vnd/day).premium insurance (pvi) for employee and 2 family members.overseas training programs and working onsite opportunity.good benefits of trade union activities, team building and company trip.global career path and transparent performance review system.loyalty bonus and day off for your long-service award every 5, 10, 15... year.opportunity to work in global projects of fast developing company being a part of innovation team contributing initiative ideas to the hi-tech world.engage in our diverse training programs which surely help strengthen both your personal and professional skills\n",
      "================================================\n",
      "data-02-06/2716/data.html\n",
      "mô tả công việc\n",
      "- take the initiative to organize business unit within the organization to gather and combine the necessary business-related data.\n",
      "- use data to analyze, assess, and pinpoint areas for improvement in the present business processes.\n",
      "- collaborate with other teams to meet business requirements.\n",
      "- define specific business requirements and work with the appropriate data team members to translate these into technological requirements.\n",
      "- verifying provided data schema.\n",
      "- doing data extraction, transformation as carpla’s standards\n",
      "- extracting, transforming, and onboarding data\n",
      "- data analysis and quality assurance for your product\n",
      "- leading, guiding, mentoring other team members\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "- bachelor’s degree in engineering, computer science (or equivalent experience)\n",
      "- at least 6 months of relevant experience as a data analysis\n",
      "- 3+ years of experience working as business analyst\n",
      "- in-depth knowledge of car domain is nice to have.\n",
      "- extensive experience working with data analytics and related technologies.\n",
      "- demonstrable experience and skills with ms excel and ms powerpoint\n",
      "- thorough knowledge of the relevant business units\n",
      "- basic knowledge of data management issues\n",
      "- significant data quality and metadata management expertise\n",
      "- some familiarity with product and project management is desirable.\n",
      "- nice to have prior fintech experience.\n",
      "- in-depth knowledge of sql (complex join, subqueries, unions,e.g…) and powerbi is nice to have\n",
      "- excellent understanding of business architecture ideas and how they're used.\n",
      "- excellent written english communication skills\n",
      "- ability to move fast and be efficient, making decisions on objective data evidence.\n",
      "- ability to work independently.\n",
      "quyền lợi\n",
      "- salary up to 1800$\n",
      "- health-care insurance tic\n",
      "- working hour: 8h00-17h30 or 8h30 - 18h00 mon - fri\n",
      "- salary package 14-16 months/ year\n",
      "- performance review at least 1/ year\n",
      "- team building, yep\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 10/06/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/1677/data.html\n",
      "responsibilities:\n",
      " \n",
      "\n",
      "receiving and understanding business requirements  \n",
      "examine, analyze and evaluate source data \n",
      "do the mapping source data with data warehouse  \n",
      "design, build, execute, and manage the data extraction process. \n",
      "design, build, execute periodically & adhoc reports  \n",
      "compare & checking data \n",
      "hand over source code, jobs to extract data to operation department \n",
      "join it project and perform assigned tasks within the project scope \n",
      "perform other tasks assigned by the team leader \n",
      "hand over source code, jobs to extract data to operation department \n",
      "join it project and perform assigned tasks within the project scope\n",
      "perform other tasks assigned by the team leader \n",
      "\n",
      "requirements:\n",
      " \n",
      "1.     1. educational qualifications\n",
      " \n",
      "graduate majoring related to it or mis\n",
      " \n",
      "2.     2. relevant knowledge / expertise\n",
      " \n",
      "\n",
      "knowledge of banking (products, services, process,..) \n",
      "knowledge of mis, data warehouse \n",
      "knowledge of database management and data mining \n",
      "knowledge of data model, dimensional model \n",
      "proficient programming languages: c#, vb.net, sql, pl / sql, visual fox \n",
      "proficient database: oracle, sql server, visual fox, ms access \n",
      "proficient etl tools: datastage, ssis, odi, informatica… \n",
      "can using data modeling tools: erwin, power designer…\n",
      "\n",
      " \n",
      "3.     3. skills\n",
      " \n",
      "\n",
      "foreign language: english (can read documents and communicate) \n",
      "skills to use the support software: microsoft office, microsoft project ... \n",
      "communications capability  \n",
      "problem solving capability \n",
      "skills to collect, filter, analyze and evaluate information. \n",
      "ability to teamwork\n",
      "\n",
      " \n",
      "4.     4. relevant \n",
      "-----------------------------------------------\n",
      "experiences\n",
      " \n",
      "\n",
      "at least 02 years of working experience in banking data processing or related fields in mis, \n",
      "data warehouse\n",
      "\n",
      " \n",
      "5.\n",
      "================================================\n",
      "data-02-06/2500/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responsibilities\n",
      "\n",
      "review suspicious transactions generated by fraud detection systems, the analyst must be highly sensitive to abnormal /fraudulent transactions to minimize loss at the earliest stage and be alert to the new emerging fraud trends/patterns. ensure all alerts have been reviewed and cleared timely \n",
      "responsible for making sound judgements and decisions on the alerts in accordance to the operating guidelines and procedures to prevent and minimize fraud losses. \n",
      "analyze alerts and investigate transactional activities to detect suspicious fraud activity to minimize fraud losses for the respective businesses and ensure that fraud loss does not exceed the plan \n",
      "contact customers using the existing contact strategy for suspected fraud transactions to verify/validate suspicious transactions via outbound call/email. \n",
      "responsible for shift/daily/weekly reports. \n",
      "proactive escalate and follow-up on resolving system incident and fraud incident. \n",
      "able to work on a 24x7 shift. meet the productivity and quality expectations for this function. \n",
      "process offline requests from acquirers, cpo, and other operating units in a timely manner. \n",
      "meet expected service levels in handling cpo inbound calls.\n",
      "\n",
      " \n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2420/data.html\n",
      "mô tả công việc\n",
      "\n",
      "mục tiêu\n",
      "\n",
      "chịu trách nhiệm về phân tích và các báo cáo kết quả thực hiện thu hồi nợ của trung tâm xử lý tín dụng\n",
      "\n",
      "phân tích báo cáo kết quả hiệu suất thực hiện\n",
      "\n",
      "thêm dữ liệu từ các nguồn (dw) cho phân tích kết quả hiệu suất thu hồi nợ theo yêu cầu từ các cấp quản lý;\n",
      "thực hiện các phân tích phân phúc theo danh sách phân loại nợ\n",
      "cung cấp dữ liệu để kiểm tra hoặc thực hiện các mô phỏng cho đề xuất/chính sách/chương trình mới\n",
      "dự báo tỷ lệ chuyển đổi nhóm nợ theo tuần/tháng\n",
      "\n",
      "vận hành\n",
      "\n",
      "theo dõi và kiểm soát chính sách thưởng, mức chi trả thực và chỉ tiêu đặt ra/\n",
      "thực hiện chạy thử nghiệm tính hiệu quả của chính sách hoặc các thực hiện mới\n",
      "theo dõi kiểm soát các thử nghiệm để thấy được tính hiệu quả của bất kỳ thay đổi được triển một cách kịp thời\n",
      "\n",
      "lập báo cáo\n",
      "\n",
      "cung cấp báo cáo kết quả hiệu quả xử lý tín dụng tuần/tháng\n",
      "đảm bảo các hoạt động vận hành tuân thủ theo các quy định, chính sách và thủ tục đã được phê duyệt\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "\n",
      "tốt nghiệp đại học, chuyên ngành toán, thống kê, ngân hàng, kinh tế, quản trị kinh doanh là một lợi thế\n",
      "tối thiểu 1 năm kinh nghiệm lĩnh vực liên quan\n",
      "thành thạo tiếng anh và việt\n",
      "kỹ năng phân tích và tư duy logic\n",
      "sử dụng thành thạo các công cụ báo cáo (sql/ python)\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2678/data.html\n",
      "================================================\n",
      "data-02-06/3000/data.html\n",
      "mô tả công việc\n",
      " ● the engineer is responsible for the data product’s implementation. supervisor quality of product to make sure its functions meet requirements● research new technology to apply for big data products. continuously suggest advanced technical solutions to make the product best● work with leader very closely to make sure each other opinions are aligned● hand-on development of features through architect, design, and implementation● code yourself, perform code review and code optimization for maximizing system performance \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2101/data.html\n",
      "================================================\n",
      "data-02-06/2878/data.html\n",
      "responsibilitiesas data engineer in ibm consulting, your role and responsibilities  understand the business requirement and the business vision. analyse the technical project requirements and deliverables. coordinate with the ba and development team to make the team understand the requirement and deliverables. overseeing daily technical operations.  prepare and present progress report of the projects. track the progress of the tasks of individual team members and report on any risks/issues. drive proof of concept initiatives. when needed, quickly design and implement a prototype of a system or component review the work done by the team for continuous improvement and adoption of best practices and coding standards. communicating with customer po/pm on the progress and requirements of the development team. work with team on creating reusable components. guide the team members and provide them technical and functional clarifications. creation of mock data for testing in development and sit environments. creation of data model for various layers in a datalake on cloud and on-prem setup. review sprint completion, sit test reports, traceability matrix and then share it with customer project manager.  required \n",
      "-----------------------------------------------\n",
      "experience:    strong technical experience of 7-12 years working with data projects preferably in cloud (aws, google, azure) and with at least 3 end-to-end production implementations in cloud hands-on experience of over 5 years in working with python, pyspark and its associated common packages to load and transform data hand-on experience of over 5 years working in cloud technologies like s3, glue, lambda, dynamodb or similar technologies  understanding and exposure of over 4 years in managing end-to-end data pipeline process and procedures experience of over 5 years in managing and driving conversations with business teams strong understanding and implementation experience of agile methodologies strong exposure and experience of over 5 years in code promotion process following devops processes in cloud self-motivated and comes with a can-do attitude with experience working in fast paced environment experience managing a team of data engineers and resolving technical issues faced by them    preferred experience:  demonstrates experience in translating high level business capability requirements into executable technical solutions broad experience of projects involving one/more of relevant data analytics technology areas viz big data engineering, data warehousing, data integration, data quality, data modelling, visualization, analytics prior experience in creating data models for building data pipelines across various layers of a data lake on cloud and on-prem setup.  prior experience working and co-ordinating directly with customer and multiple vendors across multiple locations for project delivery.required technical and professional expertiseas abovepreferred technical and professional expertiseas abov\n",
      "================================================\n",
      "data-02-06/2721/data.html\n",
      "mô tả công việc\n",
      "tham gia nghiên cứu, phát triển, xây dựng các công nghệ lõi ai cho xử lý ngôn ngữ (nlp)hỗ trợ, cải thiện, tối ưu mô hình ai trong quá trình phát triển.báo cáo công việc cho mentor\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "sinh viên từ năm 2 chuyên ngành công nghệ thông tin, điện tử viễn thông, khoa học máy tính, toán tin ứng dụng và các chuyên ngành liên quan.có kinh nghiệm lập trình python/ đã làm các bài tập project liên quan đến pythonđã làm một số project cá nhân yêu cầu kỹ năng từ một trong số các ngôn ngữ lập trình hướng đối tượngbiết sử dụng docker, git là một lợi thế.tiếng anh giao tiếp cơ bản (kỹ năng nghe nói tương đương ielts 6.5 trở lên)\n",
      "quyền lợi\n",
      "hỗ trợ cơ bản up to 5.000.000 vnd/tháng, cùng thêm các phụ phí phát sinh trong quá trình làm việc như ăn trưa, gửi xe, kinh phí chạy thí nghiệmđược làm việc trực tiếp cùng mentor nước ngoài giàu kinh nghiệmđược cung cấp laptop cá nhâncó lộ trình thăng tiến lên nhân viên chính thức rõ ràngmôi trường làm việc cởi mở và năng động, khuyến khích trao đổi ý tưởng ở mọi cấp. bạn được chủ động làm việc, sáng tạo theo cách riêngcó hỗ trợ chứng nhận thực tập tốt nghiệp\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 30/06/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2719/data.html\n",
      "mô tả công việc\n",
      "● tham gia phát triển nền tảng quản lý dữ liệu lớn.● tham gia vào hiệu suất tối ưu cho các truy vấn data trên lượng dự liệu lớn.● xử lý các yêu cầu trung bình đến khó trong dự án.● đưa ra các ý tưởng cải tiến hiệu năng, tối ưu chi phí cho toàn hệ thống.● thời gian làm việc: thứ 2 – thứ 6 (sáng: 8h00-12h00; chiều: 13h30-17h30).\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "● kiến thức:- tốt nghiệp cử nhân chuyên ngành công nghệ thông tin, điện tử viễn thông, tài chính, ngân hàng, kinh tế hoặc tương đương. ưu tiên ứng viên có bằng tốt nghiệp loại giỏi hoặc tốt nghiệp tại nước ngoài- ưu tiên có các chứng chỉ chuyên nghành data engineer, data analytics, data science cho xử lý dữ liệu lớn● kinh nghiệm:- tối thiểu 2 năm kinh nghiệm làm việc trực tiếp tại các công ty, dự án về ds- có kiến thức cơ bản về data mining- có kiến thức về phân tích và visualization dữ liệu- có kiến thức về machine learning, deep machine learning- biết cài đặt trên hadoop eco-sys, aws, gcp,… cùng các tech stack thông dụng như sparkml, jupiternotebook, airflow, vs code với các thuật toán, thư viện thông dụng hiện nay- sử dụng thành thạo python, scala và java là lợi thế- có kinh nghiệm làm việc theo mô hình agile- có kinh nghiệm trong lĩnh vực tài chính ngân hàng- có khả năng đọc viết tiếng anh (cơ bản) nghe nói (nếu có thể).\n",
      "quyền lợi\n",
      "● thu nhập cực hấp dẫn: upto 32m gross ( thỏa thuận mức lương tương xứng với năng lực và kinh nghiệm làm việc)● hỗ trợ kí hợp đồng chính thức, nhận 100% lương và đóng bảo hiểm từ ngày đầu tiên đi làm● thưởng dự án, gói thưởng lễ tết lên đến 14m/year (bonus at tết dương lịch, tết âm lịch, lễ 2/9, quà tết, quà trung thu, sinh nhật công ty, tập đoàn,. )● xét tăng lương cố định hàng năm hoặc 6 tháng/ năm theo đánh giá năng lực● được hưởng bhxh, bhyt, bhtn theo chế độ nhà nước ban hành và tặng thêm gói bhxh sức khỏe “nms care” cho nhân viên● tận hưởng nhiều sự kiện của công ty, từ thi đấu thể thao, tiệc sinh nhật hàng tháng, xây dựng đội ngũ hàng quý đến tiệc năm mới, chuyến đi công ty, du lịch hè, teambuilding, liên hoan, gala định kì gắn kết tình cảm\n",
      "================================================\n",
      "data-02-06/2965/data.html\n",
      "responsibilities\n",
      "provide custom insights and recommendations as an ambassador for advanced analytics.contribute to the long-term strategy for business intelligence, including predictive and prescriptive analytics models.deliver actionable analytics presentations and consult with key stakeholders.visualize data and communicate compelling insights.lead analytics-driven initiatives across departments.conduct in-depth analysis, identify root causes, and problem-solve.manage business intelligence projects and mentor junior analysts.\n",
      "\n",
      "-----------------------------------------------\n",
      "experience requirements\n",
      "5-7+ years of professional experience in data analysis, visualization, and deep-dive ad-hoc analysis.industry experience in fmcg/nutrition/pharma/consulting is advantageous.strong background in business intelligence, data analytics, and visualization, including dwh and bi tools.proficient in data extraction, aggregation, transformation, and modeling.advanced skills in sql, r, python, sas, and other relevant tools for working with databases.familiarity with machine learning models, supervised and unsupervised learning, and artificial intelligence.competency in bi technologies like integration services, sql server, mongodb, analysis services, automl, power bi, and qlik. education requirements\n",
      "bachelor's degree in a relevant field is required (e.g., data science, computer science, statistics, business analytics).please click the\n",
      "================================================\n",
      "data-02-06/1969/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "- phát triển các công cụ để lưu trữ dữ liệu và theo dõi hiệu suất đầu tư. tối ưu hiệu suất ghi/đọc của hệ thống cơ sở dữ liệu. - xây dựng các kết nối giao dịch với các đơn vị/đối tác cung cấp dữ liệu.- hoàn thiện hệ thống data center, data warehouse - tìm kiếm các nguồn dữ liệu mới để tăng hiệu quả và độ chính xác của các mô hình.trong một thế giới mở và phát triển nhanh hiện nay, big data giống như những mỏ vàng đang chờ được khai quật. việc thu thập và có được dữ liệu lớn là bước đầu tiên biến mình thành ông chủ của tài nguyên số. bước tiếp theo và quan trọng hơn đó là xử lý, sắp xếp, hệ thống hóa và chuẩn hóa dữ liệu. nói cách khác đây chính là bước phân loại, rèn những cục quặng thành những viên kim cương vô cùng giá trị. finpros mong chờ bạn đến xây dựng nên những viên kim cương.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "đam mê và tham vọng trở thành tên tuổi trong lĩnh vực quantitative finance (những tỷ phú công nghệ)+ nắm vững kiến thức toán từ lớp 1 đến lớp 12+ biết ít nhất 1 ngôn ngữ lập trình hướng đối tượng+ đọc hiểu các tài liệu tiếng anh+ \n",
      "================================================\n",
      "data-02-06/2633/data.html\n",
      "================================================\n",
      "data-02-06/2555/data.html\n",
      "mô tả công việc\n",
      "1. hỗ trợ quản lý trực tiếp trong các việc\n",
      "- phối hợp với người quản lý dữ liệu và các bên liên quan khác để hiểu nhu cầu dữ liệu của họ và đưa ra khuyến nghị về các vấn đề liên quan đến dữ liệu \n",
      "- tạo các báo cáo và trực quan hóa dữ liệu để truyền đạt hiệu quả thông tin chi tiết về dữ liệu tới các đối tượng không có kỹ thuật \n",
      "- tham gia vào việc phát triển và thực hiện các chiến lược và kế hoạch dữ liệu \n",
      "- luôn cập nhật những phát triển của ngành và các công nghệ mới nổi để liên tục cải thiện chất lượng và hiệu quả của các giải pháp dữ liệu. \n",
      "2. trách nhiệm chính\n",
      "- xây dựng và duy trì các mô hình dự đoán bằng các kỹ thuật học máy và thống kê tiên tiến \n",
      "- sử dụng các ngôn ngữ lập trình như python hoặc r để phân tích các tập dữ liệu lớn và phát triển các thuật toán \n",
      "- phối hợp với các nhóm đa chức năng để thiết kế và triển khai các thử nghiệm nhằm kiểm tra các giả thuyết và thu thập thông tin chuyên sâu \n",
      "- triển khai và điều chỉnh các mô hình dữ liệu để đảm bảo hiệu suất tối ưu \n",
      "- sử dụng kiểm soát phiên bản để quản lý mã và cộng tác với các thành viên khác trong nhóm \n",
      "- truyền đạt những phát hiện và hiểu biết sâu sắc cho cả các bên liên quan kỹ thuật và phi kỹ thuật \n",
      "- luôn cập nhật các xu hướng của ngành và các công nghệ mới liên quan đến khoa học dữ liệu và học máy \n",
      "- tham gia phát triển và triển khai các dự án cơ sở hạ tầng dữ liệu và kỹ thuật dữ liệu \n",
      "- làm việc với các nền tảng đám mây như gcp để triển khai và quản lý các mô hình dữ liệu\n",
      "                                                                                   \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1106/data.html\n",
      "================================================\n",
      "data-02-06/2980/data.html\n",
      "mô tả công việc: \n",
      "        \n",
      "\n",
      "trách nhiệm chính\n",
      "•    xây dựng, phân bổ và quản lý kế hoạch các chỉ tiêu kinh doanh \n",
      "•    theo dõi, báo cáo phân tích tình hình thực hiện các chỉ tiêu kinh doanh theo kế hoạch, sản phẩm dịch vụ, vùng miền\n",
      "•    đề xuất, xây dựng và vận hành các chương trình theo dõi tự động các hoạt động và chỉ tiêu kinh doanh liên quan đến khách hàng doanh nghiệp\n",
      "•    tham gia các dự án về dữ liệu (data governance) của ngân hàng theo yêu cầu\n",
      " \n",
      "yêu cầu vị trí\n",
      "•    tốt nghiệp đại học chuyên ngành tài chính – kế toán, toán kinh tế, tin học quản lý\n",
      "•    có \n",
      "-----------------------------------------------\n",
      "kinh nghiệm đọc hiểu, xử lý số liệu (ưu tiên biết corebanking (t24) và bi –tool),\n",
      "================================================\n",
      "data-02-06/583/data.html\n",
      "responsibilities\n",
      "\n",
      "support the player experience team and external analysts with their data needs\n",
      "define what data should be collected and what types of analysis that data enables\n",
      "proactively provide actionable insights and shed light on previously unexplored aspects of player experience\n",
      "together with the rest of the team, develop vision and strategy for continuous improvement of support quality\n",
      "work side by side with subcontractors, external partners and internal tech teams\n",
      "\n",
      "requirements\n",
      "\n",
      "experience in a data analyst, manager or scientist role, interpreting and visualizing data to provide actionable insight and conclusions on player behavior\n",
      "expert knowledge of sql\n",
      "coding skills with r or python, and sql at a proficient level and some experience with bi tools like qliksenser or tableau\n",
      "fluent in the data science workflow, applying statistics, understanding biases\n",
      "great communication skills, both written and spoken, especially for non-technical audience\n",
      "skills to work with a team but also work autonomously\n",
      "proactive drive to improve our games and yourself, to\n",
      "-----------------------------------------------\n",
      "experience is one of the core components of fun games that are played for decades and remembered forever. \n",
      "we are looking for a data analyst with a passion for helping millions of players to enjoy our games in a trouble-free way. in this role you will be coordinating our external analysts with their data needs as well as our internal needs for your brains. the ideal candidate is someone with a strong analytical mindset and interest in analysing player behavior. someone always on the lookout for new ways to help us serve players better and improve overall player experience with new ideas and approaches.\n",
      "responsibilities\n",
      "\n",
      "support the player experience team and external analysts with their data needs\n",
      "define what data should be collected and what types of analysis that data enables\n",
      "proactively provide actionable insights and shed light on previously unexplored aspects of player experience\n",
      "together with the rest of the team, develop vision and strategy for continuous improvement of support quality\n",
      "work side by side with subcontractors, external partners and internal tech teams\n",
      "\n",
      "requirements\n",
      "\n",
      "experience in a data analyst, manager or scientist role, interpreting and visualizing data to provide actionable insight and conclusions on player behavior\n",
      "expert knowledge of sql\n",
      "coding skills with r or python, and sql at a proficient level and some experience with bi tools like qliksenser or tableau\n",
      "fluent in the data science workflow, applying statistics, understanding biases\n",
      "great communication skills, both written and spoken, especially for non-technical audience\n",
      "skills to work with a team but also work autonomously\n",
      "proactive drive to improve our games and yourself, to\n",
      "================================================\n",
      "data-02-06/1364/data.html\n",
      "================================================\n",
      "data-02-06/2899/data.html\n",
      "mô tả công việc\n",
      "ngày nay giao dịch tự động có sẵn trên hầu hết các giao dịch trên thế giới. chúng thường được ví như “giao dịch định lượng” và chiếm 80% tất cả các giao dịch trên thị trường toàn cầu. tuy nhiên, giao dịch định lượng vẫn còn rất mới tại việt nam và finpros là một trong những đơn vị tiên phong sử dụng phương pháp này để đầu tư vào thị trường chứng khoán việt nam.chúng tôi đang tìm kiếm một cá nhân đặc biệt để gia nhập công ty với tư cách là một nghiên cứu viên định lượng. người đó phải có hiểu biết mạnh về mã hóa và thống kê. không cần kinh nghiệm tài chính nhưng ứng viên phải có tư duy nghiên cứu và hứng thú mạnh mẽ trong việc học tài chính và giao dịch chứng khoán.- khai thác và phân tích dữ liệu về thị trường chứng khoán, tìm ra những quy luật và những thống kê đủ mạnh để có thể áp dụng trong đầu tư chứng khoán.- phát triển các thuật toán và mô hình dự đoán biến động giá cổ phiếu.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "• bằng đại học các ngành liên quan: khoa học máy tính, kỹ thuật, vật lý, toán, tài chính, kinh tế...\n",
      "================================================\n",
      "data-02-06/2813/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            the business context:\n",
      "unilever food solutions (ufs) is the €2.5bn+ foodservice division of unilever. it leads the dynamic food service market across its categories and has ambitious growth objectives, marketing a range of professional food and beverage products and services to chefs across 6 clusters in 72 countries. \n",
      "digital offers a huge opportunity and future growth for ufs depends on evolving the business model and developing contact strategies to reach the 95% of operators we do not visit. ambitious targets to transform our business towards a more digitally advanced one have been agreed with the global board and set in motion. \n",
      "in line with our ambition to continuously be a data-driven organization, we aim to remove siloes and bridge gaps by synergizing the strategy and data flows from multiple global platform owners without sacrificing the quality and integrity of data.\n",
      "\n",
      "scope of work: southeast asia & south asia \n",
      "job description:\n",
      "•\tdrive and nurture stable data environment in the region, for use of the local data teams. \n",
      "•\tdesign, implement, track and drive improvement in data quality metrics.\n",
      "•\testablish data governance by standardizing data capture, ingestion, transformation, mapping and validation processes across several use cases (sales, marketing, operations and more), and rolling this out across the region.\n",
      "•\tidentify process simplification, automation, data harmonization or de-duplication opportunities to improve data quality and lead projects to execute the same. \n",
      "•\tperform data validation alongside local and global data engineers.\n",
      "•\twork with regional digital selling team to refine and update regional data strategy to support business priorities. \n",
      "•\tprovide guidance to local data teams on utilization of sharepoint, azure data warehouses and databricks within a fast-paced enterprise environment.\n",
      "•\twork closely with global data and tech teams to ensure proper roll-out and data integration for existing and new solutions.\n",
      "•\tcoordinate among the global data team and local & regional stakeholders.\n",
      "•\tmaintain proper technical documentation and network architectural diagrams for the region.\n",
      "•\tconducts data standard trainings and monitor data adherence.\n",
      "•\tsupport partner teams in developing their data management strategies to seamlessly integrate with the central tracking tools.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2084/data.html\n",
      "description\n",
      "\n",
      "based on the data source (data warehouse) that the company collects and conducts analysis, the assessment aims to provide timely information warnings for the process of resolving business crises of customers.\n",
      "perform data analysis operations on the system and combine with microsoft office excel tools.\n",
      "use of data collection tools provided by the company.\n",
      "collaborate with members of the insight team and other departments to jointly send customers brand orientation reports.\n",
      "perform other tasks as instructed by the line manager.\n",
      "\n",
      "requirements\n",
      "\n",
      "no \n",
      "-----------------------------------------------\n",
      "experience required.\n",
      "university graduate.\n",
      "proficiency in excel’s advanced features is an advantage.\n",
      "ability to search for information, update content trends on social networks, forums and n\n",
      "honesty, carefulness, hard work.\n",
      "high sense of responsibility.\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2706/data.html\n",
      "mô tả công việc</span></p></li></ol><ul style=\"margin-bottom: 0px; padding-inline-start: 48px;\"><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 12pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">xây dựng, phát triển các hệ thống lưu trữ, xử lý dữ liệu lớn (big data)</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">xây dựng các giải pháp etl có khả năng mở rộng linh hoạt với độ tin cậy cao, phục vụ cho việc khai thác/ ingest các loại dữ liệu (cấu trúc, lưu lượng, tốc độ) từ nhiều nguồn khác nhau</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">xây dựng, phát triển các công cụ khai thác dữ liệu, quản trị dữ liệu</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">thiết kế chi tiết giải pháp cho các luồng thu thập, chuẩn hóa, làm sạch, làm giàu, lưu trữ, xử lý, phân tích và hiển thị dữ liệu lớn</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">thiết kế giải pháp và trực tiếp phát triển các module, thư viện có tính chất nền tảng, có khả năng tái sử dụng cao, ảnh hưởng diện rộng</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">tạo các dịch vụ web hiệu suất cao, có thể mở rộng để theo dõi dữ liệu</span></p></li></ul><p dir=\"ltr\" style=\"line-height: 1.2; margin-left: 36pt; margin-top: 12pt; margin-bottom: 12pt;\"><br></p><ol style=\"margin-bottom: 0px; padding-inline-start: 48px;\" start=\"2\"><li dir=\"ltr\" style=\"list-style-type: decimal; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -18.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 14pt; margin-bottom: 14pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;\">yêu cầu:</span></p></li></ol><ul style=\"margin-bottom: 0px; padding-inline-start: 48px;\"><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 10pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 12pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">tốt nghiệp đại học trở lên chuyên ngành khoa học dữ&nbsp; liệu, khoa học máy tính, công nghệ thông tin, điện tử - viễn thông, toán tin,...</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 10pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">có \n",
      "-----------------------------------------------\n",
      "kinh nghiệm từ 1,5 năm làm việc về các hệ thống big data,</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-weight: 400; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">nắm vững kiến thức cơ bản về khoa học dữ liệu, giải thuật, có tư duy lập trình hướng đối tượng và cơ sở dữ liệu.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 10pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 12pt 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">kiến thức về </span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">data-warehouse</span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">, xử lý dữ liệu phân tán, xử lý dữ liệu lớn (</span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">hadoop, spark,</span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\"> …)&nbsp;</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 10pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">kiến thức về xây dựng luồng xử lý dữ liệu (batch processing, stream processing...), và các công cụ quản lý workflow (luigi, airflow…)</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">kiến thức và kinh nghiệm xây dựng hệ thống chuyên sâu về dữ liệu với kiến trúc lambda/kappa/data lake</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">có kinh nghiệm làm việc về các hệ thống big data, data-warehouse, bi, sử dụng các mã nguồn mở như hadoop ecosystem, spark, hive, kudu, kafka, hbase, cassandra;</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 10pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">khả năng lập trình chuyên sâu&nbsp; </span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">java, scala, python</span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">...</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">lập trình thông thạo spark, spark-streaming;</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">kỹ năng sử dụng một trong các loại csdl </span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">(rdbms, graph databases, nosql, ...)</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.8; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">tư duy tốt, có khả năng nghiên cứu, đánh giá và cập nhật công nghệ mới.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">tiếng anh đọc hiểu tài liệu kỹ thuật.</span></p></li></ul><p dir=\"ltr\" style=\"line-height: 1.5; margin-left: -0.1pt; text-indent: -0.1pt; text-align: justify; margin-top: 14pt; margin-bottom: 0pt; padding: 0pt 0pt 14pt 0.1pt;\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;\">lý do để đồng hành với elcom</span></p><p dir=\"ltr\" style=\"line-height: 1.5; margin-left: -0.1pt; text-indent: -0.1pt; text-align: justify; margin-top: 0pt; margin-bottom: 14pt; padding: 0pt 0pt 0pt 0.1pt;\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">môi trường chuyên nghiệp, cởi mở, trao quyền và đề cao sự sáng tạo:</span></p><ul style=\"margin-bottom: 0px; padding-inline-start: 48px;\"><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 14pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">được mentor bởi đội ngũ quản lý, manager dày dặn kinh nghiệm, hỗ trợ sát sao, nhiệt tình.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 14pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">tham gia vào những dự án lớn, ứng dụng các công nghệ hàng đầu.</span></p></li></ul><p dir=\"ltr\" style=\"line-height: 1.5; margin-left: -0.1pt; text-indent: -0.1pt; text-align: justify; margin-top: 14pt; margin-bottom: 14pt; padding: 0pt 0pt 0pt 0.1pt;\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">tập trung hỗ trợ sự phát triển cá nhân:</span></p><ul style=\"margin-bottom: 0px; padding-inline-start: 48px;\"><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 14pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">được tư vấn, đồng hành và hỗ trợ phát triển sự nghiệp cùng với hệ thống career path (phát triển theo hướng chuyên gia hoặc hướng quản lý).</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 14pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">chính sách hỗ trợ các hoạt động học tập, phát triển bản thân</span></p></li></ul><p dir=\"ltr\" style=\"line-height: 1.5; margin-left: -0.1pt; text-indent: -0.1pt; text-align: justify; margin-top: 14pt; margin-bottom: 14pt; padding: 0pt 0pt 0pt 0.1pt;\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">quan tâm đặc biệt tới nhân viên:</span></p><ul style=\"margin-bottom: 0px; padding-inline-start: 48px;\"><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 14pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">văn phòng làm việc hiện đại với không gian mở; môi trường trẻ trung, năng động, sáng tạo và phát triển.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">gói đãi ngộ cạnh tranh với mức thu nhập hấp dẫn </span><span style=\"font-size: 11pt; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">(up to 1300 usd)</span><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\"> cùng chính sách nâng lương linh hoạt( 2 lần/ năm).</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">chính sách </span><span style=\"font-size: 11pt; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">thưởng hấp dẫn trực tiếp từ lợi nhuận công ty,</span><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\"> 6 khoản thưởng cho các ngày lễ khác trong năm. </span><span style=\"font-size: 11pt; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">gói thu nhập lên tới 14, 15 tháng lương/ năm.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">chăm sóc sức khỏe toàn diện với gói </span><span style=\"font-size: 11pt; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">bảo hiểm sức khỏe elcom care</span><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\"> do pti cung cấp được thiết kế riêng cho cbnv.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">khám sức khỏe thường niên tại bệnh viện hàng đầu cả nước.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">được hưởng toàn bộ các quyền lợi theo luật lao động ban hành về chế độ tham gia bảo hiểm xã hội, nghỉ lễ, nghỉ phép năm.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">bữa trưa </span><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">được phục vụ miễn phí tại văn phòng</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">các hoạt động văn hóa, giải trí phong phú:</span><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">du lịch, teambuilding, ngày hội sinh nhật công ty tại các địa điểm du lịch, resort cao cấp.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">ngoài ra, bạn sẽ được tham gia nhiều hoạt động thú vị như: office happy hours, team outings, tham gia các câu lạc bộ cực cool như clb thể thao (zumba, bóng bàn, bóng đá, cầu lông), chơi bi-a, âm nhạc,…</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 14pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">thời gian làm việc: thứ 2 đến thứ 6.</span></p></li></ul></span>\n",
      "                                                    \n",
      "================================================\n",
      "data-02-06/275/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responsibilities\n",
      "- possess an in-depth understanding of the data structures and governance- fundamental knowledge of modern cloud computing platforms and concepts- design, create and maintain optimal data pipeline architecture- assemble large, complex data sets that meet functional/non-functional business requirements- identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.- build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using sql and cloud technologies- work with stakeholders including the executive, product, data and design teams to assist with data-related technical issues and support their data infrastructure needs- able to work in a fast-paced, multi-site location, team-oriented environment\n",
      "\n",
      "-----------------------------------------------\n",
      "experience requirements\n",
      "• 5+ years experience in a developer role• advanced working sql knowledge and experience working with relational databases, query authoring (sql) as well as working familiarity with a variety of databases.• experience with data warehousing architecture and data modeling• experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.• experienced in manipulating, processing and extracting data from various source systems.• experienced in implementing concepts such as slowly changing dimension (scd type) and change data capture (cdc) functionality in both an oltp (relational modeling) and olap (dimensional modeling) environments.• able to work independently with minimum supervision.• experience with testing methodologies with the stated major development language(s)/technology education requirements\n",
      "• bachelor’s degree in computer science, engineering, mathematics, or a related technical discipline. contact person\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/1587/data.html\n",
      "================================================\n",
      "data-02-06/1309/data.html\n",
      "description kms healthcare is the intersection of world-class technologists and proven healthcare industry expertise.we empower companies to build transformative next-gen technologies to bring about game-changing resolutions to healthcare’s most challenging problems. our solutions ensure improved data exchange while maintaining regulatory compliance and data-driven requirements. we are committed to providing innovative tools and expertise to providers, payers, life sciences, and medical technology vendors in order to help create industry-leading health solutions.at kms healthcare, we leverage technologies to enable a modern way of health service. covering end-to-end product development, we helped numerous u.s. health practices increase health treatment quality, reduce costs, and save people's lives.instead of wishing people good health, join us to make it happen.job descriptiondesign and customize reportsmodify databases according to requests and perform testsmonitoring the data quality of data pipelines, provide data management support to clientsliaise with developers to improve applications and establish best practicesresponsible for building and maintaining optimized and highly available data pipelines that facilitate deeper analysis and reporting.developing and implementing data models, data marts for enterprise data lake/data warehouse and integration development process.writing effective and scalable etl processes in building the business’ data collection systems and processing pipelines.participate in agile/scrum activities: daily standup, demo session, retrospective, estimate and planning, etc.provide mentoring/training for junior members if any.perform other tasks assigned by the leader/ manager.qualificationsgeneral requirements:intermediate level of english level.strong logical thinking and problem-solving.ability to self-learn and adapt to new technologies quickly.digital thinker, product mindset, can-do attitude, and adaptable.ability to handle multiple tasks, communicate effectively with team members and management.technical requirements:3+ years of working \n",
      "-----------------------------------------------\n",
      "experience in data analysis and reporting servicesgood knowledge in data transformation (etl) and processing solutions and sql database.experience with python programing language and reporting tools (bi, tableau, etc)experience in database performance monitoring and tuningknowledge of data modeling and data relationship analysis for the large\n",
      "================================================\n",
      "data-02-06/2767/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            we are looking for candidates with strong knowledge/\n",
      "-----------------------------------------------\n",
      "experiences in analytics and computer vision but any other field of ai will be considered too.\n",
      "\n",
      "\n",
      "\n",
      "what you will do:\n",
      "\n",
      "- getting involved in data science project from its inception to its delivery\n",
      "\n",
      "- researching our clients’ problem and dataset to assess the potential added value of data science and analytics solutions\n",
      "\n",
      "- selecting, acquiring and integrating client data for analysis\n",
      "\n",
      "- developing data hypotheses and methods and evaluating analytics and/or models\n",
      "\n",
      "- advising clients on the effectiveness of specific techniques based on project findings and comprehensive research\n",
      "\n",
      "- when required, working alongside engineers to implement data pipeline to provide data solution to clients’ problem\n",
      "\n",
      "- programming language for data science: python\n",
      "\n",
      "- cloud environment: aws, microsoft azure, google cloud platform\n",
      "\n",
      "\n",
      "\n",
      "- have strong experience/knowledge related to analysis/computer vision/other ml/ai fields\n",
      "\n",
      "- have good problem-solving skills\n",
      "\n",
      "- have hands on experience in industries as data scientist and/or r&d researcher\n",
      "\n",
      "- be proficient in at least one programming language, preferably python.\n",
      "\n",
      "- have experience/knowledge of working on the cloud (aws or azure or gcp etc)\n",
      "\n",
      "- have experiences/knowledge of databases\n",
      "\n",
      "- have experiences/knowledge of dnn, machine learning\n",
      "\n",
      "- have sufficient background in mathematics, statistics\n",
      "\n",
      "- have experience working on ai related projects\n",
      "\n",
      "- (senior) have deep understanding of a knowledge domain / industry vertical\n",
      "\n",
      "- (senior) must have experiences with leading projects and teams\n",
      "\n",
      "- be fluent in english\n",
      "\n",
      "- have a great ambition and ability to study the most leading-edge research by yourself and apply them to your own development.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "================================================\n",
      "data-02-06/1984/data.html\n",
      "responsibilities:\n",
      "\n",
      "\n",
      " identify and understand the business requirements at hand.\n",
      "                            \n",
      "\n",
      " research and experiment with multiple machine learning algorithms from various sources to determine the best solution that satisfies the requirement.\n",
      "                            \n",
      "\n",
      " clean and transform data, ensure that data is well-organized and ready for the ai model to interpret and process.\n",
      "                            \n",
      "\n",
      " designing, planning, developing, implementing, and maintaining artificial intelligence, deep learning, and machine learning against business requirements.\n",
      "                            \n",
      "\n",
      " innovate product areas with the power of ai to drive business results.\n",
      "                            \n",
      "\n",
      " perform iterative testing and experiment improvement to get the state of art results.\n",
      "                            \n",
      "\n",
      " improve the ai model until it is ready for the production environment.\n",
      "                            \n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1523/data.html\n",
      "description\n",
      " \n",
      "\n",
      "design, develop, and maintain integrations + products with llms and other ai products, including simple uis when and as necessary.\n",
      "prototype and iterate on llm/ai experiments, including fine-tuning of models and utilizing the latest in ai tool development.\n",
      "collaborate closely with team members on real-world implementation, tests, and usage of llm products.\n",
      "stay at the forefront of advancements in llms, nlp, ml, and ai technology, keeping the team ahead in product awareness + integration.\n",
      "\n",
      " \n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1985/data.html\n",
      "responsibilities:\n",
      "\n",
      "\n",
      " develop data architecture and modeling to ensure that the data architecture and model are optimized and aligned closely with business goals.\n",
      "                            \n",
      "\n",
      " design and build cubes in sql server analysis services.\n",
      "                            \n",
      "\n",
      " monitor, maintain, and enhance the data warehouse along with business intelligence systems performance, availability, and integrity.\n",
      "                            \n",
      "\n",
      " provide corrective and preventive maintenance as required.\n",
      "                            \n",
      "\n",
      " develop and implement etl (extract, transform, load) routines according to the data warehouse design and architecture in sql server.\n",
      "                            \n",
      "\n",
      " collect and harmonize data from different sources and reporting results based on end-user requirements.\n",
      "                            \n",
      "\n",
      " troubleshoot data warehouse issues including hardware and software.\n",
      "                            \n",
      "\n",
      " investigate and resolve data loading and data integrity issues to ensure data accuracy, permissions, and security configurations.\n",
      "                            \n",
      "\n",
      " maintain relationships with users to identify and develop additional data sources for the data warehouse to keep it consistent with business rules and customer needs.\n",
      "                            \n",
      "\n",
      " participate as a team member in data warehouse projects.\n",
      "                            \n",
      "\n",
      " perform other duties and responsibilities as assigned by cto or director/unit head.\n",
      "                            \n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3137/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi tiết công việc fresh speed up 2023 - program for fresher - supply chain tại b. braun vietna\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1558/data.html\n",
      "responsibilities\n",
      "\n",
      "gathers operational data from various cross functional stakeholders to examine past business performance\n",
      "identifies data patterns & trends, and provide insights to enhance business decision making capability in business planning, process improvement, solution assessment, etc.\n",
      "recommends actions for future developments & strategic business opportunities, as well as enhancement to operational policies\n",
      "may be involved in exploratory data analysis, confirmatory data analysis and/or qualitative analysis\n",
      "translate data into consumer or customer behavioral insights to drive tarting and segmentation strategies, and communicate clearly and effective to business partners and senior leads all findings\n",
      "continuously improve processes and strategies by exploring and evaluating new data sources, tools and capabilities\n",
      "work closely with internal and external business partners in building, implementing, tracking and improving decision strategies\n",
      "appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm’s reputation, its clients and assets, by driving compliance and applicable laws, rules and regulations, adhering to policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency\n",
      "responsible for routine mis reports to be delivered timely and accurately\n",
      "optimize mis reports to reduce the team workload and bring better insights to business\n",
      "\n",
      " \n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2516/data.html\n",
      "================================================\n",
      "data-02-06/2614/data.html\n",
      "description: \n",
      "        \n",
      "\n",
      " \n",
      "job description:\n",
      "\n",
      "in charge to monitor and control bounce rate of predue and no-touching customer segment via monitoring bounce rate closely (via reports) and predue performance hence having proper action plans to improve bounce rate.\n",
      "build up and monitor the communication plan with customers via communication channels such as email, zns, sms, …\n",
      "work with related divisions to deploy bounce rate improvement plans which are approved by management.\n",
      "build up strategy, plan for predue team to lead team reach target\n",
      "build up training plan about related knowledge, soft skills and contact with relevant teams such as hr training to deploy training plan to predue staff regularly.\n",
      "regularly review predue team’s process with predue team leader to simplify workflow and improve effectiveness of team\n",
      "guide and support team leader of predue team to manage team and reach target.\n",
      "control and saving expense (telephone cost) by looking for new communication channels.\n",
      "other assigned tasks from dept head.\n",
      "\n",
      " \n",
      "\n",
      "-----------------------------------------------\n",
      "job requirements:\n",
      "\n",
      "================================================\n",
      "data-02-06/1776/data.html\n",
      "mô tả công việc\n",
      " \n",
      "onboarding new clients for the non-custodial service\n",
      "verifying, reconciling, and importing of historical asset data into client portfolios\n",
      "valuation and pricing of non-custodial assets\n",
      "daily bank reconciliation for non-custodial assets\n",
      "completion of applications, redemption, and other instructions for fund managers\n",
      "executing and reviewing monthly fee process\n",
      "reconciling and processing income tax component adjustments\n",
      "preparation and auditing of annual tax reports in respect of non-custodial assets\n",
      "establishing and refining operating procedures\n",
      "user acceptance testing for system upgrades and other features and defects\n",
      "managing the day-to-day tasks and performance of the vietnam based team members\n",
      "contributing to process improvements (for both procedures and systems) in relation to the non-custodial assets\n",
      " \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3129/data.html\n",
      "description\n",
      "\n",
      "<job responsibilities>sales planning:-to follow psi planning (production – sales – inventory).-to follow up and manage monthly sales forecasts and yearly targets as company goals.-to work closely with local/regional factories and head/regional quarters for order and supply.-to receive product requirements and make quotations for customers.data analysis:- collecting and cleaning raw material data for manipulation.- key features include sale analysis by products, time period, and regions, comparing to selling products, predicting sale trends, and tracking kpis.- developing sale report for analyzing monthly sales performance of indoor air quality product categories (more than 20+ product lines and 1000+ item codes).- developed interactive reports and dashboards using advanced queries.marketing research:- market retail audit: annually conduct research with the agency to measure market movement.- market visualization research: visualizing the region's character nationwide by conducting desk research for secondary data, and qualitative/quantitative research for primary data.- using strategic models (4ps, 3cs, bcg, stp …) for getting business insight in order to help strategy decisions of annual business plan and mid-term plan.- others ad-hoc research is required.marketing:-to execute marketing plan for products being in charge.-to implement digital marketing campaigns-to organize events, seminars, exhibitions, factory tours, dealer conventions…-to produce and manage posm.administration:-to transact, negotiate, and execute contracts/payments with domain/suppliers.-prepare all payment documents for the agency and debit notes for area headquarter.-prepare material for monthly reports.-other tasks are assigned by management<necessary skill / \n",
      "-----------------------------------------------\n",
      "experience >• language skills: english - intermediate level (good english communication both verbal and written.)• educational background: bachelor degree in marketing, business, or related.• experience: - at least 2 years experience in marketing position, strong experience in market research, data analysis- experience in power bi and dax queries is plus.- knowledge of marketing principal and digital marketing.＜preferable experience＞- experience in electrical products will be plus                                    \n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2154/data.html\n",
      "================================================\n",
      "data-02-06/2155/data.html\n",
      "================================================\n",
      "data-02-06/2445/data.html\n",
      "================================================\n",
      "data-02-06/2724/data.html\n",
      "mô tả công việc\n",
      "designing and developing machine learning and deep learning systems\n",
      "running machine learning tests and experiments\n",
      "implementing appropriate ml algorithms\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "proven experience as a machine learning engineer or similar role\n",
      "understanding of data structures, data modeling and software architecture\n",
      "deep knowledge of math, probability, statistics and algorithms\n",
      "ability to write robust code in python, java and r\n",
      "familiarity with machine learning frameworks (like keras or pytorch) and libraries (like scikit-learn)\n",
      "excellent communication skillsability to work in a team\n",
      "outstanding analytical and problem-solving skills\n",
      "bsc in computer science, mathematics or similar field; master’s degree is a plus\n",
      "quyền lợi\n",
      "● package: 13, 14 salary month + project bonus ● extra package: 16 mil /employee/year (bonus at: tet, new year, your birthday, cmc corp’s birthday, 2/9 and tet’s gift, middle-autumn gift, …) ● salary review 2 times/year or on excellent performance. ● opportunity to approach newest technology trends; development of your career within an international company ● building large-scale & global software products for our clients. ● onsite opportunities: short-term and long-term assignments in us, europe, asia. ● paid annual leave: 12 days ● company’s labor policy completely pursuant to vietnamese labor legislation plus other benefits offered by the company (pti care premium, company trip, holiday, sum-up, etc) ● exciting leisure: sport and art events (football club, family day, happy hour,…) ● working time: 8h/day (from monday to friday) , flexible working time (check in: 7h30-9h00 ; check out: 16h30-18h00\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 17/06/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2239/data.html\n",
      "responsibilities\n",
      "about us\n",
      "we are building the future of real estate data, and we need your help! we are seeking \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1714/data.html\n",
      "descriptionthe bosch group is a leading global supplier of technology and services. it employs roughly 394,500 associates worldwide (as of december 31, 2020). according to preliminary figures, the company generated sales of 71.6 billion euros in 2020. its operations are divided into four business sectors: mobility solutions, industrial technology, consumer goods, and energy and building technology.the bosch group comprises robert bosch gmbh and its roughly 440 subsidiaries and regional companies in some 60 countries. if its sales and service partners are included, then bosch is represented in roughly 126 locations. this worldwide development, manufacturing, and sales network is the foundation for further growth.rbvh - robert bosch engineering and business solutions vietnam company limited is 100% owned subsidiary of robert bosch gmbh. rbvh has started its operations from 19th october, 2010 at e-town2 in hcmc. this engineering development center will be engaged in developing embedded systems and software, mechanical design and simulation, and will provide it (sap consulting, java development….) and business services (finance and accounting, economics, purchasing, logistics, translations japanese-english-japanese, information security ) solutions to the bosch group of companies globally. job descriptiondesigning and coding hadoop applications to analyze data collections.creating data processing frameworks.extracting data and isolating data clusters.testing scripts and analyzing results.troubleshooting application bugs.maintaining the data security.producing hadoop development documentation.qualificationsbachelor degree in it/ computer science or relevant backgroundhave at least 4 years of \n",
      "-----------------------------------------------\n",
      "experience in the relevant technologiesexperience in the hadoop ecosystem and its components: hdfs, yarn, mapreduce, apache spark (python/scala), apache sqoop, apache impala, apache avro, apache flume, apache kafkapreferred: having certificate cca175 – spark and hadoop developerdesigned and developed etl processexperienced in unix with scripting experience is preferredshould have strong knowledge on concepts of data warehousing models, data ingestion patterns, data quality and data governanceexperience on the hadoop systems with good understanding and knowledge of hadoop clustergood at english communication skillsadditional information\n",
      "================================================\n",
      "data-02-06/2075/data.html\n",
      "description\n",
      "\n",
      "\n",
      "study and examine the client‘s documents in english (business contracts, service agreements, price change forms, email agreements, financial terms...)\n",
      "based on pre-defined rules, process and capture the client’s documents into structured data using our tools and templates\n",
      "explore and understand client’s transactional data (accounts payable, invoice details, purchase orders, goods received, sales to customers…)\n",
      "compare the transactional data with the client’s documents to check and verify if all transactions are compliant\n",
      "identify any transactions that are non-compliant and provide the root causes alongside detailed reporting & calculations\n",
      "contact and discuss your non-compliance findings with the project team or customers by e-mails, im... and use our tools and available data/documents to resolve the non-compliance and attempt for reconciliation and recovery of any monies which may be outstanding\n",
      "handle various data integrity checks on client’s transactional data to ensure consistency and accuracy\n",
      "other assignments by line manager\n",
      "\n",
      "requirements\n",
      "\n",
      "university degree in related fields (information systems, finance, accounting, economics, business...)\n",
      "at least 1-year \n",
      "-----------------------------------------------\n",
      "experience in data analytics, cost/pricing/promotional analysis, accounts payable review, retail buying/procurement, internal auditing, freight/logistics/supply chain, business intelligence….\n",
      "working time: monday- friday, 08:00 – 17:00\n",
      "================================================\n",
      "data-02-06/1946/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "trách nhiệm\n",
      "\n",
      "phân tích các chỉ số kinh doanh & lập báo cáo nhằm đánh giá hiệu quả về tình hình hoạt động kinh doanh hiện tại của các hệ thống nhà hàng;\n",
      "phân tích, đánh giá, so sánh & đối chiếu tình hình, kết quả hoạt động kinh doanh cùng với thị trường hiện tại so với xu hướng thực tế để có thể nhận định những cơ hội tiềm năng và dự báo rủi ro;\n",
      "thiết lập các template báo cáo phù hợp với từng mô hình kinh doanh, từng tình huống cụ thể cần đánh giá & so sánh;\n",
      "phụ trách tổng hợp dữ liệu, phân tích chi phí đầu tư & nhượng quyền của một số thương hiệu. lập các mô hình phân tích đa dạng để tư vấn phương án tối ưu chi phí;\n",
      "phối hợp cùng team marketing và khối vận hành (ban quản lý nhà hàng) để phân tích hiệu quả kinh tế của các chương trình khuyến mãi và đưa ra các so sánh, khuyến nghị để mỗi thương hiệu có thể căn cứ để lựa chọn chương trình phù hợp;\n",
      "nhận order từ các phòng ban liên quan như kế toán, marketing, vận hành - ban quản lý nhà hàng, .... để triển khai thực hiện các phân tích, đánh giá và báo cáo tình hình, hiệu quả hoạt động. từ đó đưa ra các phương án, các yêu cầu để khắc phục hậu quả hoặc gia tăng hiệu quả & tận dụng các cơ hội tiềm năng;\n",
      "lập các báo cáo, phân tích các chỉ số cần thiết khác theo yêu cầu của trưởng bộ phận;\n",
      "phụ trách các công việc khác theo sự phân công của quản lý trực tiếp.\n",
      "\n",
      "yêu cầu\n",
      "\n",
      "tốt nghiệp đại học chuyên ngành kế toán / kiểm toán / tài chính hoặc các chuyên ngành liên quan;\n",
      "có \n",
      "-----------------------------------------------\n",
      "kinh nghiệm khoảng 03 năm trở lên về chuyên môn phân tích tài chính doanh nghiệp / phân tích kết quả hoạt động kinh doanh, ....;\n",
      "ưu tiên ứng viên có kinh nghiệm làm việc trong mô hình chuỗi nhà hàng f&b, chuỗi cửa hàng bán lẻ retails, fmcg, …;\n",
      "kỹ năng tổng hợp & phân tích dữ liệu tốt. thành thạo excel và các công cụ tổng, phân tích và trình bày dữ liệu như power bi - sql, power query, data studio, …ưu tiên ứng viên có kinh nghiệm làm việc với hệ thống sap / bravo / oracle;\n",
      "có kỹ năng thực hiện phân tích và tổ chức các báo cáo về tài chính, kết quả hoạt động kinh doanh chính xác và có thể đưa ra các nhìn nhận, đánh giá và góp ý hiệu quả;\n",
      "tính cách trung thực, ý thức bảo mật thông tin số liệu tốt;\n",
      "tư duy tốt về kinh doanh và nắm bắt tốt xu hướng kinh doanh của ngành/ thị trường;\n",
      "thái độ tích cực và có tinh thần đồng đội tốt. tinh thần trách nhiệm cao và chịu được áp lực công việc.\n",
      "\n",
      "phúc lợi\n",
      "\n",
      "địa điểm làm việc: lầu 7 - gigamall phạm văn đồng, 242 phạm văn đồng, hiệp bình chánh, thủ đức, tp hồ chí minh\n",
      "lương thỏa thuận theo năng lực;\n",
      "thời gian làm việc: thứ 2 - thứ 6, 8h30 - 17h30;\n",
      "công ty cung cấp đầy đủ trang thiết bị làm việc cần thiết như desktop / laptop;\n",
      "đảm bảo đầy đủ chế độ phúc lợi theo quy định của luật như: đóng bảo hiểm full 100% lương, bảo hiểm tai nạn 24/7, ... ngoài ra còn có gói bảo hiểm sức khỏe cá nhân (đối với các vị trí từ level supervisor trở lên);\n",
      "lương tháng 13 + thưởng theo kết quả hoạt động kinh doanh;\n",
      "giảm giá trên tổng hóa đơn khi dùng bữa tại các nhà hàng thuộc hệ thống của golden gate;\n",
      "môi trường trẻ trung, năng động. nhiều cơ hội phát triển;\n",
      "công ty thường xuyên có các hoạt động: du lịch hằng năm, team building, tiệc cuối năm.\n",
      "\n",
      "================================================\n",
      "data-02-06/2085/data.html\n",
      "================================================\n",
      "data-02-06/2791/data.html\n",
      "description\n",
      "\n",
      "are you seeking a professional and dynamic work environment that values collaboration and encourages individual growth?join our team of talented and passionate individuals who embody a youthful spirit and a commitment to excellence. apply now and unlock your potential with us!position: data analyst/ data analyst - team leaderwho we are:innovature bpo provides business and technology outsourcing services to clients in north america and asian markets. we enable clients to become high-performance businesses and create long-term relationships by helping drive productivity and efficiency while delivering measurable results. our commitment is to attract, develop and retain the best talents for our business, challenge our people, demonstrate “can-do” attitude and foster a collaborative and mutually supportive environment.for more information about us, please access what you will be doing:\n",
      "design, create and maintain tableau dashboards;\n",
      "conduct and create data analysis using excel, sql and tableau;\n",
      "work closely with data engineers to design data models, maintain and validate data in data warehouse;\n",
      "conduct ad hoc industry research;\n",
      "create and update slides used in client meetings, business reviews, etc.;\n",
      "proactively communicate and collaborate with external and internal stakeholders to analyze information needs and functional requirements.\n",
      "what we offer: we treat people fairly and with dignity, keeping a healthy perspective about life and work and fostering a positive and enjoyable work environment with appealing benefits as below:\n",
      "a competitive monthly salary based on your ability\n",
      "13th month tet bonus & bi-annual performance bonus\n",
      "annual salary review\n",
      "attractive employee awards: employee of year, semi-annual outstanding employee\n",
      "social insurance and healthcare insurance upon vietnam labor code\n",
      "pvi insurance package, and annual health check\n",
      "an english-speaking environment\n",
      "an open culture that spurs creativity, innovation, and inclusivity\n",
      "a variety of training courses for your career development\n",
      "diverse activities to foster relationships, including company trips, year-end party, employees’ birthdays\n",
      "an open-space office, a cafeteria, and a range of modern equipment\n",
      "other allowance from referrals and special occasions (weddings, seniority, and new-born baby)\n",
      "work location: 9th floor, ree tower, 9 doan van bo, ward 13, district 4, hcmcworking hoursmon – fri: 3pm – 6pm (office) & 9pm – 2am(wfh)\n",
      "\n",
      "your skills and \n",
      "-----------------------------------------------\n",
      "experience\n",
      "\n",
      "what we are looking for:\n",
      "bachelor’s degree in mis, information technology, computer science, or other quantitative major. an understanding of basic accounting/finance is a plus;\n",
      "significant data management and analysis experience;\n",
      "strong knowledge of tableau and able to develop insightful dashboards and reports that drive business decision making and outcomes;\n",
      "intermediate to advanced database and transact sql skills;\n",
      "intermediate powerpoint;\n",
      "experience in python, c#, vba, and ssis packages is a plus;\n",
      "understand data models, database design development, data mining and segmentation techniques.\n",
      "work behavior\n",
      "ability to lead, plan and manage in an entrepreneurial, team-oriented environment;\n",
      "highly organized with strong project management skills, and drive to meet organizational objectives; ability to manage multiple projects on interrelated timelines;\n",
      "strong written and verbal communication skills;\n",
      "demonstrate experience in getting things done in dynamic, entrepreneurial environment;\n",
      "demonstrate a high attention-to-detail in the analysis and reporting of data.\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "we treat people fairly and with dignity, keeping a healthy perspective about life and work and fostering a positive and enjoyable work environment with appealing benefits as below:\n",
      "a competitive monthly salary based on your ability\n",
      "13th month tet bonus & bi-annual performance bonus\n",
      "annual salary review\n",
      "attractive employee awards: employee of year, semi-annual outstanding employee\n",
      "social insurance and healthcare insurance upon vietnam labor code\n",
      "pvi insurance package, and annual health check\n",
      "an english-speaking environment\n",
      "an open culture that spurs creativity, innovation, and inclusivity\n",
      "a variety of training courses for your career development\n",
      "diverse activities to foster relationships, including company trips, year-end party, employees’ birthdays\n",
      "an open-space office, a cafeteria, and a range of modern equipment\n",
      "other allowance from referrals and special occasions (weddings, seniority, and new-born baby)\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/1336/data.html\n",
      "description• to be responsible for delivering accurate, timely and relevant management reports with analysis in business unit performance.• to perform pdca related to management accounting area.• to be responsible for controlling & decision support of category p&l lines, business kpis. • to coordinate with business partner and headquarter for corporate planning and monitoring to ensure the achievement of financial objectives. • to ensure appropriate financial support related in an effective, timely and professional manner to meet business targets. \n",
      "-----------------------------------------------\n",
      "job requirement• bachelor’s degree or higher in accounting or finance.• at least 03 years of experience at the same position in fmcg/ mnc/ manufacturing companies.• knowledge of accepted local accounting practices and principles.• knowledge of applicable laws, codes and regulations.• attention to detail and accuracy, adaptive to change.• strong data analysis skills (ms power bi, sql, etc.) is a plus.• strong communication, teamwork skills, planning and organizing skills.• good judgment and problem solving skills.\n",
      "================================================\n",
      "data-02-06/223/data.html\n",
      "================================================\n",
      "data-02-06/807/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "làm việc với các phòng ban liên quan để hoàn thiện các nghiệp vụ phân tích kinh doanh cụ thể cho từng dự án\n",
      "đóng vai trò đầu mối trong việc đề xuất các yêu cầu về dữ liệu cần thiết để phục vụ cho việc nghiệp vụ phân tích\n",
      "đánh giá các vấn đề, điểm cần cải thiện và đề xuất dựa trên kết quả phân tích\n",
      "xây dựng các báo cáo quản trị, báo cáo kinh doanh phục vụ cho việc quản trị hiệu quả cho chủ dự án và các phòng ban liên quan\n",
      "theo dõi hiệu suất hệ thống và xem xét, đề xuất, áp dụng các công cụ mới\n",
      "giám sát quá trình phát triển và đảm bảo tuân thủ lịch trình và khung thời gian.\n",
      "phối hợp cùng bộ phận tài chính để đưa ra các dự báo tác động dựa trên các hành động tác động.\n",
      "xác định chính sách giá phí và hiệu quả tài chính của các chính sách giá phí đó.\n",
      "tuân thủ các tiêu chuẩn tuân thủ hiện hành.\n",
      "tuân thủ các tiêu chuẩn dịch vụ về hiệu suất.\n",
      "thực hiện các nhiệm vụ khác theo sự phân công.\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "đam mê các lĩnh vực mô hình tài chính, quản trị hiệu quả tài chính, phân tích kinh doanh\n",
      "có kiến thức về phương pháp luận phân tích dữ liệu toán thống kê và phân tích định lượng.\n",
      "có kiến thức chung về hoạt động quản trị kinh doanh, mô hình kinh doanh\n",
      "có am hiểu chuyên sâu về mô hình giá/phí của các sản phẩm trong dịch vụ ngân hàng.\n",
      "kỹ năng phân tích, kỹ năng lập kế hoạch, thống kê tổng hợp số liệu, tư duy kinh doanh\n",
      "có khả năng diễn giải dữ liệu, kết quả, báo cáo phân tích bằng ngôn ngữ kinh doanh\n",
      "có kỹ năng làm việc và giao tiếp với các bên liên quan, có tư duy logic, kỹ năng giải quyết vấn đề\n",
      "có khả năng tự định hướng và tính tự tổ chức cao\n",
      "khả năng giao tiếp và hoạt động chuyên nghiệp với tất cả các cấp nhân sự và các phòng ban khác trong toàn tổ chức.\n",
      "quen thuộc với nhiều khái niệm, thực hành của lĩnh vực này.\n",
      "tư duy phản biện: có thể xử lý dữ liệu theo cách để đưa ra các đề xuất cần có tư duy phản biện.\n",
      "tốt nghiệp đại học trở lên với chuyên ngành tập trung vào tài chính, ngân hàng, quản trị kinh doanh,\n",
      "8 năm kinh nghiệm chuyên môn trong lĩnh vực tài chính/ngân hàng\n",
      "kinh nghiệm phân tích kinh doanh tối thiểu 5 năm.\n",
      "có kinh nghiệm liên quan đến xây dựng và quản trị mô hình tài chính\n",
      "thành thạo power bi, excel, spss, python…\n",
      "\n",
      "================================================\n",
      "data-02-06/1609/data.html\n",
      "================================================\n",
      "data-02-06/1288/data.html\n",
      "description\n",
      "\n",
      "\n",
      "•\tbe the expert in using data to measure and analyze business performance in each our markets and lines of business•\tmonitor key metrics and alert the business on potential issues•\tdesign market/business intelligence reports and performance measurement dashboards to share with senior management•\tdevelop and automate reports, interactively build and prototype dashboards to provide insights at scale, solving for analytical needs•\tcollaborate with cross-functional stakeholders to understand their business needs, formulate and complete end-to-end analysis that includes data gathering, analysis, ongoing scaled deliverable and presentations•\tperform ad-hoc analysis to drill down into certain business challenges, providing conclusions and advice based on data analysis•\tsupport projects on data projection, data analysis, performance tracking, and to summarize data analysis requirements•\tsupport to colleagues for understanding data insights and handling basic data analysis skills\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "job requirements\n",
      "\n",
      "\n",
      "•\t3+ yoe in analytics, project management, strategy and/or tech consulting, or other related fields. experience in e-commerce is a plus.•\tsharp critical thinking, strong analytical and numerical skills. good communication skills•\teager to work in a fast-paced and ambiguous environment•\tsolid knowlegde of sql and other programming language. hands-on experience in data extraction, cleaning, preparation, and dashboard development•\thighly energetic and self-motivated. willingness to learn attitude with ability to work under pressure•\tbachelor’s or master's degree in relevant field of study.\n",
      "\n",
      "================================================\n",
      "data-02-06/2796/data.html\n",
      "description\n",
      "\n",
      "\n",
      "as a powerapps developer intern, you will have the opportunity to gain hands-on \n",
      "-----------------------------------------------\n",
      "experience and contribute to the development of business applications using microsoft powerapps. you will work closely with the development team and under the guidance of experienced professionals to learn and apply powerapps development techniques, best practices, and design principles. this internship will provide you with valuable exposure to low-code development, business process automation, and the power platform.\n",
      "responsibilities:\n",
      "\n",
      " application development: collaborate with the development team to design and develop powerapps solutions, including canvas apps and model-driven apps, following established development practices and guidelines.\n",
      " requirement understanding: assist in gathering and documenting business requirements by engaging with stakeholders and end users to ensure clear understanding of application needs.\n",
      " user interface design: contribute to the creation of user-friendly and visually appealing user interfaces, considering usability and accessibility standards.\n",
      " data integration: assist in integrating powerapps with various data sources, such as sharepoint, sql databases, excel, and external apis, under the guidance of senior developers.\n",
      " testing and quality assurance: support the testing efforts by conducting functional testing, identifying bugs or issues, and participating in debugging and troubleshooting activities.\n",
      " documentation and reporting: contribute to the documentation of technical specifications, user guides, and other relevant materials to ensure knowledge sharing and support future maintenance.\n",
      " learning and skill development: actively participate in training sessions, workshops, and knowledge-sharing activities to enhance your powerapps development skills and stay up-to-date with industry trends.\n",
      " collaboration and communication: collaborate with team members, actively participate in meetings, and communicate progress, challenges, and ideas effectively.\n",
      "\n",
      "requirements:\n",
      "education/knowledge:\n",
      "\n",
      " education: currently pursuing a degree in computer science, information technology, or a related field. familiarity with low-code development platforms and a strong interest in business process automation is preferred.\n",
      " technical skills: basic understanding of microsoft powerapps, power platform, or related technologies.\n",
      "\n",
      "personalities/skills:\n",
      "\n",
      "have a good analytical thinking.\n",
      "have the ability to work well independently and in teams.\n",
      "good in communication skills.\n",
      "strong ability to manage time.\n",
      "================================================\n",
      "data-02-06/2627/data.html\n",
      "================================================\n",
      "data-02-06/2974/data.html\n",
      "================================================\n",
      "data-02-06/2749/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            i. data analyst\n",
      ". tiến hành phân tích sâu về trải nghiệm/hành vi của khách hàng nhằm hỗ trợ cá nhân hóa & các sản phẩm dữ liệu khác.\n",
      "· sở hữu thiết kế, phát triển và duy trì các số liệu, báo cáo, phân tích, bảng điều khiển đang diễn ra, v.v. để thúc đẩy các quyết định kinh doanh quan trọng.\n",
      "· hiểu các sản phẩm và dịch vụ cloud (google analytics, saleforces, v.v.) để theo dõi/báo cáo hiệu suất kinh doanh và các vấn đề bằng cách sử dụng các số liệu phù hợp. \n",
      "\n",
      "ii. kỹ sư lập trình\n",
      ". phát triển và vận hành các giải pháp ứng dụng nội bộ (website/mobile) cho vinpearl và các công ty thành viên trong tập đoàn: phần mềm quản lý mua hàng, nhâp kho kiểm kê, phần mềm chấm công bằng khuôn, quản lý hành lý, quản lý động vật...\n",
      ". hỗ trợ người dùng các hệ thống phần mềm nghiệp vụ\n",
      ". phối hợp với các đơn vị hoặc các công ty trong tập đoàn để xử lý khi có sự cố.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2267/data.html\n",
      "description\n",
      "\n",
      "\n",
      "develop, update and maintain complex reporting systems focusing on real-time data analyzing and data forecasting.\n",
      "quickly respond to, investigate, and resolve any working bottleneck.\n",
      "persistently work and seek innovative ways to troubleshoot performance issues and improve the team’s work efficiency and quality.\n",
      "research, identify and evaluate new technologies for implementation.\n",
      "\n",
      "\n",
      "your skills and \n",
      "-----------------------------------------------\n",
      "experience\n",
      "\n",
      "\n",
      "experience in relational database design and implementation (ms sql is a plus).\n",
      "basic knowledge of transaction locking, sql server broker.\n",
      "strong analytical skills and be able to show initiative and take a proactive approach to your work.\n",
      "good english skills.\n",
      "years of experience: 03\n",
      "prefer candidates who have a passion for long-term engagement.\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "\n",
      "attractive salary plus 13th-month salary.\n",
      "high bonus and incentive-based on performance, seniority.\n",
      "work in a dynamic environment alongside team members who are talented and passionate about what they do.\n",
      "in-house health club: gym, swimming pool, soccer field, volleyball court, and entertainment area.\n",
      "annual health check.\n",
      "personal accident & health insurance.\n",
      "social – health – insurance paid fully.\n",
      "team building events are fully sponsored by the company.\n",
      "complimentary duty meals, snacks & beverages.\n",
      "outstanding annual company trip.\n",
      "long-term service award.\n",
      "quarterly and yearly incentive awards for best-performing employees.\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2621/data.html\n",
      "================================================\n",
      "data-02-06/1289/data.html\n",
      "mô tả công việc:\n",
      "- phân tích các sản phẩm bảo hiểm nhân thọ và hệ thống đại lý;\n",
      "- định phí và phân tích sản phẩm;\n",
      "- thu thập và phân tích dữ liệu theo yêu cầu của các cấp quản lý;\n",
      "- dịch và gửi các văn bản về sản phẩm mới cho bộ tài chính phê duyệt;\n",
      "- các công việc khác theo yêu cầu của trưởng bộ phận.\n",
      " \n",
      "2. \n",
      "-----------------------------------------------\n",
      "yêu cầu công việc:\n",
      "- tốt nghiệp đại học trở lên về các chuyên ngành: bảo hiểm, toán học, kinh tế, quản trị hoặc các chuyên ngành liên quan;\n",
      "- ít nhất 03 năm kinh nghiệm làm việc ở vị trí tương đương tại các công ty bảo hiểm nhân thọ;\n",
      "- ưu tiên các ứng viên đã thi soa;\n",
      "- tiếng anh tốt 4 kỹ năng;\n",
      "- thời gian làm việc: thứ 2 - thứ 6 từ 08:30 - 17:30\n",
      "- địa điểm làm việc: \n",
      "================================================\n",
      "data-02-06/795/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description \n",
      "\n",
      "objective\n",
      "– to establish a center of excellence for bi & analytics to support the business in making better decisions, including but not limited to the areas of customer selection criteria, product pricing, employee profiling and profitability drivens apart from producing high quality, sophisticated management information reports required & helpful in governing & growing the business.\n",
      "– to establish the infrastructure including dwh & bi tools , build a large team of capable staff through recruitment, training & retention & implement the reports & models necessary for delivering the objective.\n",
      "regular activities\n",
      "– implement data governance mechanism including processes, policies, roles & responsibilities.\n",
      "– establish & maintain data warehouse & data marks with glossary & data models as well as etl tools to implement a federated bi structure.\n",
      "– implement & maintain a reporting system for primary & core management reports as well as ad hoc requests.\n",
      "– assume key responsibilities for ensuring data quality.\n",
      "– develop models for customer segmentation, models including cross sales campaigns, process optimization, revenue & loss forecasting, staff profiling, unit costing, product & segment profitability models, capacity planning & others.\n",
      "– participate in development, maintenance & validation of credit & collection scorecards.\n",
      "– implement risk reporting & monitoring platform for credit & non-credit risk.\n",
      "– facilitate design & development of academic curriculum in the area of bi & analytics.\n",
      "– compare & develop bicc as per cutting-edge & gold standards internationally to make a best-in-class coe\n",
      "\n",
      "\n",
      "required skills\n",
      "\n",
      "at least 10 years’ \n",
      "-----------------------------------------------\n",
      "experience of progressively responsible experience in a directly related area, during which both professional and management capabilities have been clearly demonstrated (managed at least 15 people).\n",
      "- statistics\n",
      "- sas knowledge\n",
      "- financial services experience \n",
      "\n",
      "================================================\n",
      "data-02-06/775/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thông tin liên hệ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "phạm vi công việc: đảm bảo công việc nghiên cứu được giao hoàn thành một cách chuyên nghiệp, bao gồm thu thập dữ liệu, hỗ trợ thực hiện nghiên cứu thị trường, cung cấp thông tin cho báo cáo khảo sát thị trường và cập nhật báo cáo thị trường hằng quý.\n",
      "\n",
      "\n",
      "nhiệm vụ\n",
      "nghiên cứu\n",
      "\n",
      "thu thập dữ liệu và cập nhật thông tin hàng quý về tình hình bất động sản\n",
      "hỗ trợ lập kế hoạch ,thực hiện nghiên cứu thị trường và tư vấn dịch vụ\n",
      "xử lý dữ liệu và cập nhật thông tin vào báo cáo tình hình thị trường bất động sản\n",
      "hỗ trợ trong việc duy trì, cập nhật và mở rộng cơ sở dữ liệu về tình hình bất động sản việt nam, trong khu vực và tình hình kinh tế\n",
      "hỗ trợ trong việc duy trì quan hệ tốt với khách hàng\n",
      "hỗ trợ việc chuẩn bị tài liệu thuyết trình,chuẩn bị các bản tin trong văn phòng và chuẩn bị các bản thông cáo báo chí\n",
      "hỗ trợ trong việc duy trì thông tin với các phòng ban khác\n",
      "cung cấp kịp thời các thông tin có liên quan đến các phòng ban khác\n",
      "dịch tài liệu theo yêu cầu\n",
      "\n",
      "phối hợp\n",
      "\n",
      "phối hợp công việc theo nhóm\n",
      "liên lạc với người quản lý và khách hàng để đảm bảo công việc được cung cấp một cách kịp thời\n",
      "có mối quan hệ tốt với các phòng ban khác để cập nhât thông tin thị trường kịp thời\n",
      "phối hợp và chia sẻ thông tin với các phòng ban khác\n",
      "hỗ trợ cấp dưới hoàn thành mục tiêu công việc chung\n",
      "\n",
      "kỹ năng và năng lực thiết yếu\n",
      "kỹ năng kinh doanh\n",
      "\n",
      "thu thập thông tin quan trọng từ các nguồn chính để hỗ trợ giải quyết vấn đề\n",
      "kỹ năng tổ chức – tìm kiếm được nguồn lực để vận hành công việc theo các tiêu chuẩn, yêu cầu, bản danh sách và khung thời gian\n",
      "tuân thủ nội quy – tuân thủ các chính sách và thủ tục của công ty\n",
      "hiểu biết về luật đất đai và các vấn đề pháp lý tại việt nam\n",
      "hiểu biết về thị trường bđs tại việt nam và các nguyên tắc hoạt động trong thị trường bđs\n",
      "kiến thức về nghiên cứu thị trường, cơ sở hạ tầng và thiết kế xây dựng\n",
      "\n",
      "kỹ năng chung\n",
      "\n",
      "tuân thủ các tiêu chuẩn – hướng đến sự hoàn chỉnh, xuất sắc\n",
      "giao tiếp bằng văn bản – viết rõ ràng và súc tích, sử dụng ngôn ngữ thích hợp, kiểm tra tài liệu, phát hiện và chỉnh sửa các lỗi, tính mạch lạc của văn bản\n",
      "làm việc nhóm – thúc đẩy sự hợp tác, chia sẻ ý tưởng và thông tin\n",
      "giải quyết vấn đề - nhận ra vấn đề và xử lý nhanh nhạy\n",
      "tạo dựng mối quan hệ tốt trong và ngoài công ty\n",
      "\n",
      "kỹ năng mềm\n",
      "\n",
      "thành thạo kỹ năng nhập liệu\n",
      "thao tác tỉ mỉ, cẩn thận – thực hiện các công việc nhằm đạt tiêu chuẩn đã đề ra về độ chính xác và chất lượng\n",
      "đổi mới – chủ động trong công việc để tăng hiệu xuất giải quyết vấn đề\n",
      "quản lý thời gian – sắp xếp thứ tự ưu tiên, đáp ứng yêu cầu thời hạn, thực hiện đồng thời các công việc một cách hiệu quả\n",
      "khả năng học hỏi – nhanh chóng hiểu và áp dụng các thông tin, khái niệm, chiến lược\n",
      "khả năng tương tác với khách hàng thuộc nhiều nền văn hóa và nền tảng đa dạng\n",
      "\n",
      "yêu cầu\n",
      "\n",
      "bằng cử nhân hoặc chuyên ngành tương đương như kinh tế/hành chính/kế toán\n",
      "ít nhất 2 năm \n",
      "-----------------------------------------------\n",
      "kinh nghiệm tại vị trí tương đương\n",
      "có kiến thức về nghiên cứu và phân tích thị trường\n",
      "có kinh nghiệm về thu thập dữ liệu, quản lý hệ thống dữ liệu\n",
      "sử dụng tiếng anh thành thạo và ưu tiên ứng viên biết thêm ngôn ngữ khác\n",
      "tối thiểu đạt điểm b- ở các bài test bằng tiếng anh và kỹ năng viết báo cáo bằng tiếng anh tốt\n",
      "\n",
      "ứng tuyển\n",
      "để sắp xếp phỏng vấn cùng savills, hãy gửi cv của bạn đến chúng tôi và cho biết vì sao bạn tin tưởng rằng mình sẽ phù hợp với vị trí ứng tuyển.\n",
      "bên cạnh những thông báo tuyển dụng cụ thể, savills việt nam rất chào đón những cá nhân xuất sắc, những người tin rằng mình sẽ thành công tại savills và trên thị trường bất động sản.\n",
      "để ứng tuyển vào các vị trí tuyển dụng của savills, vui lòng email bản cv của bạn đến địa chỉ careers@savills.com.vn\n",
      "ứng tuyển vị trí này\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "              lưu tuyết \n",
      "              hạnh\n",
      "            \n",
      "\n",
      "\n",
      "quản lý cấp caobộ phận hành chính & nhân sựhanoi\n",
      "\n",
      "+84 24 7301 9888\n",
      "\n",
      "\n",
      "liên hệ ngay\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/3162/data.html\n",
      "mô tả công việc\n",
      "evaluate and define business metricssupport accounting dept. to reconcile monthlysupport various business functions with the development and maintenance of various management reportsprovide deep-dive analysis report & recommendation on service performance, highlight any trends, patterns or changes that may impact overall conversion of specific strategic business use casesad-hoc reporting data analysis duties or other responsibilities when required.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "university degree in computer science or information technology, finance, banking or related majorfemale; experience in sql, powerbi is compulsorystrong analytical thinking and ability to learn quickly with can do attitudeadvanced excel skill with knowledge in power query, power pivots- preferably working in financial & banking institution.\n",
      "quyền lợi\n",
      "• làm việc giờ hành chính từ t2-t6 (nghỉ t7 & cn)• thu nhập ổn định• được đóng bhxh và bhyt theo quy định của nhà nước• chế độ phúc lợi về sức khỏe, du lịch hàng năm• chương trình đào tạo nghiệp vụ dành riêng cho nhân viên• lộ trình thăng tiến rõ ràng• các phúc lợi khác theo quy định của ngân hàng.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 01/07/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/1620/data.html\n",
      "mô tả công việc\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "construct, monitor and maintain datasets with the whole data generating flow.\n",
      "investigating the root causes of a reported issue as well as implementing the optimal solution.\n",
      "maintain the communication with different stakeholders to locate the issues\n",
      "fully understand the issues and their impacts, and well explain the causes and solutions\n",
      "\n",
      "location: qtsc1 building, quang trung software city, district 12, hcmc\n",
      " \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2547/data.html\n",
      "mô tả công việc\n",
      "\n",
      "lộ trình đào tạo fullstack 2 giai đoạn và cơ hội trở thành nhân viên của misa chỉ sau 3 tháng:giai đoạn 1 đào tạo kiến thức nền tảng html/css, js coding, các kỹ thuật debug với vue, ui convention, ngôn ngữ c#, .netcore, config, dựng sever với asp.net core,... giai đoạn 2đào tạo thực tế tại dự án dưới sự dẫn dắt của mentor, tham gia trực tiếp 1 trong 20 project của misa như: nền tảng kế toán, nền tảng quản trị doanh nghiệp, mintax, golf hcp, misa id...\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3135/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi tiết công việc fresh speed up 2023 - program for fresher - planning tại b. braun vietna\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2164/data.html\n",
      "responsible to employ various tools and techniques to construct frameworks that prepare information using sql, python, r, java and c++. the big data engineer will be responsible for employing machine learning techniques to create and sustain structures that allow for the analysis of data while remaining familiar with dominant programming and deployment strategies in the field. during various aspects of this process, you should collaborate with coworkers to ensure that your approach meets the needs of each project\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/830/data.html\n",
      "================================================\n",
      "data-02-06/2768/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            working on historical data to analyze purchasing price, suppliers’ capability, proposing solutions and monitoring implementation.\n",
      "comparing purchasing price to market fluctuation and identifying items to be dealt with.\n",
      "collaborate with purchasing team on continuous improvement initiatives related to purchasing data systems, processes and analytics.\n",
      "assist in providing data required to build cost to serve analysis of supplier partners. supporting detail to for budgetary needs.\n",
      "produce management report and commentary.\n",
      "supports the day-to-day analytical requests of both internal and external clients.\n",
      "completes other duties, as assigned.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1909/data.html\n",
      "================================================\n",
      "data-02-06/3010/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            reporting to the fpp manager you will be responsible for : \n",
      "\n",
      "•\tsupporting the development and implementation of best financial practices\n",
      "\n",
      "•\tpreparing management reports at detail level upon request of business partners\n",
      "\n",
      "•\tproviding financial analysis and action recommendation to business unit management for business decision, in particular:\n",
      "   o\tpartnering with va team in client hungting for finance view to ensure company strategy and profitability\n",
      "   o\tpartnering with commercial and service team in promoting business performance in both top line and bottom line\n",
      "   o\tdeveloping and ensure the process for promotion management across all clients\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/844/data.html\n",
      "descriptionreporting to supply chain manager (scm) you will be responsible for:develop and maintain a weekly/monthly forecast based on historical data, commercial activities, market intelligence, and industry trends to inform the projected demand. lead the monthly collaborative demand review as part of the s&op process. influence and collaborate with key partners in commercial, supply planning and finance to understand and interpret the potential impact demand drivers can have on demand and adjust the statistical forecast to reflect those impacts. monitor and report on important changes in sales forecasts, budgets, and business strategies. lead continuous improvement efforts to advance the demand planning and forecasting process capabilities. develop and maintain monthly forecast accuracy and forecast bias metrics. continuous improvement to the forecasting process to minimize forecast error share best practices amongst planners address demand-related issues in a timely and effective manner.\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1566/data.html\n",
      "responsibilities\n",
      "requirements\n",
      "we offer\n",
      "about us\n",
      "additional infowe are looking for interns to join our reconciliation team. as an intern in reconciliation, you may be involved in a range of activities, including:\n",
      "responsibilities\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "supporting the reconciliation process: you may be responsible for helping to reconcile data related to costs and revenue.\n",
      "communicating with stakeholders: you may be asked to communicate with stakeholders, such as finance and accounting team, da team, to identify discrepancies and to resolve any issues that arise.\n",
      "documentation and record-keeping: you may be responsible for organizing and maintaining documentation related to the reconciliation process. this could involve creating spreadsheets, updating databases, and ensuring that all records are accurate and up-to-date.\n",
      "perform other ad-hoc duties as assigned.\n",
      "\n",
      "requirements\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "well-organized and good attention to detail.\n",
      "proficient in word, excel\n",
      "excellent command of english (≈ ielts 7.0)\n",
      "strong communication and customer service skills\n",
      "self motivated and able to prioritize work and meet deadlines\n",
      "\n",
      "we offer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "attractive salary and benefits.\n",
      "flexible working hours.\n",
      "offers state-of-the-art macbook, offices, and facilities.\n",
      "convenient central district 1 office location, next to a future metro station\n",
      "onsite lunch with multiple options, including vegetarian and happy hour every thursday\n",
      "unlimited free coffee, tea, snacks, and fruit to keep you energized\n",
      "opportunity to learn about data analysis, data management, and communication skills.\n",
      "you will be involved in a variety of tasks that support the reconciliation process, and you will have the opportunity to work with a range of stakeholders across the organization.\n",
      "\n",
      "about us\n",
      "\n",
      "\n",
      "\n",
      "we are an ai fintech company specialized in assessing credit profiles of consumers in emerging markets combining pioneering ai with large alternative data sources. in 2020 we reached our ambitious milestone of credit profiling 1 billion consumers spanning 4 countries - vietnam, indonesia, india & the philippines - and building a platform for the wider industry and the financial services industry, in particular, to provide the \"un & under\" served access to credit. at the core of this initiative has been our strict and unwavering adherence to the norms of consumer data privacy and consumer data rights.\n",
      "but we're not satisfied as we embark on the next leg of our journey to deliver 100 million credit lines to consumers in the markets where we operate. although this goal is ambitious, we truly believe that by harnessing the power of ai & big data we can deliver financial access at an unprecedented scale.\n",
      "as a firm, we're audacious problem-solvers motivated by our impact on society. we deeply espouse the values of ownership - of our actions and initiatives, integrity in all we do, and agility in execution.\n",
      "we place great importance on doing what is right, what is best, and what is innovative. if you are smart, driven, and want to make a difference in the world with the most advanced and fascinating technology, come join our team. we can satisfy your desire to explore new territory and give you the runway to really make an impact. \n",
      "additional info\n",
      "\n",
      "\n",
      "\n",
      "learn more about us here:\n",
      "https://www.youtube.com/watch?v=inaedgvocl8&t=29\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1084/data.html\n",
      "chi tiết công việc machine learning engineer intern tại kyanon digita\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2751/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            •\tprepare project management dashboards/ presentations.\n",
      "•\tactively engage and contribute to cost saving project initiatives by engaging with third party consultants whilst acquiring the skills/ knowledge and learning their systems/ tools.\n",
      "•\tprovide analysis of trends and forecasts and recommend fact base actions for optimization.\n",
      "•\trecommend actions by analyzing, interpreting data, and making comparative analyses, study proposed changes in methods and materials.\n",
      "•\tanalyze financial data and create financial models for decision-making supports.\n",
      "•\tidentify and drive process improvements, including the creation of standards and ad-hoc reports, tools, and dashboards.\n",
      "•\tother tasks as assigned by manager.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2487/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responsibilities: \n",
      "control and manage all area of project from get requirement to delivery to customer focus on dwh/bi solution\n",
      "direct project's resources, develop project plan, ensure that the project is completed on time, within budget, and op meets company’s policy.\n",
      "coordinate with stakeholder to ensure the overall success of the project. \n",
      "act as a catalyst to resolve project problems and conflicts, escalation when necessary. \n",
      "ensure that impacted teams are involved and informed as early as possible in the project management process.\n",
      "monitor company common activities and corporate with others managers to solve issues if any.\n",
      "make plan to develop skill of subordinate to meet company strategy. \n",
      "monitor performance and coaching subordinate in development process, management skill and solving method.\n",
      "support pre-sales activities, includes consulting, proposing solution and estimation.\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2130/data.html\n",
      "================================================\n",
      "data-02-06/1737/data.html\n",
      "================================================\n",
      "data-02-06/2117/data.html\n",
      "description\n",
      "\n",
      "\n",
      "this position is created from newly created data analytics functions that reports under commercial and data manager. the selected candidate will be working on the digital transformation projects across multiple functions, from business intelligence to building/scaling data products that are developed internally.\n",
      "\n",
      "key responsibilities: \n",
      "\n",
      "manipulate, interpret data, analyse results using statistical techniques and provide ongoing business insights through dashboards and reports\n",
      "design and develop ds or ml solutions given business use cases or user stories / features with deep understanding of the assumptions, limitations, trade-offs.\n",
      "work with management to prioritize business and information needs\n",
      "acquire data from primary or secondary data source and maintain data warehouse\n",
      "identify, analyse, visualise and interpret trends or pattern in complex data sets\n",
      "provide ad-hoc consultation and data analysis for business hypotheses\n",
      "communicate with stakeholders to understand data content and business requirements\n",
      "work closely with data manager to create process and data governance policy to enable future expansion of the team\n",
      "\n",
      "benefits:\n",
      "\n",
      "hybrid work policy (50% work in the office & 50% work from home)\n",
      "13th month salary + kpi bonus\n",
      "16 days annual leave + 6 paid sick leave\n",
      "pvi healthcare extra\n",
      "learning & training opportunity\n",
      "allowance for personal interest: birthday, wedding, childbirth, funeral,...\n",
      "activities: sportday, charity, party,....\n",
      "\n",
      "\n",
      "\n",
      "requirements:\n",
      "education / training qualifications:\n",
      "\n",
      "university graduate, major / computer science / statistics / finance, preferred from international universities/institutions\n",
      "\n",
      "-----------------------------------------------\n",
      "experience: 2-3 years experienced in data analytics. experience in retail industry, f&b and fmcg is a plus.\n",
      "\n",
      "skill:\n",
      "================================================\n",
      "data-02-06/3071/data.html\n",
      "descriptionpublicis media is one of the four solutions hubs of publicis groupe, alongside publicis communications, publicis sapient and publicis healthcare. publicis media is committed to helping its clients navigate the modern media landscape and is present in more than 100 countries with over 17,500 employees worldwide.we are built on the foundation of trust, talent, transformation:trusttrust is the cornerstone upon which we build our relationships. we hold ourselves to the highest standards of how a partner should behave.we treat our people and our clients with respect, transparency and honesty.talentthis is first and foremost a people business. we are committed to ensuring publicis media a destination for the best talent in our industry. we value people as individuals, growing ourselves as we grow our client’s business.transformationtrue transformation comes when we stop managing change, and instead initiate change. we believe in our purpose to be the admired force for business transformation. we believe that focusing on performance and results has the power to transform client business.job descriptiondevelop media digital ecommerce plan to meet the clients’ gmv kpi requirements (traffic, a2c, purchase…etc). stay up to date with the latest technology and best practiceskey pic in handle search performance (onsite & sem) plus other ecommerce related task for 2 biggest division of top fmcg clientwork closely with e-retail partners & vendor to ensure a smooth cooperation while implementing campaignforecast sales performance trends, provide solution on optimization and quick actions to meet the kpis within a very tight periodresponsible for regular reports on ecommerce campaign (daily, monthly, campaign) and handle ad hoc task if anymonitor competition and provide suggestions for improvementqualificationsmust have extensive knowledge and working \n",
      "-----------------------------------------------\n",
      "experience in running campaigns on various search platforms such as google, search engines and onsite search tools of ecommerce platforms.familiar with agency environment (3+ years) - experienced in serving top fmcg clients - can handle working under pressure and leads junior membersstrong in search performance & search concept (user intention - keywords exploration| bidding| mapping - negative exclusion - technical set up) - proven record in seo-sem, onsite search (marketplace) or related fieldspay attention to details, comfortable working with data on daily basisknow how to use super metric, google studio & advance in excel (macro, advance formula, etc.) is a plus hands-on experience with seo/sem, google analytics sense of ownership and pride in your performance and its impact on a company’s successteamwork, time-management, and data analyst skillsknowledge on data visualization tool (google studio, tableau, power bi, power point) is a plusknowledge on other paid ads: cpas, programmatic, messenger, tiktok shop is a plusadditional informationan off-beat perspective and the courage to look at challenges.responsible and dedicated.a cheerful, humble individual who is very willing to learn every day, easy to manage and highly collaborative.someone who is honest, responsible, down to earth, hardworking, and passionate\n",
      "================================================\n",
      "data-02-06/2624/data.html\n",
      "================================================\n",
      "data-02-06/2924/data.html\n",
      "responsibilities\n",
      "\n",
      "manage campaign end to end process to ensure communications are sent to the right customers at the right time with the right offer and right communication channel\n",
      "ensure campaigns are run within approved campaign framework\n",
      "enhance campaign process to fasten turn around time on campaign delivery within accepted risk and control level\n",
      "gathers historical data from campaign activities to conduct analysis on campaign performance and provide well-reasoned recommendations to amplify/modify campaigns to achieve campaign target and meet financial plan \n",
      "translate data into consumer or customer behavioral insights to drive targeting and segmentation strategies, and communicate clearly and effectively to business partners and senior leaders all findings\n",
      "continuously improve processes and strategies by exploring and evaluating new data sources, tools, and capabilities\n",
      "work closely with internal and external business partners in building, implementing, tracking and improving decision strategies\n",
      "appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency\n",
      "\n",
      " \n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1708/data.html\n",
      "================================================\n",
      "data-02-06/3023/data.html\n",
      "descriptionthe bosch group is a leading global supplier of technology and services. it employs roughly 394,500 associates worldwide (as of december 31, 2020). according to preliminary figures, the company generated sales of 71.6 billion euros in 2020. its operations are divided into four business sectors: mobility solutions, industrial technology, consumer goods, and energy and building technology.the bosch group comprises robert bosch gmbh and its roughly 440 subsidiaries and regional companies in some 60 countries. if its sales and service partners are included, then bosch is represented in roughly 126 locations. this worldwide development, manufacturing, and sales network is the foundation for further growth.bgsv – bosch global software technologies company limited (previous name: rbvh - robert bosch engineering and business solutions vietnam company limited) is 100% owned subsidiary of robert bosch gmbh.\n",
      "\n",
      "bgsv has started its operations from 19th october, 2010 at e-town2 in hcmc. this engineering development center will be engaged in developing embedded systems and software, mechanical design and simulation, and will provide it (sap consulting, java development….) and business services (finance and accounting, economics, purchasing, logistics, translations japanese-english-japanese, information security ) solutions to the bosch group of companies globally.job descriptionresponsible for pbi (power bi) development activity extract data from sources transform raw data into usable data modelling data which follows data science theory load data to pbi, then perform visualization regarding to customer request responsible for pbi operation activity answer customer concerns consult for customer concern or requests perform bug/issue fixing apply new minor change for existing pbi providing dataset maintenance provide data freezing (depending on customer requirement) responsible for sql server development and operationsperform design database based on customer requirement responsible for etl (extract-transform-load)responsible for database maintenance provide dml process (fixing/data) correction in case of customer requirementresponsible for machine learning / ai - r&d activitiesresponsible to ml/ai learning topicresponsible to ml/ai researching application in laboratoryresponsible to ml/ai application development activityqualificationshaving 1~2 year of \n",
      "-----------------------------------------------\n",
      "experiences in power bi developmentat least 1-2 year of experience working with data warehouse systems: ms sql, oracle sql, …at least 1-2 year of experiences in machine learning / ai developmenthave python programming\n",
      "================================================\n",
      "data-02-06/2759/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      " phân tích và báo cáo:thực hiện mô hình thống kê và phân tích các tập dữ liệu có cấu trúc và phi cấu trúc để phát triển các số liệu, báo cáo và trực quan hóa các xu hướng và mẫu.\n",
      "sử dụng các chương trình, công cụ và kỹ thuật trực quan hóa dữ liệu để tạo trang tổng quan, báo cáo và bản trình bày hỗ trợ theo dõi dữ liệu.\n",
      "tạo và duy trì các mô hình thống kê để xem xét và phân tích dữ liệu liên tục và đột xuất.giao tiếp và gắn kết với các bên liên quan về mục đích và tác động của các giải pháp phân tích đối với hoạt động kinh doanh.\n",
      "chuẩn bị và quản lý dữ liệuthu thập dữ liệu từ các nguồn khác nhau: online và offline, khảo sát khách hàng...\n",
      "quản lý dữ liệu - bảo trì dữ liệu, đảm bảo quy trình, quy tắc\n",
      "lắng nghe, trao đổi và cùng các bộ phận để xây dựng kịch bản tối ưu cho trải nghiệm khách hàng bằng cách sử dụng dữ liệu (sẽ được hướng dẫn và tích lũy theo thời gian).\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "học vấn, kinh nghiệm:tốt nghiệp cao đẳng, đại học, ưu tiên chuyên ngành it.\n",
      "có từ 2 đến 4 năm kinh nghiệm trong phân tích dữ liệu hoặc vai trò liên quan trong các ngành hàng bán lẻ.\n",
      "có kinh nghiệm tạo báo cáo, trang tổng quan và bản trình bày.\n",
      "có kinh nghiệm với phân tích dữ liệu và các công cụ bi như tableau, qlikview, spark, powerbi.\n",
      "có kinh nghiệm sử dụng toán học, công cụ trực quan hóa dữ liệu, phân tích kinh doanh và công nghệ chuyển đổi khối lượng lớn dữ liệu phức tạp thành giải pháp.\n",
      "================================================\n",
      "data-02-06/747/data.html\n",
      "descriptionour client is seeking an exceptional individual to join the firm as nlp operations engineer.while prior finance or machine learning experience is not required, a successful candidate must possess a strong interest in learning about finance, global markets and machine learning.nlp operations engineer will design, implement and monitor complex proprietary platforms, pipelines, and tools to support our nlp quant researchers and pms.you will collaborate with researchers and pms to gather, analyze and spec out requirements, develop and test code robustness and latency, and manage product deliverables. a successful candidate will help build production pipelines employing state-of-the-art nlp models and techniques supporting investment strategies at scale.\n",
      "-----------------------------------------------\n",
      "job requirementmust have:bsc/m.sc. from a leading university in computer science, engineering, or a related disciplineexperience developing scalable and robust softwareexperience building distributed or data-intensive systemsexperience programming production systems in python and c++knowledge of parallelization, threading, multiprocessing, etc.familiar with workflow scheduling (e.g. airflow)experience working in linux environmentsstrong communication skills; ability to express complex concepts in simple termsnice to have:experience in deploying machine learning frameworks in productionexperience with kubernetes and kafkawork with leading cloud technologies (such as aws, and gcp)experience with sql databases (mysql, postgresql)familiar with deep learning frameworks (pytorch)\n",
      "================================================\n",
      "data-02-06/1846/data.html\n",
      "================================================\n",
      "data-02-06/174/data.html\n",
      "================================================\n",
      "data-02-06/1588/data.html\n",
      "mô tả công việc:*** vận hành và tối ưuvận hành, phát triển và tối ưu hệ thống gamificationxây dựng và tối ưu quy trình đã có bằng công nghệ hoặc các công cụ thông minh: metabase, google app script, make nâng cao năng suất cho các phòng banthúc đẩy, làm mới quy trình giúp tối giản hóa các hoạt động trong công việc*** phân tích và phát triển phối hợp với các team liên quan nhằm phân tích, đánh giá, đưa ra giải pháp giúp mở rộng và tăng trưởng nhanhlập kế hoạch và quản lý chi phí hàng tháng, đảm bảo chi tiêu vận hànhthực hiện phân tích dự báo đơn hàng và số lượng tài xế cần tuyển dụngsử dụng phân tích đề xuất các chương trình thưởng cho tài xế để cải thiện vận hành\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên:có ít nhất 01 năm kinh nghiệm ở các vị trí tương đương trong các công ty về logistics, ecommerce,…có tư duy phân tích và tối ưu vận hànhcẩn thận, tỉ mỉ trong công việc, tính chính xác caokỹ năng trung bình về sql/ google sheetskỹ năng trình bày, truyền đạt thông tin tốtkhả năng nhìn nhận tổng thể bức tranh toàn cảnh\n",
      "================================================\n",
      "data-02-06/2574/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            1) tư vấn, phân tích và đánh giá các hoạt động chức năng\n",
      "- làm việc với các phòng ban chức năng, hiểu và tư vấn các vấn đề chức năng dựa trên các định hướng dữ liệu\n",
      "- thực hiện các phân tích insights dựa trên các bài toán từ tập đoàn và phòng ban chức năng đang giải quyết\n",
      "- đề xuất các khuyến nghị để giải quyết các bài toán cùng phòng ban chức năng\n",
      "\n",
      "2) tư vấn, kết nối và thiết lập văn hóa dữ liệu cho các đơn vị:\n",
      "- kết nối, chia sẻ những thông tin, sản phẩm mới từ đội ngũ dữ liệu\n",
      "- hướng dẫn, chia sẻ những phương thức ứng dụng dữ liệu\n",
      "- tư vấn, thiết lập kết nối với các đơn vị nội bộ và bên ngoài để xây dựng những phương thức ghi nhận, lưu trữ, và khai thác dữ liệu cần thiết\n",
      "- dẫn dắt sự thay đổi bằng cách tìm hiểu các công nghệ mới, công cụ mới về phân tích dữ liệu và đề xuất các bài toán thực tế để áp dụng.\n",
      "\n",
      "3) phối hợp với đơn vị trong các hoạt động khảo sát, hoạch định, theo dõi, đánh giá, nghiệm thu các chương trình/ dự án.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2867/data.html\n",
      "================================================\n",
      "data-02-06/2560/data.html\n",
      "description\n",
      "\n",
      "                                                                                            we are seeking for an exceptionally talented software engineer to develop large scale, complex software system that controls our datasets creation. datasets are consumed internally by our researchers and our quantitative models. the successful candidate will be working on current and next-generation data acquiring system that ingest data from different format, protocol. your responsibilities will include:\n",
      "- requirement-gathering, architecting and designing extremely large-scale data system.\n",
      "- developing software systems and micro-services in python/c++.\n",
      "- integrating state-of-the-art open source software and technologies.\n",
      "- assembling platforms and frameworks to automate our data enrichment process.\n",
      "- developing and architecting next generation monitoring platform for data guarding, data governance.\n",
      "- collaborating with internal technology, research and portfolio management team.\n",
      "                                                                                    \n",
      "read full job descriptions\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2847/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            i. job purpose\n",
      "reporting to the manager, regional process engineering, this role will fulfil a lead role in providing operational performance insight, identifying improvement opportunities, and facilitating the implementation of impactful solutions to operational issues and challenges in viet nam and cambodia.\n",
      "this role will provide visibility into operations performance trends to allow for greater alignment and execution of the strategic plan. \n",
      "\n",
      "ii. roles & responsibilities \n",
      "1. data and statistical analysis\n",
      "• regular interaction with country operations management and customers for the purpose of gathering, validating and documenting operational requirements.\n",
      "• conducts systematic in-depth research and analysis into issues of varying complexity. \n",
      "• initiate, defines and leads the development and communication of effective reports to key stakeholders, including executive/senior management. \n",
      "• facilitate development of new analytics solutions to address existing gaps in analytics tools\n",
      "• estimate costs and identify business savings.\n",
      "• provides reports, presentations and relevant information to senior management as required. \n",
      "• ensure the effective development and use of information or record management systems or reporting practices.\n",
      "\n",
      "2. process improvement and change management\n",
      "• ensure team awareness of current processes and procedures, and relevant company and regulatory requirements, which may impact the operation or department. takes steps to ensure any changes are implemented. \n",
      "• ensure completion of audit and reviews of existing processes or documentation to ensure appropriate standards and rules are applied. \n",
      "• manage the identification and facilitate the implementation of process improvement initiatives to ensure minimal disruption of business operations during transition period\n",
      "• facilitate development of specific risk mitigation strategies for critical business operations\n",
      "• identify issues, risks and benefits of existing and proposed solutions and outline business impacts\n",
      "• work collaboratively with operations teams to formulate solutions to operations issues and challenges\n",
      "• simplify information and decipher technical jargon so it is easily understood by the whole team.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2400/data.html\n",
      "responsibilities guidelines\n",
      "\n",
      "\n",
      "supply chain expectations\n",
      "\n",
      "\n",
      "marketing approach\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "awards\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "our brands\n",
      "\n",
      "\n",
      "see all brands\n",
      "\n",
      "\n",
      "chocolate\n",
      "\n",
      "\n",
      "5 star\n",
      "\n",
      "\n",
      "alpen gold\n",
      "\n",
      "\n",
      "cadbury\n",
      "\n",
      "\n",
      "cadbury dairy milk\n",
      "\n",
      "\n",
      "côte d'or\n",
      "\n",
      "\n",
      "daim\n",
      "\n",
      "\n",
      "freia\n",
      "\n",
      "\n",
      "hu\n",
      "\n",
      "\n",
      "lacta\n",
      "\n",
      "\n",
      "marabou\n",
      "\n",
      "\n",
      "milka\n",
      "\n",
      "\n",
      "toblerone\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "biscuits\n",
      "\n",
      "\n",
      "barni\n",
      "\n",
      "\n",
      "belvita\n",
      "\n",
      "\n",
      "chips ahoy\n",
      "\n",
      "\n",
      "club social\n",
      "\n",
      "\n",
      "enjoy life foods\n",
      "\n",
      "\n",
      "honey maid\n",
      "\n",
      "\n",
      "kinh do\n",
      "\n",
      "\n",
      "lu\n",
      "\n",
      "\n",
      "oreo\n",
      "\n",
      "\n",
      "prince\n",
      "\n",
      "\n",
      "ritz\n",
      "\n",
      "\n",
      "tate's bake shop\n",
      "\n",
      "\n",
      "tiger\n",
      "\n",
      "\n",
      "triscuit\n",
      "\n",
      "\n",
      "tuc\n",
      "\n",
      "\n",
      "wheat thins\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "baked snacks\n",
      "\n",
      "\n",
      "7days\n",
      "\n",
      "\n",
      "perfect snacks\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "other\n",
      "\n",
      "\n",
      "beverages\n",
      "\n",
      "\n",
      "bournvita\n",
      "\n",
      "\n",
      "tang\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gum and candy\n",
      "\n",
      "\n",
      "clorets\n",
      "\n",
      "\n",
      "halls\n",
      "\n",
      "\n",
      "maynards bassetts\n",
      "\n",
      "\n",
      "sour patch kids\n",
      "\n",
      "\n",
      "stride\n",
      "\n",
      "\n",
      "trident\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "meals\n",
      "\n",
      "\n",
      "philadelphia\n",
      "\n",
      "\n",
      "royal\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "snacking made right\n",
      "\n",
      "\n",
      "overview\n",
      "\n",
      "\n",
      "esg at mdlz\n",
      "\n",
      "\n",
      "esg reporting center\n",
      "\n",
      "\n",
      "esg reporting & disclosure\n",
      "\n",
      "\n",
      "goals & progress\n",
      "\n",
      "\n",
      "standards & ratings\n",
      "\n",
      "\n",
      "esg datasheet\n",
      "\n",
      "\n",
      "reporting archive\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "our positions\n",
      "\n",
      "\n",
      "diversity, equity & inclusion\n",
      "\n",
      "\n",
      "overview\n",
      "\n",
      "\n",
      "racial equity journey\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mindful snacking\n",
      "\n",
      "\n",
      "mindful portions\n",
      "\n",
      "\n",
      "state of snacking\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "colleague & community well-being\n",
      "\n",
      "\n",
      "social sustainability\n",
      "\n",
      "\n",
      "mondelēz international foundation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sustainable snacking\n",
      "\n",
      "\n",
      "climate action\n",
      "\n",
      "\n",
      "sustainable ingredients\n",
      "\n",
      "\n",
      "environmental impact\n",
      "\n",
      "\n",
      "packaging & plastics\n",
      "\n",
      "\n",
      "impact investing\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "partners and industry memberships\n",
      "\n",
      "\n",
      "esg news\n",
      "\n",
      "\n",
      "cocoa life\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "careers\n",
      "\n",
      "\n",
      "overview\n",
      "\n",
      "\n",
      "early careers\n",
      "\n",
      "\n",
      "career areas\n",
      "\n",
      "\n",
      "our world\n",
      "\n",
      "\n",
      "job search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "news\n",
      "\n",
      "\n",
      "news stories\n",
      "\n",
      "\n",
      "all news stories\n",
      "\n",
      "\n",
      "• brands\n",
      "\n",
      "\n",
      "• business\n",
      "\n",
      "\n",
      "• careers\n",
      "\n",
      "\n",
      "• community impact\n",
      "\n",
      "\n",
      "• people\n",
      "\n",
      "\n",
      "• sustainability\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "press releases\n",
      "\n",
      "\n",
      "mdlz in the news\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2022 esg report\n",
      "\n",
      "\n",
      "investors\n",
      "\n",
      "\n",
      "overview\n",
      "\n",
      "\n",
      "investor relations\n",
      "\n",
      "\n",
      "why invest\n",
      "\n",
      "\n",
      "news & events\n",
      "\n",
      "\n",
      "financial news\n",
      "\n",
      "\n",
      "events & webcasts\n",
      "\n",
      "\n",
      "annual meeting of shareholders\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "corporate governance\n",
      "\n",
      "\n",
      "overview\n",
      "\n",
      "\n",
      "our board and committees\n",
      "\n",
      "\n",
      "board leadership\n",
      "\n",
      "\n",
      "audit committee\n",
      "\n",
      "\n",
      "governance membership & sustainability committee\n",
      "\n",
      "\n",
      "people and compensation committee\n",
      "\n",
      "\n",
      "finance committee\n",
      "\n",
      "\n",
      "governance practices and policies\n",
      "\n",
      "\n",
      "board oversight of corporate citizenship\n",
      "\n",
      "\n",
      "contacting the board and reporting wrongdoings\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "financials\n",
      "\n",
      "\n",
      "sec filings\n",
      "\n",
      "\n",
      "annual reports\n",
      "\n",
      "\n",
      "quarterly results\n",
      "\n",
      "\n",
      "gaap to non gaap schedules\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "stock\n",
      "\n",
      "\n",
      "stock information\n",
      "\n",
      "\n",
      "historic stock quote\n",
      "\n",
      "\n",
      "investment calculator\n",
      "\n",
      "\n",
      "investing in us\n",
      "\n",
      "\n",
      "dividend info\n",
      "\n",
      "\n",
      "spin-off information\n",
      "\n",
      "\n",
      "information for former cadbury shareholders\n",
      "\n",
      "\n",
      "compensation and benefits\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ir resources\n",
      "\n",
      "\n",
      "email alerts\n",
      "\n",
      "\n",
      "ir contacts\n",
      "\n",
      "\n",
      "rss feeds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "media\n",
      "\n",
      "\n",
      "overview\n",
      "\n",
      "\n",
      "media contacts\n",
      "\n",
      "\n",
      "asset library\n",
      "\n",
      "\n",
      "press releases\n",
      "\n",
      "\n",
      "live broadcast\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "countries\n",
      "\n",
      "\n",
      "asia, middle east, africa\n",
      "\n",
      "\n",
      "amea region\n",
      "\n",
      "\n",
      "australia\n",
      "\n",
      "\n",
      "bahrain\n",
      "\n",
      "\n",
      "china\n",
      "\n",
      "\n",
      "egypt\n",
      "\n",
      "\n",
      "india\n",
      "\n",
      "\n",
      "indonesia\n",
      "\n",
      "\n",
      "japan\n",
      "\n",
      "\n",
      "malaysia\n",
      "\n",
      "\n",
      "morocco\n",
      "\n",
      "\n",
      "new zealand\n",
      "\n",
      "\n",
      "nigeria\n",
      "\n",
      "\n",
      "pakistan\n",
      "\n",
      "\n",
      "philippines\n",
      "\n",
      "\n",
      "saudi arabia\n",
      "\n",
      "\n",
      "singapore\n",
      "\n",
      "\n",
      "south africa\n",
      "\n",
      "\n",
      "thailand\n",
      "\n",
      "\n",
      "united arab emirates\n",
      "\n",
      "\n",
      "vietnam\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "europe\n",
      "\n",
      "\n",
      "europe region\n",
      "\n",
      "\n",
      "northern europe\n",
      "\n",
      "\n",
      "northern europe region\n",
      "\n",
      "\n",
      "denmark\n",
      "\n",
      "\n",
      "finland\n",
      "\n",
      "\n",
      "ireland\n",
      "\n",
      "\n",
      "norway\n",
      "\n",
      "\n",
      "sweden\n",
      "\n",
      "\n",
      "united kingdom\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "central europe\n",
      "\n",
      "\n",
      "central europe region\n",
      "\n",
      "\n",
      "albania\n",
      "\n",
      "\n",
      "austria\n",
      "\n",
      "\n",
      "bosnia and herzegovina\n",
      "\n",
      "\n",
      "bulgaria\n",
      "\n",
      "\n",
      "croatia\n",
      "\n",
      "\n",
      "cyprus\n",
      "\n",
      "\n",
      "czechia\n",
      "\n",
      "\n",
      "estonia\n",
      "\n",
      "\n",
      "germany\n",
      "\n",
      "\n",
      "greece\n",
      "\n",
      "\n",
      "hungary\n",
      "\n",
      "\n",
      "kosovo\n",
      "\n",
      "\n",
      "latvia\n",
      "\n",
      "\n",
      "lithuania\n",
      "\n",
      "\n",
      "montenegro\n",
      "\n",
      "\n",
      "north macedonia\n",
      "\n",
      "\n",
      "poland\n",
      "\n",
      "\n",
      "romania\n",
      "\n",
      "\n",
      "serbia\n",
      "\n",
      "\n",
      "slovakia\n",
      "\n",
      "\n",
      "slovenia\n",
      "\n",
      "\n",
      "switzerland\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "western europe\n",
      "\n",
      "\n",
      "western europe region\n",
      "\n",
      "\n",
      "belgium\n",
      "\n",
      "\n",
      "france\n",
      "\n",
      "\n",
      "italy\n",
      "\n",
      "\n",
      "luxembourg\n",
      "\n",
      "\n",
      "netherlands\n",
      "\n",
      "\n",
      "portugal\n",
      "\n",
      "\n",
      "spain\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "eastern europe\n",
      "\n",
      "\n",
      "eurasia\n",
      "\n",
      "\n",
      "russia\n",
      "\n",
      "\n",
      "turkey\n",
      "\n",
      "\n",
      "ukraine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "latin america\n",
      "\n",
      "\n",
      "argentina\n",
      "\n",
      "\n",
      "brazil\n",
      "\n",
      "\n",
      "colombia\n",
      "\n",
      "\n",
      "costa rica\n",
      "\n",
      "\n",
      "mexico\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "north america\n",
      "\n",
      "\n",
      "canada\n",
      "\n",
      "\n",
      "united states\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact us\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/705/data.html\n",
      "description : develop proprietary market-making (”mm”) operations for pintu exchange: develop in-house quantitative trading & risk management strategies/models for mm at pintu exchange that supports mm goal priorities. collaborate with engineering, risk management, and treasury ops teams to orchestrate the implementation of semi/fully-automated quantitative trading strategies.   build & manage a team of mm quantitative researcher/trader(s), including task allocation & mentorship. quant strategies monitoring & improvement : continuously monitor model parameters and back-test existing in-house mm strategies to meet the mm goal priorities research & identify new quantitative trading strategies that meets mm goal priorities   imm goal priorities: supports the improvement of pintu exchange liquidity; satisfies internal risk parameters; improves mm’s risk-adjusted returns requirements: 5+ past professional quantitative research/trading experience in global/ regional mm firms. ideally has a minimum of 3 years in crypto and 2 years in trade-fi quant research/trading experience. good understanding of market structures in both crypto (cex & dex) and financial markets (e.g. fx). past academic background in either in comp-sci, statistics, financial engineering/operation research, or mathematics. extensive experience in programming languages such as python/r/etc, or similar applicable programming languages. excellent understanding of high frequency trading (”hft”) strategies (a must) and/or algo-trading (plus). excellent communication, leadership, & interpersonal skills. had experience in managing a team. cfa & frm is a plus. timezone: max 3 time zones away from jkt/sg (or willing to relocate to singapore/bali/jakarta). \n",
      "-----------------------------------------------\n",
      "experience.pintu is looking for a quant trader/researcher who will lead and execute proprietary market-making operations for our exchange. the position reports directly to cfo. the quant trader/researcher will work closely with the engineering, risk management, and treasury ops team.job description : develop proprietary market-making (”mm”) operations for pintu exchange: develop in-house quantitative trading & risk management strategies/models for mm at pintu exchange that supports mm goal priorities. collaborate with engineering, risk management, and treasury ops teams to orchestrate the implementation of semi/fully-automated quantitative trading strategies.   build & manage a team of mm quantitative researcher/trader(s), including task allocation & mentorship. quant strategies monitoring & improvement : continuously monitor model parameters and back-test existing in-house mm strategies to meet the mm goal priorities research & identify new quantitative trading strategies that meets mm goal priorities   imm goal priorities: supports the improvement of pintu exchange liquidity; satisfies internal risk parameters; improves mm’s risk-adjusted returns requirements: 5+ past professional quantitative research/trading experience in global/ regional mm firms. ideally has a minimum of 3 years in crypto and 2 years in trade-fi quant research/trading experience. good understanding of market structures in both crypto (cex & dex) and financial markets (e.g. fx). past academic background in either in comp-sci, statistics, financial engineering/operation research, or mathematics. extensive experience in programming languages such as python/r/etc, or similar applicable programming languages. excellent understanding of high frequency trading (”hft”) strategies (a must) and/or algo-trading (plus). excellent communication, leadership, & interpersonal skills. had experience in managing a team. cfa & frm is a plus. timezone: max 3 time zones away from jkt/sg (or willing to relocate to singapore/bali/jakarta). \n",
      "================================================\n",
      "data-02-06/2561/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descriptions\n",
      "data mart & data warehouse\n",
      "\n",
      "collaborate with the data engineer and data analyst team to build up, centralize data and improve the quality control process from multiple sources.\n",
      "manage the data collection process to be adaptable to the company’s continuous expansion, more advance analytic.\n",
      "\n",
      "data analysis and reporting\n",
      "\n",
      "assisting line manager by preparing management reports and ad-hoc analysis.\n",
      "automate ar, ap report and forecast payment schedule.\n",
      "deepdive and control payment from system of amazon, walmart ensuring timing, accuracy and completeness of cash collection. build up dashboard to get things control more efficiently.\n",
      "build up tools to optimize financing fee for cashflow.\n",
      "automate operational p&l and cashflow. connect with key metrics from s&op to give a full picture of fluctuation and figure out the root causes.\n",
      "together with finance build up automate report/dashboard for evaluating performance of portfolio by various perspectives.\n",
      "build up report/dashboard integrating key metrics relate to finance and s&op to give greater visibility of the relationships between resources, capabilities, and results.\n",
      "\n",
      "ii. skill and experience\n",
      "\n",
      "bachelor‘s degree in business, finance, or other analytical disciplines.\n",
      "minimum 02 years working experience in data analyst/business analyst/business intelligence. have experience in finance/fintech is an advantage\n",
      "proficiency in excel & sql is required. knowing python or r is an advantage.\n",
      "knowledgeable of statistics such as regression, normal distribution, etc\n",
      "impressive data visualization (not limited to tableau tools, google data studio, power bi, superset, etc.)\n",
      "\n",
      "iii. why you will love joining us?\n",
      "for you to join\n",
      "\n",
      "\n",
      "\n",
      "financial well-being: a competitive salary with 13th month salary, annual performance bonus and a variety of allowances.\n",
      "\n",
      "\n",
      "salary review: annually or on excellent performance.\n",
      "\n",
      "\n",
      "activities: company trips, team-building, and other customized monthly bonding events.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "annual leaves: 16 days off and 01 birthday leave per year.\n",
      "\n",
      "\n",
      "healthcare: annual health check, insurance according to labor law and extra bao viet insurance package.\n",
      "\n",
      "\n",
      "working environment: dynamic, friendly environments with working time flexibility (mon-fri), and other perks include snacks, coffee, and healthy food provided daily suited for hardworking, fun, and team collaboration.\n",
      "\n",
      "\n",
      "for you to grow\n",
      "\n",
      "\n",
      "ambition: we are now keeping on with our hyper growth to multicategory, multichannel, multimarket, and expanding into the world largest e-commerce enabler. hence, there will continuously be opportunities to challenge yourself, learn new skills and knowledge. \n",
      "\n",
      "\n",
      "challenges: your voice can always be heard as we embrace the eagerness of learning and sharing. you can be your own boss and create your own value with the ability to take initiative and make decisions in all aspects of work.\n",
      "\n",
      "\n",
      "chances: be led and coached by experienced and inspirational leaders and participate in various training courses where you can enlarge your knowledge and experience in the e-commerce and supply chain industry.\n",
      "\n",
      "\n",
      "for you to stay\n",
      "\n",
      "\n",
      "people: having a headquarter in the us and an operation office in vietnam, our team is young and highly motivated. you will be working with and alongside members having experiences from international corporations or high profile from vietnam that share the same passion and dedication.\n",
      "\n",
      "\n",
      "culture: our working environment is humble, collaborative and 100% healthy. we promote exchange & speak out, you can receive transparent and supportive feedback so you can perform the best.\n",
      "\n",
      "\n",
      "career path: provide you a great career path, open to rotating for your better understanding of the company and contribute across many of our functions.\n",
      "\n",
      "\n",
      "and much more, join us and let yourself explore other fantastic things!\n",
      "\n",
      " \n",
      "-----------------------------------------------\n",
      "experience in the e-commerce industry.\n",
      "we are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\n",
      "i. job descriptions\n",
      "data mart & data warehouse\n",
      "\n",
      "collaborate with the data engineer and data analyst team to build up, centralize data and improve the quality control process from multiple sources.\n",
      "manage the data collection process to be adaptable to the company’s continuous expansion, more advance analytic.\n",
      "\n",
      "data analysis and reporting\n",
      "\n",
      "assisting line manager by preparing management reports and ad-hoc analysis.\n",
      "automate ar, ap report and forecast payment schedule.\n",
      "deepdive and control payment from system of amazon, walmart ensuring timing, accuracy and completeness of cash collection. build up dashboard to get things control more efficiently.\n",
      "build up tools to optimize financing fee for cashflow.\n",
      "automate operational p&l and cashflow. connect with key metrics from s&op to give a full picture of fluctuation and figure out the root causes.\n",
      "together with finance build up automate report/dashboard for evaluating performance of portfolio by various perspectives.\n",
      "build up report/dashboard integrating key metrics relate to finance and s&op to give greater visibility of the relationships between resources, capabilities, and results.\n",
      "\n",
      "ii. skill and experience\n",
      "\n",
      "bachelor‘s degree in business, finance, or other analytical disciplines.\n",
      "minimum 02 years working experience in data analyst/business analyst/business intelligence. have experience in finance/fintech is an advantage\n",
      "proficiency in excel & sql is required. knowing python or r is an advantage.\n",
      "knowledgeable of statistics such as regression, normal distribution, etc\n",
      "impressive data visualization (not limited to tableau tools, google data studio, power bi, superset, etc.)\n",
      "\n",
      "iii. why you will love joining us?\n",
      "for you to join\n",
      "\n",
      "\n",
      "\n",
      "financial well-being:\n",
      "================================================\n",
      "data-02-06/2026/data.html\n",
      "description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "skills required\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "details\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- chịu trách nhiệm về các chỉ số đánh giá của các bộ phận và các chỉ tiêu hoạt động theo mục tiêu của công ty: + soạn thảo thiết lập phương án đánh giá theo hệ thống + công bố chỉ tiêu, lập bảng biểu tính toán theo dõi và thực hiện đề xuất điều chỉnh phù hợp với tình hình kinh doanh + theo dõi tình hình hoàn thành chỉ tiêu; + tổng hợp phân tích tính toán kết quả hoàn thành và công bố kết quả- hoàn thành các công việc khác theo sự phân công của giám đốc bộ phận* quyền lợi:- thời gian làm việc 8h-17h từ thứ 2 đến sáng thứ 7- lương, phép năm, bhxh, bhyt, bảo hiểm tai nạn 24h đầy đủ- tăng lương định kỳ hàng năm, thưởng cuối năm- chế độ nghỉ mát, khám sức khỏe, year end party...theo chính sách của công ty- môi trường thân thiện, thoải mái, chuyên nghiệp, được tham gia các khóa đào tạo nâng cao năng lực- phúc lợi đặc biệt khác dành cho nhân viên thâm niên\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "required experience / skills detail\n",
      "\n",
      "\n",
      "\n",
      "- nữ - kỹ năng tổng hợp báo cáo, phân tích số liệu, xây dựng các tiêu chí công việc. - có ít nhất 1- 2 năm \n",
      "-----------------------------------------------\n",
      "kinh nghiệm làm việc ở vị trí nhân sự, kế toán hoặc các công việc tương đương - yêu thích làm việc với các con số. - thái độ làm việc tích cực, trung thực, nhanh nhẹn, nhiệt tình và tinh thần trách nhiệm cao\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job detail\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "position type\n",
      "\n",
      "full-time\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "career level\n",
      "\n",
      "staff\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "education level\n",
      "\n",
      "bachelor's degree\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gender\n",
      "\n",
      "female\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "age\n",
      "\n",
      "25 - 33\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job categories\n",
      "\n",
      "\n",
      "clerical / administrative\n",
      "\n",
      ", \n",
      "\n",
      "human resources\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "information\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "name:\n",
      "\n",
      "\n",
      "phòng nhân sự\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lầu 19, cao ốc flemington, 182 lê đại hành, p.15\n",
      "\n",
      ", \n",
      "\n",
      "district 11\n",
      "\n",
      ", \n",
      "\n",
      "ho chi minh\n",
      "\n",
      ", \n",
      "\n",
      "viet nam\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- các ứng viên quan tâm có thể nộp hồ sơ trực tuyến, đính kèm file qua email hoặc trực tiếp đến tại công ty\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "application language:\n",
      "vietnamese\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "công ty tnhh điều hòa gree (việt nam)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "https://www.gree.com.vn\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "25 - 99 employees\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact: phòng nhân sự\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "được thành lập vào năm 1991, từ một xưởng sản xuất nhỏ hiện tại gree đã phát triển thành là một tập đoàn hàng đầu thế giới về điều hòa không khí. gree là thương hiệu điều hòa số 1 thế giới năm 2015 do tập đoàn nghiên cứu thị trường euromonitor international bình chọn. năm 2015 gree đạt doanh số 25 tỷ usd, tốc độ tăng trưởng đạt 38% so với cùng kỳ năm trước và năm 2020 được xếp hạng 246 trong danh sách 2000 công ty lớn nhất theo bình chọn và thống kê của tạp chí forbes.\n",
      "mỗi năm gree cung cấp ra thị trường thế giới 60 triệu bộ điều hòa dân dụng và 5,5 triệu bộ điều hòa thương mại, chiếm 1/3 sản lượng điều hòa thế giới, có nghĩa là cứ 3 bộ điều hòa bán ra trên thế giới thì có 1 bộ điều hòa do gree sản xuất. bên cạnh đó gree còn sở hữu hơn 14000 bằng sáng chế kỹ thuật, trong đó có hơn 5000 bằng sáng chế phát minh trong ngành điều hòa thế giới. điển hình trong đó là công nghệ g10 inverter, đây là công nghệ inverter tiên tiến nhất trên thế giới hiện nay giúp tiết kiệm 60% điện năng tiêu thụ, hoạt động ổn định và độ ồn cực thấp. công nghệ điều hòa thương mại sử dụng năng lượng mặt trời, công nghệ chiller ly tâm quang điện công suất tối đa 2000 hp. đồng thời gree cũng sở hữu nhiều môi chất lạnh thân thiện môi trường như: r410a; r290; r134; r407.\n",
      "về gree việt nam, công ty đã chính thức có mặt tại việt nam năm 2013 và đang có những bước tiến mạnh mẽ trên thị trường. trong khoảng thời gian từ 2013 đến 2015 gree đã đạt tốc độ tăng trưởng cao nhất thị trường với con số lên đến 65%. định hướng sắp tới của gree việt nam sẽ tiếp tục cung cấp đến khách hàng những sản phẩm chất lượng với nhiều tính năng vượt trội, tiết kiệm điện năng và thân thiện với môi trường. bên cạnh đó là những dịch vụ hậu mãi hấp dẫn đúng với phương châm luôn đặt sự hài lòng của khách hàng lên hàng đầu từ trước đến nay của gree.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "see more\n",
      "\n",
      "\n",
      "\n",
      "see less\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "other jobs from this company\n",
      "\n",
      "|\n",
      "\n",
      "see all\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "trợ lý kinh doanh (tiếng trung)\n",
      "\n",
      "\n",
      "công ty tnhh điều hòa gree (việt nam)\n",
      "\n",
      "\n",
      "\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[hcm] phó giám đốc hành chính nhân sự\n",
      "\n",
      "\n",
      "công ty tnhh điều hòa gree (việt nam)\n",
      "\n",
      "\n",
      "\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[hn] nhân viên tài xế\n",
      "\n",
      "\n",
      "công ty tnhh điều hòa gree (việt nam)\n",
      "\n",
      "\n",
      "\n",
      "ha noi\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[hồ chí minh] chuyên viên hành chính lễ tân - tiếng hoa cơ bản\n",
      "\n",
      "\n",
      "công ty tnhh điều hòa gree (việt nam)\n",
      "\n",
      "\n",
      "\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[hcm] chuyên viên xuất nhập khẩu - thời vụ\n",
      "\n",
      "\n",
      "công ty tnhh điều hòa gree (việt nam)\n",
      "\n",
      "\n",
      "\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "photos\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "work location\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lầu 19, cao ốc flemington, 182 lê đại hành, p.15, district 11, ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tags\n",
      "\n",
      "\n",
      "\n",
      "chinese\n",
      "office worker\n",
      "district 11\n",
      "recruitment\n",
      "human resource\n",
      "kpi\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "share\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "copied\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2710/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "tham gia nghiên cứu, thiết kế và phát triển các hệ thống data lake, data warehouse,  datapipeline;thiết kế xây dựng data pipeline theo batch và realtime, sử dụng các công nghệ big data technologytham gia triển khai các dự án cntt của ngân hàngquản lý, khai thác các hệ thống dữ liệu và báo cáonghiên cứu công nghệ và xu hướng phát triển công nghệ dữ liệu, đưa ra đề xuất nhằm cải tiến sản phẩm, trải nghiệm khách hàng, chất lượng dịch vụ.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "yêu cầu > 1 năm kinh nghiệm ở các vị trí data engineer hoặc big data engineer hoặc data scientist;ưu tiên hiểu biết 1 trong các hệ thống như hadoop eco system (on premise), spark, hive, kafka, cassandra, neo4j, elastic search…thành thạo 1 trong các ngôn ngữ lập trình: python, sql, pl/sql, java, .net, scala,…có kinh nghiệm với 1 trong các hệ thống csdl như sql server, oracle, hbase, cassandra, clickhouse, mongodb, maria db, redis,...kỹ năng làm việc nhóm và làm việc độc lập tốtcó khả năng làm việc dưới môi trường áp lực.\n",
      "quyền lợi\n",
      "rank lương không giới hạnmức lương cạnh tranh, 13 tháng lươngđược đào tạo bài bản, lộ trình thăng tiến rõ ràngcung cấp laptop/ pcnghỉ thứ 7, chủ nhật, 12 ngày phép/ nămcompany trip, team buildinghappy hours hàng tháng, free snacks, hoa quả, đồ uốngtổ chức sinh nhật, team lunch, …làm việc với khách hàng khối ngân hàng, công việc ổn định và lâu dài\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 22/06/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2666/data.html\n",
      "mô tả công việc     tham gia và đóng góp các dự án ngân hàng số, mảng sản phẩm khcn số và sme số hỗ trợ nghiên cứu các sản phẩm dịch vụ của ngân hàng, nghiên cứu và phân tích thị trường, sản phẩm/ dịch vụ của đối thủ cạnh trạnh. có cơ hội tiếp cận các công nghệ sản phẩm số mới tại lĩnh vực tài chính ngân hàng   \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2829/data.html\n",
      "mô tả công việc\n",
      " • tham gia dự án thực tế về data science, ai, machine learning trong lĩnh vực tài chính, viễn thông, ngân hàng, bảo hiểm, v.v..• tham gia các dự án phân tích dữ liệu & hành vi người dùng trên hệ thống để hiểu được insight• nghiên cứu các mô hình ml & dl cơ bản áp dụng cho các bài toán trong lĩnh vực tài chính, viễn thông, ngân hàng, bảo hiểm v.v.. \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2588/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "design and develop office 365 applications and solutions (power platforms: powerapps, power automate, sharepoint online …).\n",
      "develop and execute database queries and conduct analyses.\n",
      "create visualizations and reports for requested projects.\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "technical requirements:\n",
      "understanding ms power platform (power apps, power automate)\n",
      "report building and data visualization\n",
      "knowing background in database analytics and data mining\n",
      "knowing the program power platform \n",
      "================================================\n",
      "data-02-06/2033/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            role description\n",
      "\n",
      "analysts in the cdo team work with the business and product owner to create the backlog of epics and user stories for the team to build. they explore the data and processes to support this effort, create dashboards to help measure and communicate key metrics and test solutions built to ensure alignment with functional acceptance criteria.\n",
      "\n",
      "responsibilities\n",
      "•\tlead the effort to communicate state of the business to stakeholders regularly - enable audiences to understand the reasons behind the trends - and provide insights to drive strategic decisions.\n",
      "•\tconduct exploratory analysis - go deep into the data to develop hypotheses and to answer complex business questions\n",
      "•\tdevelop tools and automated processes that project the work out to a broader audience. strategize on democratizing data and insights to make analyses easily repeatable and generalizable by other team members in the future\n",
      "•\townership of conceptualizing, developing, and maintaining dashboards, visualizations\n",
      "•\tdevelop analytics frameworks and foundations to enable easy actionable insights and reliable measurement\n",
      "•\tbecome a data expert in your business domain and own data quality\n",
      "•\tempower the team to answer data questions quickly and easily by building high-quality ground truth data sets\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/778/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thông tin liên hệ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "phạm vi công việchỗ trợ trưởng phòng/ quản lý nhóm nghiên cứu thị trường trong việc phân tích thông tin, duy trì cơ sở dữ liệu và dự thảo báo cáo.\n",
      "\n",
      "\n",
      "chi tiết công việc\n",
      "\n",
      "duy trì / cập nhật cơ sở dữ liệu với sự hỗ trợ từ nhóm nghiên cứu\n",
      "viết / cập nhật báo cáo về tất cả các lĩnh vực của thị trường bất động sản\n",
      "liên lạc với khách hàng trong nước và quốc tế và chính quyền việt nam\n",
      "đi du lịch đến các tỉnh hoặc thành phố khác để nghiên cứu thị trường, nếu cần thiết\n",
      "viết báo cáo dựa trên phạm vi công việc sẽ được cung cấp bởi khách hàng\n",
      "tích cực tìm kiếm doanh nghiệp mới\n",
      "duy trì các tiêu chuẩn cao nhất về đạo đức và bảo mật mọi lúc\n",
      "liên lạc với ban quản lý tài sản, cơ quan và các bộ phận khác trong công ty để đảm bảo sự hiểu biết tổng thể về thị trường bất động sản tại việt nam\n",
      "liên lạc với khách hàng một cách độc lập để đảm bảo công việc bổ sung cho công ty\n",
      "duy trì hiểu biết chi tiết về luật đất đai và các vấn đề pháp lý liên quan khác tại việt nam\n",
      "các nhiệm vụ khác được giao bởi người quản lý của bạn\n",
      "\n",
      "yêu cầu\n",
      "trình độ học vấn\n",
      "\n",
      "bằng đại học marketing / cử nhân / kinh tế / tài chính\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "kinh nghiệm\n",
      "\n",
      "tối thiểu 2 - 3 năm kinh nghiệm ở vị trí tương tự\n",
      "kỹ năng giao tiếp, đàm phán và giao tiếp mạnh mẽ, để liên lạc với đồng nghiệp, khách hàng\n",
      "khả năng làm việc với các tài nguyên cntt như cơ sở dữ liệu và bảng tính để thu thập và quản lý thông tin\n",
      "\n",
      "tính cách\n",
      "\n",
      "hiểu biết sâu sắc về nghiên cứu thị trường và phân tích thị trường\n",
      "phải hiểu các nguyên tắc và thực hành chăm sóc khách hàng\n",
      "chú ý đến chi tiết và hướng đến kết quả\n",
      "mô hình định tính và định lượng mạnh\n",
      "kỹ năng viết báo cáo và phân tích mạnh mẽ\n",
      "kiểm soát độ chính xác / chất lượng\n",
      "thúc đẩy tăng trưởng trong một môi trường chuyển tiếp\n",
      "kỹ năng giao tiếp, giao tiếp, thuyết trình và viết lách tuyệt vời\n",
      "thúc đẩy, năng lực, linh hoạt và sẵn sàng học hỏi\n",
      "kỹ năng tổ chức và quản lý thời gian tuyệt vời với khả năng đa tác vụ\n",
      "khả năng làm việc hiệu quả dưới áp lực\n",
      "sáng tạo, trí tưởng tượng và khả năng sử dụng sáng kiến\n",
      "kỹ năng làm việc nhóm, phân tích và giải quyết vấn đề tốt\n",
      "nhận thức liên quan đến kinh doanh và kiến thức tốt về các vấn đề hiện tại\n",
      "\n",
      "để sắp xếp phỏng vấn cùng savills, hãy gửi cv của bạn đến chúng tôi và cho biết vì sao bạn tin tưởng rằng mình sẽ phù hợp với vị trí ứng tuyển.\n",
      "bên cạnh những thông báo tuyển dụng cụ thể, savills việt nam rất chào đón những cá nhân xuất sắc, những người tin rằng mình sẽ thành công tại savills và trên thị trường bất động sản.\n",
      "để ứng tuyển vào các vị trí tuyển dụng của savills, vui lòng email bản cv của bạn đến địa chỉ careers-hcmc@savills.com.vn\n",
      "ứng tuyển\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/1916/data.html\n",
      "================================================\n",
      "data-02-06/1176/data.html\n",
      "responsibilities: \n",
      "\n",
      "\n",
      "support brand, marketing and communication business\n",
      "\n",
      "\n",
      "support quality and management of the internal and/or external communications initiatives to support communications\n",
      "\n",
      "\n",
      "preparation, implementation & evaluation of event plan; ensure marketing campaign efficiency and effectiveness to reach the defined brand goals\n",
      "\n",
      "\n",
      "develop relevant content & coordinate with business team and other stakeholders to communicate and acquire adequate resources to ensure effectiveness of outputs\n",
      "\n",
      "\n",
      "conduct market researches & update business intelligence\n",
      "\n",
      "\n",
      "​\n",
      "apply now \n",
      "email your cv to recruitment@cel-consulting.com \n",
      "or apply online at\n",
      "​\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1198/data.html\n",
      "mô tả công việc\n",
      "\n",
      "- tổng hợp, phân tích thông tin kinh tế, thị trường trong lĩnh vực bảo hiểm phi nhân thọ.\n",
      "- thiết kế, xây dựng báo cáo định kỳ về kết quả kinh doanh, kpis của tổng công ty, các vùng, các đơn vị định kỳ.\n",
      "- phân tích các dữ liệu kinh doanh, kết quả bán hàng theo các chiều: hành vi khách hàng, hiệu quả sản phẩm, hiệu quả các kênh bán, năng suất lao động…\n",
      "- tổng hợp, phân tích báo cáo quản trị, báo cáo phân tích kinh doanh theo yêu cầu của ban điều hành.\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "• tốt nghiệp đại học trở lên các khối trường kinh tế, tài chính, ngân hàng...\n",
      "• có kỹ năng tổng hợp, phân tích số liệu, thông tin, lên báo cáo;\n",
      "• có khả năng làm việc độc lập;\n",
      "• có kỹ năng về phân tích định lượng, tư duy logic, giải quyết vấn đề\n",
      "• sử dụng thành thạo tin học văn phòng (word, excel…); sql; vba...\n",
      "\n",
      "\n",
      "job tags:\n",
      "chuyên viên kế hoạch\n",
      "nhân viên kế hoạch\n",
      "planning specialist\n",
      "nhân viên kế hoạch thư ký\n",
      "planning staff\n",
      "strategic planning executive\n",
      "strategic planning staff\n",
      "chuyên viên phân tích kinh doanh\n",
      "chuyên viên phân tích kinh doanh\n",
      "\n",
      "================================================\n",
      "data-02-06/2076/data.html\n",
      "description:\n",
      "- documents / data understanding: be able to read, review, and understand various business documents in english, and compare this information to financial data and try to identify any mistakes made by our client. - reports preparation: assist in the preparation and presentation of various reports to the manager and our clients regarding the mistakes identified in the documents or data. - quality checks / communication: ensuring proper information flow between your team and the recovery department is maintained and the response time to all recovery department queries is kept to a minimum.\n",
      "requirement: - undergraduate or similar (english/economics/accounting/logistics/information management)- english (intermediate - advanced). - careful, detail- working time: monday- friday, 08:00 – 17:00 - submit english cv benefit: - salary: gross 09 - 11 million - 13&14th-month salary payment- 14+ full-paid annual leave- a day off for christmas (25th december)- company trip- happy hour- annual health check- personal health care card- parking fee- training program ( excel, vba, sql, python,....)- mid-autumn gift, tet gift, year-end party, team building, sport\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2227/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description\n",
      "\n",
      "- responsible for the development and maintenance of modern data warehouse and lakehouse solutions.- use kafka to stream raw data into data lake.- develops and maintains data flows within azure.- perform data quality and metadata management.- data visualization using power bi, tableau.- work directly with technical customers to design cloud-based technical architectures, approaches.- support/troubleshoot data pipelines.\n",
      "\n",
      "your skills and \n",
      "-----------------------------------------------\n",
      "experience\n",
      "\n",
      "- bachelor degree in it/ computer science or relevant background.- have at least 5 year of experience in the relevant technologies.- expertise in implementation of modern data warehouse and lakehouse solutions, data quality and metadata management.- strong experience with azure synapse analytics, dedicated and serverless sql pools, adls gen2, azure data factory, databricks, stream analytics.- extensive etl/elt experience with azure data movement and transformation capabilities (azure synapse pipelines, azure data flow).- excellent working knowledge on sql/tsql.- deep knowledge of azure synapse data pipeline orchestration and computation framework azure synapse with spark pools.- strong experience on data modelling of dimensional, temporal, slowly changing dimensions and full/incremental/delta data loading processes.- familiarity with data visualization techniques using power bi cloud, tableau is a plus.- microsoft azure data engineer associate (dp-203) preferred.- good at english communication skills.\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "why bosch?because we don't just follow trends, we create them.because together we turn ideas into reality, working every day to make the world of tomorrow a better place. do you have high standards when it comes to your job? so do we. at bosch, you will discover more than just work.benefits and career opportunities\n",
      "working in one of the best places to work in vietnam\n",
      "join a dynamic and fast growing global company (english-speaking environment)\n",
      "\n",
      "13th-month salary bonus + attractive performance bonus (you'll love it!) + annual performance appraisal\n",
      "\n",
      "100% monthly basic salary and mandatory social insurances in 2-month probation\n",
      "\n",
      "onsite opportunities: short-term and long-term assignments\n",
      "\n",
      "15++ days of annual leave + 1 day of birthday leave\n",
      "premium health insurance for employee and 02 family members\n",
      "\n",
      "flexible working time\n",
      "lunch and parking allowance\n",
      "various training on hot-trend technologies/ foreign language (english/chinese/japanese) and soft-skills\n",
      "\n",
      "fitness & sport activities: football, badminton, yoga, aerobic\n",
      "free in-house entertainment facilities and snack\n",
      "join in various team building, company trip, year-end party, tech talks and a lot of charity events\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/529/data.html\n",
      "================================================\n",
      "data-02-06/2128/data.html\n",
      "================================================\n",
      "data-02-06/2454/data.html\n",
      "description \n",
      "\n",
      "\n",
      " enable audio description \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " transcript \n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2304/data.html\n",
      "description\n",
      "\n",
      "as a gaming data analyst, your primary responsibilities will include:\n",
      "gathering, processing, and analyzing extensive datasets to uncover trends and insights that can enhance in-game performance and player \n",
      "-----------------------------------------------\n",
      "experience.\n",
      "collaborating closely with various teams, including game designers, developers, ua, and product managers, to comprehend game objectives and offer data-driven recommendations.\n",
      "creating and maintaining comprehensive dashboards, reports, and visualizations to effectively communicate key performance indicators to stakeholders.\n",
      "identifying potential areas of growth and optimization through the analysis of player behavior, in-game economy, and content performance.\n",
      "designing and implementing a/b tests to evaluate the effectiveness of proposed changes and support informed decision-making.\n",
      "continuously monitoring and analyzing game performance to ensure product goals are met and to inform future development strategies.\n",
      "staying current with industry trends, tools, and best practices in gaming analytics to drive ongoing improvement within the team.\n",
      "\n",
      "\n",
      "your skills and experience\n",
      "\n",
      "\n",
      "bachelor's or master's degree in computer science, statistics, mathematics, or a related field.\n",
      "a minimum of 2 years of experience in data analytics, preferably within the gaming industry.\n",
      "proficiency in sql and experience handling large datasets and complex data structures.\n",
      "familiarity with data visualization tools (e.g., looker studio, power bi) and a strong ability to present data effectively.\n",
      "proficient in statistical analysis and data modeling techniques.\n",
      "experience with a/b testing and experimental design principles.\n",
      "exceptional problem-solving skills and a keen eye for detail.\n",
      "excellent communication and teamwork abilities, with the capacity to work well in a dynamic, team-focused environment.\n",
      "a passion for gaming and a deep understanding of game mechanics and player behavior.\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "\n",
      "great facility to work. you will have a macbook and extra high definition screens\n",
      "remote work 12 days / annual leave 12 days / sick leave 2 days\n",
      "premium health insurance package for you and your relatives\n",
      "annual health check-up at the premium clinic\n",
      "development opportunity: sponsorship for all training courses includes business english...\n",
      "interesting workout activities: gym/fitness, yoga, kick-boxing, football after work\n",
      "with regular discussions, you will have a lot of opportunities to learn from experts in their fields\n",
      "13th-month salary + annual bonus + project bonus\n",
      "twice yearly performance review and one-time salary review per year\n",
      "reward & recognition in mobile platform\n",
      "international opportunity to expose and grow\n",
      "professional, creative working environment and talented teams, equal-opportunities & agile culture\n",
      "at least one abroad travel every year. we often send our elites to international conferences like gdc, wwdc, google i/o... to update the latest technology\n",
      "1-2 annual luxury company trip, team building\n",
      "free food & drinks, kitchen at work, playstation & billiards corner\n",
      "friday evening party, happy hours, team activities, and awesome parties\n",
      "the remaining annual leave will be transferred to the next working year\n",
      "additional allowance, gifts for birthdays, giving-birth, weddings, illness, mid-autumn festival, lunar new year, 1/1, 1/5, 1/6…\n",
      "paternity leave policy offers more than 10 days of paid leave, not including days-off according to vietnam labor law regulations\n",
      "free parking\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/515/data.html\n",
      "description summary similar job\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2251/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            - số lượng cần tuyển: 7\n",
      "- thiết kế, kiểm tra, hoàn thiện các quy trình tự động hóa bằng công cụ vba excel theo các tài liệu được cung cấp.\n",
      "- hỗ trợ, duy trì, giám sát và khắc phục sự cố trong quá trình triển khai và vận hành.\n",
      "- chi tiết công việc sẽ được trao đổi thêm vào buổi phỏng vấn.\n",
      "- thời gian làm việc: 8:00 - 17:00 (thứ 2 - thứ 6).\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3115/data.html\n",
      "mô tả công việc\n",
      "- làm việc onsite tại ngân hàng, tập đoàn, doanh nghiệp đối tác- xây dựng giải pháp và lập trình các tầng xử lý hệ thống mis bao gồm: data warehouse, data model, bi- tích hợp tất cả các nguồn dữ liệu từ các hệ thống ứng dụng vào data warehouse- hỗ trợ các đơn vị nghiệp vụ ngân hàng khi có nhu cầu khai thác dữ liệu từ hệ thống mis/dw.- thực hiện phân tích các mô hình dữ liệu, dự đoán, dự báo, báo cáo phân tích,...- báo cáo định kỳ theo quy định hoặc theo yêu cầu của cấp quản lý trực tiếp- thực hiện các công việc khác theo sự phân công của quản lý trực tiếp.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "- tốt nghiệp đại học trở lên các chuyên ngành công nghệ thông tin hoặc các ngành có liên quan.- tiếng anh: khả năng giao tiếp; đọc hiểu tài liệu kỹ thuật.có ít nhất một trong các nhóm kỹ năng sau:- nắm vững kiến thức về database (oracle, sql, server), thành thạo pl/sql và các công cụ tích hợp dữ liệu elt.- có kinh nghiệm tối thiểu 1 năm làm việc với các công cụ bi (obiee/oas)- có kinh nghiệm tối thiều 1 năm phân tích dữ liệu, sử dụng các ngôn ngữ r, python,... sử dụng công cụ sas.có các kinh nghiệm sau là lợi thế:- có các chứng chỉ công nghệ liên quan đến hệ thống mis/dw như: oracle,bi, data analytics .- có kinh nghiệm sử dụng công cụ etl: datastage, ssis, odi, informatica,.. \n",
      "================================================\n",
      "data-02-06/2523/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "- thực hiện các phân tích sâu về dữ liệu của công ty ở dạng đồ thị, biểu đồ, sơ đồ, bảng biểu và báo cáo; sau đó sử dụng các dữ liệu đó để xác định xu hướng và tạo mô hình dự đoán những gì có thể xảy ra trong tương lai.- cộng tác, trao đổi, hợp tác với các bộ phận kinh doanh và các bộ phận khác trong công ty để hiểu và chuyển chúng thành các thông tin hữu ích.- có khả năng lên yêu cầu và xây dựng các hệ thống báo cáo phân tích dữ liệu môt cách trực quan.- có khả năng đưa ra các giải pháp về việc khắc phục sự cố và giải quyết các vấn đề về dữ liệu.- triển khai thực hiện báo cáo đột xuất (nếu có, theo yêu cầu của công ty, bộ phận làm việc), có thể phối hợp tốt với các nhóm phát triển sản phẩm và kỹ thuật.- có khả năng đào tạo kỹ thuật, phân tích dữ liệu cho các thành viên trong bộ phận...\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "- tốt nghiệp đại học trở lên chuyên ngành liên quan đến digital marketing, market research, toán, khoa học máy tính, quản trị thông tin, công nghệ thông tin, thống kê,....- có kỹ năng đọc và viết tiếng anh tốt- biết và code cơ bản r, python- sử dụng thành thạo công cụ phổ biến như: google data studio, sql server, powerbi, tableau, sas…- có kỹ năng sử dụng các công cụ visualize để chuyển hóa dữ liệu thành graphics; kỹ năng chuyển hóa dữ liệu thành actionable insight- có kỹ năng phân tích sắc bén, khả năng thu thập, tổ chức, phân tích và phổ biến lớn thông tin một cách chi tiết và chính xác- có kỹ năng lập kế hoạch, kiểm soát việc thực hiện kế hoạch- có ít nhất 03 năm kinh nghiệm trong lĩnh vực phân tích dữ liệu- kỹ năng áp dụng kỹ thuật trực quan hóa và khám phá dữ liệu hiện đại để cung cấp thông tin chi tiết hữu ích\n",
      "quyền lợi\n",
      "- được hưởng đầy đủ các chế độ phúc lợi xã hội như: bhyt, bhxh, bh thất nghiệp và nghỉ mát hàng năm;- mức lương thỏa thuận đảm bảo xứng đáng với sự đóng góp của mỗi người. cơ chế lương thưởng linh hoạt và khuyến khích sự phát triển của mỗi cá nhân.- môi trường làm việc chuyên nghiệp, sáng tạo, được đào tạo nâng cao kĩ năng trong quá trình làm việc, có nhiều cơ hội khẳng định bản thân và thăng tiến trong nghề nghiệp.- thời gian làm việc: 8h30 - 17h30 các ngày từ thứ 2 đến thứ 6 trong tuần;- nghỉ thứ 7, chủ nhật và các ngày lễ khác, phép năm theo quy định của luật lao động.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 30/06/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2444/data.html\n",
      "================================================\n",
      "data-02-06/1246/data.html\n",
      "description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "are you an analytics engineer looking to take the next step in your career?are you looking for a company where dbt is central to their data workflow?are you looking for a company where remote is built into the company dna, and not coronavirus-induced?do you want to work at a company where the leadership is engaged with bi and sees it as a strategic priority?do you want a central role in crafting the bi strategy, and building a data team?do you want to reach and make a positive impact on millions of people?note: we're also hiring for other positions. this job might be for you if you:like being able to set your own hours and work from homelike exercising your creativity and experimentationlike having responsibilitylike working collaborativelylike having a dependable, reliable stream of workwant to make the world a better placeare comfortable with a fast-changing environment.you should not take this job if you:have a strong need/desire for in-person social interaction at workdislike asynchronous communicationlike following instructions and being told what to dodon't like needing to come up with ideasdon't have a real interest or \n",
      "-----------------------------------------------\n",
      "experience in online education.about usfluentu is an online education company that helps people learn languages with real-world videos, including movie trailers, music videos, news and inspiring talks. we have a website, ios app (usually among the top 50 grossing ios education apps), and android app. founded in 2011, we’re a profitable, stable company with long-term focus, and we’re proudly self-funded. and we've been remote/distributed since day one.we get 5 million visitors per month on our blogs, 100,000+ people on our email list, and many more receiving web and mobile notifications.this is a unique opportunity to play a pivotal role on our business intelligence strategy, which is still in the early stages. we've worked with a reputable consultancy until now, and you'll be our first dedicated hire focused specifically on bi data engineering, empowered to build a program from the foundation up.job descriptionas our first analytics engineer, you will be responsible for:working in an agile/kanban style methodology while balancing long-term data modeling & infrastructure planninginterpreting & executing analytics feature requests from senior stakeholdersplanning & documenting work to be done, with regular feedback to stakeholders to minimize unnecessary workmaintaining & improving the entire data pipeline from start to finish, from extracting data from saas api's to configuring display options/creating charts for end users in looker, eg:using data-extractor-as-a-service tools such as stitch to extract data on a scheduled basis & oversee automated loading behaviorcreating & maintaining proprietary extraction tools, such as bash scripts on google cloud instancesmanaging the dbt etl pipelineacting as looker admin (development, security & administration)using software engineering best-practices (such as version control, component-based software/architecture, dry code etc).implementing testing frameworks & subjecting all work to qayou would work closely with the founder of fluentu and our other leadership.how we workwe’re a 100% distributed/remote team. here’s a little bit more about how we work:almost all of our communication is text-based (mostly via asana) and we value clear communication, among other things.most things are not urgent. we take pride in having a calm work environment.we also have a flat collaborative environment.we make decisions based on logic/reason.we believe in getting things done and continuous improvement.qualificationsour ideal candidate:can work in a fast-paced environment and be responsive to new requirementsis terrific at written communicationcan explain technical concepts to a non-technical audienceunderstands basic principles around content marketingis comfortable managing their own time and workflow independentlycan juggle multiple projects & work streams concurrentlyhas most or all of the following technical skills:experience working collaboratively using githas strong sql skills (we use bigquery standard sql)understands data modelling concepts, à la kimball dimensional modellingexceptional understanding of data manipulation (ie joins, data granularity, referential integrity, uniqueness/primary/foreign keys etc)some knowledge of sql database performancelooker, dbt & google cloud knowledge (can be easily learned if you possess the above skills)ideally linux/cloud architecture & python skills but these are not mandatory.has a deep interest in language learning or online education.is able to work a minimum of 25+ hours per week (pay is hourly) and is looking for something long-term.how to applyplease click here and fill out the form.\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2849/data.html\n",
      "description\n",
      "\n",
      "global fashion group is the leading fashion and lifestyle destination in growth markets across latam, sea and anz. our three e-commerce platforms: the iconic, zalora and dafiti connect an assortment of international, local and own brands to millions of consumers from diverse cultures and lifestyles. powered by our best-in-class operational infrastructure, which is fashion-specific and tailored to local market needs, our platforms provide an inspiring and seamless end-to-end customer \n",
      "-----------------------------------------------\n",
      "experience. we stand for benchmark-setting customer service, delivery options, returns policies, and curation of brands.the data squadour data team knows our customers and their shopping habits better than they do. have you ever noticed suggested items when shopping online? or maybe a matching item for something you have just added to your bag? that’s our team!\n",
      "================================================\n",
      "data-02-06/2906/data.html\n",
      "description\n",
      "\n",
      "\n",
      "build and socialise business dashboards and reports to support business decision-making and growth. \n",
      "develop and implement data assets (e.g. marketing and sales performance, customer \n",
      "-----------------------------------------------\n",
      "experience etc.)\n",
      "================================================\n",
      "data-02-06/2669/data.html\n",
      "================================================\n",
      "data-02-06/2909/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "                                                                                            - ensure the data quality and integrity in database\n",
      "- fix any issue related to database performance and provide corrective measures\n",
      "- create complex functions, scripts, stored procedures and triggers to support application development\n",
      "- develop best practices for database design and development activities\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/597/data.html\n",
      "descriptionthe role: research is at the core of our client. through rigorous exploration and unconstrained thinking about how to apply data to the financial markets, our researchers are in constant search of new alphas. we strive to understand data in ways our competitors don’t believe is possible. researchers at our client employ tested processes seeking to identify high-quality predictive signals that we believe are undiscovered by the wider market. these signals are mathematical expressions of data that are used as inputs in our quantitative models.our client is seeking an exceptional individual to join the firm as a quantitative researcher. the person must have a strong understanding of the investment research process to create computer-based models that seek to predict movements of global financial markets. while prior finance experience is not required, a successful candidate must possess a strong interest in learning about finance and global markets. candidates will have a research scientist mindset; be a self-starter, a creative and persevering deep thinker who is motivated by unsolved challenges.its impact: as we pursue our goal of creating new alphas, we need researchers who will lead us there. our client product’s unique investment platform is a leader amongst its peers and the methodology we employ is cutting edge. we desire people who will help us in our relentless pursuit to succeed. \n",
      "-----------------------------------------------\n",
      "job requirementph.d. or m.s. degree from a leading university in a quantitative or highly analytical field (e.g.\n",
      "================================================\n",
      "data-02-06/2679/data.html\n",
      "responsibilities\n",
      "\n",
      "leverage splunk and other data loss prevention systems to develop and produce recurring reports (fortnightly, quarterly, etc.) and metrics that clearly describe, measure, and report data protection posture and the data loss prevention services capability.\n",
      "leverage data management, analysis, and data mining techniques to derive trends and patterns in data.\n",
      "look for areas of improvement in process, policies, and business operating models\n",
      "triage incidents daily to prevent data loss to unauthorized entities or external third parties.\n",
      "escalate policy-breach incidents to -business through an event management system and provide other divisions of the bank with guidance on how to handle data and share information in secure ways.\n",
      "\n",
      "requirements\n",
      "must have:\n",
      "\n",
      " 3+ years of \n",
      "-----------------------------------------------\n",
      "experience in cybersecurity incident handling and experience in security operation center in banking/finance.\n",
      "knowledge of security policy and technical standard development, multi-tiered trust zone structures, and complex edr, xdr management systems.\n",
      "experience with splunk and other similar tools/platforms.\n",
      "experience in improving and automating reports.\n",
      "programming or scripting experience with python or others.\n",
      "strong verbal and writing english skills\n",
      "attention to detail and task completeness\n",
      "a self-starter who can work unsupervised and delivery on their commitments\n",
      "strong interpersonal and communication skills with the ability to lead and work as part of a team\n",
      "knowledge with iso 27000 series, nist scf…\n",
      "\n",
      "================================================\n",
      "data-02-06/2528/data.html\n",
      "mô tả công việc\n",
      "cài đặt, triển khai các thuật toán ai mới trên môi trường cpu, gpu. có khả năng quản lý được môi trường dev trên conda.có khả năng hướng dẫn giúp level junior hiểu được ý tưởng thuật toán ai và cách thức xây dựng, sử dụng model ai. biết sử dụng pretrained model và turning mode. có khả năng phân tích về yêu cầu nghiệp vụ để hiểu rõ vấn đề cần giải quyết, các nguồn dữ liệu có thể tận dụng, cách thức model tích hợp vào hệ thống, để nâng cao hiệu quả model và xây dựng model với đầu vào / đầu ra phù hợp.có khả năng kiểm tra và phân tích hiệu năng, độ chính xác của các model. giải thích được kết quả model cho da/ba một cách trực quan, dễ hiểu.đánh giá kết quả sau tác động, đề xuất / thực hiện các phương pháp phân tích / tối ưu model.đề xuất được các phương pháp tối ưu model và cải tiến được độ chính xác mô hình.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "tốt nghiệp chính quy loại khá trở lên chuyên ngành khoa học máy tính, cntt, toán học ứng dụng, điện tử; ..trình độ tiếng anh toeic 650 trở lên hoặc tương đươngkinh nghiệm 1 năm trở lên với vai trò ai engineer hoặc tương đươngưu tiên: đã tham gia xây dựng, triển khai >= 2 sản phẩm, giải pháp ai\n",
      "quyền lợi\n",
      "chế độ lương thưởng hấp dẫn với lương tháng 13đánh giá hiệu suất: 2 lần/nămcơ hội thăng tiến và thu nhập phù hợp tùy vào chuyên môn hoặc khả năng quản lý.được học hỏi: sds tạo điều kiện cho mọi người rèn luyện ở mọi lúc mọi nơi, đồng hành và thúc đẩy phát triển cá nhân từ đồng nghiệp và quản lý giàu kinh nghiệmđược thử sức trong một môi trường làm việc trẻ trung, cởi mở với chính sách đãi ngộ tốtdu lịch hằng năm với địa điểm hấp dẫn, thường xuyên tổ chức các hoạt động team building gắn kết cộng đồng, các hoạt động vui chơi giải trí cho nhân viên.tham gia chương trình hàng tháng, các buổi liên hoan, sinh nhật hàng tháng, tiệc noel, tất niên,…được tham gia bhxh, bhyt, bhtn, chế độ nghỉ phép \n",
      "================================================\n",
      "data-02-06/3043/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            mission: to ensure reports delivered with high quality in timely manner\n",
      "to ensure data in good quality to uploaded to the system and to improve efficiency of data processing\n",
      "\n",
      "accountabilities:\n",
      "• conduct checkings on reports prepared by bas to ensure reports delivered with highest quality in timely manner\n",
      "• joining with bas to investigate and complete reports if needed\n",
      "• to be the mentor for daily advise, guidance and coaching to the team members\n",
      "• joining with bas to investigate and complete reports if needed\n",
      "• to monitor and supervise progress and completion of other tasks done by bas or investigation specialist to ensure standard speed of service and quality\n",
      "• to be dedicated persons for some specific accounts in order to answer report- related inquries from clients; or guidence to suppliers to fulfill requested documents\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2083/data.html\n",
      "descriptions:\n",
      "\n",
      "identify client needs, draft project briefs to collect and optimize data for research projects.\n",
      "independently set up & manage assigned projects. quality control the research process and output deliverables.\n",
      "be responsible for data checking, interpreting data, and providing feedback to clients.\n",
      "summarize data for the production of tables, charts, and graphs.\n",
      "write/ develop reports and documents containing actionable recommendations and attend client ‘s presentation.\n",
      "make sure the reports are on schedule; the quality of the report is in accordance with the company’s standards and client requirements.\n",
      "regular & timely correspondence on clients’ inquiries and maintaining relationships with clients.\n",
      "provide in-depth market analysis – markets, consumers, campaign.\n",
      "put effort in ensuring multi projects are within set deadlines & time budgets.\n",
      "other tasks assigned by insight & account leader/manager.\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "job requirements:\n",
      "\n",
      "bachelor’s degree in marketing, economics, business administration, or related fields.\n",
      "at least 1 year experience in a research/insight role or related position.\n",
      "having experience in social listening is an advantage.\n",
      "working at an agency is a plus.\n",
      "be enthusiastic about social media empowerment and its possibilities to build strong brand propositions.\n",
      "be convenient for analyzing a variety of data types (number, text, image…) analysis.\n",
      "good at analytical and report writing skills.\n",
      "trend catching.\n",
      "willingness to analyze data points for large databases.\n",
      "strong interpersonal, negotiation and communication skills for liaising with colleagues, customers..\n",
      "english proficiency, especially in developing reports.\n",
      "proficient in office informatics, especially excel and powerpoint.\n",
      "\n",
      "why you’ll love working here: \n",
      "\n",
      "young, dynamic environment and freedom to creative.\n",
      "transparency and honesty are the 2 factors from our core value.\n",
      "trust with customer and commitment through standard quality products and solutions.\n",
      "human oriented.\n",
      "\n",
      "benefits include: \n",
      "\n",
      "100% salary during probation.\n",
      "working monday – friday.\n",
      "company trip, team-building and other social activities.\n",
      "work from home policy\n",
      "salary bonus, performance review\n",
      "gifts on holidays, birthday\n",
      "13th-month salary\n",
      "training-on-the-job\n",
      "\n",
      "contact info:\n",
      "\n",
      "email: recruitment@kompa.ai\n",
      "facebook: kompa life\n",
      "\n",
      "================================================\n",
      "data-02-06/2567/data.html\n",
      "================================================\n",
      "data-02-06/142/data.html\n",
      "mô tả công việc\n",
      "- chúng tôi đang tìm kiếm đồng đội data engineer với vai trò khai phá mỏ vàng dữ liệu hàng triệu khách hàng.- với vai trò này kỹ sư dữ liệu bao gồm phát triển kiến trúc dữ liệu có thể mở rộng, hợp lý hóa việc thu thập dữ liệu, thiết lập các quy trình mang dữ liệu lại với nhau từ nhiều nguồn và bảo vệ chất lượng dữ liệu bằng cách dọn dẹp dữ liệu bị hỏng. - thiết kế, phát triển và duy trì các giải pháp dữ liệu.- trình bày thông tin thông qua các báo cáo.- thiết kế, xây dựng và triển khai các giải pháp etl, bi, olap- duy trì và hỗ trợ các nền tảng phân tích dữ liệu- cộng tác với các nhóm để tích hợp hệ thống.- làm việc từ t2 đến t7 hàng tuần (8h-17h)\n",
      "yêu cầu\n",
      "- có kiến thức về phát triển data warehouse star schema - fact/dimension/snowflake/cap/ oltp/olap/ horizontal scale và vertical scale và khai phá dữ liệu.- sử dụng thành thạo ngôn ngữ lập trình java / python.- có \n",
      "-----------------------------------------------\n",
      "kinh nghiệm về data streaming (kafka/ storm/ samza/ aws kinesis...)- có kinh nghiệm sử dụng message queue (rabbitmq / google pubsub/ aws sns/ active mq)\n",
      "================================================\n",
      "data-02-06/3034/data.html\n",
      "================================================\n",
      "data-02-06/2166/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responsibilities: \n",
      "tiếp nhận yêu cầu từ chuyên viên ban báo cáo, tìm hiểu yêu cầu nghiệp vụ\n",
      "khảo sát, phân tích và đánh giá dữ liệu nguồn, thực hiện mapping dữ liệu nguồn với yêu cầu nghiệp vụ và cơ sở dữ liệu data warehouse\n",
      "thiết kế, xây dựng job/chương trình trích xuất dữ liệu\n",
      "thực hiện mapping dữ liệu nguồn với kho dữ liệu\n",
      "thiết kế, xây dựng, thực thi job trích xuất dữ liệu (etl)\n",
      "tham gia dự án và thực hiện các công việc được phân công trong phạm vi dự án\n",
      "thực hiện các công việc khác theo phân công của trưởng ban\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1947/data.html\n",
      "description\n",
      "ownership of designing, developing, building, testing and maintaining our next generation data etl platform\n",
      "champion the effort to continuously improving the efficiency and flexibility of the platform and services\n",
      "create web/app-based metric reports using standard frameworks\n",
      "pinpoint and clarify key issues that need action, lead the response and articulate results clearly in actionable form\n",
      "show a strong aptitude for carrying out solutions and translating objectives into a scalable solution that meets end customers’ needs within deadlines\n",
      "troubleshooting and debugging to optimise the performance\n",
      "take charge to recommend proactively and deploy methods to improve our data reliability, quality and efficiency\n",
      "support ad-hoc data related requests using mysql, s3 and aws redshift \n",
      "job requiments\n",
      "bachelor's degree in computer science, software or computer engineering, applied math, physics, statistics, or a related field, preferred\n",
      "at least 3 years of hands-on working \n",
      "-----------------------------------------------\n",
      "experience in data/software engineering in a highly scalable production environment\n",
      "2 years of experience developing data warehouses on snowflake platform, required\n",
      "good knowledge of architecting large-scale data infrastructure in the cloud platform good knowledge of big data technologies like hadoop,hive,spark, redshift aws or other real-time streaming\n",
      "good knowledge of server-side programming languages (preferably python) and golang.\n",
      "devops experience (devops or gitlab) delivering continuous improvements\n",
      "data visualization and dashboarding experience (power bi, tableau, etc.)\n",
      "================================================\n",
      "data-02-06/2129/data.html\n",
      "================================================\n",
      "data-02-06/792/data.html\n",
      "description \n",
      "\n",
      "job responsibilities (include, but not limited to):\n",
      "– monitor model production and testing processes; monitor dataset production; investigate and troubleshoot issues\n",
      "– address questions from internal consumers relating to market data, examine datasets and interact with vendors\n",
      "– compile and analyze model production statistics and produce specialized reports\n",
      "job qualifications:\n",
      "– \n",
      "-----------------------------------------------\n",
      "experience working in unix/linux; familiar with bash scripting\n",
      "– the candidate must have knowledge of computer systems, object oriented design, data structures and algorithms and familiarity with at least one major programming language (perl, python, java, c++), experience with relational databases (mysql)\n",
      "– bachelor’s degree required; degree in computer science/electrical engineering or\n",
      "related field preferred\n",
      "– strong written and verbal communication skills\n",
      "– excellent analytical skills and a passion for solving problems\n",
      "– be detail oriented and capable of multitasking and delivering in fast-paced work environment\n",
      "\n",
      "================================================\n",
      "data-02-06/2097/data.html\n",
      "================================================\n",
      "data-02-06/2581/data.html\n",
      "================================================\n",
      "data-02-06/2972/data.html\n",
      "================================================\n",
      "data-02-06/2534/data.html\n",
      "mô tả công việc\n",
      "tổ chức và phân tích dữ liệu từ các nguồn dữ liệu có sẵn (doanh thu, chi phí, lợi nhuận theo ngành hàng, theo siêu thị, theo bộ phận, theo ngày/tháng/quý/năm ...).trực quan hóa dữ liệu bằng hệ thống bảng biểu, đồ thị, giúp người đọc hiểu được các thông tin chi tiết.trình bày các báo cáo, phát hiện cho các bên có liên quan, đưa ra các nhận định và đề xuất các ý kiến đóng góp cho các quyết định liên quan đến vận hành (phát triển danh mục sản phẩm, chương trình khuyến mãi, ...)một số công việc khác theo yêu cầu \n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "học vấn: tốt nghiệp đại học các chuyên ngành: qtkd/ kinh tế/ toán tin ứng dụng/toán thống kê/ tài chính hoặc các ngành có liên quan.kinh nghiệm từ 1-3 năm tại vị trí tương đương ngành hàng bán lẻ, chuỗi siêu thị, fmcg ...kỹ năng cần thiết: phân tích dữ liệu (excel, power bi, ...)kỹ năng trình bày báo cáo, thuyết trìnhtư duy logic\n",
      "quyền lợi\n",
      "lương cạnh tranh, lương tháng 13++, thưởng cuối năm.phụ cấp cơm 50.000/ngàythời gian làm việc: từ 8h-17h00, t2-t6phụ cấp ngoại ngữ hấp dẫn, lên đến 3.000.000/tháng (anh, hàn)chế độ bhxh, bhyt, bhtn trên tổng thu nhập; bảo hiểm tai nạn 24h; bảo hiểm chăm sóc sức khỏe.môi trường làm việc năng động, có nhiều cơ hội đào tạo và thăng tiến.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "hết hạn nộp đơn\n",
      "\n",
      "================================================\n",
      "data-02-06/1633/data.html\n",
      "================================================\n",
      "data-02-06/2086/data.html\n",
      "================================================\n",
      "data-02-06/2001/data.html\n",
      "================================================\n",
      "data-02-06/2493/data.html\n",
      "================================================\n",
      "data-02-06/890/data.html\n",
      "descriptionthe bosch group is a leading global supplier of technology and services. in 2013, its roughly 281,000 associates generated sales of 46.4 billion euros. since the beginning of 2013, its operations have been divided into four business sectors: automotive technology, industrial technology, consumer goods, and energy and building technology. the bosch group comprises robert bosch gmbh and its roughly 360 subsidiaries and regional companies in some 50 countries. if its sales and service partners are included, then bosch is represented in roughly 150 countries. this worldwide development, manufacturing, and sales network is the foundation for further growthrbvh - robert bosch engineering and business solutions vietnam company limited is 100% owned subsidiary of robert bosch gmbh. rbvh has started its operations from 19th october, 2010 at e-town2 in hcmc. this engineering development center will be engaged in developing embedded systems and software, mechanical design and simulation, and will provide it (sap consulting, java development….) and business services (finance and accounting, economics, purchasing, logistics, translations japanese-english-japanese, information security ) solutions to the bosch group of companies globally. job descriptioncreate data model based on data sourcegenerate different kinds of powerbi reportrequirement verificationtask estimationunit testingqualificationsbachelor degree in it/ computer science or relevant backgroundhave at least 4 years of \n",
      "-----------------------------------------------\n",
      "experience in power bi developmenthands-on experience in sql query in sql serverhands-on experience in sql server integration services (ssis)hands-on experience in  sql server reporting services (ssrs)good at unit testing and integration test strategieswilling to support team members/others on db-related tasksgood english communication skillsmust be able to multi-task and deal with changing prioritiesadditional informationwhy bosch?because we don't just follow trends, we create them.because together we turn ideas into reality, working every day to make the world of tomorrow a better place. do you have high standards when it comes to your job? so do we. at bosch, you will discover more than just work.benefits and career opportunitiesworking in one of the best places to work in vietnamjoin a dynamic and fast growing global company (english-speaking environment)13th-month salary bonus + attractive performance bonus (you'll love it!) + annual performance appraisal100% monthly basic salary and mandatory social insurances in 2-month probationonsite opportunities: short-term and long-term assignments15++ days of annual leave + 1 day of birthday leavepremium health insurance for employee and 02 family membersflexible working timelunch and parking allowancevarious training on hot-trend technologies/ foreign language (english/chinese/japanese) and soft-skillsfitness & sport activities: football, badminton, yoga, aerobicfree in-house entertainment facilities and snackjoin in various team building, company trip, year-end party, tech talks and a lot of charity event\n",
      "================================================\n",
      "data-02-06/1517/data.html\n",
      "================================================\n",
      "data-02-06/3076/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "                                                                                            the business intelligence developer is a member of the data and analytics team. the business intelligence analyst will work hand-in-hand with business stakeholders to assess needs and deliver data products that support and enhance decision-making. this individual will be well versed in data warehousing, and data reporting, particularly with scripting languages such as sql, and dashboard creation using visualization tools such as power bi. this position will require a high degree of attention to detail along with the ability to review calculations for quality assurance as well as solid communication and organization skills. \n",
      "the business intelligence developer will work at mitek vietnam as a part of the global data group.\n",
      "\n",
      "duties & responsibilities\n",
      "•\tability to build power bi reports/dashboards and reports by connecting to varied data sources.\n",
      "•\testimate technical requirements and breaks down work to user stories and tasks.\n",
      "•\tdesign and work on proof of concepts that can be demonstrated to the customer.\n",
      "•\tperform data cleaning & data profiling\n",
      "•\toptimize report performance.\n",
      "•\tprepare holistic documentations (process and technical) to enable proper knowledge transfer between both the data team as well as current/future users.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1629/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "* what our projects are about: we design, develop and maintain enterprise bi/data warehouse/data lake for clients in various domains. depending on our availability and your suitability, you may be assigned to projects with english-speaking or vietnamese-speaking clients, on-premises or cloud technologies etc. you will work with the following roles: project manager, data architect, data analyst, data scientist.- build optimal data pipelines- build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using sql and aws/gcp/azure technologies- identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, redesigning infrastructure for greater scalability, etc.- collaborate with clients and internal cross-functional teams including the executive, product, data, and business teams- work with data and analytics experts to strive for greater functionality in our data systems* benefits:- salary: max 40m;- working time: 8:30-18:00 (off 1.5h from 12h to 13h30 for lunch) from monday to friday- flat structure- salary review twice a year- friendly, supportive and transparent environment - we notice and celebrate our team members’ accomplishments monthly- 13th month salary, annual heath-check, insurance under vietnamese labor law, monthly teambuilding- bic health insurance package- psychological safety; your ideas are always welcomed.\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2599/data.html\n",
      "mô tả công việc\n",
      "\n",
      "quản lý, phát triển đội ngũ chuyên viên phân tích dữ liệu kinh doanh (business intelligence) của ngân hàng, tập trung vào cung cấp thông tin đầy đủ và chuyên sâu để đưa ra các quyết định kinh doanh\n",
      "đưa ra các góc nhìn chuyên sâu từ nguồn dữ liệu để trả lời các vấn đề về kinh doanh, giúp ra các quyết định dựa trên dữ liệu và đề xuất các phương án cải tiến vận hành cho ngân hàng.\n",
      "chủ động quản lý triển khai kế hoạch về phân tích dữ liệu kinh doanh (bi) của ngân hàng, sắp xếp mức độ ưu tiên các công việc để đảm bảo cân bằng giữa các nhu cầu ngắn hạn và các nhu cầu chiến lược của ngân hàng. tham gia điều phối các dự án xây dựng các dashboards phục vụ quản trị của ngân hàng.\n",
      "trình bày các phân tích và khuyến nghị cho ban lãnh đạo, sử dụng kỹ năng dẫn dắt dựa trên kết quả phân tích dữ liệu để nâng cao hiệu quả vận hành và mang lại các thay đổi chiến lược cho ngân hàng. hỗ trợ ban lãnh đạo rà soát / điều phối quá trình thu thập thông tin, phân tích số liệu cho mục đích xây dựng chiến lược kinh doanh của ngân hàng.\n",
      "phối hợp với các phòng ban khác để đưa ra các sáng kiến về phân tích dữ liệu kinh doanh (bi) nhằm nâng cao hiệu quả hoạt động, giảm chi phí và nâng cao doanh số bán hàng.\n",
      "phối hợp với cntt để xây dựng các công cụ phân tích dự báo.\n",
      "chịu trách nhiệm chính trong việc định nghĩa và quản trị các chỉ tiêu kinh doanh, xây dựng các dashboards tự động và khả năng tự phục vụ trong phân tích số liệu của các phòng ban khác, xây dựng các quy trình về phân tích dữ liệu.\n",
      "đảm bảo các chuyên viên phân tích số liệu có đầy đủ công cụ, kỹ năng và kiến thức để hoàn thành công việc được giao\n",
      "\n",
      "yêu cầu tuyển dụng\n",
      "1. bằng cấp, chứng chỉ\n",
      "tốt nghiệp đại học ngành tài chính, kinh tế, toán thống kê ….\n",
      "2. \n",
      "-----------------------------------------------\n",
      "kinh nghiệm\n",
      "\n",
      "ít nhất 5 năm kinh nghiệm trong mảng phân tích số liệu (bi).\n",
      "ít nhất 2 năm kinh nghiệm quản lý đội ngũ phân tích số liệu có từ 3 chuyên viên trở lên.\n",
      "\n",
      "3. kỹ năng, yêu cầu khác\n",
      "\n",
      "am hiểu sản phẩm, dịch vụ ngành ngân hàng.\n",
      "kỹ năng phân tích và giải quyết vấn đề tốt.\n",
      "kỹ năng giao tiếp, thuyết trình, thuyết phục và quản lý dự án tốt.\n",
      "quen thuộc với cơ sở dữ liệu (sử dụng ngôn ngữ sql), hiểu được mô hình dữ liệu và các liên hệ. có thể làm việc được với các kỹ sư dữ liệu và chuyên viên phân tích dữ liệu để xây dựng các bảng dữ liệu, các data marts cần cho công việc của bộ phận.\n",
      "có kỹ năng xây dựng dashboard bằng các công cụ như power bi, data studio ….\n",
      "quen thuộc với python và các công cụ để hỗ trợ xử lý dữ liệu lớn.\n",
      "\n",
      "================================================\n",
      "data-02-06/2483/data.html\n",
      "description\n",
      "                \n",
      "as our new database sql developer, you'll be an essential part of our dynamic it operations department. you'll be responsible for improving our group database systems performance, with a key focus on improving our applications sql queries, stored procedures and objects. working with our team of experts, you'll be initiated to all aspect of database administration, this position will offer you the possibility to grow your technical skills.\n",
      "\n",
      "design and develop sql queries, stored procedures, and database objects\n",
      "develop and maintain etl processes for importing and exporting data\n",
      "create and maintain performance reports\n",
      "optimize database performance through query optimization, indexing, and other techniques\n",
      "collaborate with cross-functional teams to design and implement database solutions that meet business requirements\n",
      "troubleshoot and resolve database-related issues\n",
      "participate in database design and architecture discussions\n",
      "ensure that database systems meet security and compliance requirements.\n",
      "\n",
      "our ideal candidate\n",
      "\n",
      "3+ years of experience working as a sql developer or backend developer\n",
      "strong experience with microsoft sql server\n",
      "experience with etl processes and tools\n",
      "knowledge of database design and architecture principles\n",
      "experience with reporting tools such as ssrs or power bi\n",
      "strong analytical and problem-solving skills\n",
      "excellent communication and collaboration skills\n",
      "\n",
      "nice to have\n",
      "\n",
      "experience with cloud database technologies such as azure sql database\n",
      "familiarity with data warehousing concepts and technologies\n",
      "experience with postgressql and nosql databases such as mongodb\n",
      "\n",
      "why us?\n",
      "\n",
      "being part in an international and multicultural environment\n",
      "fast growing global company, opportunities to grow quickly with a tailored made career path\n",
      "soft skill trainings: interpersonal communication, team management, project management\n",
      "ability to support non-profit organizations\n",
      "you will have the opportunity to unlock your potential, both professional and personally\n",
      "\n",
      "mantu group is proud to be an equal opportunity workplace. we are committed to promoting diversity within the workforce and creating an inclusive working environment. for this purpose, we welcome applications from all qualified candidates regardless of gender, sexual orientation, race, ethnicity, beliefs, age, marital status, disability or other characteristics.\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3155/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact info\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "the responsibility of this this role will be:\n",
      "\n",
      "responsible for the structuring and execution of the company’s in-house data construction and management.\n",
      "responsible for integration and analysis on etl and varieties of data sources•participate in etl implementation and enhancement.\n",
      "work with business analyst to understand the technical & business requirements.\n",
      "work with data integration technologies such as ssis, azure data factory, function app.\n",
      "work with data storage tools such as azure blob, azure sql, mongodb.\n",
      "\n",
      "key skills & responsibility\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "experience in relevant domain (crm, big data, business intelligence, analytics reporting).\n",
      "experience with etl, data management, transformation, and modelling•experience with cloud technologies•required knowledge in sql, c#, .net.\n",
      "experience with reporting service like ssrs.\n",
      "knowledge and experience in end-to-end project delivery, hybrid / agile delivery methodologies•previous experience as a data engineer or in a similar role.\n",
      "technical expertise with data models, data mining, and segmentation techniques.\n",
      "knowledge of programming languages •hands-on experience with sql database design.\n",
      "great numerical and analytical skills•degree in computer science, it, or similar field•data engineering certification will be plus•good communication skill.\n",
      "\n",
      "qualification\n",
      "\n",
      "bachelors or masters in it or computer science.\n",
      "master or equivalent.\n",
      "\n",
      "soft skills\n",
      "\n",
      "excellent written and verbalcommunication skills.\n",
      "capacity to manage high stress situations.\n",
      "ability to multi-task and manage various project elements simultaneously.\n",
      "leadership skills•big picture thinking and vision.\n",
      "attention to detail•conflict resolution skills.\n",
      "\n",
      "to apply for an interview with savills, please send your cv (with your photo attached) and a clear summary of why you believe you have a strong fit with savills. further to specific advertised vacancies, savills vietnam encourages applications from talented individuals who feel they have what it takes to succeed at savills and in the real estate market.\n",
      "for career opportunities, please email your cv and cover letter to careers-hcmc@savills.com.vn\n",
      "apply now\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/1555/data.html\n",
      "descriptionkms was established in 2009 as a u.s.-based software development & consulting company with development centers in vietnam. over 13 years of operation, we have been trusted globally for the superlative quality of software services, products, technology solutions and engineers' expertise.kms technology focuses on custom software development and a wide variety of consulting serviceskms healthcare specialises in the healthcare industry, provides a unique blend of consultative healthcare technology solutions backed by the power of full lifecycle development supportkms solutions serves the asia pacific region, bringing the world's innovative technologies to help organizations achieve their business goals through world-class digital capabilities and fit-for-purpose solutionsbesides providing services, kms builds and successfully launches its own software companies through its internal startup incubator, kms labs. the most notable companies with millions of users worldwide include qasymphony, kobiton, katalon, grove, and visily.kms is committed to providing tangible contributions and long-lasting impacts to the communities through leveraging our it expertise. the company has also been recognized by prestigious industry awards as a great workplace in vietnam, asia, and the u.s. for many years in a row.job descriptionstudy and transform data science prototypesdesign and develop machine learning systemsresearch and implement appropriate ml algorithmsperform statistical analysis and fine-tuning using test resultstrain and retrain systemextent existing ml libraries if necessaryfollow given procedures and instructions to produce well-designed, testable and clean codeperform other duties as assignedqualifications3+ years of \n",
      "-----------------------------------------------\n",
      "experience in developing machine learning/data science applicationstrong experience in computer visionstrong programming skills in python, javascriptgood foundation in math and algorithmshave knowledge of neural networksexperience in using ml frameworks such as tensorflow/ keras/ pytorchadditional informationperks you'll enjoy\n",
      "================================================\n",
      "data-02-06/2649/data.html\n",
      "mô tả công việc\n",
      "– nghiên cứu, cài đặt, cải tiến các mô hình xử lý xử lý ảnh, thị giác máy tiên tiến trên thế giới.\n",
      "– xây dựng hệ thống giám sát băng tải, kho hàng.\n",
      "– xây dựng hệ thống ekyc, chấm công.\n",
      "ii. yêu cầu\n",
      "– có kiến nền tảng về xác suất thống kê.\n",
      "– có kiến thức tốt về thuật toán, học máy.\n",
      "– có tư duy và kỹ năng lập trình tốt.\n",
      "– có khả năng đọc tài liệu, các bài báo khoa học bằng tiếng anh.\n",
      "– có \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1957/data.html\n",
      "================================================\n",
      "data-02-06/2203/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- nghiên cứu, thiết kế và duy trì tối ưu hệ thống xử lý dữ liệu cho bảng điều khiển phân tích  thời gian thực, theo dõi và báo cáo sự cố.\n",
      "- tự động hóa các quy trình thủ công, tối ưu hóa việc cung cấp dữ liệu, thiết kế lại cơ sở hạ tầng  để tăng phạm vi mở rộng, đảm bảo tính ổn định và toàn vẹn dữ liệu. \n",
      "- xây dựng tool sets/framework để thu thập dữ liệu trên internet trên quy mô lớn. - sử dụng message queue, microservice, docker để kiểm soát đường ống dữ liệu, cải thiện và  mở rộng đường ống chịu lỗi để tích hợp lượng lớn dữ liệu từ nhiều nguồn dữ liệu, với nhiều  định dạng dữ liệu.\n",
      "- làm việc với các bên liên quan để xác định thông số kỹ thuật hệ thống, lập kế hoạch và thiết  kế kiến trúc hệ thống, lựa chọn phần mềm hoặc phần cứng thích hợp và đề xuất các phương  pháp tích hợp.\n",
      "- đánh giá và phát triển các công nghệ / giải pháp mới để làm cho cơ sở hạ tầng đáng tin cậy  hơn, tính sẵn sàng cao và quy mô lớn.\n",
      "* quyền lợi được hưởng\n",
      "- mức lương – thưởng\n",
      "+ junior: khởi điểm up to 18.000.000 vnđ\n",
      "+ senior: lương up to 40.000.000 vnđ. đối với ứng viên có \n",
      "-----------------------------------------------\n",
      "kinh nghiệm sẽ thỏa thuận dựa trên năng lực, đảm bảo mức cạnh tranh so với thị trường.\n",
      "- hưởng từ 13-16 tháng lương/năm, chưa tính các khoản thưởng khác.\n",
      "- được tham gia vào các dự án lớn đang đang triển khai tại các cơ quan nhà nước, các tập đoàn, \n",
      "================================================\n",
      "data-02-06/435/data.html\n",
      "================================================\n",
      "data-02-06/2918/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            •\tcomplete analytical projects from start to finish (data gathering and manipulation, overall analytical assessment, project documentation, communication packaging, and presentation of results). interpret data and analyze results using exploratory and statistical techniques.\n",
      "•\tcreate data visualizations to help understand the analytic results.\n",
      "•\tdevelop and implement data collection systems and other strategies that optimize statistical efficiency and data quality.\n",
      "•\tacquire data from corporate data warehouse and other secondary data sources.\n",
      "•\tidentify, analyze, and interpret trends or patterns in complex datasets.\n",
      "•\twork closely with managements to prioritize business and provide end users the reporting to identify the improvement opportunities.\n",
      "•\tdevelop new innovations in the use of data and data mining techniques.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2269/data.html\n",
      "mô tả công việc\n",
      "\n",
      "1. demand planning:\n",
      "• ensure sale forecast at sku levels of aggregation for sales forecast & demand planning consistency, through the building of a consensus between sales forecasts, sales history and the financial trend.\n",
      "• analyse historical sales in order to classify demand and build up safety stock and re-order point at sku level to ensure smooth execution of the planning process.\n",
      "2 supply planning control:\n",
      "• build up replenishment for each sku to make decision when to order. ensure optimal stock level, ensure correct stock allocation.\n",
      "• manage stock allocation in case of insufficient supply from wh, 3pl.\n",
      "• monthly update optimal min – max stock level for all store’s as a basis for daily replenishment\n",
      "• create goods primary transfer plan across centralize wh and stores, dc’s ensuring supply for the category in charge.\n",
      "• track the actual vs plan to ensure supply as per order target set.\n",
      "• collaborate with demand planning to optimize primary cost as per budget\n",
      "3. collaboration:\n",
      "• coordinate with merchandise (buyer), allocate team to ensure sustainable goods supply for store’s supersports with all basic requirements on quantity and timely basis.\n",
      "• collaborate with logistic team to work on relevant resource readiness to streamline the products flow from warehouse to dc’s, store’s.\n",
      "4. risk management of supply planning\n",
      "• control product life cycle in collaboration with stakeholder’s in order to maintain sku rationalization.\n",
      "5. planning system implementation:\n",
      "• responsible for updating relevant item master data real time\n",
      "6. others:\n",
      "• follow the kpi: inventory turn, fill rate, demand planning accuracy, aging stock\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "• bachelor degree in supply chain management, business analytics, business administration\n",
      "• more than 2\n",
      "================================================\n",
      "data-02-06/3039/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "                                                                                            this position will be responsible for analyzing data, preparing reports and dashboard to support decision making, identifying areas for improvement in order to improve efficiency and effectiveness.\n",
      "\n",
      "key accountabilities\n",
      "•\tcollect and analyze data to identify trends, patterns, and opportunities for improvement\t\n",
      "•\tprepare monthly/ quarterly/ ad-hoc reports and dashboard\t\n",
      "•\tbuilds and manages databases by organizing and analyzing a wide range of data source\n",
      "•\tcollaborate with cross-functional teams to collect data and coordinate activities\t\n",
      "•\tstay up-to-date with industry trends and best practices \n",
      "•\tdesign the smart report\t\n",
      "\n",
      "key performance indicators:\n",
      "•\ttimeliness and accuracy of relevant reports and dashboards\t\n",
      "•\tcost optimization\t\n",
      "•\tnumber of initiatives/ recommendations to drive business process improvement\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3042/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            1.\tcollection and sorting of data from various sources;\n",
      "2.\tstructure unformatted data and interpret results;\n",
      "3.\tprepare data presentations after necessary data processing;\n",
      "4.\tmake recommendations to adapt to existing business strategies;\n",
      "5.\tfinding authentic data sources;\n",
      "6.\tpresent and preparing charts and other consumable data in a visual form;\n",
      "7.\tbuild algorithms and machine learning models;\n",
      "8.\tcorrelating data to form actionable insights;\n",
      "9.\tcombine models through ensemble modeling;\n",
      "10.\tbuild predictive models;\n",
      "11.\tenhance data collection process;\n",
      "12.\tdevelop, implement and maintain databases;\n",
      "13.\tdevelop a/b testing framework to test data quality;\n",
      "14.\tautomate data collection processes;\n",
      "15.\tfilter data and create valuable reports.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2298/data.html\n",
      "descriptioncolliers (nasdaq, tsx: cigi) is a leading global real estate services and investment management company. with operations in 68 countries, our 14,000 enterprising people work collaboratively to provide expert advice and services to maximize the value of property for real estate occupiers, owners and investors. for more than 20 years, our \n",
      "-----------------------------------------------\n",
      "experienced leadership team, owning more than 40% of our equity, have delivered industry-leading investment returns for shareholders.job descriptionfollow line manager to lead the team conducting the valuation for residential & commercial real estate properties.build, maintain, expanse and enhance client relationships in order to achieve the business plan for valuation & advisory team.responsible for administering, managing and controlling the operation of the team to achieve the business performance as well as to ensure compliance of valuation standards (both international and vietnam), vietnam laws. ensuring that all policies and procedures are adhered to so that consistent and standard practice is achieved across the colliers group.recruit, supervising, training, developing staff on valuation and client requirements as well as assessing staff performance. leading and training the team in valuation approach (income approach; market approach, cost approach), carry out feasibility study and market research, highest and best use report for real estate development consulting.design and implement databases for ease of reference of up-to-date market information and establish systems to ensure that those databases are accurate and up to date at all times.prepare as required market weekly and monthly reports and other studies, documents as instructed by the line manager.at all times to be aware of activity within the marketplace relevant to your field of operation and be mindful of developing such information received into business opportunities for the company.various other job related tasks as assigned by the bod.qualificationsbachelor's degree in finance, economics or related fieldmof license or mrics is in a must.5+ years of property valuation consulting experience.in-depth knowledge of valuation approaches: cost, market, and income approach; experience in financial modelling, real estate project feasibility study.strong analytical and problem-solving skills, as well as strong team building, interpersonal and communication skills (both written and oral).presentation skill is required.ability to work independently, exercising good initiative and judgementproficiency with microsoft excel, word, and powerpoint.flexibility for travel to conduct the sites inspection and market research\n",
      "================================================\n",
      "data-02-06/2394/data.html\n",
      "================================================\n",
      "data-02-06/961/data.html\n",
      "responsibilities: \n",
      "\t                \t            \n",
      "\n",
      "participate to the development of our software with sql database and c.\n",
      "analyze client’s requirements\n",
      "design and develop new features according to detailed specifications\n",
      "\n",
      "\t                \t                    requirements: \n",
      "\t                \t            \n",
      "you have:\n",
      "\n",
      "    an university degree in computer science or equivalent technical area.\n",
      "    fluent usage of c or c++.\n",
      "    good skills of sql.\n",
      "    conceptual knowledge of relational databases\n",
      "    good command of english\n",
      "\n",
      "your profile enhancers:\n",
      "\n",
      "    practical \n",
      "-----------------------------------------------\n",
      "experience as a developer\n",
      "    knowledge of oracle / pro c / pl-sql\n",
      "    good command of french is a plus\n",
      "    experience with network programing, unit environment and good knowledge of the voip network is a plus.\n",
      "\n",
      "personality requirements\n",
      "\n",
      "- hard working, responsible, creative, strong interpersonal and communication skills.\n",
      "\n",
      "- ability of working independent and teamwork\n",
      "\n",
      "\t                \t                    we offer: \n",
      "\t                \t            \n",
      "successful candidate will come in one of the european subsidiaries for 3 months internal training to our methods and product.\n",
      "opportunity to work with international company, high reputation clients on the financial, commercial financial fields: silicon valley bank, bnp parisbas, societe generale, ge capital, ups capital kbc, barclays, bbva, france telecom orange, etc.\n",
      "salary range: attractive, or negotiable depending your expertise and experience.\n",
      "social and health insurance: according to the current government regulations competitive remuneration package including performance driven benefits:soft skill training, 13th month salary, project bonus, loyalty program (3% of your total annual income), key person package (yearly bonus, monthly telephone fee, health insurance for your dependents), additional health care program - generali, annual health examination, lunch allowance (840,000 vnd/month), activities: company trip, football, volleyball ...\n",
      "trainings and continuous investment into your professional development\n",
      "friendly work environment with international working standards\n",
      "                                                send your cv by clicking \n",
      "                            \n",
      "                                here. apply now!\n",
      "                            we are eager to meet you!\n",
      "================================================\n",
      "data-02-06/450/data.html\n",
      "responsibilities include conducting a fully digital banking product lifecycle analysis including analyzing requirements, conducting analyses, developing reports, dashboards, and data insight recommendations, also monitor performance and quality control to identify improvements.\n",
      "what you will do\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "understand product & processes\n",
      "interpret data, analyze results using statistical techniques and provide ongoing reports\n",
      "develop and implement databases, data collection systems, data analytics, and other strategies that optimize statistical efficiency and quality\n",
      "acquire data from primary or secondary data sources and maintain databases/data systems\n",
      "identify, analyze, and interpret trends or patterns in complex data sets\n",
      "work with management to prioritize business and information needs\n",
      "locate and define new process improvement opportunities\n",
      "\n",
      "what you need to have\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bachelor's degree in mathematics, economics, finance, computer science, data science, information management, or statistics. proven working \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2606/data.html\n",
      "================================================\n",
      "data-02-06/1973/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responsibilities: \n",
      "nghiên cứu các xu hướng và đề xuất các giải pháp, ứng dụng hoặc mô hình sử dụng trí tuệ nhân tạo (ai)/ dữ liệu lớn (big data) và các công nghệ mới (videocall, nfc, blockchain, ar/vr,..) vào hoạt động sản xuất kinh doanh của ngân hàng\n",
      "tham gia tìm kiếm, thẩm định và tư vấn lựa chọn giải pháp của các đối tác và nhà cung cấp có công nghệ hiện đại, phù hợp với xu hướng chuyển đổi số\n",
      "phối hợp cùng các phòng ban bộ phận khác và đối tác công nghệ trong việc nghiên cứu phát triển ứng dụng giải pháp công nghệ mới.\n",
      "thực hiện các công việc khác theo sự phân công của cán bộ quản lý\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2937/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            1.\tinstallation, configuration and upgrading of database server software (oracle, ms sql, my sql, ..) and related products.\n",
      "2.\tmonitoring system performance and identifying problems that arise.\n",
      "3.\testablish and maintain sound backup and recovery policies and procedures.\n",
      "4.\tannually perform switchover databases to dr site to ensure standby databases working well.\n",
      "5.\tupgrade or patching databases when required.\n",
      "6.\tsuggesting changes and improvements for database maintenance or protection.\n",
      "7.\tprotecting the database against threats or unauthorized access.\n",
      "8.\tplan growth and changes (capacity planning).\n",
      "9.\twork as part of a team and provide 24x7 support when required.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1751/data.html\n",
      "================================================\n",
      "data-02-06/836/data.html\n",
      "================================================\n",
      "data-02-06/2156/data.html\n",
      "description\n",
      "\n",
      "\n",
      "life at agoda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "all teams\n",
      "contentcustomer \n",
      "-----------------------------------------------\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "senior business intelligence analyst (bangkok based, relocation provided)\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "================================================\n",
      "data-02-06/1641/data.html\n",
      "================================================\n",
      "data-02-06/1175/data.html\n",
      "responsibilities: \n",
      "\n",
      "\n",
      "support brand, marketing and communication business\n",
      "\n",
      "\n",
      "support quality and management of the internal and/or external communications initiatives to support communications\n",
      "\n",
      "\n",
      "preparation, implementation & evaluation of event plan; ensure marketing campaign efficiency and effectiveness to reach the defined brand goals\n",
      "\n",
      "\n",
      "develop relevant content & coordinate with business team and other stakeholders to communicate and acquire adequate resources to ensure effectiveness of outputs\n",
      "\n",
      "\n",
      "conduct market researches & update business intelligence\n",
      "\n",
      "\n",
      "​\n",
      "apply now \n",
      "email your cv to recruitment@cel-consulting.com \n",
      "or apply online at\n",
      "​\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1250/data.html\n",
      "================================================\n",
      "data-02-06/2834/data.html\n",
      "================================================\n",
      "data-02-06/2708/data.html\n",
      "mô tả công việc\n",
      "1. mảng data: (70%)- tham gia xây dựng và quản trị các hệ thống danh mục, master data. tham gia cấu trúc, chuẩn hóa các luồng dữ liệu- kết nối dữ liệu giữa các hệ thống crm, hệ thống kcb và các nền tảng khách hàng khác- thiết lập các chỉ số tracking kinh doanh/mkt hàng tuần, hàng tháng, đưa ra cảnh báo và dự báo- triển khai xây dựng và tự động hóa hệ thống báo cáo, chi tiết cho ban giám đốc công ty và các cấp quản lý để theo dõi hiệu suất và công việc kinh doanh, vận hành- sử dụng các công cụ bi (power bi, data studio…) để thiết kế hệ thống báo cáo cho các bộ phận kinh doanh và vận hành trong công ty.- đề xuất các công cụ, các cấu trúc và luồng dữ liệu hoặc phương án nâng cao việc tự động hóa và tính chính xác của báo cáo2. phần hạ tầng/it support: (30%)- hỗ trợ nhân sự dưới cơ sở trong việc quản lý, phân chia đầu việc vận hành- thẩm định các phương án đề xuất về dịch vụ công nghệ, hạ tầng, thiết bị- định hướng nhân sự it dưới cơ sở dưới góc độ data\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "- tốt nghiệp đại học, cao đẳng về chuyên ngành kinh doanh, công nghệ thông tin, toán học hoặc các chuyên ngành liên quan khác.- có kinh nghiệm làm việc trong ngành phân tích dữ liệu là một lợi thế. hoặc bạn sẽ phải chấp nhận làm thực tập sinh hoặc nhân viên học việc tại các doanh nghiệp.- có khả năng sử dụng các công cụ, phần mềm phân tích dữ liệu- có khả năng code cơ bản với các ngôn ngữ lập trình như sql, python để xử lý mô hình dự báo.- có kỹ năng phân tích sắc bén, khả năng thu thập, tổ chức, phân tích và phổ biến lượng lớn thông tin một cách chi tiết và chính xác- kỹ năng lập kế hoạch, kiểm soát việc thực hiện kế hoạch.- cẩn thận, kiên nhẫn, chịu khó, ham học hỏi, có tinh thần trách nhiệm\n",
      "quyền lợi\n",
      "'- mức lương: \n",
      "================================================\n",
      "data-02-06/1674/data.html\n",
      "================================================\n",
      "data-02-06/2610/data.html\n",
      "================================================\n",
      "data-02-06/1828/data.html\n",
      "mô tả công việc\n",
      " - chịu trách nhiệm về nhập liệu lên hệ thống tất cả các đơn hàng (oversea, local, fedex…)\n",
      "- quản lý số liệu và chứng từ liên quan khâu nhập hàng\n",
      "- sắp xếp, lưu trữ và bàn giao hóa đơn định kỳ cho kế toán\n",
      "- transfer- issue số liệu trên hệ thống oracle theo yêu cầu\n",
      "- xử lý các công việc phát sinh của data trên hệ thống\n",
      "- hỗ trợ các công việc liên quan đến data team\n",
      "- các công việc khác theo yêu cầu của cấp trên \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2036/data.html\n",
      "responsibility:-design, generate, analyze and develop regular and ad-hoc hr reports ex. hr dashboard etc. -assist in development of standard hr reports for ongoing customer needs by using appropriate tools. help maintain data integrity in systems by running queries and analysing data -handle hr management system for direct hire staff -support management on structural policy matters related to the hris. -work alongside the it department to perform regular assessments and improvements to the hris. -ensure all hr-related systems are compliant with data protection laws. -carry out the tasks assigned by superior.​\n",
      "-----------------------------------------------\n",
      "job requirement:minimum 4 years experience in it, data analyzing, building system for employee information management.familiar with power bi, sql, excelbachelor/ college degree in hr, business administration, it or related field.good communication in english and presentation skills.high pressure ability\n",
      "\n",
      "================================================\n",
      "data-02-06/802/data.html\n",
      "description: \n",
      "\n",
      " understand \"pain points\" from the business, analyze, prepare data, develop statistical model development/ machine learning algorithms/ other ai techniques\n",
      " perform tracking and optimization of implemented/operationalized models\n",
      " provide advanced analytics focus on forecasting future events and behaviors, enabling businesses to conduct what-if analyses to predict the effects of potential changes in business strategies\n",
      "\n",
      "requirement: \n",
      "1/ educationai quaiifications\n",
      "\n",
      "minimum graduated from university or above/ or master degree in economics/ statistics/ mathematics\n",
      "\n",
      "2/ relevant knowiedge/ expertise\n",
      "\n",
      "proficient in python, r\n",
      "hands-on \n",
      "-----------------------------------------------\n",
      "experience on machine learning, deep learning, statistics\n",
      "skillful in using excel, powerpoint and word as the primary working tools\n",
      "\n",
      "3/ skills\n",
      "\n",
      "quick and flexible learning skills to adapt to new things and work on multiple tasks\n",
      "skill of communication, human relations, building relationships with stakeholders.\n",
      "identification and problem-solving skills\n",
      "critical thinking skills\n",
      "teamwork skill\n",
      "presentation and negotiation skills\n",
      "analysis and conflict management skills\n",
      "coordinating personnel and work skills\n",
      "building relationships with customers skills\n",
      "\n",
      "4/ relevant experiences\n",
      "\n",
      "+3 years of experience in advanced analytics/ machine learning/ deep learning\n",
      "having a broad knowledge of business related to advanced analysis\n",
      "\n",
      "5/ personal characteristic\n",
      "\n",
      "high sense of responsibility, honest, careful, accurate and sensitive in work\n",
      "creativity and creating team spirit\n",
      "be proactive and enthusiastic in work\n",
      "confident, creative, dynamic\n",
      "high customer service spirit\n",
      "have the spirit of cooperation and support each other\n",
      "\n",
      "================================================\n",
      "data-02-06/1007/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responsibilitiesgathering, analyzing and interpreting external and internal data and comparing to goals;building segmentation for customer;support operation, analysis and report daily - week - month at the request of the team leader;support cross-departmental projects (operation, marketing, tech, fa...);participate in projects, features, innovation research and development;research and update domestic and foreign market situation in related fields and target audience;set up the gamification program for each customer group;control monthly cost of promotions;in-depth customer analysis to give a view of the customer base and propose solutions.gains and opportunitiesopportunity to tackle and apply creativity in solving problems;ability to adapt fast-paced and demanding environments;ability to work with large data sets to support decision-making;chances to take part in many interesting projects.requirementsbachelor’s degree in business, management, or related field;at least 1 years \n",
      "-----------------------------------------------\n",
      "experience in sales, management, customer service, finance, administration, or related field;have business knowledge, grasp the psychology and behavior of customers;data-driven decision-making;programming (python, sql) and data science knowledge is a plus;strong verbal and written communication skills;analytical mind for problem-solving;actively innovative attitude; well-ordered method of working.benefitssalary range: up to 25m/month;competitive salary and benefits (macbook & pvi insurance);13th salary & performance pay;on-job training about programming languages (python, sql) and tools/ platforms (metabase, integromat, hubspot, data studio, zendesk, coda);working 5 days/week;yearly performance review;regular team building events, happy hour,...;sharp, motivated creative and supportive colleagues in a fun office environment;address: rivera park tower, 7/28 thanh thai street, 10 ward, ho chi minh city\n",
      "================================================\n",
      "data-02-06/2714/data.html\n",
      "mô tả công việc\n",
      "- tham gia thu thập dữ liệu dựa trên nhu cầu nghiên cứu của khách hàng và tham gia xây dựng hướng tiếp cận dữ liệu phù hợp (ví dụ số lượng mẫu, phương pháp chọn mẫu, xử lý dữ liệu đầu vào, các loại dữ liệu cần thu thập, …) để bổ sung đủ dữ liệu cho nghiên cứu bằng social listening tools.\n",
      "- tham gia theo dõi, phát hiện và báo cáo thông tin tiêu cực về công ty/thương hiệu/ sản phẩm/chương trình thông qua social listening tools.- tham gia thu thập dữ liệu dựa trên nhu cầu nghiên cứu của khách hàng và tham gia xây dựng hướng tiếp cận dữ liệu phù hợp (ví dụ số lượng mẫu, phương pháp chọn mẫu, quy trình xử lý dữ liệu, các loại dữ liệu cần thu thập, …) để bổ sung đủ dữ liệu cho nghiên cứu.\n",
      " - làm quen với việc xây dựng khung báo cáo theo đúng nhu cầu của khách hàng.\n",
      "- tham gia theo dõi, phát hiện và báo cáo thông tin tiêu cực về công ty/thương hiệu/ sản phẩm/chương trình.\n",
      "- đánh giá, phân loại thông tin (cảm xúc người dùng, loại sản phẩm, tính chất sản phẩm,…) theo yêu cầu của dự án, ngành hàng.\n",
      "- tham gia vào quá trình tính toán, phân tích dữ liệu.\n",
      "- tham gia viết báo cáo tổng kết và trình bày trước khách hàng.\n",
      "- tham gia quản lý các dữ liệu khác của khác hàng và công ty.\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "sinh viên năm 2, năm 3, ưu tiên các bạn yêu thích ngành marketing, digital marketing, market research.\n",
      "- yêu thích công việc trên máy tính, làm việc với con số và chữ, có khả năng tìm kiếm trên google, am hiểu internet, các mạng xã hội.\n",
      "- yêu cầu tính cách: cẩn thận, kiên nhẫn, chịu khó, ham học hỏi, có tinh thần trách nhiệm và tự giác\n",
      "- yêu cầu kỹ năng: microsoft office (word, excel, powerpoint), spss,…\n",
      "- thời gian làm việc: full-time/part-time\n",
      "trong cv yêu cầu ghi rõ về kinh nghiệm làm việc và quá trình học tập của bản thân.\n",
      "quyền lợi\n",
      "- được huấn luyện chi tiết các kĩ năng thu thập và phân tích dữ liệu, cơ hội cập nhật thông tin và xu hướng thị trường\n",
      "- theo đuổi định hướng chuyên sâu ngành marketing, digital marketing hoặc market research\n",
      "- được làm việc trong môi trường chuyên nghiệp, vui vẻ và hòa đồng.\n",
      "\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 17/06/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2628/data.html\n",
      "responsibilities: \n",
      "đánh giá các nguồn dữ liệu để định vị các vấn đề cần giải quyết liên quan đến chất lượng & tính sẵn sàng của dữ liệu, đề xuất phương án thu thập & làm giàu dữ liệu.\n",
      "phát triển & vận hành các báo cáo các chỉ số đo lường chất lượng dữ liệu, tạo cơ sở đề xuất phương án cải thiện chất lượng dữ liệu và điều chỉnh chiến lược quản trị dữ liệu.\n",
      "phát triển & duy trì các tài liệu mô tả đặc tính dữ liệu để thiết lập tiêu chuẩn quản trị & sử dụng dữ liệu, hợp tác với các đơn vị để đảm bảo chất lượng dữ liệu được duy trì theo thời gian.\n",
      "thực hiện các đánh giá để định vị các vấn đề liên quan đến mô hình quản trị dữ liệu, kiến trúc dữ liệu, chất lượng dữ liệu, quán lý siêu dữ liệu, dữ liệu chuẩn & dữ liệu tham chiếu.\n",
      "đóng vai trò điều phối đối với các đơn vị kinh doanh, chức năng & công nghệ để đám bảo các yêu cầu về bảo vệ an toàn dữ liệu được đinh nghĩa rõ ràng, minh bạch, xuyên suốt và là cấu phần quan trọng của hoạch định và tối ưu vận hành.\n",
      "phát triển chính sách & quy trình quản trị & khai thác dữ liệu trong tổ chức, bao gồm: hướng dẫn xử lý & sử dụng dữ liệu, triển khai hệ thống công nghệ giúp giám sát & theo dõi việc khai thác dữ liệu trong hệ thống.\n",
      "phát triển, ban hành & triển khai khung quản trị dữ liệu toàn hàng bao gồm nguyên tắc, chính sách, tiêu chuẩn & quy trình với trọng tâm là cải thiện chất lượng dữ liệu, tính sẵn sàng, chính xác & khả dụng của dữ liệu dựa trên việc điều chỉnh & phát triển hệ thống chính sách, văn bản, quy trình, kiến trúc & công nghệ.\n",
      "phát triển & vận hành danh mục tài liệu mô tả & tham khảo cho hệ thống dữ liệu, bao gồm hệ thống phân quyền, danh mục từ điển dữ liệu.\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2266/data.html\n",
      "description summary similar job\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2032/data.html\n",
      "responsibility (csr)code of conduct overseas returneesjoin usour culture employee journey career at monroe internship executive recruitment consultantsenior executive recruitment consultantprinciple consultantassistant division head division headjoin monroecontact\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1752/data.html\n",
      "description\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1.\n",
      "dedicate time to generating new business and pitching clients. \n",
      " \n",
      "\n",
      "2.\n",
      "develop and work with the team to establish future-facing insights, implications, and recommendations, delivering advice, making recommendations, and identifying and solving problems\n",
      ".\n",
      "\n",
      " \n",
      "\n",
      "3.\n",
      " design, implement, test, deploy, and maintain stable, secure, and scalable data engineering solutions and pipelines in support of data and analytics projects, including integrating new sources of data into our central data warehouse, and moving data out to applications and affiliates.\n",
      "\n",
      " \n",
      "\n",
      "4.\n",
      "build reports and data visualizations, using data from the data warehouse and other sources.\n",
      "implement and monitor best in class security measures in our data warehouse and analytics environment, with an eye towards the evolving threat landscape.\n",
      " \n",
      "\n",
      "5.\n",
      "produce scalable, replicable code and engineering solutions that help automate repetitive data management tasks.\n",
      " \n",
      "\n",
      "6.\n",
      "collaborating with our ai & business intelligence teams.\n",
      " \n",
      "\n",
      "7.\n",
      "contributing to a data-driven culture.\n",
      " \n",
      "\n",
      "8.\n",
      "manage the data team at ha noi.\n",
      " \n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2568/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "mục đích công việc:\n",
      " chịu trách nhiệm: (i) thu thập dữ liệu, phân tích năng suất lao động; (ii) xây dựng chính sách đãi ngộ nhân sự và các chương trình phúc lợi trên toàn ngân hàng, phù hợp với chiến lược kinh doanh theo từng thời kì. trách nhiệm :\n",
      "phối hợp với các đơn vị trên toàn hệ thống để chuẩn hóa phương pháp đo lường, phục vụ cho việc xây dựng chính sách đãi ngộ phù hợp, công bằng;\n",
      "xây dựng, cập nhật chính sách về chế độ đãi ngộ nhân sự phù hợp với định hướng chiến lược và tình hình hoạt động kinh doanh của vib tại từng thời kỳ.\n",
      "xây dựng, cải tiến và tự động hóa các công cụ đo lường quản lý dữ liệu năng suất lao động;\n",
      "tư vấn và giải đáp các vấn đề liên quan đến chính sách đãi ngộ trong quá trình triển khai;\n",
      "thực hiện các nhiệm vụ khác theo phân công của cấp quản lý.\n",
      " yêu cầu:\n",
      "\n",
      "cử nhân chuyên ngành tài chính, quản trị kinh doanh hoặc các chuyên ngành có liên quan đến tính toán và xử lý số liệu; sử dụng công cụ sql, python hoặc tableau, power bi\n",
      "có hiểu biết chung về lĩnh vực quản trị nhân sự;\n",
      "có tư duy logic tốt, cẩn thận và khả năng tập trung cao;\n",
      "khả năng làm việc với số liệu, kỹ năng phân tích tốt;\n",
      "kỹ năng excel thành thạo;\n",
      "sử dụng tốt tiếng anh (nghe, nói, đọc, viết). \n",
      "\n",
      "\n",
      "\n",
      "chia sẻ công việc này\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tfacebook\n",
      "\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tlinkedin\n",
      "\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/806/data.html\n",
      "mô tả công việc\n",
      "\n",
      "đánh giá các vấn đề, điểm cần cải thiện và đề xuất dựa trên kết quả phân tích\n",
      "xây dựng các báo cáo quản trị, báo cáo kinh doanh phục vụ cho việc quản trị hiệu quả cho chủ dự án và các phòng ban liên quan\n",
      "theo dõi hiệu suất hệ thống và xem xét, đề xuất, áp dụng các công cụ mới\n",
      "phối hợp cùng bộ phận tài chính để đưa ra các dự báo tác động dựa trên các hành động tác động.\n",
      "xác định chính sách giá phí và hiệu quả tài chính của các chính sách giá phí đó.\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "có kiến thức về phương pháp luận phân tích dữ liệu toán thống kê và phân tích định lượng.\n",
      "có kiến thức chung về hoạt động quản trị kinh doanh, mô hình kinh doanh\n",
      "có am hiểu chuyên sâu về mô hình giá/phí của các sản phẩm trong dịch vụ ngân hàng.\n",
      "kỹ năng phân tích, kỹ năng lập kế hoạch, thống kê tổng hợp số liệu, tư duy kinh doanh\n",
      "có khả năng diễn giải dữ liệu, kết quả, báo cáo phân tích bằng ngôn ngữ kinh doanh\n",
      "có kỹ năng làm việc và giao tiếp với các bên liên quan, có tư duy logic, kỹ năng giải quyết vấn đề\n",
      "có khả năng tự định hướng và tính tự tổ chức cao\n",
      "tư duy phản biện: có thể xử lý dữ liệu theo cách để đưa ra các đề xuất cần có tư duy phản biện.\n",
      "tốt nghiệp đại học trở lên với chuyên ngành tập trung vào tài chính, ngân hàng, quản trị kinh doanh,\n",
      "có ít nhất 2 năm kinh nghiệm chuyên môn trong lĩnh vực tài chính/ngân hàng\n",
      "kinh nghiệm phân tích kinh doanh tối thiểu 1 năm.\n",
      "có kinh nghiệm liên quan đến xây dựng và quản trị mô hình tài chính\n",
      "thành thạo power bi, excel, spss, python…\n",
      "\n",
      "================================================\n",
      "data-02-06/2230/data.html\n",
      "mô tả công việc\n",
      "\n",
      " * tham gia vào quá trình phát triển các sản phẩm sốbao gồm phát triển tính năng mới, nâng cấp tính năng, phát hiện và sửa chữa lỗi.\n",
      " * làm việc với các trưởng nhóm, quản lý để thốn\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3136/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi tiết công việc fresh speed up 2023 - program for fresher - accounting & finance tại b. braun vietna\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1240/data.html\n",
      "mô tả công việc\n",
      "\n",
      "lập trình cơ sở dữ liệu, bi cho các dự án thiết kế, xây dựng kho dữ liệu (data warehouse), phân tích & khai thác dữ liệu cho các ngân hàng ở việt nam\n",
      "làm các công việc được giao từ quản trị dự án\n",
      "\n",
      " \n",
      "yêu cầu năng lực\n",
      "\n",
      "tốt nghiệp đại học chuyên ngành công nghệ thông tin, toán tin, khoa học máy tính…\n",
      "\thoặc các ngành học liên quan tới kỹ thuật\n",
      "nắm vững kiến thức về một trong các hệ cơ sở dữ liệu: sql server, mysql, oracle..\n",
      "nắm vững kiến thức về các câu lệnh sql là một lợi thế\n",
      "đã hoàn thành một bài tập ứng dụng, đồ án hoặc tham gia dự án thực tế là một lợi thế\n",
      "\n",
      "quyền lợi\n",
      "\n",
      "mức lương hấp dẫn\n",
      "thưởng lương thứ 13, thưởng kinh doanh cuối năm, thưởng các ngày lễ đặc biệt (sinh nhật, 8/3, 20/10, 2/9, lì xì đầu năm…)\n",
      "xem xét và đánh giá năng lực và tăng lương 2 lần/ năm\n",
      "tham gia bảo hiểm xã hội, bảo hiểm y tế, bảo hiểm thất nghiệp theo luật quy định.\n",
      "khám sức khỏe định kỳ hàng năm, hưởng gói bảo hiểm sức khỏe fss care\n",
      "du lịch 2 lần/ năm, các chương trình teambuilding kết nối hàng tháng\n",
      "tham gia các khóa học đào tạo về nghiệp vụ, kỹ năng và chuyên môn công nghệ do công ty tổ chức\n",
      "\n",
      "\n",
      "nơi nhận hồ sơ\n",
      "\n",
      "email nhận cv: tuyendung@fssc.com.vn\n",
      "điện thoại hỗ trợ: 0943013663 (ms thủy) hoặc 0934504208 (ms.linh)\n",
      "fanpage: https://www.facebook.com/fss.com.vn/\n",
      "linkedin: https://www.linkedin.com/in/financial-software-solutions-jsc-0a0a52129/\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1913/data.html\n",
      "responsibilities: \n",
      "xây dựng database khách hàng, quản lý chất lượng\n",
      "thiết kế, xây dựng và khởi chạy các quy trình xuất, chuyển đổi và tải dữ liệu mới\n",
      "phụ trách nghiên cứu các công cụ để phát triển tính năng cho phần mềm dữ liệu hỗ trợ công việc/ kỹ năng kiến thức về phân tích\n",
      "phối hợp với đội cntt nội bộ để làm rõ các yêu cầu về kiến trúc tích hợp dữ liệu\n",
      "khai thác, phân tích và xử lý từ dữ liệu nguồn để tổng hợp về kho dữ liệu\n",
      "triển khai và quản lý công việc, chi phí theo kế hoạch crm đã xây dựng\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2591/data.html\n",
      "================================================\n",
      "data-02-06/1440/data.html\n",
      "================================================\n",
      "data-02-06/1643/data.html\n",
      "responsible for innovation project management, conducting or monitoring research to understand the market & competitor status deeply, thereby developing and initiating new competitive adverti...\n",
      "                                \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2035/data.html\n",
      "responsibilities:\n",
      "\n",
      "\n",
      "\t\tdesign and implement short- and long-term strategic goals for system and software management and maintenance\n",
      "\n",
      "\t\tdesign, create, and oversee implementations of end-to-end integrated systems\n",
      "\n",
      "\t\treview new and existing system designs, make recommendations to improve or change the system\n",
      "\n",
      "\t\tprovide architectural expertise and support to others on the development team\n",
      "\n",
      "\t\tresearch new technologies in system development, create and develop investment plans in such systems to increase cost efficiency and flexibility\n",
      "\n",
      "\t\tconsult with department heads and end users for further infrastructure development\n",
      "\n",
      "\t\tdevelop and execute test plans to check the technical performance of the infrastructure and report\n",
      "\n",
      "\t\tidentify security risks and advise how to mitigate them\n",
      "\n",
      "\t\tdefine hardware and software specifications for the system to be designed\n",
      "\n",
      "\n",
      "requirements:\n",
      "\n",
      "\n",
      "\t\tms/bs degree in computer science, engineering or equivalent preferred\n",
      "\n",
      "\t\tover 4 years of \n",
      "-----------------------------------------------\n",
      "experience working in the solution architect position\n",
      "\n",
      "\t\tstrong knowledge about tech-stacks:\n",
      "\n",
      "\n",
      "\n",
      "fullstack: django / mysql / jquery / bootstrap / docker\n",
      "\n",
      "se: c++, python\n",
      "\n",
      "cloud: aws (ec2, api gateway, lamda, vpc, …)\n",
      "\n",
      "\n",
      "\n",
      "\t\tproven experience in developing strategic system architecture plans\n",
      "\n",
      "\t\texperience in designing vms (video management system), cloud systems\n",
      "\n",
      "\t\tstrong knowledge of software evaluation principles and practices\n",
      "\n",
      "\t\tsolid understanding of information processing fundamentals and best practices\n",
      "\n",
      "\t\texcellent written and verbal communication skills\n",
      "\n",
      "\t\texperience conducting technology, trends, standards and products research\n",
      "\n",
      "\t\tsolid track record in prioritizing and executing tasks when under extreme pressure\n",
      "\n",
      "\t\texperience providing guidance and leadership to novice systems engineers\n",
      "\n",
      "\t\tproven experience identifying, analyzing and resolving system problems\n",
      "\n",
      "\t\tbusiness english\n",
      "\n",
      "\n",
      "\t\n",
      "================================================\n",
      "data-02-06/2226/data.html\n",
      "mô tả công việc\n",
      "\n",
      "1. performance management & analytics:\n",
      "• issue-focus analysis: perform data analytics to identify trends & underlying patterns & provide recommendations to support business decision making.\n",
      "• lead the design and implementation of analytics projects/ data sharing/ analytics exercises within ops division.\n",
      "• advise project owners/managers performance management methods, conduct post-launch evaluation for strategic & critical functional projects and initiatives/process.\n",
      "• conducts kpi assessment for the division and underlying departments.\n",
      "• lead the design and implementation of unit cost model within ops division\n",
      "2. dashboards/ report/ warehouse/ data services:\n",
      "• design, manage & review periodic report/ dashboard (monthly, weekly, daily…) and provide data services to ad-hoc requests to support the division head and stakeholders of the division.\n",
      "• continuously & actively identify areas of potential improvement/ simplification/ automation and implement these changes for dashboards/ reports/ warehouse/ data services to enhance operations & team productivity, capacity.\n",
      "• be the pic from ops team to work with relevant stakeholders (bi center, data analytics & insight, it, etc.) regarding operations data rules, data extraction, data mart.\n",
      "3. team management & development\n",
      "• ensure all team members are motivated, challenged by proper task allocation, talent\n",
      "identification & development, coaching & mentoring, team engagement activities.\n",
      "4. stakeholder management\n",
      "• deliver satisfactory stakeholder management & influencing, maintaining good relationship with other department & divisions: departments in ops, bi center, it, business departments, project management office, finance,…\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "• university graduate major: economics/ management/banking/ finance\n",
      "• at least 3 years in banking industry, in which at least 1 year working in operations of a bank.\n",
      "• having knowledge & experience at planning/ performance management/ analytics role in financial service is an advantage.\n",
      "• good understanding of data modelling and prediction.\n",
      "• strong critical & analytical thinking\n",
      "• logical & assertive communication\n",
      "• influencing skill\n",
      "• curiosity, agility, high adaptability to vuca contexts & demanding stakeholders\n",
      "• passionate, proactive, self-motivated\n",
      "benefits\n",
      "• attractive income, competitive salary and bonus according to ability\n",
      "• bonus on holidays and new year (according to banking policy from time to time)\n",
      "get preferential loans according to the bank's policy from time to time\n",
      "• attractive leave mode according to job rank\n",
      "• compulsory insurance according to labor law & vpbank care insurance for employees depending on rank and working time\n",
      "• participate in training courses depending on the training framework for each position\n",
      "• working time: monday - friday & saturday morning (two saturday mornings/month off)\n",
      "• dynamic, friendly working environment with many opportunities for training, learning and development; participate in many interesting cultural activities (sports event, talents, teambuilding activities...)\n",
      "\n",
      "\n",
      "job tags:\n",
      "head of performance management - hanoi - ta\n",
      "head of performance management operation division - hanoi - ta\n",
      "\n",
      "================================================\n",
      "data-02-06/2951/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            yes4all is one of the leading brands for home sporting goods & furniture in the e-commerce market. founded in 2010, we have strived to be in the top 1% retailers on amazon us. based in california with an operation office in hcmc, we have more than 350 young and talented members with expert knowledge and \n",
      "-----------------------------------------------\n",
      "experience in the e-commerce industry.\n",
      "we are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end-to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\n",
      "\n",
      "i. job descriptions\n",
      "\n",
      "•\tbe responsible for strategic analysis and recommendations directly for board of directors. be actively involved in and provide an input into the strategic planning process for a company’s business that currently operated in usa and is expanding to international markets.\n",
      "•\tbe accountable for monthly strategic reports which using wide range of data to provide meaningful insight and assists in business strategy at the highest level.\n",
      "•\tresponsible for the detail of management dashboard metric and data analysis.\n",
      "•\tconduct project management in a wide range of insightful and strategic research for the senior leadership team gain a deeper understanding of existing and new markets (including detailed market sizing and market share analysis), as well as enhance knowledge of key competitors in each of our markets.\n",
      "•\tresponsible for identifying not only key business opportunities but also potential risks, putting forward recommendations and presenting the conclusions to the leadership team for consideration\n",
      "•\tclosely work with internal stakeholders in different departments to clarify and suggest any improvement in processes, business strategy and risk managements.\n",
      "•\treview internal business operation, consolidating reports and challenging the financial indicators, market sizing assumptions, business opportunities, product qualities, saving, customers review and others business aspects from different departments.\n",
      "•\tleverage insights to evaluate organizational operation health, identify potential business issues, and potential growth. connecting all the dots from internal to external data to assist corporate development senior manager and strategy director to define segment’s future short, medium and long-term strategy.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "================================================\n",
      "data-02-06/2259/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "xây dựng database khách hàng, quản lý chất lượng\n",
      "thiết kế, xây dựng và khởi chạy các quy trình xuất, chuyển đổi và tải dữ liệu mới\n",
      "phụ trách nghiên cứu các công cụ để phát triển tính năng cho phần mềm dữ liệu hỗ trợ công việc/ kỹ năng kiến thức về phân tích\n",
      "phối hợp với đội cntt nội bộ để làm rõ các yêu cầu về kiến trúc tích hợp dữ liệu\n",
      "khai thác, phân tích và xử lý từ dữ liệu nguồn để tổng hợp về kho dữ liệu\n",
      "triển khai và quản lý công việc, chi phí theo kế hoạch crm đã xây dựng\n",
      "\n",
      "địa điểm làm việc\n",
      "- hà nội: số 5 điện biên phủ, ba đình\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2625/data.html\n",
      "responsibility. able to work under high pressure\n",
      "-----------------------------------------------\n",
      "experience in budget controlling, forecasting, and budgeting. a candidate who used to work in big 4 firms is preferable.good knowledge in ifrs, vas and tax laws/regulations.ms. office (word, excel, power-point), data knowledge and process, sql or power bi skill is an advantage.strong written and spoken english language skills, including the ability to structure communications clearly, confidently, and logically.hard-working, honest, and self-responsibility. able to work under high pressure\n",
      "================================================\n",
      "data-02-06/1402/data.html\n",
      "descriptionthe bosch group is a leading global supplier of technology and services. it employs roughly 394,500 associates worldwide (as of december 31, 2020). according to preliminary figures, the company generated sales of 71.6 billion euros in 2020. its operations are divided into four business sectors: mobility solutions, industrial technology, consumer goods, and energy and building technology.the bosch group comprises robert bosch gmbh and its roughly 440 subsidiaries and regional companies in some 60 countries. if its sales and service partners are included, then bosch is represented in roughly 126 locations. this worldwide development, manufacturing, and sales network is the foundation for further growth.rbvh - robert bosch engineering and business solutions vietnam company limited is 100% owned subsidiary of robert bosch gmbh. \n",
      "rbvh has started its operations from 19th october, 2010 at e-town2 in hcmc. this engineering development center will be engaged in developing embedded systems and software, mechanical design and simulation, and will provide it (sap consulting, java development….) and business services (finance and accounting, economics, purchasing, logistics, translations japanese-english-japanese, information security ) solutions to the bosch group of companies globally. job descriptiondeveloping and implementing an overall organizational data strategy that is in line with business processes. the strategy includes data model designs, database development standards, implementation and management of data warehouses and data analytics systems.​identifying data sources and working out a plan for data management that is aligned with organizational data strategy.​coordinating and collaborating with cross-functional teams, stakeholders for the smooth functioning of the enterprise data system. ​managing end-to-end data architecture, from selecting the platform, designing the technical architecture, and developing the application to finally testing and implementing the proposed solution.​planning and execution of big data solutions on premises or cloud using technologies such as hadoop. in fact, the big data architect roles and responsibilities entail the complete life-cycle management of a hadoop solution. ​defining and managing the flow of data and dissemination of information within the organization. ​integrating technical functionality, ensuring data accessibility, accuracy, and security.​conducting a continuous audit of data management system performance, refine whenever required, and report immediately any breach or loopholes to the stakeholders.​qualificationsbachelor degree or above in it/ computer science or relevant background​have at least 15+ year of \n",
      "-----------------------------------------------\n",
      "experience in it and 5+ year of\n",
      "================================================\n",
      "data-02-06/1147/data.html\n",
      "================================================\n",
      "data-02-06/2964/data.html\n",
      "mô tả công việc\n",
      " analyzing and designing information systems:\n",
      "- analyze business processing or business needs and system design, using techniques such as, pattern design, data modeling and requirement analysis.\n",
      "- utilize the information system in the process analysis and solution of business problems such as development of integrated production and inventory control and cost analysis systems.\n",
      "- define the business goals and devise business flow diagrams describing logical operational steps of programs.\n",
      "- assess the usefulness of pre-developed application packages and adapt them to a user environment.\n",
      "implementing and developing the information systems:\n",
      "- use object-oriented programming languages, as well as client and server applications development processes and multimedia and internet technology.\n",
      "- determine computer software or hardware needed to set up or alter system.\n",
      "- expand or modify system to serve new purposes or improve work flow for business.\n",
      "- coordinate and link the computer systems within an organization to increase compatibility and so information can be shared.\n",
      "- recommend new equipment or software packages to improve business operations\n",
      "- read manuals, periodicals, and technical reports to learn how to develop programs that meet staff and user requirements.\n",
      "- together with ict supervisor of application development to make a development roadmap of information systems to match business strategies and objectives.\n",
      "assuring the quality of information systems\n",
      "- develop, document and revise system design procedures, test procedures, and quality standards.\n",
      "- provide staff and users with assistance solving computer related problems, such as malfunctions and program problems.\n",
      "- review and analyze computer printouts and performance indicators to locate code problems, and correct errors by correcting codes.\n",
      "- execute sit ( system integration testing) , uat( user exception testing) and undertake project coordinator activities\n",
      "- work with outsourcing vendors to control the product quality on time and on budget \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2579/data.html\n",
      "================================================\n",
      "data-02-06/2104/data.html\n",
      "mô tả công việc\n",
      " creation of technical specifications for integrations related to data management, system integration, reporting, transformation and performance. design and build of etl solutions and data integrations maintain update-to-date documentation of data catalog, etl flows, data dictionary. design, implement, maintain data models with ralph kimball’s dimensional modelling methodology. ensuring technical, security and performance standards are met build and maintain data pipelines using tools such as nifi, airflow, etc. evaluate and define kpis to monitor and manage data quality tuning and improving the performance of db/dwh. support data scientists, data analyst to explore data in data warehouse. build and maintain integration data flow provided to other departments. practice sustainable incident response and blameless postmortems. participate in end to end engineering solutions with regard to data processing and data delivery and integration, including data processing job/pipeline tool suite, batch framework and platform, micro-service framework and platform. work closely with stakeholders to identify improvements in existing processes and new processes that bring meaningful and actionable insight to the underlying data.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      " completion of a degree or diploma in computer science, information technology, engineering or a related discipline. english proficiency is required at least three years of hands-on experience, preferably in big data infrastructure experienced with data-lake, data warehouse, data mart have experience with a programming language (python / go / javascript) for data processing and analysis. experience designing sql tables, indexing, tuning queries, and optimizations across different functional environments\n",
      "================================================\n",
      "data-02-06/1245/data.html\n",
      "responsibilities:\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tyou will be responsible for building and running the data processing pipeline on google cloud platform \n",
      "– work with implementation teams from concept to operations, providing deep technical expertise for successfully deploying large scale data solutions in the enterprise, using modern data/analytics technologies on gcp\n",
      "– design pipelines and architectures for data processing\n",
      "– implement methods for devops automation of all parts of the build data pipelines to deploy from development to production\n",
      "– formulate business problems as technical data problems while ensuring key business drivers are captured in collaboration with product management\n",
      "– extract, load, transform, clean and validate data\n",
      "– supporting and debugging data pipelines \n",
      "\n",
      "requirements: \n",
      "\t\t\t\t\t\t\t\t\t\t\tmust-have requirements\n",
      "– at least 4 years of experience working as a data engineer\n",
      "– good development experience in data warehouse platform\n",
      "– experience with data staging, data transformation and change data management\n",
      "– good experience in advanced sql\n",
      "– good python skills\n",
      "– experience in a cloud datawarehouse platform (can be any but big query is mostly preferred)\n",
      "– good command of english communication\n",
      "good-to-have requirements\n",
      "– experience with gcp\n",
      "– relative experience in containerization: docker and kubernetes\n",
      "– relative experience in declarative ci/cd or devops\n",
      "– relative experience in infrastructure as a code (iaac) (i.e., terraform, cloud build)\n",
      "– experience with automated testing (ideally robot framework)\n",
      "– relative experience in data management: data governance, data architecture, data modelling, data quality, data integration\n",
      "preferred language for application: english\n",
      "\n",
      "-----------------------------------------------\n",
      "experience range: from 3 years\n",
      "job location: hcmc\n",
      "duty & responsibilities:\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tyou will be responsible for building and running the data processing pipeline on google cloud platform \n",
      "– work with implementation teams from concept to operations, providing deep technical expertise for successfully deploying large scale data solutions in the enterprise, using modern data/analytics technologies on gcp\n",
      "– design pipelines and architectures for data processing\n",
      "– implement methods for devops automation of all parts of the build data pipelines to deploy from development to production\n",
      "– formulate business problems as technical data problems while ensuring key business drivers are captured in collaboration with product management\n",
      "– extract, load, transform, clean and validate data\n",
      "– supporting and debugging data pipelines \n",
      "\n",
      "requirements: \n",
      "\t\t\t\t\t\t\t\t\t\t\tmust-have requirements\n",
      "– at least 4 years of experience working as a data engineer\n",
      "– good development experience in data warehouse platform\n",
      "– experience with data staging, data transformation and change data management\n",
      "– good experience in advanced sql\n",
      "– good python skills\n",
      "– experience in a cloud datawarehouse platform (can be any but big query is mostly preferred)\n",
      "– good command of english communication\n",
      "good-to-have requirements\n",
      "– experience with gcp\n",
      "– relative experience in containerization: docker and kubernetes\n",
      "– relative experience in declarative ci/cd or devops\n",
      "– relative experience in infrastructure as a code (iaac) (i.e., terraform, cloud build)\n",
      "– experience with automated testing (ideally robot framework)\n",
      "– relative experience in data management: data governance, data architecture, data modelling, data quality, data integration\n",
      "preferred language for application: english\n",
      "\n",
      "================================================\n",
      "data-02-06/1839/data.html\n",
      "description: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2124/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description tối ưu hóa thử nghiệm trong bộ phận phát triển bằng cách sử dụng công nghệ phần mềm...\n",
      "                            \n",
      "apply for this job\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2525/data.html\n",
      "mô tả công việc\n",
      "entry information from the life insurance application documents into the system, ensuring accuracy and turn-around time.check data and the validity of the application life insurance form before issuemake a data report for new business departmentcheck and executing regular or ad-hoc of division/ department reports.recommend to nb team leader/ nb head initiatives in improving the tasks accurately and efficiently. \n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "at least 3 years experience in administration or financial service sectorgood computer skill (especially in ms excel, power bi know-how, word, power point, data analysis), life insurance or accounting is preferable, basic english.bachelor degree (full-time university degree with majors in economics / insurance / business administration / marketing / banking / finance / accounting).good communicate skill, strong interpersonal and customer service skill.carefulness\n",
      "quyền lợi\n",
      "chế độ bảo hiểmdu lịchphụ cấpđồng phụcchế độ thưởngchăm sóc sức khỏeđào tạotăng lươngnghỉ phép năm\n",
      "cách thức ứng tuyển\n",
      "\n",
      "hết hạn nộp đơn\n",
      "\n",
      "================================================\n",
      "data-02-06/2575/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            position purpose:\n",
      "\n",
      "data analyst is responsible to manage internal sales database (most of which comes from our distributors database and from our esalesweb system). data analyst’s roles are not only to manage data but also to analyze which data matters and generating reports for insights that lead to better decisions and strategic business moves.\n",
      "\n",
      "\n",
      "responsibilities and tasks:\n",
      "\n",
      "data management & analysis:\n",
      "\n",
      "- manage internal sales & operation database (either from our distributor database or from esalesweb), generate, analyze & conduct market/ trade insights report and other relevant analysis on regular basis to support business strategic planning.\n",
      "\n",
      "trade marketing administration:\n",
      "\n",
      "- support in post-evaluation & liquidation phase of trade promotion (doi, rebate, etc.), visibility programs (in-side store and outside store) and other activation campaigns.\n",
      "\n",
      "- technically supporting esalesweb users (field force reps) in day-to-day operational tasks.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2760/data.html\n",
      "mô tả công việc\n",
      "nghiên cứu và phát triển các hệ thống lưu trữ, xử lý dữ liệu lớn (big data), datawarehouse.xây dựng và tối ưu hóa data pipelines, architectures và data sets.xây dựng các giải pháp etl có khả năng mở rộng linh hoạt với độ tin cậy cao, phục vụ cho việc khai thác dữ liệu từ nhiều nguồn khác nhau.xây dựng, phát triển các công cụ khai thác dữ liệu, quản trị dữ liệu.thiết kế chi tiết giải pháp cho các việc thu thập, chuẩn hóa, làm sạch, làm giàu, lưu trữ, xử lý, phân tích dữ liệu.mô hình hóa, phân tích dữ liệu phục vụ cho báo cáo và thực hiện phân tích dữ liệu.lập báo cáo về các kết quả phân tích dữ liệu.thực hiện các nhiệm vụ khác theo phân công của cấp quản lý\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "tối thiểu 2 kinh nghiệm trong vai trò data engineerkiến thức về lập trình, cấu trúc dữ liệu & giải thuật tốtlập trình thành thạo một trong những ngôn ngữ như python, javathành thạo các ngôn ngữ xử lý dữ liệu như sql, nosql, mongodb, big querykiến thức về lập trình lưu trữ, xử lý dữ liệu phân tán, xử lý dữ liệu lớn (hadoop, spark, elastic search…)kiến thức về xây dựng luồng xử lý dữ liệu (batch processing, stream procesing, ...)khả năng học hỏi và thích ứng nhanh với công nghệ mới.là người tỉ mỉ, năng động và có trách nhiệmbiết quản lý thời gian, có kỹ năng phân tích và giải quyết vấn đềkhả năng làm việc độc lập & làm việc nhómkỹ năng giao tiếp tốt\n",
      "quyền lợi\n",
      "1. mức lương: up to 40.000.000đ2. thời gian, địa điểm làm việctừ thứ hai đến thứ sáu hàng tuần và thứ bảy cách tuần.sáng: \n",
      "================================================\n",
      "data-02-06/1709/data.html\n",
      "mô tả công việc\n",
      "data task\n",
      "– hoàn thiện và làm giàu hệ thống báo cáo của công ty\n",
      "– làm việc với các stackholder để làm rõ yêu cầu về dữ liệu/dashboard\n",
      "– xây dựng dashboard theo yêu cầu. hình thức thể hiện linh hoạt, phù hợp với thói quen của stackholder và tính chất của yêu cầu (excel, power bi hoặc python/r…)\n",
      "innovation task\n",
      "– triển khai các project về phân tích hành vi khách hàng, dự báo doanh số… góp phần nâng cao trải nghiệm khách hàng tại abs và tối ưu hóa các nguồn doanh thu/chi phí của công ty.\n",
      "– tư vấn, hỗ trợ các stackholder về việc ứng dụng phân tích định lượng vào công việc hàng ngày, cải thiện chất lượng công việc.\n",
      " \n",
      "ii. \n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "bắt buộc\n",
      "– kinh nghiệm làm việc tối thiểu 2 năm trong lĩnh vực data\n",
      "– thành thạo truy vấn sql và các ngôn ngữ tương tự (oracle, mysql, postgresql…)\n",
      "– sử dụng thành thạo bi tools (power bi là điểm cộng) và r/python\n",
      "điểm cộng\n",
      "– có kinh nghiệm triển khai các mô hình phân tích định lượng vào thực tế là lợi thế\n",
      "– ứng viên có kinh nghiệm làm việc trong ngành tài chính nói chung và công ty chứng khoán nói riêng.\n",
      "\n",
      "================================================\n",
      "data-02-06/3059/data.html\n",
      "================================================\n",
      "data-02-06/2347/data.html\n",
      "description\n",
      "\n",
      "planning and forecasting + cash flow planning, coordinating with accounting to get information and daily update cash flow  + forecast monthly p&l and analyze operational data for finance team leader.performance analysis  + tracking operational kpis (expense ratio, risk percentage, etc.).  + prepare and reason variance report (this month vs last month, actual vs forecast). + analyze operational data.any other responsibilities and ad-hoc reports assigned by senior in charge.\n",
      "\n",
      "\n",
      "\n",
      "requirements\n",
      "\n",
      "\n",
      "bachelor’s degree in finance, finance & accounting, corporate finance, economics, business or related field.\n",
      "minimum of 2 years \n",
      "-----------------------------------------------\n",
      "experience as a financial analyst, financial analyst, financial planning, analysis, modeling, or in a similar position. knowledge of the e-commerce market is preferable.\n",
      "strong critical thinking, analytical thinking, systematic problem-solving skills. \n",
      "high proficiency with the use of ms office, especially excel (intermediate and above). knowing about bi tool is an advantage\n",
      "ability to learn new concepts and tasks quickly, detail-oriented and able to perform in a high-pressure environment.\n",
      "good communication in english spoken & written skills.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "benefits\n",
      "\n",
      "at crossian, our people are the key to our success. we believe in creating an attractive total compensation package (tcp) that not only retains employees but allows them to excel in their profession. these include:\n",
      "competitive gross salary (14-30 million vnđ depending on what you bring to the table)\n",
      "full salary during probation\n",
      "20 days work-from-home & 12 days of paid annual leave\n",
      "global health insurance package for yourself and direct family members\n",
      "guaranteed 13th month salary\n",
      "quarterly bonus & year-end bonus as part of our profit sharing program\n",
      "a pantry & a crossian cafe stocked with goodies, ready to serve\n",
      "lots of other company benefits including 5* annual company trip, budget for frequent team building activities and other monthly / quarterly / annual company events\n",
      "general company t&d program + dedicated t&d budget for managers\n",
      "================================================\n",
      "data-02-06/1808/data.html\n",
      "================================================\n",
      "data-02-06/1297/data.html\n",
      "description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "view all jobs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                              mangtas                                                                          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thanks for visiting our career page. please review our open positions and apply to the positions that match your qualifications. \n",
      "\n",
      "\n",
      "\n",
      "data engineer - remote - senior\n",
      "\n",
      "\n",
      "remote                    \n",
      "\n",
      "contracted                \n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "experienced                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    share\n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mangtas is looking for a data analyst to join our team in our remote office. the data analyst is responsible for managing our master data set and developing respective reports/visualizations.the ideal person for this position has an exceptional eye for detail, expertise as a data analyst, and a solid understanding of popular data analysis tools. he/she will work closely with product owners across various lines of business to understand the objectives of the organization and prioritize any requirements.responsibilities:\n",
      "================================================\n",
      "data-02-06/161/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responsibilities:responsible for planning, connecting, designing, scheduling, and deploying data warehouse systems. develops, monitors, and maintains etl processes, reporting applications, and data warehouse design.plan, create, coordinate, and deploy data warehouses.design end user interface.create best practices for data loading and extraction.develop data architecture, data modeling, and etfl mapping solutions within structured data warehouse environment.develop reporting applications (power bi).design and build cubes while performing custom scripts.develop and implement etl routines according to the dwh design and architecture.support the development and validation required through the lifecycle of the dwh and business intelligence systems, maintain user connectivity, and provide adequate security for data warehouse.monitor the dwh and bi systems performance and integrity provide corrective and preventative maintenance as required.manage multiple projects at once.job \n",
      "-----------------------------------------------\n",
      "qualification: bachelor of information technology, computer science or related field eg. business, economic and trading.certificate in da/ba/bigood understanding of etl good knowledge of application & database design and development skills.competencies & skillsgood communication in english (speaking, listening and writing)good collaboration high responsibility, reliability, flexibility and service mind.\n",
      "\n",
      "================================================\n",
      "data-02-06/3068/data.html\n",
      "================================================\n",
      "data-02-06/2379/data.html\n",
      "description\n",
      "\n",
      "responsibilities:\n",
      "reporting:\n",
      "\n",
      " dive deeply into financial data and become a subject matter expert to provide additional insights. provide timely and accurate financial information to all relevant stakeholders; make use of the information to boost operational productivity and cost efficiency. \n",
      " own & develop management reports for management on the overall performance of the business. \n",
      " partner with the business owners and related departments to collaborate on metrics, goals, and business reviews.\n",
      "\n",
      "controlling:\n",
      "\n",
      " develop and implement effective and efficient financial controlling processes and coordinate with internal teams to solve problems when they arise. \n",
      " monitor budget and contract approval process; control capex and opex spending within budget and make sure cost efficiencies. \n",
      " system admin: playing key role of admin/superuser for system that finance team is using.\n",
      "\n",
      "forecasting:\n",
      "\n",
      " provide monthly forecasts to support management and have best action and control for the period.\n",
      " support annual budgeting.\n",
      " identify and research variances to forecast, budget, and prior-year expenses, proactively identifying opportunities for improvement.\n",
      "\n",
      "requirements:\n",
      "\n",
      "bachelor’s degree in accounting, finance or related fields.\n",
      "2+ years of related \n",
      "-----------------------------------------------\n",
      "experience. experience in big4 audit firms and/or logistics industry is preferable.\n",
      "highly analytical and ability to analyze large data sets to extract actionable insights to provide creative recommendations to management and business partners.\n",
      "highly proficiency in excel is a must, knowledge of sql is a plus.\n",
      "highly curious, logical, self-motivated, independent, proactive, and result oriented.\n",
      "ability to work cross-functionally, to thrive in a dynamic and fast-paced environment, and to manage and prioritize multiple projects with tight deadlines.\n",
      "demonstrate strong leadership skills, with exceptional interpersonal and communication skills (both written and verbal) to influence other leaders in finance and business.\n",
      "fluent in english.\n",
      "\n",
      "\n",
      "apply now\n",
      "\n",
      "================================================\n",
      "data-02-06/2485/data.html\n",
      "description\n",
      "\n",
      "building and optimizing ‘big data’ data pipelines, architectures and data sets;\n",
      "design, develop, and maintain data pipelines, warehouses, datalake.\n",
      "build the data products that technical users will depend on for business intelligence and ad-hoc access.\n",
      "work side by side with our data science to build and automate data pipeline, data etl, etc. on distributed data processing platform such as spark.\n",
      "prepare data inputs for a generic blueprint “model builder”\n",
      "build production data pipeline for daily etl and model retraining\n",
      "end-to-end data processing, troubleshooting, and problem diagnosis.\n",
      "\n",
      "2. your skills and \n",
      "-----------------------------------------------\n",
      "experiences\n",
      "must have:\n",
      "\n",
      "up to 2-3 years of experience as a data engineer or software engineer.\n",
      "working experience with 1 or more languages / frameworks (java, scala, python).\n",
      "strong interest to learn and develop skills in analyzing and implementing data pipelines for structured and unstructured data.\n",
      "good at multi-threading, atomic operations, computation framework: spark (dataframe, sql,…), distributed storage, distributed computing.\n",
      "experience with aws (ec2, s3, lambda, rds, emr, redshift, glue) is an added advantage.\n",
      "experience with rdbms (postgresql) and nosql (dynamo) databases is an advantage.\n",
      "experience with big data tools (hadoop, spark, kafka) is an added advantage.\n",
      "experience with etl tools (airflow, airbyte, talend) is an added advantage.\n",
      "understand designs of resilience, fault-tolerance, high availability, and high scalability, …\n",
      "tools: ci/cd, gitlab,…\n",
      "good at communication & team working.\n",
      "being open-minded, willing to learn new things.\n",
      "\n",
      "bonus points:\n",
      "\n",
      "cloud experience (aws, gcp, etc), aws is a plus.\n",
      "experience in performance tuning/optimizing big data programs.\n",
      "having knowledge of distributed query engines: presto, hive,…\n",
      "\n",
      "\n",
      "3. why you’ll love working here\n",
      "\n",
      "income = net salary + benefit + performance bonus (>14 months salary).\n",
      "review salary twice per year base on your performance and output.\n",
      "health check once per year.\n",
      "health insurance pvi care if you work here more than one year.\n",
      "enjoy all of our company policies: insurance, vacation, public holiday, party, birthday and more.\n",
      "free coffee, tea and cakes.\n",
      "we have these clubs for you to join: football, table football, music, english, media and more.\n",
      "have a chance to involved and learn from our senior.\n",
      "have our senior to review your works, instruct you during the project using scrum.\n",
      "get advices for career development.\n",
      "\n",
      "working hours: 8h30 am -12h00 pm & 1h00 pm – 5h30 pm. (monday to friday)\n",
      "================================================\n",
      "data-02-06/2608/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            -\tanalysis, coordinate, challenge bl / clients to have realistic forecast\n",
      "-\tfinalize po quality\n",
      "-\tdefine, calculate bs/excess stock \n",
      "-\tinvolve and resolve matter related to inventory\n",
      "-\thave frequent meeting with clients\n",
      "-\tkeep clients satisfaction on service level\n",
      "-\tmake report on inventory and service level or ad-hoc\n",
      "-\tinput idea to supervisor for process improvement\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2008/data.html\n",
      "================================================\n",
      "data-02-06/2663/data.html\n",
      "description\n",
      "-----------------------------------------------\n",
      "job requirementsjob benefitapply/  refe\n",
      "================================================\n",
      "data-02-06/666/data.html\n",
      "responsibilities\n",
      "\n",
      "manage, develop, and grow a team of business intelligence analytic professionals, centered on providing insights and aiding in business decision-making.\n",
      "creates actionable business insights to answer business questions, drive business decisions, and develop recommendations to improve operations.\n",
      "drive a business intelligence roadmap; prioritize analysis requests to balance the tactical and strategic information needs of the business. oversees the planning of projects to produce power bi reporting dashboards and perform meaningful quantitative or qualitative analyses addressing impactful business issues or questions.\n",
      "present analysis and recommendations to senior leaders, using data-driven storytelling and influence to drive improvements in business operations and strategic change. coordinate with decision makers in the company to ensure that information gathering, and analysis support the overall development of business strategies.\n",
      "collaborates with other departments to identify and generate potential business intelligence initiatives, that result in business efficiency, cost saving, and/or marketing/trade effectiveness.\n",
      "cooperates with data science team to build and incorporate predictive analytics tools like alerts, notifications, forecast, recommendation into business intelligence reports.\n",
      "collaborate with product management, data science, and data engineering leaders to design and develop information management capabilities.\n",
      "lead the definition and governance of key business metrics, drive the vision and building of automated dashboards and self-service analytic capabilities, and engineer data-driven processes that drive business value.\n",
      "ensures that business intelligence analysts have the tools, training, and understanding of the field to produce effective dashboards, reports, and metrics.\n",
      "\n",
      " \n",
      "requirements\n",
      "\n",
      "over 10 years of working \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2139/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xây dựng và phát triển hạ tầng dữ liệu tập trung. data warehouse, data lake\n",
      "triển khai các luồng đồng bộ và xử lý dữ liệu (etl và data pipeline)\n",
      "cập nhật và xử lý các vấn đề phát sinh trong quá trình vận hành hạ tầng dữ liệu. đảm bảo các yêu cầu theo từng giai đoạn dự án\n",
      "thiết kế, đề xuất các giải pháp kỹ thuật xuyên suốt vòng đời dữ liệu.\n",
      "thiết kế, đề xuất mô hình dữ liệu tại doanh nghiệp.\n",
      "triển khai các api, cổng kết nối để trao đổi dữ liệu, đảm bảo tính an toàn và bảo mật theo yêu cầu.\n",
      "\n",
      "\n",
      " yêu cầu chung: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "có \n",
      "-----------------------------------------------\n",
      "kinh nghiệm về công nghệ lưu trữ và xử lý dữ liệu lớn, lập trình;\n",
      "có khả năng thiết kế và triển khai các mô hình dữ liệu đa chiều, thiết kế pipeline và triển khai các công cụ etl.\n",
      "có kinh nghiệm\n",
      "tư duy tổng thể tốt và có khả năng triển khai chi tiết.\n",
      "ưu tiên:\n",
      "\n",
      "\n",
      "ứng viên có kinh nghiệm trong mảng tài chính, chứng khoán.\n",
      "ứng viên có kinh nghiệm làm việc với azure hoặc aws.\n",
      "có kinh nghiệm xử lý etl dữ liệu với ssis và ssas là một lợi thế.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " quyền lợi: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thời gian làm việc 5 ngày/tuần (từ thứ hai đến thứ sáu).\n",
      "cơ hội thăng tiến, phát triển nghề nghiệp công bằng.\n",
      "thu nhập hấp dẫn, cạnh tranh.\n",
      "được hưởng chế độ bhxh, bhyt, bhtn, bảo hiểm sức khỏe theo quy định của công ty.\n",
      "được tham gia các chương trình đào tạo, huấn luyện của công ty.\n",
      "môi trường làm việc chuyên nghiệp, thân thiện, năng động.\n",
      "mức lương: thỏa thuận\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " hồ sơ yêu cầu: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bản thông tin ứng viên theo mẫu của mbs.\n",
      "các mẫu thông tin ứng viên/cv khác không theo mẫu mbs là hồ sơ không hợp lệ.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " thời hạn nhận hồ sơ:  phỏng vấn cuốn chiếu ngay khi nhận được hồ sơ đến khi tuyển được ứng viên phù hợp\n",
      "nơi nhận hồ sơ: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nộp bản thông tin ứng viên theo mẫu của mbs theo hình thức sau:\n",
      "\n",
      "nộp hồ sơ online trên website tuyển dụng/gửi qua email:\n",
      "================================================\n",
      "data-02-06/3157/data.html\n",
      "mô tả công việctóm tắt công việclà một thành viên trong team bên phía việt nam cùng nghiên cứu, trao đổi với team bên phía nhật bản.nghiên cứu và phát triển các ứng dụng dựa trên ai bao gồm hồi quy, phân loại, phân cụm, đề xuất, học sâu...nghiên cứu và phát triển trên môi trường đám mây (amazon, google, ibm)kiến thức kỹ thuật cập nhật về dịch vụ đám mây, dữ liệu lớn và lĩnh vực liên quan đến học máy (thị giác máy tính, nlp, v.v.)trình bày các chủ đề kỹ thuật phức tạp một cách rõ ràng và có cấu trúc, khả năng kiểm duyệt các cuộc thảo luận, cuộc họp và dự án.kiến thức chuyên môn về ít nhất một ngôn ngữ lập trình. python được ưu tiênmức lương hấp dẫn up to $3000có thể phỏng vấn onlinereview lương hàng nămbảo hiểm xã hội, bảo hiểm y tế, bảo hiểm thất nghiệp đóng full lương.tham gia lớp học tiếng nhật, đào tạo chuyên môn do công ty tổ chứctham gia hoạt động teambuilding và du lịch hàng nămtrợ cấp chứng chỉ it, chứng chỉ tiếng nhật, trợ cấp tham gia hội thảotự do ăn mặc thoải mái, không gò bóhappy time ăn uống 1 lần 1 tuầnnghỉ sau sinh 6 thángkho truyện tranh và sách tiếng nhật freeđồng nghiệp trẻ trung, năng động, thân thiện, hoà đồnggiờ làm việc : từ thứ 2 đến thứ 6 hàng tuần (8:30 - 12:00 và 13:30 - 18:00\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/647/data.html\n",
      "descriptions\n",
      "1. supply chain expansion, optimization & process standardization: \n",
      "\n",
      "detect and realize cost - cash - service level optimization opportunities by fine-tuning supply chain configurations and driving for smooth applications: incoterms, lead time, moq, multi-sourcing, port of loading, forms of loading, etc., at product, market and seasonality levels.\n",
      "work on ongoing supply chain development projects, that strongly bond with the hyper growth across product selections, channels, platforms, sources (supply-based) and markets (demand-based) of the company. \n",
      "develop product pricing strategy with sales, marketing and sourcing teams to optimize physical flow and financial flow;\n",
      "involve in supply & demand planning for multinational markets;\n",
      "head to the automation, standardization and scalability of all the expansion projects.\n",
      "\n",
      "2. data analysis, interpretation and visualization: \n",
      "\n",
      "perform operational analytics in various but strongly connected fields: pricing, demand forecast, inventory, sales, etc. with the highest curiosity and eagerness for value creation.\n",
      "collaborate with cross-functional teams to form effective hypotheses based on business needs.\n",
      "test hypotheses; examine the results; do scenario, sensitivity, etc. analyses to spot out growth opportunities.\n",
      "build interactive trackers, creative visualizations as well as concrete management reports to govern project outcomes and support bias-for-action decision-making.\n",
      "conduct deep-dive / root cause analyses for long-term fixes.\n",
      "\n",
      "3. project management: \n",
      "\n",
      "initiate, set up plans and timelines; coordinate and follow up with cross-functional departments to drive the projects.\n",
      "actively communicate the objectives & progress to the stakeholders based on aligned success metrics, deep-dive on arising issues and take reaction plans to ensure high-quality deliverables at a timely manner\n",
      "\n",
      "ii. skill and experience\n",
      "\n",
      "bachelor degree and above in supply chain, business or data analytics.\n",
      "1 year of experience in supply chain/business/data analytics. retail supply chain and/or e-commerce experience is highly valued. fresher with excellent analytical and academic background is also welcome.\n",
      "advanced ms office is compulsory. be fluent in at least one query/code language (r, mysql & python are preferred).\n",
      "great attention to detail, strong analytical and data story-telling sense with a “continuous improvement” mindset.\n",
      "good command of spoken & written english and vietnamese is a must.\n",
      "good at time management, teamwork, and multitasking. have strong ownership and responsibility for deliverables.\n",
      "willing to learn, thrive in a fast-paced environment and have a can-do attitude                          \n",
      "\n",
      "iii. why you will love joining us?\n",
      "for you to join\n",
      "\n",
      "financial well-being: a competitive salary with 13th month salary, annual performance bonus and a variety of allowances.\n",
      "salary review: annually or on excellent performance.\n",
      "activities: company trips, team-building, and other customized monthly bonding events.\n",
      "annual leaves: 16 days off and 01 birthday leave per year.\n",
      "healthcare: annual health check, insurance according to labor law and extra bao viet insurance package.\n",
      "working environment: dynamic, friendly environments with working time flexibility (mon-fri) and other perks include snacks, coffee, and healthy food provided daily suited for hardworking, fun, and team collaboration.\n",
      "\n",
      "for you to grow\n",
      "\n",
      "ambition: we are now keeping on with our hyper growth to multicategory, multichannel, multimarket, and expanding into the world largest e-commerce enabler. hence, there will continuously be opportunities to challenge yourself, learn new skills and knowledge.\n",
      "challenges: your voice can always be heard as we embrace the eagerness of learning and sharing. you can be your own boss and create your own value with the ability to take initiative and make decisions in all aspects of work.\n",
      "chances: be led and coached by experienced and inspirational leaders and participate in various training courses where you can enlarge your knowledge and experience in the e-commerce and supply chain industry.\n",
      "\n",
      "for you to stay\n",
      "\n",
      "people: having a headquarter in the us and an operation office in vietnam, our team is young and highly motivated. you will be working with and alongside members having experiences from international corporations or high profile from vietnam that share the same passion and dedication.\n",
      "culture: our working environment is humble, collaborative and 100% healthy. we promote exchange & speak out, you can receive transparent and supportive feedback so you can perform the best.\n",
      "career path: provide you a great career path, open to rotating for your better understanding of the company and contribute across many of our functions.\n",
      "\n",
      "and much more, join us and let yourself explore other fantastic things!\n",
      "-----------------------------------------------\n",
      "experience in the e-commerce industry.\n",
      "we are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end-to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\n",
      "i. job descriptions\n",
      "1. supply chain expansion, optimization & process standardization: \n",
      "\n",
      "detect and realize cost - cash - service level optimization opportunities by fine-tuning supply chain configurations and driving for smooth applications: incoterms, lead time, moq, multi-sourcing, port of loading, forms of loading, etc., at product, market and seasonality levels.\n",
      "work on ongoing supply chain development projects, that strongly bond with the hyper growth across product selections, channels, platforms, sources (supply-based) and markets (demand-based) of the company. \n",
      "develop product pricing strategy with sales, marketing and sourcing teams to optimize physical flow and financial flow;\n",
      "involve in supply & demand planning for multinational markets;\n",
      "head to the automation, standardization and scalability of all the expansion projects.\n",
      "\n",
      "2. data analysis, interpretation and visualization: \n",
      "\n",
      "perform operational analytics in various but strongly connected fields: pricing, demand forecast, inventory, sales, etc. with the highest curiosity and eagerness for value creation.\n",
      "collaborate with cross-functional teams to form effective hypotheses based on business needs.\n",
      "test hypotheses; examine the results; do scenario, sensitivity, etc. analyses to spot out growth opportunities.\n",
      "build interactive trackers, creative visualizations as well as concrete management reports to govern project outcomes and support bias-for-action decision-making.\n",
      "conduct deep-dive / root cause analyses for long-term fixes.\n",
      "\n",
      "3. project management: \n",
      "\n",
      "initiate, set up plans and timelines; coordinate and follow up with cross-functional departments to drive the projects.\n",
      "actively communicate the objectives & progress to the stakeholders based on aligned success metrics, deep-dive on arising issues and take reaction plans to ensure high-quality deliverables at a timely manner\n",
      "\n",
      "ii. skill and experience\n",
      "\n",
      "bachelor degree and above in supply chain, business or data analytics.\n",
      "1 year of experience in supply chain/business/data analytics. retail supply chain and/or e-commerce experience is highly valued. fresher with excellent analytical and academic background is also welcome.\n",
      "advanced ms office is compulsory. be fluent in at least one query/code language (r, mysql & python are preferred).\n",
      "great attention to detail, strong analytical and data story-telling sense with a “continuous improvement” mindset.\n",
      "good command of spoken & written english and vietnamese is a must.\n",
      "good at time management, teamwork, and multitasking. have strong ownership and responsibility for deliverables.\n",
      "willing to learn, thrive in a fast-paced environment and have a can-do attitude\n",
      "================================================\n",
      "data-02-06/794/data.html\n",
      "description \n",
      "\n",
      "job responsibilities (include, but not limited to the following):\n",
      "– work with the global team in designing and implementing data retrieval software for various data sets\n",
      "– implement the rules and procedures that ensure integrity in data sets\n",
      "– collect and analyze statistics on market data applications and devise approaches to improve the relevant processes\n",
      "– develop and enhance monitoring tools to detect various types of errors in data\n",
      "job qualifications:\n",
      "– background in computer science, engineering, math or physics, with minimum\n",
      "– bachelor’s degree. proof of good academic record (such as gpa and other relevant test scores)\n",
      "– effective problem-solving skills both independently and as member of a team\n",
      "– good communication skills: must be fluent in english, spoken and written\n",
      "– \n",
      "-----------------------------------------------\n",
      "experience working under linux environment, familiar with vi or emacs for editing files\n",
      "– interested in applying technology to real world situation, comfortable working in fast paced work environment, detail oriented and capable performing tasks under time pressure\n",
      "– experience with programming in c/c++, familiar with common algorithms and data structures (binary tree, sorting, etc), object oriented programming and design patterns. familiarity with compilers, debuggers under linux (gcc, g++, gdb).\n",
      "– experience with scripting languages, such as perl, python, and shell scripting\n",
      "– knowledge of basic statistics/probability, familiar with concepts such as correlation, standard deviation and how to compute\n",
      "– familiarity with databases (such as mysql)\n",
      "position based in hanoi, vietnam.\n",
      "\n",
      "================================================\n",
      "data-02-06/2229/data.html\n",
      "================================================\n",
      "data-02-06/169/data.html\n",
      "================================================\n",
      "data-02-06/2584/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "data-02-06/1690/data.html\n",
      "responsibilities:\n",
      "\n",
      "create and maintain optimal data pipeline architecture.\n",
      "assemble large, complex data sets that meet functional / non-functional business requirements.\n",
      "identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\n",
      "build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using sql and azure ‘big data’ technologies.\n",
      "build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.\n",
      "work with stakeholders including the executive, product, data and design teams to assist with data-related technical issues and support their data infrastructure needs\n",
      "keep our data separated and secure across national boundaries through multiple data centers and azure regions\n",
      "create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader\n",
      "work with data and analytics experts to strive for greater functionality in our data systems.\n",
      "maintain master data, reference data, and data quality on daily basic.\n",
      "\n",
      "requirements:\n",
      "\n",
      "3+ years of \n",
      "-----------------------------------------------\n",
      "experience in a similar role \n",
      "graduate degree in computer science, statistics, informatics, information systems, or another quantitative field\n",
      "experience building and optimizing ‘big data’ data pipelines, architectures, and data sets.\n",
      "experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.\n",
      "experience supporting and working with cross-functional teams in a dynamic environment.\n",
      "advanced working sql knowledge and experience working with relational databases, query authoring (sql) as well as working familiarity with a variety of databases.\n",
      "strong analytic skills related to working with unstructured datasets.\n",
      "build processes supporting data transformation, data structures, metadata, dependency, and workload management.\n",
      "a successful history of manipulating, processing, and extracting value from large, disconnected datasets.\n",
      "working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2646/data.html\n",
      "mô tả công việc:\n",
      "• phân tích yêu cầu cùng ba nhằm nắm vững nghiệp vụ trước khi thực hiện.\n",
      "• tiếp nhận yêu cầu từ các dự án và đưa ra giải pháp.\n",
      "• thiết kế kiến trúc phần mềm nói chung cho công ty, bao gồm: big data, data warehouse,\n",
      "application, database đáp ứng: chạy đúng, chạy nhanh, có khả năng mở rộng dễ dàng,…\n",
      "• làm việc với các team khác trong quá trình phân tích và xây dựng phần mềm.\n",
      "• sẵn sàng nghiên cứu chuyên sâu và nhanh chóng các giải pháp công nghệ chưa có kinh\n",
      "nghiệm.\n",
      "• có khả năng tốt về quản lý công việc và thời gian của bản thân và cả nhóm. cam kết\n",
      "đúng thời hạn với công việc được giao và đảm bảo tiến độ cho các thành viên trong\n",
      "nhóm.\n",
      "• hướng dẫn các thành viên trong nhóm gỡ lỗi, tìm ra giải pháp tối ưu. định hướng, đào tạo\n",
      "các thành viên về cách thức phân tích, giải quyết vấn đề và code chất lượng cao.\n",
      "ii. yêu cầu:\n",
      "• có kiến thức tốt về kiến trúc máy tính và kiến trúc phần mềm. thông thuộc nhiều thiết kế\n",
      "phần mềm.\n",
      "• có ít nhất 3 năm \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2683/data.html\n",
      "================================================\n",
      "data-02-06/2205/data.html\n",
      "descriptionas the world's leader in digital payments technology, visa's mission is to connect the world through the most creative, reliable and secure payment network - enabling individuals, businesses, and economies to thrive. our advanced global processing network, visanet, provides secure and reliable payments around the world, and is capable of handling more than 65,000 transaction messages a second. the company's dedication to innovation drives the rapid growth of connected commerce on any device, and fuels the dream of a cashless future for everyone, everywhere. as the world moves from analog to digital, visa is applying our brand, products, people, network and scale to reshape the future of commerce.at visa, your individuality fits right in. working here gives you an opportunity to impact the world, invest in your career growth, and be part of an inclusive and diverse workplace. we are a global team of disruptors, trailblazers, innovators and risk-takers who are helping drive economic growth in even the most remote parts of the world, creatively moving the industry forward, and doing meaningful work that brings financial literacy and digital commerce to millions of unbanked and underserved consumers.you're an individual. we're the team for you. together, let's transform the way the world pays.job descriptionvisa consulting & analytics (vca) is visa's consulting division, serving visa's clients (including card issuers, acquirers and merchants) and solving their strategic problems focused on improving performance and profitability. drawing on our expertise in strategy consulting, payments, data analytics, marketing, operational and macroeconomics, vca drives high impact and tangible financial results. the incumbent will be part of vca data science geographic team cluster of indonesia, philippines, vietnam, myanmar and cambodia (ipvmc) markets, and will be responsible for data science backed consulting engagements with visa's clients in vietnam. the team is involved in a comprehensive range of consulting services and solutions to our clients, that address unique challenges in areas such as strategic growth, profitability, risk management, digital strategy and data-driven portfolio management decisions.if you like to use fact-based, data-driven solutions to solve for business problems that deliver value and enable vietnam clients to win more business, you should apply.what a sr data scientist does at visa:the sr data scientist is a key member of the visa analytics and consulting (vca) team. as a sr data scientist for vietnam, you will be supporting the design, development and implementation of analytics driven strategies and solutions for key visa clients. you will collaborate with our vca, business, and technology teams across the organization to implement solutions to drive business performance.in this role, you are expected to:define detailed scope and methodology, creating and executing on the framework with appropriate data mining techniquessupport and deliver analytics projects from conception to completion with actionable insights and recommendationsclearly communicate the findings and recommendations, drive deployment and implementation of analytics solutions, and track business value impactresearch industry metrics and business context and bring this context to bear in analysesactively seek out opportunities to innovate by using non-traditional data and new modeling techniques fit for purpose to the needs of our clientsensure all project documentation is up to date and maintain the highest levels of quality in deliverablesperform as an independent contributor mostly, with high engagement with consultants and other data science team members to deliver projectsenhance existing analytic techniques by promoting new methodology and best practices in analytics fieldhigh interaction with external clients, and manage internal and external stakeholderson a per-project basis, work on client site as requiredthis role reports to the head of data science for the vietnam country team and this position will be based in our hanoi or ho chi minh city visa office.why this is important to visaas a payment consulting arm of visa, vca is growing a team of highly specialized experts that can provide best in class payment expertise to the client. we want to bring this expertise closer to our clients by placing the sr data scientist in-market in vietnam. we are a global organization leveraging global expertise and best practice with local knowledge and understanding of our client partners. this enables us to deepen our partnership with our clients and bring value to their business. qualificationswhat you will need: we are looking to hire candidates that have already accumulated a variety of \n",
      "-----------------------------------------------\n",
      "experience, you will be curious about the payments industry, results-driven and client-centric. as a candidate you should have both technical and business acumen:degree (masters or ph.d. would be an advantage) in quantitative field such as statistics, mathematics, operational research, computer science, economics, or engineering or equivalent experienceminimum 8 years of analytical expertise in applying statistical solutions to business problemshands on experience with one or\n",
      "================================================\n",
      "data-02-06/2433/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      " about the jobyou will collaborate with various organizational departments in vietnam office to collect, analyze, understand requirements and propose technical solution for data analysis, reporting and forecasting to support business for decision making.what you will dodesign, implement, validate/test, and maintain the report system to fit all requirements.directly working with various departments to deliver tasks.actively working with stakeholders to propose new ideas - execute the ideas to help the business achieve the overall goal.collect analysis, reporting & forecasting requirements (in english) from stakeholders (production, accounting, sales, customer service and human resources...).present the report/findings (in english) to stakeholders. \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1990/data.html\n",
      "description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "skills required\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "details\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-nhận yêu cầu, phân tích và làm việc quản lý dự án để thiết lập chương trình dự án.\n",
      "- phân tích yêu cầu dự án, kiểm soát năng suất và chất lượng dự án.\n",
      "-phối hợp với quản lý nhóm để phân chia và sắp xếp nhân viên theo bảng kế hoạch dự án.\n",
      "- liên hệ trực tiếp với khách hàng để hiểu rõ yêu cầu dự án.\n",
      "- đào tạo, hướng dẫn nhân viên thực hiện dự án.\n",
      "- làm báo giá dự án khi được yêu cầu.\n",
      "- báo cáo hàng tuần hoặc hàng tháng theo yêu cầu của quản lý.\n",
      "- thay mặt quản lý dự án làm việc với các phòng ban liên quan\n",
      "- các công việc khác theo sự phân công của quản lý dự án.\n",
      "* thời gian làm việc: giờ hành chính (thứ 2 – 6, nghỉ giữa giờ 1 tiếng)\n",
      "* quyền lợi\n",
      "- môi trường làm việc chuyên nghiệp, cơ hội phát triển và thăng tiến\n",
      "- lương tháng 13 + thưởng hiệu quả kinh doanh\n",
      "- phép năm (12 ngày/năm, bao gồm phép trong 2 tháng thử việc)\n",
      "- thẻ gửi xe miễn phí\n",
      "- tham gia đầy đủ chế độ bhxh, bhyt, bhtn (bh 100% lương)\n",
      "- khám sức khỏe định kỳ hằng năm\n",
      "- gói bảo hiểm sức khỏe cao cấp\n",
      "- du lịch công ty\n",
      "- các phúc lợi từ công đoàn (quà vào các dịp lễ/tết, sinh nhật...)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "required experience / skills detail\n",
      "\n",
      "\n",
      "\n",
      "- kỹ năng phân tích thông tin và dữ liệu.\n",
      "- kỹ năng đàm phán để trao đổi và thảo luận với khách hàng về các yêu cầu của dự án.\n",
      "- khả năng làm việc độc lập, làm việc nhóm,\n",
      "- thành thạo vi tính văn phòng.\n",
      "- tiếng anh thành thạo 4 kỹ năng\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job detail\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "position type\n",
      "\n",
      "full-time\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "career level\n",
      "\n",
      "staff\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "education level\n",
      "\n",
      "diploma (3 years)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gender\n",
      "\n",
      "male / female\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job categories\n",
      "\n",
      "\n",
      "clerical / administrative\n",
      "\n",
      ", \n",
      "\n",
      "customer service\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "information\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "name:\n",
      "\n",
      "\n",
      "hr department\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2nd floor, anna building, quang trung software city\n",
      "\n",
      ", \n",
      "\n",
      "district 12\n",
      "\n",
      ", \n",
      "\n",
      "ho chi minh\n",
      "\n",
      ", \n",
      "\n",
      "viet nam\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- các ứng viên quan tâm vui lòng nộp hồ sơ trực tuyến, gửi kèm file hoặc nộp trực tiếp tại công ty.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "application language:\n",
      "english\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "digi-texx vietnam ltd.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "http://www.digi-texx.vn/\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1.000 - 4.999 employees\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact: hr department\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "digi-texx là công ty chuyên cung cấp các giải pháp về công nghệ thông tin & gia công quy trình kinh doanh (bpo), có 100% vốn đầu tư của đức với hơn 19 năm \n",
      "-----------------------------------------------\n",
      "kinh nghiệm.\n",
      "================================================\n",
      "data-02-06/965/data.html\n",
      "descriptionaccountable for executing, validate, process and technology with a goal of delivering high quality and on-time data according to internal slaswork closely with team lead to drive initiatives within input operationssupport all pm&fv activity within the country and any assigned taskfollow and monitor data files flow from dacreate and maintain documentation per projectensure sop is followed and updated according to changessupport training of associate within pm&fv operationresearch questions arising from internal and external sources relating to delivered dataidentify problems; determine root cause as well as short- and long-term resolutions. make recommendations for enhancements/improvement to internal nielseniq operational processes qualificationsbachelor’s degree in a statistical, mathematical, or technical fieldgood english level (written and oral) & local language (vietnam)good at ms office, sql/oracle/access, especially in writing queriesat least 1-2 years of \n",
      "-----------------------------------------------\n",
      "experience in data processingstrong quality & detail orientationsolid problem solvingability to work well in a fast-face environmentable to work effectively within team and stakeholder (cs/oo/io_delivery team)logical thinking, strong analytical and problem-solving skillsgood communication skillsadditional informationabout nielseniqnielseniq is a global measurement and data analytics company providing the most complete and trusted view of consumers and markets in 90 countries covering 90% of the world’s population. focusing on consumer-packaged goods manufacturers and fmcg and retailers, we enable customers to defy what’s possible. how? we combine unparalleled datasets, pioneering\n",
      "================================================\n",
      "data-02-06/1295/data.html\n",
      "descriptionbgsv – bosch global software technologies company limited (previous name: rbvh - robert bosch engineering and business solutions vietnam company limited) is 100% owned subsidiary of robert bosch gmbh.\n",
      "bgsv has started its operations from 19th october, 2010 at e-town2 in hcmc. this engineering development center will be engaged in developing embedded systems and software, mechanical design and simulation, and will provide it (sap consulting, java development….) and business services (finance and accounting, economics, purchasing, logistics, translations japanese-english-japanese, information security ) solutions to the bosch group of companies globally.job descriptionensure the data quality and integrity in databasesfix any issue related to database performance and provide corrective measurescreate functions, scripts, stored procedures and triggers to support application developmenttake regular database backuptest databases and perform bug fixesdepartment hiring this position: bdqualifications\n",
      "-----------------------------------------------\n",
      "experience level:1+ years (expertise in database development)qualifications:bachelor degree in it/ computer sciencehands-on experience in oracle database developmenthands on experience in development using sql, pl/sqlgood english communication skillsbe flexible/ comfortable if working in shiftadditional informationjob location:hcmc: etown 2, 364 cong hoa, ward 13, tan binh dist., hcmchanoi: 29 lieu giai, ngoc khanh, ba dinh dist., hanoiso... why bosch?\n",
      "because - together - we turn the ideas into reality, working every day to make the world of tomorrow a better place.as a boschler, you will have a chance to:work in one of the best places to work in vietnamjoin a dynamic and fast growing global company (english-speaking environment)get 13th-month salary bonus + attractive performance bonus (you'll love it!) + annual performance appraisal100% monthly basic salary and mandatory social insurances in 2-month probationonsite opportunities: short-term and long-term assignments15++ days of annual leave + 1 day of birthday leavepremium health insurance for employee and 02 family membersflexible working timelunch and parking allowancegood benefits of company activitiesopportunity to work in global projects of fast developing company and being a part of innovation team contributing initiative ideas to the hi-tech world.engage in our diverse training programs which surely help strengthen both your personal\n",
      "================================================\n",
      "data-02-06/2563/data.html\n",
      "responsible for developing programs and automated processes to cleanse, integrate and evaluate large datasets from disparate sources and implement business logic to build data warehouse, data marts to serve business functions including mis reports, bi dynamic reports, ml use cases, and other applications requested by business operation.\n",
      "responsible for working with other stakeholders to support data pipelines, convert data models to data products.\n",
      "\n",
      "data integration:\n",
      "\n",
      "obtain and integrate data and information from various sources into the centralized platforms, solutions, and statistical models.\n",
      "write scripts and ingest raw data to build and maintain optimized data pipelines and etl solutions as business support tools in providing analysis.\n",
      "ensure data assets are organized and stored in an efficient way so that information is easy to access and retrieve\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1834/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "- kiểm soát ngân sách hàng năm của phòng chiến lược bao gồm nhưng không giới hạn:+ thu thập danh sách cộng dồn từ các nhóm kinh doanh 3 miền (trade marketing, modern channel, vnm shop) (đầu, giữa & cuối tháng)+ lập danh sách cộng dồn hoa hồng và chi phí tu trả trước (đầu & cuối tháng)+ theo dõi và kiểm soát ngân sách thương mại (opex) và cac (hoa hồng) & chi phí nạp tiền trả trước+ phân bổ lại ngân sách phòng chiến lược 3 miền (nếu có)+ hàng quý: rà soát, phân bổ lại ngân sách cho các năm còn lại trên cơ sở kế hoạch đã điều chỉnh- cập nhật báo cáo tình báo cáo thị trường hàng ngày/tuần/tháng.- hỗ trợ hành chính của phòng chiến lược(chấm công,book phòng,thanh toán cho nv đi công tác..)- các nhiệm vụ và công việc khác được giao theo yêu cầu sản xuất kinh doanh của công ty.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "trình độ & kinh nghiệm- người có bằng cấp về kinh doanh, tài chính, kế toán, luật hoặc các ngành học liên quan khác.- có từ 1 năm kinh nghiệm về quản lý ngân sách hoặc các vị trí liên quan.\n",
      "================================================\n",
      "data-02-06/2936/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            - develop a plan and detail the implementation of the search for new growth mkt channels for customer or driver acquisition;\n",
      "- survey, refer to effective growth features for customers or drivers;\n",
      "- connect with mkt teams and other departments (product, business\n",
      "- development, operations…) to develop customer or driver development strategies;\n",
      "- research, test and develop new customer acquisition channels, new forms of customer search with optimal costs and advertising effectiveness;\n",
      "- analyze existing metrics and test campaigns to generate reports and identify effective new merchant acquisition channels;\n",
      "- gain a number of new customers and quality.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2389/data.html\n",
      "mô tả công việc\n",
      " 1.tổng hợp và phân tích số liệu liên quan đến ngành hàng, mkt, doanh số sell in/out, vận hành ... và lập báo cáo hàng tuần/tháng\n",
      "\n",
      "phối hợp với đội lập trình, marketing và ngành hàng để tổng hợp số liệu bán hàng và các chỉ số liên quan\n",
      "thiết kế các bảng biểu và báo cáo nội bộ phù hợp với yêu cầu của quản lý\n",
      "gửi báo cáo hàng tuần cho quản lý\n",
      "cập nhật thường xuyên thông tin tài chính cho các quản lý liên quan để hỗ trợ ra quyết định kinh doanh.\n",
      "\n",
      "2. lập kế hoạch ngân sách và theo dõi thực tế thực hiện ngân sách\n",
      "\n",
      "phối hợp với đội lập trình, marketing và ngành hàng để tổng hợp số liệu bán hàng và các chỉ số liên quan\n",
      "thiết kế các bảng biểu và báo cáo nội bộ phù hợp với yêu cầu của quản lý\n",
      "gửi báo cáo hàng tuần cho quản lý\n",
      "cập nhật thường xuyên thông tin tài chính cho các quản lý liên quan để hỗ trợ ra quyết định kinh doanh.\n",
      "\n",
      "3. kiểm soát hàng tồn kho, kiểm soát hiệu quả hoạt động của các bộ phận\n",
      "\n",
      "tìm hiểu thị trường, hoạt động của công ty và các đầu mối làm việc\n",
      "lập kế hoạch ngân sách hàng tháng (theo mẫu hoặc tự thiết kế)\n",
      "trình duyệt ngân sách với quản lý và giám đốc\n",
      "phân bổ ngân sách cho các bộ phận liên quan\n",
      "theo dõi việc sử dụng ngân sách và đánh giá hiệu quả\n",
      "\n",
      "4. quản lý, giám sát và đôn đốc việc thực hiện doanh số, lợi nhuận theo chỉ tiêu cam kết\n",
      "\n",
      "hỗ trợ quản lý nh trong việc cung cấp thông tin và dữ liệu tài chính phục vụ cho việc giám sát việc thực hiện doanh số.\n",
      "thường xuyên kiểm soát, đôn đốc các quản lý nh về tiến độ thực hiện doanh số.\n",
      "báo cáo bgd về tình hình thực hiện doanh số và đưa ra các giải pháp tài chính phục vụ cho việc ra quyết định.\n",
      " \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1550/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- operate/implement technological solutions/systems/tools to prevent frauds, automate and systemize alerts/risk limits.- operate, upgrade and complete process/procedures to prevent frauds related to digital wallets transactions, promotional campaigns, international cards payment...- constantly monitor/identify risk arising from products/services and provide solutions to overcome and prevent similar situation from occurring in the future.- coordinate with other teams/departments to implement and fully comply with digital wallet and payment processing rules/regulations of the state bank of vietnam and the international card organization.- participate in development process of new product and monitor existing products/services to provide solutions related to fraud prevention. identify risk/fraud and alert related teams/departments in a timely manner.- develop team members to strengthen their technical and soft skills to identify, analyze, evaluate, and respond to risks\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2869/data.html\n",
      "================================================\n",
      "data-02-06/448/data.html\n",
      "================================================\n",
      "data-02-06/2604/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            - quản lý, tổ chức hệ thống hồ sơ và dữ liệu trong công ty một cách khoa học;\n",
      "- xử lý các dữ liệu sản xuất từ hệ thống để lập báo cáo, dự báo xu hướng, tham mưu cho ban giám đốc về các vấn đề trong sản xuất và đề xuất cải tiến.\n",
      "- phối hợp chặt chẽ với bộ phận sản xuất và sử dụng các công cụ xử lý dữ liệu để tìm ra nguyên nhân cốt lõi của các vấn đề phát sinh trong sản xuất.\n",
      "- tối ưu hóa các dự án cải tiến và tự động hóa trong nhà máy nhằm nâng cao hiệu suất và báo cáo kết quả bằng dữ liệu trực quan.\n",
      "- sử dụng dữ liệu để phân tích và tham mưu cho người quản lý về chiến lược và định hướng ra quyết định.\n",
      "- các công việc khác theo phân công của người quản lý.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1578/data.html\n",
      "mô tả công việc:\n",
      "\n",
      "chịu trách nhiệm xây dựng, thực hiện và kiểm soát các báo cáo và phân tích của trung tâm chiến lược và giải pháp ngân hàng số\n",
      "trách nhiệm:\n",
      "thực hiện, duy trì và tự động hóa các báo cáo định kỳ của trung tâm chiến lược và giải pháp ngân hàng số;\n",
      "thực hiện các báo cáo phân tích cũng như đưa ra các tiêu chí đánh giá hiệu quả hoạt động trên các nền tảng ngân hàng số;\n",
      "sử dụng các công cụ và kỹ thuật phân tích nhằm khai phá dữ liệu và phân tích chuyên sâu về hành vi người dùng trên các nền tảng ngân hàng số;\n",
      "phối hợp với các đơn vị có liên quan để xác định xu hướng/cơ hội tăng trưởng khách hàng dựa trên các phân tích chuyên sâu; xây dựng bản mô tả yêu cầu về những thông tin dữ liệu cần được tổng hợp và đồng bộ;\n",
      "thực hiện các nhiệm vụ khác theo phân công của cấp quản lý\n",
      "yêu cầu:trình độ cử nhân trở lên chuyên ngành công nghệ thông tin, hệ thống thông tin quản lý, khoa học máy tính hoặc các lĩnh vực có liên quan;\n",
      "tối thiểu 7 năm (chuyên gia)/5 năm (chuyên viên cao cấp)/3 năm (chuyên viên chính)/2 năm (chuyên viên) \n",
      "-----------------------------------------------\n",
      "kinh nghiệm làm việc tại các vị trí liên quan trong lĩnh vực tài chính ngân hàng hoặc nhóm ngành công nghệ thông tin;\n",
      "am hiểu về khai thác dữ liệu (data mining), lập mô hình thống kê, phân tích dữ liệu số và hoạt động kinh doanh;\n",
      "thành thạo các công cụ báo cáo bi như tableau, qlikview & powerbi;\n",
      "kỹ năng trình bày và thuyết trình tốt;\n",
      "kỹ năng phân tích và đọc hiểu báo cáo tốt;\n",
      "\n",
      "================================================\n",
      "data-02-06/2826/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            working hour: 40 hours/week, from 10 am to 18 pm, monday - friday\n",
      "department: data entry office\n",
      "location: nguyen van huong street, thao dien ward, district 2, hcmc\n",
      "\n",
      "we are looking for database entry. if you're detail-orientated and are an expert \n",
      "on excel, this job might suit you.\n",
      "1. input and manage data;\n",
      "2. follow up the sales procedures to make sure all the documents, invoices are\n",
      "sent correctly as per direct supervisor requests;\n",
      "3. other duties as required.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3121/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "                                    mô tả công việc:\n",
      "- chúng tôi đang tìm kiếm một nhà phân tích dữ liệu kinh doanh dược phẩm có kỹ năng và năng động để tham gia vào nhóm của chúng tôi. ứng viên trúng tuyển sẽ chịu trách nhiệm phân tích và diễn giải các tập dữ liệu phức tạp, cung cấp thông tin chi tiết hữu ích để hỗ trợ các quyết định kinh doanh trong ngành dược phẩm.\n",
      "trách nhiệm công việc:\n",
      "- thu thập, làm sạch và phân tích các bộ dữ liệu lớn từ nhiều nguồn khác nhau, bao gồm số liệu bán hàng, báo cáo nghiên cứu thị trường và phản hồi của khách hàng.\n",
      "- phát triển và duy trì cơ sở dữ liệu, bảng tính và các công cụ khác để tổ chức và phân tích dữ liệu.\n",
      "- sử dụng phần mềm thống kê và phân tích dữ liệu để xác định xu hướng và mẫu trong dữ liệu và chuẩn bị báo cáo cho quản lý.\n",
      "- cộng tác với các nhóm chức năng chéo để hiểu các yêu cầu kinh doanh và phát triển các giải pháp đáp ứng các nhu cầu đó.\n",
      "- giải thích và truyền đạt kết quả dữ liệu cho các bên liên quan phi kỹ thuật một cách rõ ràng và ngắn gọn.\n",
      "- theo dõi các xu hướng của ngành, đối thủ cạnh tranh và các thay đổi về quy định để cung cấp thông tin chuyên sâu về thị trường dược phẩm.\n",
      "- phát triển và thực hiện các chiến lược dựa trên dữ liệu để tối ưu hóa quy trình kinh doanh và tăng lợi nhuận.\n",
      "                                \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2044/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "1. quản lý hiệu quả hoạt động của chức năng.\n",
      "2. theo dõi và kiểm soát hiệu quả hoạt động cung ứng: chi phí logistic, tồn kho, mua hàng…\n",
      "3. đánh giá biến động của chi phí vận chuyển: xe nhà và xe thuê ngoài.\n",
      "4. đề xuất giải pháp để tối ưu việc sử dụng chi phí vận chuyển.\n",
      "5. dự báo rủi ro biến động chi phí logistic.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "– nam/nữ, tuổi từ 25 – 35\n",
      "– tốt nghiệp đại học chuyên ngành kiểm toán, tài chính, …\n",
      "– tối thiểu 3 năm kinh nghiệm kế toán/ tài chính\n",
      "– kỹ năng thiết lập, trình bày báo cáo; phân tích đánh giá dữ liệu; xây dựng aop-kpi và quản trị giá thành (công ty sản xuất)\n",
      "– ưu tiên đã từng tham gia triển khai sap/ sử dụng sap\n",
      "\n",
      "================================================\n",
      "data-02-06/596/data.html\n",
      "================================================\n",
      "data-02-06/3158/data.html\n",
      "mô tả công việc\n",
      "– nghiên cứu đề xuất các giải pháp về ai (computer vision) \n",
      "– triển khai giải pháp trên cloud & edge device (jetson nano, pi3…)\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/683/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "1. lập kế hoạch:\n",
      "\n",
      "tham gia lập kế hoạch chiến lược 5 năm & kế hoạch tài chính hàng năm;\n",
      "báo cáo đánh giá tình hình thực hiện kế hoạch định kỳ;\n",
      "xây dựng và kiểm soát mô hình lập, theo dõi kế hoạch.\n",
      "\n",
      "2. quản trị kết quả kinh doanh:\n",
      "\n",
      "kiểm soát kết quả kinh doanh;\n",
      "đề xuất các giải pháp để cải thiện kết quả kinh doanh;\n",
      "phân tích & đánh giá kết quả kinh doanh của ngành hàng, sản phẩm, khu vực;…\n",
      "dự phóng kết quả kinh doanh định kỳ;\n",
      "xây dựng & kiểm soát các mô hình đánh giá kết quả kinh doanh.\n",
      "\n",
      "3. quản trị cơ sở dữ liệu tài chính: \n",
      "\n",
      "xây dựng và phát triển dữ liệu;\n",
      "cải tiến công cụ thực hiện công việc.\n",
      "\n",
      "4. quản lý & duy trì hiệu quả hoạt động của nhóm: \n",
      "\n",
      "kiểm soát các công việc của nhóm mình phụ trách đảm bảo chính xác, kịp thời và hiệu quả.\n",
      "\n",
      "5. các công việc khác theo chỉ đạo và phân công trực tiếp từ các cấp quản lý. \n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/733/data.html\n",
      "descriptionavery dennison (nyse: avy) is a global materials science company specializing in the design and manufacture of a wide variety of labeling and functional materials. the company’s products, which are used in nearly every major industry, include pressure-sensitive materials for labels and graphic applications; tapes and other bonding solutions for industrial, medical, and retail applications; tags, labels and embellishments for apparel; and radio frequency identification (rfid) solutions serving retail apparel and other markets. headquartered in glendale, california, the company employs more than 30,000 employees in over 50 countries. reported sales in 2019 were $7.1 billion. learn more at www.averydennison.com.job description● diễn giải và phân tích dữ liệu bằng các kỹ thuật thống kê. làm báo cáo kết quả hằng ngày.● hỗ trợ phát triển và triển khai các hệ thống thu thập dữ liệu nhằm tối ưu hóa hiệu quả● thống kê và chất lượng dữ liệu● thu thập và quản lý dữ liệu từ các nguồn dữ liệu chính hoặc phụ. duy trì hệ thống cơ sở dữ● liệu● xác định, phân tích và diễn giải các xu hướng đang hoặc sắp diễn ra sau khi phân tích dữ● liệu.● phối hợp chặt chẽ với các bên liên quan để xử lý các yêu cầu của công ty.● hỗ trợ cải tiến quy trình làm việc để đạt hiệu quả cao hơn.\n",
      "-----------------------------------------------\n",
      "qualifications● tốt nghiệp cao đẳng trở lên các ngành lên quan tới toán thống kê, quản lý dữ liệu, it...● có hiểu biết về các phương pháp và công cụ phân tích dữ liệu / quản lý dữ liệu● sử dụng tốt các công cụ thống kê như excel, spss, sas...● tư duy logic và có khả năng trình bày báo cáo rõ ràng, rành mạch, dễ hiểu.additional informationrecruiter in charge: ms. minh minh - [email\n",
      "================================================\n",
      "data-02-06/1196/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "lập kế hoạch, theo dõi, phối hợp với các đơn vị liên quan trong xây dựng, thí điểm, triển khai chính thức và quản lý mô hình dữ liệu.\n",
      "thực hiện xây dựng các văn bản liên quan đến quản trị dữ liệu (gồm chính sách, tiêu chuẩn, quy định, quy trình, hướng dẫn…) theo phân công phụ trách.\n",
      "quản lý công tác làm sạch dữ liệu.\n",
      "rà soát, đánh giá, phối hợp với các đơn vị liên quan trong phân tích nguyên nhân và đề xuất các giải pháp xử lý các vấn đề về chất lượng dữ liệu.\n",
      "phối hợp với các đơn vị liên quan xây dựng ma trận phân quyền truy cập các hệ thống dữ liệu tại mic.\n",
      "hướng dẫn, phối hợp với các đơn vị trong việc triển khai phân loại bảo mật dữ liệu.\n",
      "tiếp nhận các nhu cầu, thực hiện xây dựng báo cáo phân tích theo yêu cầu.\n",
      "nghiên cứu, đề xuất, thực hiện xây dựng các báo cáo phân tích chuyên sâu.\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "\n",
      "tốt nghiệp\n",
      "================================================\n",
      "data-02-06/2546/data.html\n",
      "================================================\n",
      "data-02-06/2929/data.html\n",
      "mô tả công việc\n",
      " top 3 reasons to join usengaging perks and benefits for your well-beingworld-class technology for parcel trackingculture that embraces growth and teamworkthe job\n",
      "do you want to be at the forefront of parcel perform's product for a ground-breaking b2b platform solution in e-commerce logistics?\n",
      "parcel perform is looking for an amazing data engineer to support us on the product development and innovation front!\n",
      "we are a dynamic, fast-growing team that's excited about e-commerce and logistics and the opportunity to transform these industries with data and technology. join us and our journey to drive growth in the e-commerce market. we are looking for you as a data engineer.\n",
      "we need you on our team!\n",
      "you will be part of a young & motivated team, driving the next level of growth of our parcel perform and parcel monitor applications that help customers track e-commerce shipments around the globe. as part of our team, you will have a very direct impact on the success of the company.\n",
      "as a data engineer, you are in charge of the data ecosystem, which includes everything from data sources and databases to data storage solutions. these components are connected by pipelines that transport and transform data.\n",
      "you will be working side by side with our data scientists and architects in both data analysis processes and bringing prediction models to the production environment.\n",
      "and you will also be developing analytical tools and programs. though we are promoting the use of open sources, some situations call for bespoke software for better customization, user \n",
      "-----------------------------------------------\n",
      "experience, and data accuracy.\n",
      "your skills and experience\n",
      "we at parcel perform believe in innovation, energy and resourcefulness for everything we do. we will not stop delivering an outstanding product that we can be proud of and need you to help us inform the world. you need to feel the same way about our offering and bring along the following things:\n",
      "\n",
      "at least 5 years of working as a data engineer\n",
      "solid foundation in python and at least another language in the jvm family\n",
      "deep knowledge of sql database design\n",
      "experience with distributed systems, high volume databases, and etl pipelines\n",
      "familiarity with big data analysis\n",
      "exposure to a wide range of nosql solutions\n",
      "excellent critical thinking, organizational and communication skills\n",
      "strong ownership and good collaboration skills to work in a team\n",
      "good english communication\n",
      "\n",
      "why you'll love working here\n",
      "we at parcel perform are dedicated to being a platform for growth for all our team members, regardless of function and location.\n",
      "\n",
      "the opportunity to work in a fast-growing, super exciting and innovative business that will revolutionize the e-commerce logistics industry. you will be the needle of success on the growth of a global product that will become a key platform behind successful e-commerce logistics worldwide.\n",
      "the ability to continuously learn and develop in an international setting with you being a critical driver behind the success of us achieving our mission.\n",
      "an environment where everybody never stops growing and focuses on succeeding - we continuously work with you on your strengths and weaknesses across many important dimensions and look at ways for you to address them and further your development\n",
      "your entry ticket into being part of the parcel perform journey, where you will work with and alongside people from around the world that share the same passion and dedication.\n",
      "\n",
      "who are we at parcel perform!\n",
      "parcel perform is the leading delivery experience platform. it enables modern e-commerce enterprises to create unique end-to-end customer journeys and optimize logistics operations with powerful data integrations, parcel tracking, delivery notifications and logistics performance reports in real-time.\n",
      "parcel perform's scalable saas platform executes more than 100m parcel updates daily and integrates with 800+ carriers. the data-first company is pioneering innovative ml / ai use cases in e-commerce logistics including its 'date of arrival' prediction engine. parcel perform is the partner of choice for top brands, marketplaces and carriers across all major verticals globally.\n",
      " \n",
      "================================================\n",
      "data-02-06/1037/data.html\n",
      "================================================\n",
      "data-02-06/697/data.html\n",
      "description﻿\n",
      "gear inc is seeking real-time analyst positions for our moderation team. our real time analyst will work directly with regional workforce manager and be responsible for following tasks, including but not limited to:\n",
      "monitors real-time work volume and schedule conformance via tcs to efficiently utilize staffing resourcescoordinates and manages same-day and/or short-term offline event scheduling for moderation agents while maintaining acceptable performance of the centeranalyses trends such as volume, aht, latency, utilization, shrinkages, and attendance to understand and plan for potential overstaffing/understaffing conditions; adjust plans prior to and/or same day to enable teams to attain appropriate performance resultsparticipates in help desk internal and external communications to relay how issues are impacting the center's performanceeffectively communicate center performance and information by providing reports and updates regarding recent, current, and future business productivityensures that service level targets as well as other programs/client targets through schedule adherence and compliance.\n",
      "\n",
      "-----------------------------------------------\n",
      "job requirements\n",
      "university degree, ideally in a relevant degree such as data analyst or similar;minimum of 1 year of proven experience in a relevant position;proficient in english communicationdemonstrated ability to create and analyze quality reportsadvanced knowledge in real time management analysis with strong decision making skillscontent moderation familiarity is a plusexcellent data analysis skills with strong logical thinking mindset; ability to organize and analyze data in a structured mannerintermediate knowledge in performing root cause analysis.highly proficient in using ms excelimpeccable attention to detail.\n",
      "what benefits you will get\n",
      "1. salary and benefits\n",
      "attractive salary and benefits (competitive basic salary, lunch allowance, 13th salary, additional bonus, profit sharing) and annual salary review.100% compulsory insurance covered by the company after the probation.premium healthcare and mental health care service for you, 100% covered by the company.extra bonus per personal events (wedding, funeral, hospitalization, newborn baby) and a very cute baby box for staff who are going to welcome a new baby angel to the world.annual health check, annual flu vaccination.fantastic internal events.summer vacation (paid days off and bonus).paid leave (12 days/year).\n",
      "2. working environment\n",
      "5 shifts per week, night shifts included (equivalent to 40 working hours/ week).international, fun and professional working environmentstanding desks if you like, modern hardware, no dress code, free drinks (coffee, tea, etc.)english working environmentinternal english class fully sponsored by the company with a native teacher during working time.training and career development opportunities.\n",
      "all interested candidates are welcome to apply. please send your resume expressing your interest to us. kindly note that only shortlisted candidates will be contacted by our hr team.\n",
      "================================================\n",
      "data-02-06/1727/data.html\n",
      "================================================\n",
      "data-02-06/1086/data.html\n",
      "responsibilities change as we grow, so we favor logical people over those who are merely \n",
      "-----------------------------------------------\n",
      "experienced\n",
      "================================================\n",
      "data-02-06/3075/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi tiết công việc trưởng nhóm phân tích kinh doanh (business intelligence leader) tại công ty tnhh routine việt na\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2695/data.html\n",
      "================================================\n",
      "data-02-06/2665/data.html\n",
      "mô tả công việc\n",
      "\n",
      "1. nhận chỉ tiêu bán hàng của công ty, lên kế hoạch thúc đẩy doanh thu, triển khai thực hiện đảm bảo đạt chỉ tiêu được giao.\n",
      "2. đào tạo, hướng dẫn các chính sách chương trình của acs tới các đại lý, nhân viên đại lý hợp tác với acs việt nam.\n",
      "3. lên lịch đi tuyến hàng tuần đến các đại lý để chăm sóc, trao đổi, nắm bắt các thông tin bán hàng tại đại lý kịp thời.\n",
      "4. tìm kiếm và phát triển thị trường, mở mới các đại lý phù hợp để mở rộng hợp tác.\n",
      "5. hỗ trợ đại lý xử lý các vấn đề liên quan đến chương trình, chính sách của acs.\n",
      "6. triển khai trưng bày hình ảnh posm của acs trong đại lý.\n",
      "7. sắp xếp lịch làm việc cho nhân viên tư vấn, giám sát việc hoàn thành chỉ tiêu được giao. hỗ trợ nhân viên xử lý các vướng mắc trong công việc.\n",
      "8. báo cáo kết quả bán hàng hàng tuần, hàng tháng và các vấn đề tại thị trường, chính sách của đối thủ cho cấp trên. tìm hiểu và báo cáo nguyên nhân\n",
      "dẫn đến doanh số giảm/tăng, đề xuất giải pháp khắc phục.\n",
      "9. tìm hiểu chương trình, kế hoạch của đối thủ cạnh tranh\n",
      "10. thực hiện các công việc khác được cấp trên giao.\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "1.tuân thủ đúng các quy định của công ty\n",
      "2. quản lý nhân viên\n",
      "3. triển khai chính xác chương trình, chính sách tới các đối tác hợp tác .\n",
      "4. hoàn thành chỉ tiêu doanh thu được giao.\n",
      "- giới tính: nam, nữ (ưu tiêu nam)\n",
      "- tuổi: < 35\n",
      "\n",
      "================================================\n",
      "data-02-06/2820/data.html\n",
      "================================================\n",
      "data-02-06/2877/data.html\n",
      "description\n",
      "\n",
      "\n",
      "\n",
      "implementation of customer retention initiatives: identify and understand customer’s recruiting challenges to prepare and present a customized consumer recruitment & retention plandevelop & monitoring key metrics to measure acquisition (lead, mqls, new users) & customer engagement, and retention; thus identify opportunities for business growthdevelop & optimize personalized customer journey, web/app products for users across their customer journeys (both lifetime and decision journey)ensure frequent updates of findings/data analysis i.e. how the process works/ pro-cons/how to improve/any cost saving/effectiveness etc ensure consistency in brand communication messages across communication materialsdata & insights generationgather and analyse consumers’ data to generate actionable insights to support for business decisions (in collaboration with data manager & customer growth manager)build/enhance real-time performance dashboards to monitor and manage effective customer management, campaign management, customer lifecycle value management (in collaboration with data manager and growth manager) conformationcollect information, draw conclusions based on analysis, give advice on optimizing existing business and proposes plans/corrective actions for cost optimization.keep all expenditures within the approved budget.ensure team activities are complied with company business code of conduct and all local applicable laws within scope of function responsibility.the above responsibilities are not intended to be an exhaustive list of all responsibilities and duties required of employees assigned to this job. the incumbent may be asked to perform other duties as assigned by the company or line manager \n",
      "\n",
      "\n",
      "read more\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2150/data.html\n",
      "mô tả công việc\n",
      "nghiên cứu, xây dựng phương án, lập trình, thử nghiệm và tối ưu kết quả các bài toán ai thuộc các lĩnh vực: + xử lý ảnh: object detection, segmentation, classification; ocr; image captionin + xử lý ngôn ngữ tự nhiên: chatbot, text normalization … + xử lý tiếng nói: speech recognition, speech synthesis, wakeup word … + các bài toán về robotics, ai on edge devices … \n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "sinh viên đã tốt nghiệp chuyên ngành cntt, đtvt, đktđ các trường đại học.\n",
      "================================================\n",
      "data-02-06/2894/data.html\n",
      "descriptionpi associates is a quantitative asset management firm. we apply a scientific, regulated approach to investments, in short, involves identifying factors, or characteristics, of stocks that, in the long run, outperform the rest of the market.responsibilities• design, test, and implement algorithmic trading strategies • analyze large datasets to identify market trends and patterns • develop predictive models using machine learning algorithms • work closely with traders, data scientists, and portfolio managers to inform investment decisions• communicate findings and insights to the broader team and stakeholdersskillsdata analysisalgorithmstradingmachine learningfinancerequirement• degree in a relevant field such as mathematics, statistics, computer science, or finance • strong technical skills, including expertise in machine learning, data analysis, and algorithmic trading • \n",
      "-----------------------------------------------\n",
      "experience working with large financial datasets and time-series data\n",
      "================================================\n",
      "data-02-06/2686/data.html\n",
      "responsibility for the data engineering team and its employees, as well as technical oversight of the data products being developed. being involved in initiatives all over the globe (asia pacific, europe, and beyond) necessitates a high degree of adaptability and versatility in order to meet the many demands that come into the team. the ongoing expansion of the current team's capability and technical ability is critical. being calm and focused while navigating a complicated issue area will allow for effective problem solving in this position.\n",
      "job descripton\n",
      "\n",
      "proven etl design and implementation expertise\n",
      "design and modeling of databases (multidimensional, 3nf, data vault)\n",
      "agile approach and tool experience (jira, confluence)\n",
      "developing development standards\n",
      "taking charge of growth tasks\n",
      "developer recruitment and instruction\n",
      "team learning should be encouraged.\n",
      "identifying commercial prospects\n",
      "topics of reporting and visualization must be understood and driven.\n",
      "serve as a primary source of communication for regional data needs\n",
      "understanding of the insurance industry, abs knowledge (desirable)\n",
      "knowledge of how to use containerized platforms for production (desirable)\n",
      "kafka knowledge (data merging in near real time) (desirable)\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/198/data.html\n",
      "mô tả công việc\n",
      "- lập trình và phát triển các báo cáo phân tích dữ liệu bi (business intelligence), hoặc tạo các phần mềm tool tự động rpa (robotics process automation).- thực hiện mô tả, phân tích các yêu cầu phần mềm.- kết hợp với các bộ phận khác (kiểm thử, hệ thống,...) để hoàn thành, triển khai dự án.- báo cáo và thực hiện các công việc theo yêu cầu của quản lý.- nhận thực tập, học việc, fullstack \n",
      "yêu cầu ứng viên\n",
      "- tốt nghiệp các trường đh/cđ/trung tâm đào tạo chuyên ngành cntt.- có hiểu biết về lập trình hướng đối tượng, biết một trong các ngôn ngữ lập trình sau: c sharp, asp, java.- hiểu biết về mvc framework.- đã có kiến thức hoặc kinh nghiệm về tableau hoặc rpa hoặc python là một lợi thế.- có khả năng đọc hiểu tài liệu tiếng anh.- có khả năng làm việc độc lập và theo nhóm.- cẩn thận, kiên nhẫn và ham học hỏi.  \n",
      "quyền lợi\n",
      "- mức lương lên đến 20 triệu. trao đổi cụ thể khi phỏng vấn- môi trường làm việc chuyên nghiệp, thân thiện- có cơ hội làm việc trực tiếp và qua mạng với khách hàng nhật bản.- được traning dạng ojt trong thời gian đầu mới vào công ty- làm việc 5 ngày/tuần (được nghỉ thứ 7, chủ nhật) và các ngày lễ, tết theo quy định của chính phủ việt nam- được tính đây đủ ot khi làm thêm theo quy định của luật lao động- được đào tạo và hỗ trợ các điều kiện phát huy khả năng ở mức cao nhất.- thực hiện thưởng cả năm và thưởng các ngày lễ, tết của việt nam.- ngoài quy định nâng lương 1 lần/năm, có thể được xem xét nâng lương trước thời hạn tùy năng lực và khả năng đáp ứng \n",
      "-----------------------------------------------\n",
      "yêu cầu công việc- được tham gia các chế độ bhxh, bhyt, bhtn theo pháp luật hiện hành- các chế độ phúc lợi khác theo quy định của công ty như nghỉ mát hàng năm, sinh nhật, thăm hỏi ốm đau, hiếu, hỉ. \n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 03/06/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2648/data.html\n",
      "================================================\n",
      "data-02-06/2301/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      " * basic job functions: • prepares & reviews financial management reports for cost center. • supports functional leader with strategic analysis to drive operational goals. • assists activities in the financial planning processes to deliver the desired organizational rollup. * essential functions & responsibilities:• analyze financial reports timely & accurately and summarize for management review• analyze the variances of monthly business performance and support the key business stakeholders on an action plan to achieve positive changes to the operational metric.• work with business partner and accounting to communicate potential opportunities and analyses to further drive business results.• resolve financial month end close process issues until fixed to ensure meeting the deadlines•work with business partner to develop monthly forecast and annual budget assumption. \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2507/data.html\n",
      "mô tả công việc\n",
      "- lập trình xử lý ảnh, ai deep learning cho các ứng dụng kiểm tra lỗi sản phẩm, đọc mã vạch qr, datamatrix, barcode … , nhận diện kí tự và tích hợp với robot để định vị trí sản phẩm để robot gắp đặt.- setup camera vision , lựa chọn camera, lens, đèn phù hợp để thu được hình ảnh tốt nhất và lên cấu hình vision cho từng bài toán.- lập trình thiết kế phần mềm máy tính, visual studio c++, c sharp, sqlserver,... - lập trình quản lý hệ thống nhà máy, server truyền thông công nghiệp, lưu trữ truy xuất dữ liệu.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "- kinh nghiệm: kinh nghiệm từ 01 năm lĩnh vực lập trình machine vision(đối với ứng viên mới ra trường/ chưa có kinh nghiệm: công ty có đào tạo tại cơ sở hà nội từ 03-06 tháng, có lương)- học vấn: tốt nghiệp các trường kỹ thuật ( bách khoa, công nghiệp, học viện kỹ thuật quân sự, giao thông vận tải và các trường kỹ thuật khác)\n",
      "================================================\n",
      "data-02-06/2815/data.html\n",
      "mô tả công việc: \n",
      "\n",
      "1. phân tích dữ liệu kinh doanh\n",
      "•\tsử dụng các công cụ và kỹ thuật phân tích nhằm khai thác dữ liệu và phân tích chuyên sâu về khách hàng/sản phẩm/ xu hướng thị trường;\n",
      "•\tthực hiện các báo cáo quản trị phân tích hoạt động kinh doanh, các báo cáo phân tích chuyên đề nhằm xác định cơ hội kinh doanh trên cơ sở ứng dụng các phần mềm truy vấn dữ liệu, mô hình phân tích dữ liệu và data mining;\n",
      "•\t xây dựng giải pháp làm giàu dữ liệu, thực hiện phân tích kinh tế vĩ mô, hoạt động ngành, phân tích xu hướng kinh doanh, phân tích chuyên sâu về môi trường kinh doanh bên ngoài, nội bộ ngân hàng dựa trên dữ liệu.\n",
      "\n",
      "2. xây dựng mô hình dự báo \n",
      "•\tsử dụng mô hình và hệ thống dữ liệu để phân tích: các yếu tố vĩ mô, tác động chính sách ảnh hưởng đến chỉ tiêu kinh doanh bán lẻ; phân tích đánh giá tác động, xây dựng các kịch bản dự báo kinh doanh bán lẻ;\n",
      "•\txây dựng các mô hình dự báo hành vi khách hàng bán lẻ: mô hình hành vi trả nợ trước hạn cho sản phẩm cho vay, mô hình hành vi rút trước hạn và tái tục cho sản phẩm tiền gửi; mô hình dự báo dòng tiền cho casa,...\n",
      "•\ttham gia xây dựng, nâng cấp các hệ thống báo cáo, các công cụ phục vụ cho công tác báo cáo và phân tích hoạt động kinh doanh.\n",
      "                                                                                   \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1316/data.html\n",
      "responsible for developing and implementing predictive models and analytics that can forecast customer behavior, identify patterns, and provide valuable insights from data. your role will involve collaborating with cross-functional teams to identify business problems, design experiments, and communicate findings to stakeholders. the ideal candidate should have a strong background in statistics, machine learning, and programming, with \n",
      "-----------------------------------------------\n",
      "experience working on large-scale data projects in a fast-paced environment.\n",
      "responsibilities\n",
      "qualifications\n",
      "what we offer\n",
      "additional inf\n",
      "================================================\n",
      "data-02-06/355/data.html\n",
      "================================================\n",
      "data-02-06/779/data.html\n",
      "================================================\n",
      "data-02-06/649/data.html\n",
      "mô tả công việc\n",
      "\n",
      "responsibilities\n",
      "-  effectively engage with stakeholders to understand their business problems and then formulate a data-driven approach for resolution.\n",
      "- visualize data using reporting/ dashboard tools & techniques and be accountable for the availability, quality and accuracy of reporting.\n",
      "- actively look for areas of potential simplification/ automation and implement these changes.\n",
      "- document and follow existing processes to reporting and data quality management.\n",
      "- continuous research and improvement to become subject matter expert on our data repositories/ analytic solutions. provide thought leadership to the team on use and interpretation.\n",
      "- build predictive models and machine learning algorithms. propose solutions and strategies to business challenges.\n",
      "- ability to communicate with non-technical/ technical peers.\n",
      "- provide ad-hoc data and analytics support to the business and perform other related duties as assigned.\n",
      "- inherently curious about data with a strong desire to keep up to date with the latest developments in analytics/ visualization and machine learning.\n",
      "qualifications/ skills\n",
      "- bachelor's degree in statistics, applied math, computer science or a related field.\n",
      "- 2+ years of \n",
      "-----------------------------------------------\n",
      "experience in data analytics working closely with business functions.\n",
      "- knowledge of statistical and predictive modeling concepts, machine learning approaches, clustering and classification techniques/ recommendation and optimization algorithms is preferred.\n",
      "- proficient in microsoft excel, sql and visualization tools. power bi experience is a plus.\n",
      "- experience with python/ r programming is a plus.\n",
      "- experience in the retail/ fnb industry is highly desirable but not mandatory.\n",
      "- attention to details.\n",
      "- critical thinking.\n",
      "- can-do attitude.\n",
      "- decent communication skills.\n",
      "================================================\n",
      "data-02-06/2241/data.html\n",
      "responsibilities\n",
      "we are looking for an \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2938/data.html\n",
      "mô tả công việc\n",
      "\n",
      "customer master data is in charge of creating, updating, monitoring and storing customer master data. he or she is responsible for ensuring that the customer data is properly maintained to help sales operations.- entry data to create and change customers in sap based on information provided by the sales team and relevant functions, reviewing the information to ensure the completeness and accuracy of customer master data based on the business requirement/process.- works with appropriate team members to resolve master data issues in an efficient and timely manner.- other tasks assigned by line managers (filling documents, storage data,…) \n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2310/data.html\n",
      "responsible for industrialization, deployment and functional maintenance of data products/solutions, including digital products, business intelligence, and machine learning use cases.- collaborate with other member and user to build data pipelines.- responsible for quality checking and testing.- collaboratively work to solve research problems.- develop new algorithms and computational tools to solve research problems.- review research code created by other team members.- write technical documentation and reports.- continue learning new technologies, introducing existing products, improving product \n",
      "-----------------------------------------------\n",
      "experience, and creating more value\n",
      "================================================\n",
      "data-02-06/2349/data.html\n",
      "responsibilities\n",
      "\n",
      "manage, develop, and grow a team of business intelligence analytic professionals, centered on providing insights and aiding in business decision-making.\n",
      "creates actionable business insights to answer business questions, drive business decisions, and develop recommendations to improve operations.\n",
      "drive a business intelligence roadmap; prioritize analysis requests to balance the tactical and strategic information needs of the business. oversees the planning of projects to produce power bi reporting dashboards and perform meaningful quantitative or qualitative analyses addressing impactful business issues or questions.\n",
      "present analysis and recommendations to senior leaders, using data-driven storytelling and influence to drive improvements in business operations and strategic change. coordinate with decision makers in the company to ensure that information gathering, and analysis support the overall development of business strategies.\n",
      "collaborates with other departments to identify and generate potential business intelligence initiatives, that result in business efficiency, cost saving, and/or marketing/trade effectiveness.\n",
      "cooperates with data science team to build and incorporate predictive analytics tools like alerts, notifications, forecast, recommendation into business intelligence reports.\n",
      "collaborate with product management, data science, and data engineering leaders to design and develop information management capabilities.\n",
      "lead the definition and governance of key business metrics, drive the vision and building of automated dashboards and self-service analytic capabilities, and engineer data-driven processes that drive business value.\n",
      "ensures that business intelligence analysts have the tools, training, and understanding of the field to produce effective dashboards, reports, and metrics.\n",
      "\n",
      " \n",
      "requirements\n",
      "\n",
      "over 10 years of working \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1915/data.html\n",
      "================================================\n",
      "data-02-06/2557/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description\n",
      "\n",
      "                                                                                            - xây dựng và thiết kế các mô hình kiến trúc hạ tầng lưu trữ, biến đổi dữ liệu\t\t\t\t\n",
      "- thực hiện & lưu lại tài liệu các thiết kế, cách biến đổi dữ liệu vào kho tài liệu chung, chia sẻ với các bên liên quan\t\t\t\t\n",
      "- vận hành, xử lý các luồng dữ liệu đảm bảo không xảy ra lỗi, ảnh hưởng đến khách hàng & các hệ thống liên quan\t\t\t\t\n",
      "- phối hợp với nhóm phân tích dữ liệu & người dùng cuối để thiết kế các data model phục vụ báo cáo & phân tích dữ liệu \t\t\t\t\n",
      "- phối hợp với nhóm quản trị dữ liệu để thực hiện kiểm soát các luồng dữ liệu, chất lượng, định dạng dữ liệu đảm bảo tính phù hợp với các mục đích sử dụng dữ liệu trong ngân hàng\t\t\t\t\n",
      "- tối ưu hạ tầng lưu trữ, biến đổi dữ liệu để tăng hiệu quả, tiết kiệm chi phí cho ngân hàng\t\t\t\t\n",
      "- tham gia hỗ trợ các dự án cntt với vai trò là thành viên dự án\t\t\t\t\n",
      "- thực hiện các yêu cầu khác theo phân công của quản lý trực tiếp\n",
      "                                                                                    \n",
      "read full job descriptions\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2681/data.html\n",
      "================================================\n",
      "data-02-06/974/data.html\n",
      "responsibilities\n",
      "design and develop etl pipelines with external services, including client wrappers.participate in designing and implementing foundational layers, including data models, workflow, and storage systems.perform dataops, including data correction and schema evolution migration.\n",
      "\n",
      "-----------------------------------------------\n",
      "job requirements:\n",
      "1 year+ in python, a basic understanding of java.basic knowledge of git, *nix; kubernetes is a plus.a hungry learner and a good writer. you will be the subject matter expert at a variety of external integrated services. adaptability and a strong sense of quality communication and documentation will be great edges.have an appreciation of sound and evolvable data schema design. on the opposite side, having a solid sense and ability to detect schema design smells.\n",
      "special benefits:\n",
      "be trained with data engineering experts and specialists.being a part of the incredible team building\n",
      "================================================\n",
      "data-02-06/2995/data.html\n",
      "description\n",
      "\n",
      "\n",
      "life at agoda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "all teams\n",
      "contentcustomer \n",
      "-----------------------------------------------\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "head of paid search (bangkok based, relocation provided)\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "================================================\n",
      "data-02-06/3118/data.html\n",
      "mô tả công việc: \n",
      "        \n",
      "\n",
      "trách nhiệm chính\n",
      "- cài đặt mới, cấu hình, cập nhật các bản vá lỗi phần mềm csdl oracle, sql server\n",
      "- cấu hình các giải pháp nâng cao tính sẵn sàng của hệ thống csdl oracle, sql server\n",
      "- cấu hình tính năng kiểm toán csdl.\n",
      "- giám sát hiệu năng các hệ thống csdl oracle, sql server.\n",
      "- thiết lập các cảnh báo tự động cho hệ thống csdl, gửi báo cáo hàng ngày tình trạng csdl thông qua email, sms.\n",
      "- hỗ trợ tinh chỉnh, tối ưu hóa các câu lệnh truy vấn chậm.\n",
      "- sử dụng tính năng phân vùng, nén, mã hóa dữ liệu trong csdl giúp tăng hiệu năng, giảm dung lượng lưu trữ, nâng cao tính bảo mật hệ thống csdl.\n",
      "- tham gia các dự án liên quan đến hệ thống csdl oracle, sql server.\n",
      "- thực hiện các công việc khác theo sự phân công của cấp quản lý.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "1. bằng cấp/chứng chỉ:\n",
      "================================================\n",
      "data-02-06/1347/data.html\n",
      "description\n",
      " job summary  responsible to serve as the customer interface for the demand plan and shipment information, develop feasible operational plan and maintain ownership over the execution of the operational plan, achieve the objective of customer satisfaction, minimize jabil liability and continuously improve the performance of the planning metrics.  essential duties and responsibilities  · work with bu and customer to develop a collaborative demand plan through properly executing the demand management process  · create a master schedule through resource analysis including material sizing and capacity sizing  · load master schedule into the jabil erp system.  · create and maintain a feasible production plan and closely work with operation team to achieve successful execution of the plan.  · develop revenue forecast and closely monitor the actual performance and drive for immediate corrective action and recovery plan in case there is potential miss to the revenue target.  · monitor planning metrics and drive for continuous improvement  · comply and follow all procedures within the company security policy and the rules of the road  · may perform other duties and responsibilities as assigned  management & supervisory responsibilities  · typically reports to management . direct supervisor job title(s) typically include: planning supervisor, planning manager.  · job is not directly responsible for managing other employees (e.g., hiring/termination and/or pay decisions, performance management).  please do not change any wording in this section. only include who the direct supervisor is.  job qualifications  knowledge requirements  · thorough knowledge of erp/mrp  · 1 to 2 years materials related experiences  · advanced pc skills including knowledge of jabil's software packages  · ability to read and interpret documents such as safety rules, operating and maintenance instructions, and procedure manuals.  · ability to write routine reports and correspondence.  · ability to speak effectively before groups of customers or employees of organization, strong communication skills.  · ability to apply common sense understanding to carry out instructions furnished in written, oral, or diagram form.  · ability to deal with problems involving several concrete variables in standardized situations.  · ability to calculate figures and amounts such as discounts, interest, commissions, proportions, percentages, area, circumference, and volume.  · ability to apply concepts of basic algebra and geometry.  · strong proficiency in determining logistics requirements to enable company’s business goals and objectives with ability to devise and implement strategy to achieve targets.  · proficient verbal and written english skill  education & experience requirements  bachelor’s degree required.  or an equivalent combination of education, training, or experience. \n",
      "\n",
      "jabil, including its subsidiaries, is an equal opportunity employer and considers qualified applicants for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identify, age, disability, genetic information, veteran status, or any other characteristic protected by law.\n",
      "\n",
      "\n",
      "                        be aware of fraud: when applying for a job at jabil you will be contacted via correspondence through our official job portal with a jabil.com e-mail address; direct phone call from a member of the jabil team; or direct e-mail with a jabil.com e-mail address. jabil does not request payments for interviews or at any other point during the hiring process. jabil will not ask for your personal identifying information such as a social security number, birth certificate, financial institution, driver’s license number or passport information over the phone or via e-mail. if you believe you are a victim of identity theft, contact your local police department. any scam job listings should be reported to whatever website it was posted in.\n",
      "                    \n",
      "accessibility accommodation\n",
      "if you are a qualified individual with a disability, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access jabil.com/careers site as a result of your disability. you can request a reasonable accommodation by sending an e-mail to always_accessible@jabil.com with the nature of your request and contact information. please do not direct any other general employment related questions to this e-mail. please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.\n",
      "-----------------------------------------------\n",
      "experience, technical and design capabilities, manufacturing know-how, supply chain insights and global product management expertise to enable success for the world’s leading brands. we are driven by a common purpose to make a positive impact for each other, our communities, and the environment.\n",
      "job description\n",
      " job summary  responsible to serve as the customer interface for the demand plan and shipment information, develop feasible operational plan and maintain ownership over the execution of the operational plan, achieve the objective of customer satisfaction, minimize jabil liability and continuously improve the performance of the planning metrics.  essential duties and responsibilities  · work with bu and customer to develop a collaborative demand plan through properly executing the demand management process  · create a master schedule through resource analysis including material sizing and capacity sizing  · load master schedule into the jabil erp system.  · create and maintain a feasible production plan and closely work with operation team to achieve successful execution of the plan.  · develop revenue forecast and closely monitor the actual performance and drive for immediate corrective action and recovery plan in case there is potential miss to the revenue target.  · monitor planning metrics and drive for continuous improvement  · comply and follow all procedures within the company security policy and the rules of the road  · may perform other duties and responsibilities as assigned  management & supervisory responsibilities  · typically reports to management . direct supervisor job title(s) typically include: planning supervisor, planning manager.  · job is not directly responsible for managing other employees (e.g., hiring/termination and/or pay decisions, performance management).  please do not change any wording in this section. only include who the direct supervisor is.  job qualifications  knowledge requirements  · thorough knowledge of erp/mrp  · 1 to 2 years materials related experiences  · advanced pc skills including knowledge of jabil's software packages  · ability to read and interpret documents such as safety rules, operating and maintenance instructions, and procedure manuals.  · ability to write routine reports and correspondence.  · ability to speak effectively before groups of customers or employees of organization, strong communication skills.  · ability to apply common sense understanding to carry out instructions furnished in written, oral, or diagram form.  · ability to deal with problems involving several concrete variables in standardized situations.  · ability to calculate figures and amounts such as discounts, interest, commissions, proportions, percentages, area, circumference, and volume.  · ability to apply concepts of basic algebra and geometry.  · strong proficiency in determining logistics requirements to enable company’s business goals and objectives with ability to devise and implement strategy to achieve targets.  · proficient verbal and written english skill  education & experience requirements  bachelor’s degree required.  or an equivalent combination of education, training, or experience. \n",
      "\n",
      "jabil, including its subsidiaries, is an equal opportunity employer and considers qualified applicants for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identify, age, disability, genetic information, veteran status, or any other characteristic protected by law.\n",
      "\n",
      "\n",
      "                        be aware of fraud: when applying for a job at jabil you will be contacted via correspondence through our official job portal with a jabil.com e-mail address; direct phone call from a member of the jabil team; or direct e-mail with a jabil.com e-mail address. jabil does not request payments for interviews or at any other point during the hiring process. jabil will not ask for your personal identifying information such as a social security number, birth certificate, financial institution, driver’s license number or passport information over the phone or via e-mail. if you believe you are a victim of identity theft, contact your local police department. any scam job listings should be reported to whatever website it was posted in.\n",
      "                    \n",
      "accessibility accommodation\n",
      "if you are a qualified individual with a disability, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access\n",
      "================================================\n",
      "data-02-06/2897/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      " - nhập và theo dõi, thống kê tất cả các số liệu về hàng hóa, sản phẩm, các số liệu phát sinh trong từng khâu sản xuất- thống kê (hàng ngày) chi tiết tất cả các số liệu đầu vào quá trình sản xuất phát sinh,kiểm tra định mức sử dụng, tỷ lệ hao hụt...- thực hiện báo cáo tổng kết các số liệu đã được thống kê, theo dõi và ghi lại sự cố bất thường tại nhà máy; theo dõi đôn đốc tiến độ sản xuất và giao hàng.- làm báo cáo sản xuất hàng ngày và các báo cáo công việc khác theo yêu cầu của cấp trên \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2979/data.html\n",
      "description\n",
      "\n",
      "as the data engineer, you are responsible for building and maintaining an organization’s entire data ecosystem, which includes everything from data sources and databases to data storage solutions. this also includes building data pipelines that are used to transport data from a data source to a data warehouse. these pipelines are crucial: they are what enable an organization to access and analyze its data, and use the insights to make business decisions. data pipelines transport and transform data according to established business rules or a line of exploratory analysis the business wants to undertake.your key responsibilitiesdeliver advanced analytical services   ● planning / prioritization:     - based on decisions following the business process, the product development team together with cto will work to allocate time and resources to the decided work slate.     - you’ll work closely with senior stakeholders to ensure all aspects of the data business are considered in these advances. feedback will be collected directly and indirectly through sales and define development projects and schedules together with the cto.   ● quality management/testing:      - you’ll ensure a high quality level in case of new releases, apis and functionalities, as well as in the standard of reporting provided to clients. the high quality is based on adequate and extensive testing.   ● explore data warehousing:      - you’ll build the data warehouse strategy that should provide consistent, clean, and integrated data.   ● your kpi include:      - 100% delivery of the data engineering roadmap      - minimum 2 application delivery per monthdata governancedata governance will be a very important part of your role as date engineer.  primarily, you will be responsible for protecting your organization’s data from interference, theft, corruption, and loss. governing data includes creating strategic data access policies, both internally and externally.   ● keep up with ever-changing data protection regulations.   ● avoid data breaches by ensuring that everyone who can access information is authorized.   ● put measures to protect stored data and data that is being transmitted.as a data engineer, you will be responsible for driving data security awareness across the organization by outlining and enforcing rules, rights, and accountabilities. it is helpful if a set of standards is in place in regard to naming, abbreviation, acronyms, etc. consistency in these areas will help data to be easily catalogued and make sure that employees can find the data they are looking for without wasting time. crucially, you will need to keep data ethics at the forefront of your operation. this includes:   ● protecting collected data from leaks.   ● being aware of the intentions of anyone who might want to purchase your data.   ● ensuring your own organization is using data ethically.optimizing data management process & delivering documentation   ● establish and implement the overall strategy and transformation in collaboration with the c-level stakeholders, other counterparts and functional teams for the group to enable measurable results for each country.   ● you’ll engage in agile/scrum methodologies to ensure adherence to roadmap.   ● you’ll work in a 'squad' formation, partnering with the product team to run sprints, manage the backlog, build out capabilities, etc.   ● your kpi include:      - 100% data products documentation for the external stakeholders.      - improving efficiency rate.\n",
      "\n",
      "your skills and \n",
      "-----------------------------------------------\n",
      "experience\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2435/data.html\n",
      "chi tiết công việc [fashion] data analysis tại networld asi\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1640/data.html\n",
      "================================================\n",
      "data-02-06/1551/data.html\n",
      "responsible and convenient payment options at checkout.\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2475/data.html\n",
      "responsible to do power bi report development, data analytics and reporting including data modelling and data visualization. we also run several sql server databases, so if you're an expert in that area, you'll be very useful. from time to time you also required to perform adhoc task such as data extraction of business related data to assist operation user. we are also collaborating with our development teams to separate transaction logic and application logic as much as possible through the use of database functions. you will undoubtedly have an advantage if you have prior programming \n",
      "-----------------------------------------------\n",
      "experience.\n",
      "2 type for this positions:\n",
      "\n",
      "full - time job, definite term contract (1 - 3 years)\n",
      "full - time job, permanent contract\n",
      "================================================\n",
      "data-02-06/3159/data.html\n",
      "responsibilities:\n",
      "\n",
      "growing, leading, and managing the ai engineering team\n",
      "collaborating with cross-functional teams to understand needs and translate them into system requirements\n",
      "developing and implementing ai models for nlp, automated scoring, speech recognition…\n",
      "overseeing project management including planning, coordinating, and executing tasks effectively\n",
      "conducting research to identify new trends in ai and incorporate them into our product development\n",
      "conducting regular health checks and system diagnostics to troubleshoot and resolve any issues in a timely manner.\n",
      "continually monitoring ai systems and implementing improvements for efficiency, scalability, and stability.\n",
      "\n",
      "requirements:\n",
      "\n",
      "general requirements\n",
      "\n",
      "\n",
      "proven \n",
      "-----------------------------------------------\n",
      "experience in team leadership and management\n",
      "proven experience in project management\n",
      "minimum of 3 years of experience in a similar role\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2718/data.html\n",
      "mô tả công việc\n",
      "đảm bảo hoàn thành mục tiêu của nhóm thông qua việc cung cấp thông tin đầu vào cho quá trình ra quyết định và giải quyết vấn đề.lập kế hoạch, phân chia công việc/nhiệm vụ cho các thành viên trong nhóm để đáp ứng hoàn thành tiến độ của dự án.phân tích yêu cầu của người dùng cuối và tư vấn phương pháp phân tích dữ liệu, lựa chọn kpi, đo lường phù hợp.đề xuất các giải pháp dự án: kinh doanh, kỹ thuật, xử lý dữ liệu tự động và trực quan hóa báo cáoxây dựng các luồng etl, mô hình hóa dữ liệu và bố cục báo cáo thiết kếxây dựng tài liệu hướng dẫn sử dụng và đào tạo người dùng cuốichuẩn bị và quản lý tất cả các tài liệu của dự án.quản lý hệ thống báo cáo bi đảm bảo hoạt động ổn định.tham gia quản trị, quản lý dữ liệu và chất lượng dữ liệu của các yêu cầu dữ liệu chủ.đảm bảo người dùng và hệ thống phù hợp khi truy cập dữ liệu trong phạm vi quyền hạn cho phép.thực hiện đánh giá định kỳ và sửa đổi vai trò ủy quyền/bảo mật của các báo cáo để phù hợp với nhu cầu thay đổi của tổ chức.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "tốt nghiệp chuyên ngành các khối ngành về hệ thống thông tin,…có chứng chỉ về phân tích dữ liệu: power bi.tiếng anh giao tiếp với khách hàng mức khá tốt.khả năng làm việc độc lập và đảm nhận vai trò lãnh đạo trong nhóm.khả năng giao tiếp hiệu quả để thiết lập mối quan hệ làm việc với khách hàng.có khả năng phân tích, lập mô hình dữ liệu trong môi trường hoặc tập dữ liệu lớn.ưu tiên có sự hiểu về biết về lĩnh vực dầu khíthành thạo phân tích, triển khai báo cáo trên power bi và các công cụ etl & dwh khác (sap bw, azure, sql, power query,...)có kinh nghiệm làm việc với r và python, power apps, power automate,..có kinh nghiệm làm việc với các công cụ và công nghệ quản lý dữ liệu chủ (mdm)kỹ năng tư duy phân tích và khái niệm nâng cao.\n",
      "quyền lợi\n",
      "lương cứng thỏa thuận theo kinh nghiệm và năng lực.có lương tháng thứ 13, thưởng lễ tết, thưởng theo kết quả kinh doanh của công ty (gói thu nhập năm 14-16 tháng/năm)\n",
      "================================================\n",
      "data-02-06/1195/data.html\n",
      "================================================\n",
      "data-02-06/828/data.html\n",
      "================================================\n",
      "data-02-06/2639/data.html\n",
      "mô tả công việc\n",
      "– tham gia xây dựng hệ thống học máy tự động\n",
      "– triển khai, cài đặt, tích hợp các luồng phân tích dữ liệu lớn, học máy tự động.\n",
      "– tích hợp nền tảng ghtk bigdata vào hệ thống học máy tự động.\n",
      "ii. yêu cầu\n",
      "– có kiến thức cơ bản về học máy/trí tuệ nhân tạo.\n",
      "– có kiến thức tốt về kỹ nghệ phần mềm\n",
      "– có \n",
      "-----------------------------------------------\n",
      "kinh nghiệm làm việc với java, csdl nosql.\n",
      "– là lợi thế nếu:\n",
      "+ có kinh nghiệm làm việc với ít nhất một trong các khung nền tảng sau, ví dụ: kubeflow, mlflow,\n",
      "aws sagemaker, google ai platform, azure machine learning, datarobot, mlflow.\n",
      "+ có kinh nghiệm huấn luyện và triển khai các mô hình học máy/trí tuệ nhân tạo.\n",
      "iii. quyền lợi\n",
      "– lương fresher đến senior: 500$ – 2000$ (đánh giá tăng lương theo năng lực định kỳ);\n",
      "– bảo hiểm sức khỏe cao cấp generali;\n",
      "– môi trường làm việc trẻ trung, năng động, thời gian làm việc linh hoạt;\n",
      "– làm việc cùng đội ngũ công nghệ giỏi chuyên môn, có cơ hội để phát huy tối đa năng lực của bản thân;\n",
      "– liên tục được đào tạo về kiến thức, kỹ năng liên quan đến các lĩnh vực hoạt động của công ty;\n",
      "– được cung cấp đầy đủ phương tiện làm việc theo yêu cầu của tính chất công việc;\n",
      "– các hoạt động tập thể, giải trí đa dạng (clb bóng đá, game, bi lắc, …); sự kiện team-building hàng năm;\n",
      "– được đảm bảo đầy đủ các chế độ phúc lợi theo quy định của pháp luật hiện hành và của công ty;\n",
      "– thưởng tết nguyên đán, tết dương lịch, ngày lễ khác và thưởng thành tích nổi bật.\n",
      "iv. thông tin khác\n",
      "– thời gian làm việc: 9:00 – 18:30; thứ hai – thứ sáu và hai ngày thứ bảy trong tháng luân\n",
      "phiên\n",
      "– địa chỉ: toà nhà ghtk, đường phạm hùng, phường mễ trì, quận nam từ liêm, hà nội.\n",
      "v. cách thức ứng tuyển\n",
      "để ứng tuyển vị trí ai/mlops, vui lòng gửi cv & cover letter về email: talent.acquisition@ghtk.co\n",
      "tiêu đề: ai/mlops_họ tên.\n",
      "================================================\n",
      "data-02-06/2355/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "                                                                                            job purpose summary:\n",
      "the job holder is responsible for analyzing the retail segment performance to support strategic planning for retail bank business franchise, drive and manage sales performance including risks thereof, through analytic.\n",
      "\n",
      "key responsibilities and accountabilities:\n",
      "functional (job responsibilities)\n",
      "1.\tsupport setting of strategic business direction with head of pfs and maintaining the retail bank franchise through analytics.  responsible for ongoing market analysis to ascertain competitive positioning and identify risks with recommendations to support development of the product & sales strategy.\n",
      "2.\tsupport the business in setting up and managing key performance drivers including achievement against revenue & expense goals, productivity, incentives management as well as trend analysis and forecasting for all channels.\n",
      "3.\tmaintaining a pulse on external as well as internal market to keep abreast of market development and to stay ahead of competition.   identify early warning signals to mitigate risks of product and sales strategies turning ineffective.\n",
      "4.\tmanaging performance risks identified through analytics by developing tactical campaigns & promotions with businesses to close gaps.\n",
      "5.\twork closely with internal partners such as finance and it for support of data management and analysis.\n",
      "6.\tmaintain close relationship with sales channels to provide continuing support and to enhance productivity.\n",
      "7.\tany other tasks as assigned by the line manager \n",
      "\n",
      "organizational (organizational responsibilities)\n",
      "1.\tmeet key parameters in achievement of p&l drivers against forecast\n",
      "2.\tenhance franchise parameters in market share and positioning\n",
      "3.\tinfluence sales productivity\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2583/data.html\n",
      "================================================\n",
      "data-02-06/2553/data.html\n",
      "================================================\n",
      "data-02-06/841/data.html\n",
      "================================================\n",
      "data-02-06/1200/data.html\n",
      "================================================\n",
      "data-02-06/2499/data.html\n",
      "descriptioncreate sharepoint workspaces and modify.create workflows in nintex (within sharepoint)create power bi reports - using daxinterface power bi with other databasesutilise office 365 products for making interactive presentations in power point, and other digital presentation vehicles.create animations in presentations.record and edit videos for uploading into scorm compliant software (articulate 365) for training material.turn simple text information into high quality digital multi-media presentations.skillsoperationsstatisticsmathematicsengineeringmicrosoft office skillsrequirementminimum of 3 years of relevant work \n",
      "-----------------------------------------------\n",
      "experience.able to work independently under remote supervision by expatessential skillsbachelor’s degree and academic excellence from quantitative field.msc level in engineering, operations, statistics, physics, mathematics or equivalent technical field.microsoft office (intermediate)fluent english competency (toeic 700 or above)benefits13th month salaryinternal healthcare plan16 days annual leavecareer data analyst data scientistdata analystmodec management servicesthe job was closedappl\n",
      "================================================\n",
      "data-02-06/558/data.html\n",
      "================================================\n",
      "data-02-06/829/data.html\n",
      "================================================\n",
      "data-02-06/436/data.html\n",
      "================================================\n",
      "data-02-06/1728/data.html\n",
      "responsible for innovation project management, conducting or monitoring research to understand the market & competitor status deeply, thereby developing and initiating new competitive adverti...\n",
      "                                \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/70/data.html\n",
      "description \n",
      "\n",
      "– giới thiệu giải pháp về data với khách hàng chủ yếu trong lĩnh vực tài chính, ngân hàng\n",
      "– thực hiện demo tính năng sản phẩm, triển khai các dự án thử nghiệm (poc, pilot) về data.\n",
      "– nghiên cứu các giải pháp, công nghệ data theo định hướng của công ty.\n",
      "– các công việc khác theo yêu cầu\n",
      "\n",
      "\n",
      "required skills\n",
      "\n",
      "kỹ năng\n",
      "– ưu tiên tốt nghiệp đh chuyên ngành cntt hoặc điện tử viễn thông\n",
      "– có \n",
      "-----------------------------------------------\n",
      "kinh nghiệm phát triển etl hoặc báo cáo như: sql, datastage, tableau, powerbi, python..\n",
      "– có kinh nghiệm tham gia một trong các loại hình dự án data analytics, business inteligence, data warehouse, data lake, bigdata…\n",
      "– ưu tiên các ứng viên có hiểu biết về giải pháp data của ibm như cloud pak for data, singlestore\n",
      "– có khả năng giao tiếp & đọc hiểu tài liệu kỹ thuật tiếng anh.\n",
      "– kỹ năng ứng xử, giao tiếp, thuyết trình tốt\n",
      "– kỹ năng giải quyết vấn đề và làm việc theo nhóm\n",
      "– có khả năng làm việc độc lập, chủ động, trách nhiệm, nhiệt tình trong công việc.\n",
      "yêu cầu khác\n",
      "– sức khỏe, tính tuân thủ kỷ luật;\n",
      "– có khả năng học hỏi và làm việc trong môi trường chịu áp lực cao.\n",
      "\n",
      "\n",
      "\n",
      "benefit\n",
      "\n",
      "– thưởng kpi hàng tháng 20% lương.\n",
      "– thưởng nhân viên xuất sắc tháng.\n",
      "– thưởng các dịp lễ\n",
      "– thưởng tháng lương thứ 13: chuyển tự động vào cuối tháng 12 hàng năm.\n",
      "– thưởng dự án.\n",
      "– bảo hiểm sức khỏe 24/7.\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/915/data.html\n",
      "================================================\n",
      "data-02-06/1139/data.html\n",
      "mô tả công việc \n",
      "\n",
      "\n",
      "nhập, xuất và quản lý các tập dữ liệu lớn từ nhiều nguồn khác nhau. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thiết kế và triển khai các quy trình etl để chuyển đổi dữ liệu thô thành thông tin có thể sử dụng được. \n",
      "\n",
      "\n",
      "thực hiện kiểm tra chất lượng dữ liệu, xác định và giải quyết các vấn đề, chẳng hạn như dữ liệu không nhất quán, trùng lặp và thiếu giá trị. \n",
      "\n",
      "\n",
      "phát triển và duy trì từ điển dữ liệu, dòng dữ liệu và tài liệu siêu dữ liệu. \n",
      "\n",
      "\n",
      "cộng tác với các nhóm chức năng khác để đảm bảo dữ liệu được thu thập, lưu trữ và bảo mật đúng cách. \n",
      "\n",
      "\n",
      "luôn cập nhật những phát triển của ngành, các công nghệ mới nổi và các phương pháp hay nhất về quản lý dữ liệu. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hỗ trợ việc ra quyết định dựa trên dữ liệu bằng cách cung cấp dữ liệu cho các bên liên quan một cách kịp thời và chính xác. \n",
      "\n",
      "\n",
      "yêu cầu \n",
      "\n",
      "\n",
      "tốt nghiệp đại học chuyên ngành hoa học máy tính, toán học, thống kê, kinh tế, tài chính, kiểm toán, kế toán hoặc lĩnh vực liên quan. \n",
      "\n",
      "\n",
      "có ít nhất 1 năm kinh nghiệm trong lĩnh vực quản lý dữ liệu và quy trình etl. \n",
      "\n",
      "\n",
      "kiến thức tốt về các công cụ quản lý dữ liệu (excel, sql), công cụ etl và kho dữ liệu. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "khả năng đã được chứng minh để phân tích và diễn giải các tập dữ liệu lớn. \n",
      "\n",
      "\n",
      "chú ý đến từng chi tiết và mức độ chính xác cao. \n",
      "\n",
      "\n",
      "khả năng làm việc độc lập cũng như là một phần của nhóm. \n",
      "\n",
      "\n",
      "kỹ năng giải quyết vấn đề và tư duy phản biện mạnh mẽ. \n",
      "\n",
      "\n",
      "có kiến thức về các ngôn ngữ lập trình như python là một lợi thế. \n",
      "\n",
      "\n",
      "chế độ \n",
      "\n",
      "\n",
      "mức lương cạnh tranh, có thể thương lượng dựa trên hiệu suất làm việc, thưởng dựa trên năng suất làm việc. \n",
      "\n",
      "\n",
      "giải phóng toàn bộ tiềm năng của bạn với nhiều cơ hội thăng tiến và phát triển nghề nghiệp, nơi bạn có thể thử thách bản thân và đạt đến những tầm cao mới. \n",
      "\n",
      "\n",
      "trở thành một phần của môi trường làm việc hợp tác, năng động và hòa nhập, khuyến khích sự sáng tạo, thúc đẩy tinh thần đồng đội và tôn vinh sự đa dạng, nơi bạn có thể phát triển và thành công. \n",
      "\n",
      "\n",
      "tham gia một công ty tư vấn và nghiên cứu độc lập hàng đầu đi đầu trong đổi mới, nơi bạn có thể phát triển kỹ năng và thăng tiến trong sự nghiệp. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tích lũy kinh nghiệm vô giá trong các ngành công nghiệp then chốt ở việt nam và tương tác với ban lãnh đạo cấp cao, giúp bạn tiếp xúc có giá trị với các quan điểm và ý tưởng khác nhau. \n",
      "\n",
      "\n",
      "có vô số cơ hội được tham gia đào tạo và phát triển, từ đào tạo tại chỗ và các chương trình nội bộ đến các khóa học chuyên nghiệp, để giúp bạn phát huy hết tiềm năng của mình. \n",
      "\n",
      "\n",
      "được hưởng nhiều phúc lợi toàn diện, từ bảo hiểm và các kỳ nghỉ dưỡng của công ty cho đến các sự kiện và dã ngoại hàng tháng của nhóm, để đảm bảo cân bằng giữa cuộc sống – công việc. \n",
      "\n",
      "\n",
      "được tiếp cận với các chính sách bảo hiểm xã hội và bảo hiểm y tế tốt nhất có thể, cũng như bảo hiểm thất nghiệp và bảo hiểm lao động, tất cả đều tuân theo các quy định của luật lao động, giúp bạn an tâm và được bảo vệ. \n",
      "\n",
      "\n",
      "gửi cv\n",
      " email liên hệ: talents@fiingroup.vn \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/796/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description \n",
      "\n",
      "– together with the bod, the senior financial analyst will be responsible for company’s investment opportunities assessments.\n",
      "– provide analytical and research support in the analysis of company’s investments.\n",
      "– monitor performance of existing real estate portfolio, and analyze future investment opportunities.\n",
      "– perform valuation, feasibility studies, investment return and sensitivity analyses\n",
      "– assist with investment committee presentation preparation\n",
      "– coordinate and review forecasts and budgets\n",
      "– responsible for oversight and performance of varied areas of financial analysis and reporting including but not limited to: standard monthly management reporting and variance analyses, account reconciliations, financial reporting, budgeting, forecasting and strategic planning\n",
      "– activities will generally focus on project assessment, financial modeling, valuations, investment structuring, legal framework review, negotiations and other related activities.\n",
      "\n",
      "\n",
      "required skills\n",
      "\n",
      "- university degree in accounting/ financial.\n",
      "- at least 4 years-\n",
      "-----------------------------------------------\n",
      "experience at the same position for multinational companies\n",
      "- advanced ms excel including experience modeling transactions, word, power point, familiarity with applications used for business.\n",
      "- good communication in english. \n",
      "\n",
      "================================================\n",
      "data-02-06/659/data.html\n",
      "description\n",
      "address current problems related to ai of the company\n",
      "propose new solutions to the company to take full advantage of its massive data\n",
      "monitor performance, accuracy of ml models based on the use of methods as rmse, rmsea, mae, mse, mape, accuracy, recall, precision, … \n",
      "requirement\n",
      "bachelor's degree in data science, computer science, it, applied math, or related; or relevant practical \n",
      "-----------------------------------------------\n",
      "experience is fine\n",
      "good linguistic competence in english: conventional toeic (reading and listening) >= 550;\n",
      "proficient in query languages as sql and nosql\n",
      "good programming skills: python (required)\n",
      "nice to have: c++, java. scala …\n",
      "experience with ai frameworks such as keras, pytorch, tensorflow …\n",
      "knowledge of machine learning as decision trees, linear regression, ensemble (random forest, boosting tree), k-means, svm, pca…\n",
      "knowledge of deep learning, neural network, various kinds of network mlp, cnn, lstm, rnn…\n",
      "possession of global certificates of ai (tensorflow developer certificate, google professional machine learning engineer certification ...) or of data engineer (aws, cca, ccp, ibm certified data engineer, google - - professional data engineer …) are a big plus\n",
      "creative thinking, self-research capability, ability to work in a team, up-to-date knowledge of new technologies\n",
      "benefits\n",
      "salary: 1500$ - 2200$ \n",
      "allowances: 1,000,000 vnd per month on lunch and transportation\n",
      "address current problems related to ai of the company\n",
      "propose new solutions to the company to take full advantage of its massive data\n",
      "monitor performance, accuracy of ml models based on the use of methods as rmse, rmsea, mae, mse, mape, accuracy, recall, precision, … \n",
      "unlimited utilization of all monkey products\n",
      "opportunities to collaborate with renowned business partners (facebook, coc coc, etc.)\n",
      "chances to work in a well-recognized company which has achieved successes on both national and global scale, namely first place startup in 2016 gist tech-i competition awarded by the american former president barack obama, first place in vietnamese talent competition, top 1 most loved children application on app store and google play\n",
      "first-handed experience with top-notch international teaching and learning materials and approaches\n",
      "chances to work closely with excellent vietnamese and american educators and linguists.\n",
      "positive and open-minded environment which is made up of people who are always ready to listen and share\n",
      "courses fully funded by the company to improve one's competence and skills\n",
      "salary review every 6 months\n",
      "bonuses on kpi, projects, new ideas, boost-up bonus; on-the-spot reward; rewards for new suggestions of contribution recognition and employee gifts on special occasions\n",
      "equipment and devices provided at work, or allowance for using personal devices\n",
      "number of days-off, public and new year holidays, annual leave will be under labor law\n",
      "attractive maternity regime for both male and female employees\n",
      "entitled to social insurance, health insurance, underemployment insurance and other benefits according to the company's policies\n",
      "health screening and wellness check-up services at prestigious hospitals\n",
      "daily tea-break, weekly gather-up, monthly birthday party and annual summer trip\n",
      "other benefits are discussed during the interview  \n",
      "giới thiệu việc làm này\n",
      "\n",
      "\n",
      "\n",
      "        chia sẻ bài viết\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "chia sẻ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sao chép đường dẫn\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2293/data.html\n",
      "mô tả công việc:- đóng góp vào cách tiếp cận thương mại và thành công của thuốc càng nhanh càng tốt;- xây dựng hệ thống thu thập dữ liệu điện tử cho các dự án thử nghiệm lâm sàng (sẽ được đào tạo trước khi thực hiện công việc);- quản lý dữ liệu lâm sàng như là làm sạch dữ liệu, mã hóa, nhập dữ liệu;- tạo các tài liệu liên quan đến dự án (sẽ được đào tạo trước và trong quá trình làm việc);- viết chương trình (sas - phần mềm phân tích thống kê) để tạo bộ dữ liệu, bảng biểu hỗ trợ phân tích, thống kê số liệu thử nghiệm lâm sàng (sẽ được đào tạo trước khi thực hiện công việc).......................................................................................................................................................................* benefit:- working time: 8 hours/day, be off on saturday and sunday; no overtime working policy- be off vietnam holiday and some japanese holidays;- having allowance for lunch, telephone, insurance;- having bao viet insurance for employee, employee’s children and annual health check;- off-site/on-site meeting, team building … (nha trang, vinperal land …);- joining company’s japanese class; bonus for jlpt from 5 million vnd to 40 million vnd;- “work from home” policy for staffs in pregnancy or having children under 2 years old;- support 100% fee of hpv vaccine;- honor and reward employees working 5 years (10 million vnd), 10 years (20 million vnd) in 2022.\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2263/data.html\n",
      "================================================\n",
      "data-02-06/2609/data.html\n",
      "================================================\n",
      "data-02-06/692/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "tham gia xây dựng cơ sở dữ liệu khách hàng, các hệ thống quản trị dữ liệu khách hàng;\n",
      "chủ trì đề xuất hệ thống, quy trình để quy tụ, kết nối dữ liệu từ các hệ thống khác nhau về tập trung để khai thác và phân tích;\n",
      "thực hiện phân tích, đánh giá dữ liệu phục vụ tối ưu hóa các hoạt động điều hình sản xuất, kinh doanh của đơn vị;\n",
      "phát triển và triển khai cơ sở dữ liệu, hệ thống thu thập dữ liệu, phân tích dữ liệu;\n",
      "phân tích để đánh giá hiệu quả, cảnh báo nguy cơ rủi ro cũng như phân tích, đánh giá theo yêu cầu, đề nghị, đơn đặt hàng của các đơn vị liên quan;\n",
      "chủ trì lập đề bài về thu thập và phân tích dữ liệu, phối hợp với các đơn vị trong nội bộ để xây dựng các công cụ phân tích, khuyến nghị, truyền thông, ứng dụng và khai thác công nghệ ai tiếp cận hiệu quả tới từng khách hàng;\n",
      "đưa ra các kiến nghị, dự báo, báo cáo phục vụ công tác quản trị, xây dựng chiến lược, lập kế hoạch kinh doanh. \n",
      "xây dựng các chỉ tiêu đo lường. xây dựng bảng điều khiển kỹ thuật số (dashboard) phục vụ ban lãnh đạo và các bộ phận liên quan;\n",
      "lựa chọn các phương án tối ưu, xây dựng và triển khai các mô hình dựa trên hệ thống dữ liệu nhằm đáp ứng mục tiêu vận hành và cải tiến hệ thống;\n",
      "các nhiệm vụ khác theo sự phân công của ban lãnh đạo trung tâm và trưởng bộ phận.\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2725/data.html\n",
      "mô tả công việc\n",
      "- cài đặt, cấu hình, quản trị, vận hành, tối ưu các hệ thống csdl sử dụng oracle database và/hoặc ms sql server, mysql;- triển khai, quản trị, vận hành các hệ thống: oracle rac, dataguard, oracle weblogic, oracle e-business suite (ebs), oracle golden gate, ms sql cerver cluster…- giám sát hoạt động của hệ thống, xử lý sự cố kỹ thuật.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "- tốt nghiệp đại học, cao đẳng chuyên ngành công nghệ thông tin, toán - tin, tin học quản lý hoặc các chuyên ngành có liên quan;- có kinh nghiệm cài đặt, quản trị hệ thống csdl oracle (rac, dataguard, golden gate, odi); ms sql cluster;- có từ 2 năm kinh nghiệm quản trị csdl trở lên;- am hiểu về hệ điều hành linux, unix;- có kinh nghiệm quản trị hệ thống ứng dụng oracle e-business suite (ebs), oracle weblogic, oracle golden gate, ms sql cluster là một lợi thế.\n",
      "quyền lợi\n",
      "- lương cứng từ 15-30 triệu/tháng (net);- lương tháng thứ 13, thưởng các dịp lễ tết, thưởng định kỳ;- làm việc trong môi trường năng động, chuyên nghiệp có nhiều cơ hội thăng tiến;\n",
      "================================================\n",
      "data-02-06/825/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description. \n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2874/data.html\n",
      "================================================\n",
      "data-02-06/2419/data.html\n",
      "================================================\n",
      "data-02-06/776/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thông tin liên hệ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tổng quan  hỗ trợ trưởng phòng nghiên cứu / phó giám đốc bộ phận nghiên cứu thu thập thông tin, duy trì dữ liệu và soạn thảo báo cáo.\n",
      "\n",
      "\n",
      "chi tiết công việc\n",
      "\n",
      "thường xuyên cập nhật / cải thiện cơ sở dữ liệu thông tin về bất động sản và phân tích theo ngày để cung cấp những hiểu biết sâu sắc về thị trường bất động sản hiện nay\n",
      "nghiên cứu dữ liệu được chọn lọc cùng sự hợp tác chặt chẽ với khách hàng và đồng nghiệp để đáp ứng các yêu cầu của dự án.\n",
      "tiến hành phân tích dữ liệu chuyên sâu bằng các phương pháp truyền thống và cải tiến.\n",
      "viết / phát triển các báo cáo và tài liệu có chứa các dữ liệu được cập nhật hàng ngày.\n",
      "đi đến các tỉnh, thành phố khác để nghiên cứu thị trường nếu cần thiết\n",
      "liên lạc với bộ phận quản lý bất động sản, môi giới và các bộ phận khác trong công ty để đảm bảo hiểu biết tổng thể về thị trường bất động sản.\n",
      "am hiểu mong đợi của khách hàng và thiết kế các cuộc khảo sát để đáp ứng yêu cầu của dự án\n",
      "nắm bắt kỳ vọng của khách hàng liên quan đến phân tích chuyên sâu và tính kịp thời bên trong các sản phẩm được giao.\n",
      "luôn duy trì các tiêu chuẩn đạo đức và bảo mật cao nhất\n",
      "am hiểu / cập nhật luật đất đai và các vấn đề pháp lý khác có liên quan của việt nam.\n",
      "hướng dẫn và phụ trách đào tạo nhân viên cấp dưới / thực tập sinh khi được yêu cầu.\n",
      "\n",
      "yêu cầu\n",
      "trình độ học vấn\n",
      "\n",
      "có hiểu biết sâu sắc về nghiên cứu và phân tích thị trường, đặc biệt là bất động sản\n",
      "chú ý đến chi tiết và luôn hướng đến đạt được kết quả\n",
      "\n",
      "kỹ năng giao tiếp\n",
      "\n",
      "kỹ năng giao tiếp cá nhân và đàm phán tốt\n",
      "thông thạo tiếng anh (nói và viết)\n",
      "\n",
      "kỹ năng máy tính\n",
      "\n",
      "khả năng sử dụng công nghệ thông tin: xây dựng cơ sở dữ liệu và bảng tính bằng excel để thu thập và quản lý thông tin.\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "kinh nghiệm\n",
      "\n",
      "tối thiểu 1 năm kinh nghiệm ở vị trí liên quan.\n",
      "\n",
      "yêu cầu bản thân\n",
      "\n",
      "kỹ năng phân tích và viết báo cáo tốt\n",
      "hiểu các nguyên tắc và thực hành chăm sóc khách hàng\n",
      "kỹ năng giao tiếp, giao tiếp và viết lách tốt\n",
      "có năng lực, tính linh hoạt và sẵn sàng học hỏi\n",
      "kỹ năng tổ chức và quản lý thời gian xuất sắc với khả năng đa nhiệm\n",
      "khả năng viết lách tốt để làm báo cáo và thuyết trình\n",
      "có khả năng làm việc hiệu quả dưới áp lực cao.\n",
      "tính sáng tạo, trí tưởng tượng và khả năng áp dụng sáng kiến vào công việc\n",
      "kỹ năng làm việc nhóm, phân tích và giải quyết vấn đề tốt\n",
      "nhận thức liên quan đến kinh doanh và kiến thức tốt về các vấn đề thời sự.\n",
      "\n",
      "hồ sơ ứng tuyển sẽ được tuyệt đối bảo mật. thông tin cá nhân được thu thập chỉ dành cho mục đích tuyển dụng nhân sự. ứng viên trúng tuyển sẽ có mức lương cao cạnh tranh và con đường sự nghiệp vững chắc.\n",
      "ứng tuyển\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/3113/data.html\n",
      "description\n",
      "\n",
      "\n",
      "là một thành viên trong team bên phía việt nam cùng nghiên cứu, trao đổi với team bên phía nhật bản.\n",
      "nghiên cứu và phát triển các ứng dụng dựa trên ai bao gồm hồi quy, phân loại, phân cụm, đề xuất, học sâu...\n",
      "nghiên cứu và phát triển trên môi trường đám mây (amazon, google, ibm)\n",
      "kiến thức kỹ thuật cập nhật về dịch vụ đám mây, dữ liệu lớn và lĩnh vực liên quan đến học máy (thị giác máy tính, nlp, v.v.)\n",
      "trình bày các chủ đề kỹ thuật phức tạp một cách rõ ràng và có cấu trúc, khả năng kiểm duyệt các cuộc thảo luận, cuộc họp và dự án.\n",
      "kiến thức chuyên môn về ít nhất một ngôn ngữ lập trình. python được ưu tiên\n",
      "\n",
      "\n",
      "\n",
      "your skills and experience\n",
      "\n",
      "\n",
      "có kiến thức, \n",
      "-----------------------------------------------\n",
      "kinh nghiệm cơ bản về chatgpt và các công nghệ ai tổng quát khác\n",
      "thực hiện xử lý phân tích dữ liệu bằng python\n",
      "\n",
      "có kỹ năng và kiến thức về phát triển mô hình ai thông qua fine-tuning, tiền xử lý dữ liệu và học máy\n",
      "đã từng tiếp xúc với học máy trong nghiên cứu (nhận dạng giọng nói, nhận dạng hình ảnh, xử lý ngôn ngữ tự nhiên, v.v.)\n",
      "chủ động xác định các vấn đề, đề xuất và thực hiện các giải pháp\n",
      "coi trọng sự hợp tác và giao tiếp trong nhóm, có thể thúc đẩy các dự án một cách suôn sẻ\n",
      "có trí tưởng tượng và óc sáng tạo linh hoạt, kết hợp các công nghệ và ý tưởng mới một cách tích cực\n",
      "khả năng đọc/viết/giao tiếp bằng tiếng anh hoặc tiếng nhật. tiếng nhật được ưu tiên\n",
      "chuyên gia có động lực cao và định hướng kinh doanh với thái độ có thể làm được.\n",
      "ưu tiên có kinh nghiệm hoặc đam mê trong lĩnh vực liên quan đến ai khác\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "\n",
      "mức lương hấp dẫn\n",
      "================================================\n",
      "data-02-06/309/data.html\n",
      "================================================\n",
      "data-02-06/2519/data.html\n",
      "================================================\n",
      "data-02-06/1800/data.html\n",
      "================================================\n",
      "data-02-06/2220/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "tham gia cùng team để trả lời các câu hỏi liên quan đến sản phẩm, marketing, business\n",
      "\n",
      "\n",
      "ghi nhận, đo lường hoạt động của khách hàng từ quá trình quảng cáo đến các giai đoạn tương tác trong game\n",
      "\n",
      "\n",
      "thống kê, phân tích, đánh giá các dữ liệu để hiểu hơn về hành vi người dùng\n",
      "\n",
      "\n",
      "xây dựng các dashboard, báo cáo để truyền tải thông tin hiệu quả và nhanh chóng\n",
      "\n",
      "\n",
      "đưa ra gợi ý xây dựng, tối ưu các tính năng, hệ thống của sản phẩm để tăng trải nghiệm người chơi và đáp ứng chiến lược về mặt kinh doanh\n",
      "\n",
      "\n",
      "phân tích đối thủ cạnh tranh, xu hướng thị trường và ngành công nghiệp game\n",
      "\n",
      "\n",
      "nghiên cứu và xây dựng các mô hình thống kê để diễn giải các dữ liệu trong quá khứ và dự đoán thay đổi tương lai\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "\n",
      "tốt nghiệp đại học hoặc sinh viên năm cuối chuyên ngành kinh tế, kinh doanh, công nghệ thông tin hoặc các chuyên ngành liên quan\n",
      "\n",
      "\n",
      "hiểu biết chung về dữ liệu và phân tích dữ liệu.\n",
      "\n",
      "\n",
      "có tư tuy logic, định hướng dữ liệu, định hướng chi tiết\n",
      "\n",
      "\n",
      "sử dụng tiếng anh linh hoạt trong nghiên cứu, phân tích thông tin\n",
      "\n",
      "\n",
      "khả năng giao tiếp và làm việc nhóm\n",
      "\n",
      "\n",
      "ưu tiên các ứng viên:\n",
      "\n",
      "\n",
      "có đam mê về game, chơi nhiều thể loại game, hiểu biết về quy trình làm game\n",
      "\n",
      "\n",
      "có khả năng sử dụng sql, các tool visualization\n",
      "\n",
      "\n",
      "có kiến thức về các mô hình về định lượng hoặc kinh tế lượng\n",
      "\n",
      "\n",
      "sẵn sàng học python để xử lý big data từ nhiều nguồn và những công nghệ mới.\n",
      "\n",
      "\n",
      "quyền lợi\n",
      "\n",
      "\n",
      "lương tháng 13, thưởng lễ tết.\n",
      "\n",
      "\n",
      "được đề xuất, xét thưởng và xét tăng lương định kỳ hàng quý.\n",
      "\n",
      "\n",
      "tham gia các hoạt động tập thể như team bonding, company trip, year end party hàng năm\n",
      "\n",
      "\n",
      "khám sức khỏe định kỳ hàng năm\n",
      "\n",
      "\n",
      "được tiếp cận những thách thức để chinh phục, nhiều cơ hội thăng tiến và phát triển.\n",
      "\n",
      "\n",
      "được làm việc trong môi trường năng động, trẻ trung, thời gian linh động.\n",
      "\n",
      "\n",
      "được đào tạo những kỹ năng mới phục vụ cho công việc.\n",
      "\n",
      "\n",
      "được tài trợ các khóa học theo chương trình đào tạo của công ty.\n",
      "\n",
      "\n",
      "mức thu nhập tương xứng với năng lực và trình độ.\n",
      "\n",
      "\n",
      "được tài trợ tham gia các hoạt động thể thao như bóng đá, bơi lội…\n",
      "\n",
      "\n",
      "📌loại hình công việc: toàn thời gian\n",
      "📌địa điểm làm việc: phú nhuận\n",
      "✨mức lương: 10.000.000₫ -> 20.000.000₫ /tháng\n",
      "💌cv xin gửi về minhdt@imba.co\n",
      "tagged as: data analyst, python, sql\n",
      "================================================\n",
      "data-02-06/827/data.html\n",
      "================================================\n",
      "data-02-06/1564/data.html\n",
      "responsibilities include monitoring risk of porfolio, focus on reducing negative financial outcomes of digital banking including analyzing requirements, conducting analyses, developing reports, dashboards, data insight recommendations, also track performance and quality control to identify improvements. specifically, you will:\n",
      "\n",
      "understand end to end digital lending process includes onboarding, usage, and collection.\n",
      "develop risk reports to manage the quality of portfolio and monitor the ratio of non-performing loan, delinquency, and loss rate below the standards of the sbv and ifrs.\n",
      "develop ad-hoc reports which focus on actual problems being faced and business impact to notify leaders.\n",
      "develop a monitoring report for tracking progress and rules of decision engine.\n",
      "evaluate credit scoring/ fraud score/ income score/ 3rd party data for recommendations of credit strategies.\n",
      "work with engineering team to implement automated risk strategies.\n",
      "work closely with the product team to explore data. use data to contribute toward strategic decision-making, and planning.\n",
      "propose optimization of risk policy and initiatives to achieve overall risk target.\n",
      "\n",
      "what you need to have\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "proven working experience as a data analyst, or credit risk analytics.\n",
      "have knowledge of credit products.\n",
      "adept at full task flow from data query and collecting, report writing to presenting findings based on significant amounts of information with attention to detail and accuracy.\n",
      "technical expertise regarding data models, database design development, data mining, and segmentation techniques.\n",
      "strong knowledge of and experience with databases (sql).\n",
      "familiar with tools for analyzing datasets (excel, vba, r, python, etc).\n",
      "have experience with data visualization tools such as powerbi, google data studio, tableau, metabase, qlikview, etc.\n",
      "bs in mathematics, economics, finance, computer science, data science, information management, or statistics.\n",
      "experience with other self-service data analytics tools, nosql is nice to have.\n",
      "willing to learn on the job and ready to adapt to changes in requirements.\n",
      "\n",
      "what you will get \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "opportunity to work and learn from one of the best and brightest technology teams in vietnam\n",
      "be part of a winning team with exponential growth regionally\n",
      "top market rate pay\n",
      "generous benefits: health insurance package for family, free food at the office - all day, grab for work allowance\n",
      "\n",
      "about us\n",
      "\n",
      "\n",
      "\n",
      "trusting social is an ai fintech company specialized in assessing credit profiles of consumers in emerging markets combining pioneering ai with large alternative data sources. in 2020 we reached our ambitious milestone of credit profiling 1bn consumers spanning 4 countries - vietnam, indonesia, india & the philippines - and building a platform for the wider industry and the financial services industry in particular to provide the 'un & under' served access to credit. at the core of this initiative has been our strict and unwavering adherence to the norms of consumer data privacy and consumer data rights.\n",
      "but we're not satisfied as we embark on the next leg of our journey to deliver 100 million credit lines to consumers in the markets where we operate. although this goal is ambitious, we truly believe that by harnessing the power of ai & big data we can deliver financial access at unprecedented scale.\n",
      "as a firm, we're audacious problem solvers motivated by our impact on society. we deeply espouse the values of ownership - of our actions and initiatives, integrity in all we do and agility in execution.\n",
      "we place great importance on doing what is right, what is best and what is innovative. if you are smart, driven and want to make a difference in the world with the most advance and fascinating technology, come join our team. we can satisfy your desire to explore new territory and give you the runway to really make an impact. \n",
      "additional info\n",
      "\n",
      "\n",
      "\n",
      "learn more about us here:\n",
      "https://www.youtube.com/watch?v=inaedgvocl8&t=29\n",
      "-----------------------------------------------\n",
      "experience recruiting world-class talents, come join us.\n",
      "what you will do\n",
      "\n",
      "\n",
      "\n",
      "senior risk analyst responsibilities include monitoring risk of porfolio, focus on reducing negative financial outcomes of digital banking including analyzing requirements, conducting analyses, developing reports, dashboards, data insight recommendations, also track performance and quality control to identify improvements. specifically, you will:\n",
      "\n",
      "understand end to end digital lending process includes onboarding, usage, and collection.\n",
      "develop risk reports to manage the quality of portfolio and monitor the ratio of non-performing loan, delinquency, and loss rate below the standards of the sbv and ifrs.\n",
      "develop ad-hoc reports which focus on actual problems being faced and business impact to notify leaders.\n",
      "develop a monitoring report for tracking progress and rules of decision engine.\n",
      "evaluate credit scoring/ fraud score/ income score/ 3rd party data for recommendations of credit strategies.\n",
      "work with engineering team to implement automated risk strategies.\n",
      "work closely with the product team to explore data. use data to contribute toward strategic decision-making, and planning.\n",
      "propose optimization of risk policy and initiatives to achieve overall risk target.\n",
      "\n",
      "what you need to have\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "proven working experience as a data analyst, or credit risk analytics.\n",
      "have knowledge of credit products.\n",
      "adept at full task flow from data query and collecting, report writing to presenting findings based on significant amounts of information with attention to detail and accuracy.\n",
      "technical expertise regarding data models, database design development, data mining, and segmentation techniques.\n",
      "strong knowledge of and experience with databases (sql).\n",
      "familiar with tools for analyzing datasets (excel, vba, r, python, etc).\n",
      "have experience with data visualization tools such as powerbi, google data studio, tableau, metabase, qlikview, etc.\n",
      "bs in mathematics, economics, finance, computer science, data science, information management, or statistics.\n",
      "experience with other self-service data analytics tools, nosql is nice to have.\n",
      "willing to learn on the job and ready to adapt to changes in requirements.\n",
      "\n",
      "what you will get\n",
      "================================================\n",
      "data-02-06/2521/data.html\n",
      "================================================\n",
      "data-02-06/1603/data.html\n",
      "descriptionare you looking for a fun place to work?\n",
      "join the game! leader in the development and publishing of games, gameloft® has established itself as a pioneer in the industry, creating innovative gaming \n",
      "-----------------------------------------------\n",
      "experiences for over 20 years. gameloft creates games for all digital platforms, from mobile to cross-platform titles for pc and consoles. gameloft operates its own established franchises such as asphalt®, dragon mania legends, modern combat and dungeon hunter and also partners with major rights holders including lego®, universal, illumination entertainment, hasbro®, fox digital entertainment, mattel®, lamborghini®, and ferrari®. gameloft distributes its games in over 100 countries and employs 3,600 people worldwide. every month, 55 million unique users can be reached by advertisers in gameloft games with gameloft for brands, a leading b2b offering dedicated to brands and agencies. gameloft is a vivendi company.\n",
      "================================================\n",
      "data-02-06/430/data.html\n",
      "responsibilities\n",
      "requirements\n",
      "what we offer\n",
      "about us\n",
      "additional inforesponsibilities\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "extract actionable business insights from data, formulate business solutions based on data to improve the company's revenue\n",
      "design, develop, and operate machine learning models and rules to find the best potential customers\n",
      "actively learn about the market, seek out opportunities to innovate the customer acquisition, monitoring, and retention solutions\n",
      "perform complex activities related to financial products, business analysis, and build dashboards for portfolio monitoring\n",
      "monitor and optimize system performance, resource consumption\n",
      "collaborate and consult with peers, colleagues, and managers to resolve issues and achieve goals\n",
      "\n",
      "requirements\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ms or phd in computer science, statistics, mathematics, or related fields\n",
      "at least 5 years of professional working \n",
      "-----------------------------------------------\n",
      "experience in applying machine learning solutions to business problems\n",
      "results-oriented with strong analytical and problem-solving skills\n",
      "good business acumen with a strong ability to solve business problems through data-driven quantitative methodologies\n",
      "the ability to communicate results clearly to technical and non-technical audiences.\n",
      "demonstrated ability to research and innovate solutions\n",
      "experience with python, database management systems, and sql\n",
      "experience with software design and software development\n",
      "experience in bank-related products such as unsecured personal loans and credit cards is a plus\n",
      "\n",
      "what\n",
      "================================================\n",
      "data-02-06/2879/data.html\n",
      "responsibility will be to support the execution of quality assurance activities and help identify areas for improvement in our operational workflows.\n",
      " \n",
      "you’ll do \n",
      "\n",
      "support in implementation expertise tasks in the operations department to ensure accurate and complete compliance with regulations.\n",
      "provide support in the reception, verification, and preparation of professional documents to maintain data integrity and accuracy.\n",
      "assist in the implementation and operation of business process procedures to enhance efficiency and effectiveness.\n",
      "collect and analyze data to evaluate process performance and identify opportunities for optimization.\n",
      "contribute to the continuous improvement of operational processes by proposing innovative ideas and solutions to enhance work efficiency and effectiveness.\n",
      "assist in preparing reports and presentations on process quality metrics and findings.\n",
      "perform other tasks as assigned by superiors.\n",
      "\n",
      " \n",
      "you have\n",
      "\n",
      "undergraduate or graduate students preferred majoring in business administration, international business, finance, economics, or a related discipline.\n",
      "knowledge of quality management systems and methodologies is a plus.\n",
      "familiarity with operational processes and workflow is advantageous.\n",
      "high proficiency in using ms office applications, particularly excel and powerpoint.\n",
      "strong attention to detail and commitment to maintaining high-quality standards.\n",
      "excellent analytical & critical thinking and problem-solving skills.\n",
      "excellent communication and presentation skills\n",
      "be creative, fast-learner with positive thinking and always open for challenges\n",
      "\n",
      " \n",
      "we offer\n",
      "\n",
      "monthly internship allowance: 3,000,000 vnd \n",
      "meal & parking fees provided\n",
      "working time: at least 20 hours/week\n",
      "flexible schedule for students\n",
      "weekly shoulder massage treatment.\n",
      "professional and creative office view\n",
      "annual team building: summer trip, many indoor and outdoor activities such as soccer club, swimming club, cycling club… \n",
      "\n",
      " \n",
      "why you’ll love working here\n",
      "\n",
      "gain hands-on \n",
      "-----------------------------------------------\n",
      "experience in quality assurance processes and methodologies, enhancing your skills in operational excellence and process improvement.\n",
      "work closely with experienced professionals who will guide and support you throughout your internship, providing valuable insights and knowledge.\n",
      "expand your knowledge and understanding of operational quality assurance practices, allowing you to develop a strong foundation for a future career in this field.\n",
      "connect with professionals in the industry, building valuable relationships and expanding your professional network.\n",
      "receive regular feedback and performance evaluations, enabling you to assess your strengths and areas for improvement.\n",
      "collaborate with cross-functional teams, enhancing your teamwork and communication skills in a professional setting.\n",
      "benefit from a flexible work schedule that accommodates your academic commitments and allows for a healthy work-life balance.\n",
      "================================================\n",
      "data-02-06/1900/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "data-02-06/3084/data.html\n",
      "chi tiết công việc chief actuary tại prudential vietnam assurance private lt\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/249/data.html\n",
      "descriptionthe bosch group is a leading global supplier of technology and services. it employs roughly 394,500 associates worldwide (as of december 31, 2020). according to preliminary figures, the company generated sales of 71.6 billion euros in 2020. its operations are divided into four business sectors: mobility solutions, industrial technology, consumer goods, and energy and building technology.the bosch group comprises robert bosch gmbh and its roughly 440 subsidiaries and regional companies in some 60 countries. if its sales and service partners are included, then bosch is represented in roughly 126 locations. this worldwide development, manufacturing, and sales network is the foundation for further growth.bgsv – bosch global software technologies company limited (previous name: rbvh - robert bosch engineering and business solutions vietnam company limited) is 100% owned subsidiary of robert bosch gmbh. bgsv has started its operations from 19th october, 2010 at e-town2 in hcmc. this engineering development center will be engaged in developing embedded systems and software, mechanical design and simulation, and will provide it (sap consulting, java development….) and business services (finance and accounting, economics, purchasing, logistics, translations japanese-english-japanese, information security ) solutions to the bosch group of companies globally. job descriptiongather business requirements from end usersanalyze data sources and related tables for customer’s reporting requirementdevelop data pipelines and design data models to support reporting purposedevelop dashboards and operating reports for daily/hourly usagehandle uat workshops and provide trainings to end-userstroubleshoot and handle dashboard and data issuessupport presales activities such as proof of concept, demonstration, proposalacquire new technologies related to sap analyticsbuild guided configurations, document templates, etc. for faster deliverablesqualificationsmore than 3 year-\n",
      "-----------------------------------------------\n",
      "experience in delivery of sap analytics solutionexperience in working with or certified sap analytics cloud, sap data warehouse on cloudexperience in working with data warehousing using sap bw or ms sqlexperience in working with data visualization tools such as sap businessobjects (design studio, lumira...), ms power bigood sql skills and python is preferredknowledge of business processes in sap erp (fico, mm, sd...) is a plusgood communication skills and experience with international clientsproactive and flexible to work onsite or offshoreadditional informationdescribe your perks and cultur\n",
      "================================================\n",
      "data-02-06/3013/data.html\n",
      "responsibilities1. làm việc với các phòng ban để lấy yêu cầu nghiệp vụ, nguồn dữ liệu cần thiết để xây dựng đầu bài cho các dự án quản trị dữ liệu (các dự án ca governance, data governance, master data)2. tham gia thiết kế và giám sát xác thực thông tin/xác thực khách hàng/xác thực giao dịch/xác thực kênh bán; giám sát sla các service điểm chạm đến khách hàng.3. tham gia thiết kế hệ thống và chính sách quản lý dữ liệu (quản lý dữ liệu khoa học, phân cấp trách nhiệm người dùng, khai thác dữ liệu hiệu quả, minh bạch, xây dựng nguyên tắc và giám sát thực thi). duyệt các adhoc nằm ngoài chính sách.4. thực hiện các báo cáo quản trị thông minh để cảnh báo và đề xuất biện pháp.5. tiếp nhận và xử lý các yêu cầu về phân tích dữ liệu hiện có, đưa ra phân tích, dự đoán tình huống, xu thế.iii. tiêu chuẩn vị trí/ \n",
      "-----------------------------------------------\n",
      "job requirements1. trình độ học vấn: tốt nghiệp chuyên ngành tài chính, kinh tế, bảo hiểm, quản trị dữ liệu\n",
      "================================================\n",
      "data-02-06/3138/data.html\n",
      "responsible for risk data compilation, analysis, and reporting·         collect complex information for data processing tasks ·         be responsible for the accurate and timely production of weekly/monthly risk reports.  customers / stakeholders ·         review daily process updates for defect free implementation·         improve customer service and increase productivity. ·         provide accurate and valid referrals to the respective fcc/level leadership & teamwork·         acquire and share best practices relating to procedures / latest anti money laundering trends to relevant processes /contingent sites.·         support to increase awareness of anti money laundering across the section.operational effectiveness & control ·         take necessary actions to mitigate the likelihood of any operational risk occurring.·         continuously assess the operational risks inherent in the business, taking in account the changing economic or market conditions, legal and regulatory requirements, operating procedures and practices, management restructurings and the impact of new technology\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2542/data.html\n",
      "responsible for:\n",
      "\n",
      "coaching a team of data scientists and analysts and nurturing a strongly collaborative and inclusive culture of trust, excellence, and empowerment.\n",
      "clarifying and standardizing core organizational and movement metrics.\n",
      "partnering with data engineering to automate data pipelines and build data products that make data and insights accessible.\n",
      "collaborating with colleagues in the research & decision science group to cultivate a practice of data-informed decision-making across the foundation.\n",
      "managing evaluation and analysis to support organization-wide forecasting, goal-setting, and strategic planning.\n",
      "continuous development and improvement of our data models, visualizations, and reports for easier interpretation and increased accessibility.\n",
      "sharing results and knowledge derived from data with foundation staff and wikimedia communities.\n",
      "\n",
      "skills and \n",
      "-----------------------------------------------\n",
      "experience:\n",
      "\n",
      "experience leading cross-team initiatives to identify, define, and track core metrics.\n",
      "a coach and mentor with high emotional intelligence: evidenced by humility, tact, compassion, high levels of integrity, and good listening skills.\n",
      "demonstrated commitment to equity, inclusion, and diversity.\n",
      "experience leading projects and programs to build and maintain user-facing data products such as dashboards, trusted datasets, and knowledge bases.\n",
      "a facilitator with strong collaboration skills and an empowerment approach to open and transparent management.\n",
      "\n",
      "qualities that are important to us:\n",
      "\n",
      "ability to explain data and insights clearly to non-specialist audiences and gain their understanding and confidence.\n",
      "empathy towards and commitment to work with the wikimedia affiliates and volunteer communities.\n",
      "discretion and competence in handling sensitive or confidential data.\n",
      "curiosity and critical thinking skills; a lifelong learner who sees situations through multiple lenses.\n",
      "ability to link qualitative and quantitative information to make actionable recommendations to the wikimedia foundation and communities.\n",
      "commitment to the mission of the organization and our values and guiding principles.\n",
      "self-motivated with an ability to navigate through ambiguity and complexity. the wikimedia ecosystem is complex, resources are limited, and our guiding principles are ambitious. we want you to work to find solutions embracing these factors.\n",
      "\n",
      "additionally, we’d love it if you have:\n",
      "\n",
      "exposure to, and interest in, ethical data management and privacy practices.\n",
      "experience with large-scale data processing & storage tools (we use hadoop, hive, presto, and spark).\n",
      "contributed to wikimedia projects or have experience working in other open source projects.\n",
      "experience with superset or other open source visualization and reporting tools.\n",
      "\n",
      "about the wikimedia foundation\n",
      "the wikimedia foundation is the nonprofit organization that operates wikipedia and the other wikimedia free knowledge projects. our vision is a world in which every single human can freely share in the sum of all knowledge. we believe that everyone has the potential to contribute something to our shared knowledge, and that everyone should be able to access that knowledge freely. we host wikipedia and the wikimedia projects, build software experiences for reading, contributing, and sharing wikimedia content, support the volunteer communities and partners who make wikimedia possible, and advocate for policies that enable wikimedia and free knowledge to thrive.\n",
      "================================================\n",
      "data-02-06/2173/data.html\n",
      "================================================\n",
      "data-02-06/2690/data.html\n",
      "================================================\n",
      "data-02-06/2823/data.html\n",
      "description\n",
      "\n",
      "\n",
      "life at agoda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "all teams\n",
      "contentcustomer \n",
      "-----------------------------------------------\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "head of search engine optimization (seo) – bangkok based, relocation provided\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "================================================\n",
      "data-02-06/2377/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description summary similar job\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2479/data.html\n",
      "responsibilitiescan learn extensive knowledge through the work processwork as part of a team to develop applications and servicesknow how to analyze ai task requirements and propose technical solutionsknow how to analyze program complexities for optimizationknow how to build, run and profile softwareknow how to write reusable, testable, maintainable, and scalable codestrong will to learn new knowledge/expertise and quick adaptability to changes\n",
      "-----------------------------------------------\n",
      "job requirements and qualificationsdoing a bs in computer science/computer engineering/data science. msc level candidate would be a bonushave a good grasp of mathematics especially linear algebra, probability, discrete mathvery familiar with python or c/c++. experience with other languages is also welcomebasic/mediate knowledge of algorithms and data structures is a bonusexperience with machine learning/deep learning frameworks such as scikit-learn, tensorflow, pytorch is a bonusexperience with image processing or natural language processing is a bonusbenefits and perksallowance for 3 months of participationlearn how to make technology productspotential to advance to a full-time position following the successful completion of the internship;access to training programs/ courses and continuous opportunities for personal development;opportunity to work in a professional environmentfree weekly social events and activities at enouvo.an inspiring place to work and a chance to be part of the enouvo family with all of the young, talented and passionate colleaguesabout usenouvo group is a company specializing in providing innovative and technological solutions. after 10 years of operation, enouvo has grown and expanded in many fields such as it, digital product development, agency, coworking space and cafe. we always strive to create the most outstanding products to not only bring value to customers but also contribute to the development of the community.how to applydoes this role sound like a good fit? email us at [email\n",
      "================================================\n",
      "data-02-06/2659/data.html\n",
      "================================================\n",
      "data-02-06/1799/data.html\n",
      "description\n",
      "\n",
      "design and develop data pipelines that extract, transform, and load data from various sources into different departments‘ data warehouses using modern data stack technologies.\n",
      "design and maintain data models that provide a structured view of the data, allowing different departments to analyze and explore their data easily.\n",
      "perform descriptive analysis to provide valuable and actionable insights for departments’ businesses.\n",
      "prepare reports for the management stating trends, patterns, and predictions using relevant data.\n",
      "work closely with our data engineers and project managers to deliver high-quality data solutions to different departments.\n",
      "ensure different departments‘ data is secured and compliant with relevant regulations and standards.\n",
      "provide technical support to different departments, troubleshoot issues, and ensure timely resolution of technical problems.\n",
      "participate in code reviews to ensure that our solutions are of high quality and follow best practices.\n",
      "contribute to the company‘s growth by identifying new opportunities for our services, building relationships with departments, and delivering high-quality solutions that exceed their expectations.\n",
      "stay up-to-date with the latest trends and technologies in data analytics and continuously improve your skills and knowledge.\n",
      "\n",
      "requirement\n",
      "\n",
      "at least 2 year of hands-on \n",
      "-----------------------------------------------\n",
      "experience with sql, additional experience with programming languages (python, r) is a plus\n",
      "at least 1 year of experience with any visualization tools (power bi, tableau…)\n",
      "strong proficiency in sql and experience with etl processes and data modeling.\n",
      "experience with cloud platforms, such as google cloud platform (gcp) or amazon web services (aws).\n",
      "strong problem-solving skills and ability to work independently and in a team environment.\n",
      "excellent communication and collaboration skills to work effectively with departments and cross-functional teams.\n",
      "strong attention to detail and ability to manage multiple projects simultaneously.\n",
      "passion for data and keeping up with the latest trends and technologies in data analytics.\n",
      "prior experience working in a consulting or client-facing role is a plus.\n",
      "================================================\n",
      "data-02-06/273/data.html\n",
      "responsibilities\n",
      "job purpose- the job holder supervises the setup of analytical tools to generate insights for customer journeys and product enhancements using programming methods, processes and systems to consolidate and analyze unstructured, diverse big data sources.- the job holder is required to take initiative in experimenting various technologies and tools with vision of creating innovative data driven insights for the business at the quickest pace possible and keep current with technical and industry developments.key accountabilities (1)data solutioning- evaluate effectiveness of proposed models and track business performance against data analysis model.- build cutting-edge algorithms and work with machine learning and deep learning tools to deliver advance analytics solutions across the firm including recommendation engines, customized data models, customer journeys, graph modes, etc.- drive application of machine learning and big data techniques across different journeys and squads.- manage, execute, and review complex data science projects in an agile manner and in compliance with internal regulatory requirements.key accountabilities (2)data insighting- lead the identification and interpretation of meaningful and actionable insights from large data and metadata sources.- review processes and tools designed to monitor and analyze model performance and data accuracy.- proactively lead discussions in 3+ squads to identify questions and issues for data analysis- collaborate with data engineers to build complex, technical algorithms in data analytics software applications to improve work efficiency.key accountabilities (3)projects management- manage project conflicts, challenges and dynamic business requirements to keep operations running at high performance.- work with team leads to resolve people problems and project roadblocks, conduct post mortem and root cause analysis to help squads continuously improve their practices to ensure maximum productivity.talent development- mentor and coach data analysts into fully competent data scientists.- identify and encourage areas for growth and improvement within the tribe.\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2518/data.html\n",
      "responsibility to ensure developed modules are matched with business requirements.\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2390/data.html\n",
      "description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "benefits\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "skills required\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "details\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- thu thập và xử lý dữ liệu marketing từ các nguồn khác nhau (ví dụ: facebook, google ads), hệ thống crm, và các nguồn dữ liệu khác. xử lý và làm sạch dữ liệu để đảm bảo tính nhất quán trong phân tích.\n",
      "- áp dụng các kỹ thuật và công cụ phân tích dữ liệu để tìm hiểu thông tin từ dữ liệu marketing. phân tích các chỉ số hiệu suất quảng cáo, tiếp cận khách hàng, tương tác và hành vi của khách hàng trên các kênh trực tuyến nhằm ra các đề xuất và chiến lược dựa trên phân tích dữ liệu để tối ưu hoá các chiến dịch digital marketing.\n",
      "- chuẩn bị và thực hiện các báo cáo hàng tuần, hàng tháng hoặc theo yêu cầu từ quản lý và các bộ phận liên quan.\n",
      "- làm việc chặt chẽ với các bộ phận liên quan để nắm rõ yêu cầu và đồng thời hỗ trợ trong việc đưa ra quyết định tối ưu để cải tiến quy trình của phòng marketing.\n",
      "- các nhiệm vụ khác theo sự phân công của trưởng bộ phận.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job benefits\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "quà chúc mừng sinh nhật, các dịp lễ, tết,...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hỗ trợ ăn nhẹ trong giờ làm việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "được hưởng chế độ bhyt, bhxh, bhtn theo quy định\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "định kỳ khám sức khỏe hằng năm\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "được review 2 lần trong năm\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "chương trình team building để kết nối đồng nghiệp\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "required experience / skills detail\n",
      "\n",
      "\n",
      "\n",
      "* kiến thức:\n",
      "- có \n",
      "-----------------------------------------------\n",
      "kinh nghiệm từ 3 đến 5 năm trong vị trí data analyst.\n",
      "- nắm rõ các thuật ngữ chuyên về digital marketing sẽ là một lợi thế.\n",
      "- am hiểu cách thức vận hành của các nền tảng online: facebook, google,...\n",
      "* kỹ năng:\n",
      "- có kỹ năng phân tích dữ liệu cẩn thận và chính xác\n",
      "- sử dụng thành thạo các công cụ phân tích dữ liệu.\n",
      "- lập kế hoạch công việc đảm bảo sự hiệu quả và tiến độ của công việc.\n",
      "- có kỹ năng tốt trong việc giải quyết vấn đề và có khả năng trình bày và giao tiếp lưu loát tự tin.\n",
      "* thái độ:\n",
      "- tự tin: làm việc với các con số, đồ thị, biểu đồ, thống kê.\n",
      "- tư duy chủ động, trách nhiệm, ham học hỏi & không ngừng phát triển;\n",
      "- sẵn sàng học hỏi và chịu được áp lực\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job detail\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "position type\n",
      "\n",
      "full-time\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "career level\n",
      "\n",
      "staff\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "education level\n",
      "\n",
      "bachelor's degree\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gender\n",
      "\n",
      "male / female\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job categories\n",
      "\n",
      "\n",
      "advertising / promotion / pr\n",
      "\n",
      ", \n",
      "\n",
      "marketing\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "information\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "name:\n",
      "\n",
      "\n",
      "ms.ly\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "307 a nguyễn trọng tuyển, phường 10\n",
      "\n",
      ", \n",
      "\n",
      "phu nhuan district\n",
      "\n",
      ", \n",
      "\n",
      "ho chi minh\n",
      "\n",
      ", \n",
      "\n",
      "viet nam\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- các ứng viên quan tâm vui lòng gửi hồ sơ trực tuyến qua careerlink, gửi kèm file hoặc trực tiếp đến tại công ty\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "application language:\n",
      "vietnamese\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "công ty cổ phần teecom\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "http://teecom.vn/\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "25 - 99 employees\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact: ms.ly\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "chính thức thành lập vào tháng 10/2020, teecom là một trong những công ty khởi nghiệp phát triển vượt bậc trong ngành thương mại điện tử.đội ngũ nhân sự trẻ, năng động, dày dặn về kinh nghiệm chuyên môn, dám ước mơ và không ngại thử thách để đưa ra những ý tưởng, sản phẩm thành hiện thực trên thị trường quốc tế.tầm nhìn:xây dựng một hệ sinh thái thương mại điện tử toàn cầu có trị giá 100 triệu đô vào năm 2026.sứ mệnh:kiến tạo một hệ sinh thái cởi mở, sáng tạo và học hỏi nhanh giúp mỗi cá nhân phát triển tối đa tiềm năng, tạo ra các sản phẩm tập trung vào khách hàng, biến các ý tưởng trở nên thành công trên thị trường thương mại điện tử toàn cầu.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "see more\n",
      "\n",
      "\n",
      "\n",
      "see less\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "other jobs from this company\n",
      "\n",
      "|\n",
      "\n",
      "see all\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "golang developer\n",
      "\n",
      "\n",
      "công ty cổ phần teecom\n",
      "\n",
      "\n",
      "\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "full stack technical lead\n",
      "\n",
      "\n",
      "công ty cổ phần teecom\n",
      "\n",
      "\n",
      "\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nhân viên chăm sóc khách hàng\n",
      "\n",
      "\n",
      "công ty cổ phần teecom\n",
      "\n",
      "\n",
      "\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "market research analyst | chuyên viên nghiên cứu thị trường\n",
      "\n",
      "\n",
      "công ty cổ phần teecom\n",
      "\n",
      "\n",
      "\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "senior it business analyst\n",
      "\n",
      "\n",
      "công ty cổ phần teecom\n",
      "\n",
      "\n",
      "\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tags\n",
      "\n",
      "\n",
      "\n",
      "marketing\n",
      "phu nhuan district\n",
      "market research staff\n",
      "data processing\n",
      "data analyst\n",
      "product manager\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "share\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "copied\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/885/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responsible for handling other tasks assigned by team leader\n",
      "this position will report to team leader\n",
      "\n",
      "what we are looking for:\n",
      "\n",
      "bachelor’s degree in business, accounting, economics, finance or other analytical majors\n",
      "at least 1-2 years’ \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/171/data.html\n",
      "================================================\n",
      "data-02-06/2529/data.html\n",
      "mô tả công việc\n",
      "- phát triển, thử nghiệm các thuật toán, mô hình nhận dạng ảnh và xử lý âm thanh trong lĩnh vực thị giác máy tính (computer vision), xử lý hình ảnh, xử lý âm thanh … áp dụng vào lĩnh vực chính là tự động phát hiện vi phạm bản quyền phim ảnh trong lĩnh vực media streaming - nghiên cứu và áp dụng các công nghệ mới nhất trong lĩnh vực thị giác máy tính vào các bài toán ứng dụng trong lĩnh vực phân tich vi phạm bản quyền trong lĩnh vực truyền thông đa phương tiện … - nghiên cứu và áp dụng các công nghệ mới nhất trong lĩnh vực nhận diện âm thanh vào các bài toán ứng dụng trong lĩnh vực phân tich vi phạm bản quyền âm nhạc... - giải quyết các bài toán về machine learning, deep learning, bigdata, media streaming khác. - phát triển các dự án ai từ yêu cầu của hệ thống. - các công việc liên quan khác theo yêu cầu của trưởng bộ phận. - các ứng viên mới ra trường sẽ được đào tạo.\n",
      "yêu cầu ứng viên\n",
      "- tốt nghiệp chuyên nghành cntt hoặc liên quan - không yêu cầu kinh nghiệm, được tào tạo kỹ năng về ai để có thể phục vụ công việc - có kiến thức về opencv, có kiến thức nền tảng về xử lý ảnh  - có kiến thức về lĩnh vực machine learning, deeplearning - từng làm việc trên các nền tảng tensorflow, keras, caffe, pytorch... là 1 lợi thế  - thông thạo ngôn ngữ lập trình python là 1 lợi thế - có kỹ năng làm việc nhóm, có khả làm việc độc lập, khả năng đọc các tài liệu nước ngoài tốt - thành thạo các công cụ quản lý mã nguồn và công cụ lập trình: pycharm, git , ...\n",
      "quyền lợi\n",
      "- môi trường làm việc chuyên nghiệp, thân thiện.- được đào tạo về ai thường xuyên, liên tục- làm việc 5 ngày/tuần (được nghỉ thứ 7, chủ nhật) và các ngày lễ, tết theo quy định của chính phủ việt nam.- được đi du lịch trong/ ngoài nước ít nhất 1 lần/ năm- thực hiện thưởng cả năm và thưởng các ngày lễ, tết của việt nam.- ngoài quy định nâng lương 1 lần/năm, có thể được xem xét nâng lương trước thời hạn tùy năng lực và khả năng đáp ứng \n",
      "-----------------------------------------------\n",
      "yêu cầu công việc.- được tham gia các chế độ bhxh, bhyt, bhtn theo pháp luật hiện hành.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "hết hạn nộp đơn\n",
      "\n",
      "================================================\n",
      "data-02-06/2887/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            ●\tthe engineer is responsible for the data product’s implementation. supervisor quality of product to make sure its functions meet requirements\n",
      "●\tresearch new technology to apply for big data products. continuously suggest advanced technical solutions to make the product best\n",
      "●\twork with leader very closely to make sure each other opinions are aligned\n",
      "●\thand-on development of features through architect, design, and implementation\n",
      "●\tcode yourself, perform code review and code optimization for maximizing system performance\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1537/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- phân tích, dự báo doanh thu theo tuần, tháng - thiết kế, duy trì theo dõi hệ thống kpi đo lường hiệu quả kinh doanh;- tra soát, trích xuất dữ liệu thực hiện các ad-hoc report theo yêu cầu- nghiên cứu dữ liệu tìm insight cải thiện kết quả cho bộ phận kinh doanh- xây dựng các dashboard nhằm trực quan hóa dữ liệu phục vụ cho điều hành kinh doanh- công việc trao đổi thêm khi phỏng vấn\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2766/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            •\tcollect and verify market information to ensure information’s accuracy for tone analysis to produce effective and in time reports on chip mill stocks, log prices, log volumes, vessel loading at ports\n",
      "•\tcontinuously update colleagues and management on other related market information i.e movement, development, trends, challenges etc. in terms of woodchips production and sourcing and any issue/change in the business environment that may have an impact on the company’s strategy\n",
      "•\tdevelop new source/suppliers\n",
      "•\tfollow up assigned projects as required and other assignments required by the management\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3095/data.html\n",
      "mô tả công việc\n",
      " participating in asilla's products and building projects in the computer vision sector using deep learning technology. asilla's products are the core technology in video analysis, including anomaly detection and multiple-camera tracking.\n",
      "specifically:\n",
      "\n",
      "\n",
      "building deep learning, machine learning models in action recognition, and video analysis.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "analyzing and processing images and video data to prepare for the training process.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "integrating ai models into application systems.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "optimizing the performance of the application systems.\n",
      "\n",
      " \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2498/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- thu thập và xử lý dữ liệu marketing từ các nguồn khác nhau (ví dụ: facebook, google ads), hệ thống crm, và các nguồn dữ liệu khác.\n",
      "- xử lý và làm sạch dữ liệu để đảm bảo tính nhất quán trong phân tích.\n",
      "- áp dụng các kỹ thuật và công cụ phân tích dữ liệu để tìm hiểu thông tin từ dữ liệu marketing.\n",
      "- phân tích các chỉ số hiệu suất quảng cáo, tiếp cận khách hàng, tương tác và hành vi của khách hàng trên các kênh trực tuyến nhằm ra các đề xuất và chiến lược dựa trên phân tích dữ liệu để tối ưu hoá các chiến dịch digital marketing.\n",
      "- chuẩn bị và thực hiện các báo cáo hàng tuần, hàng tháng hoặc theo yêu cầu từ quản lý và các bộ phận liên quan.\n",
      "- làm việc chặt chẽ với các bộ phận liên quan để nắm rõ yêu cầu và đồng thời hỗ trợ trong việc đưa ra quyết định tối ưu để cải tiến quy trình của phòng marketing.\n",
      "- các nhiệm vụ khác theo sự phân công của trưởng bộ phận.\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1033/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "mục đích công việc: chịu trách nhiệm tham gia thiết kế, tích hợp và phát triển cơ sở dữ liệu các nền tảng ngân hàng số.trách nhiệm chính:thiết kế, tích hợp và xây dựng hệ thống cơ sở dữ liệu của các nền tảng ngân hàng số;phối hợp với các đơn vị liên quan để đảm bảo dữ liệu được cập nhật đầy dủ, kịp thời và chính xác nhằm phục vụ nhu cầu báo cáo và phân tích dữ liệu;làm việc với các đối tác để triển khai, phát triển các giải pháp ứng dụng cloud & big data;chủ động nghiên cứu, áp dụng công nghệ mới về tích hợp dữ liệu từ nhiều nguồn dữ liệu khác nhau như multi-cloud & on - premise database;thực hiện các nhiệm vụ khác theo phân công của cấp quản lý.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc:trình độ cử nhân trở lên chuyên ngành công nghệ thông tin, hệ thống thông tin quản lý, khoa học máy tính hoặc các lĩnh vực có liên quan;\n",
      "tối thiểu 7 năm (chuyên gia)/5 năm (chuyên viên cao cấp)/ 3 năm (chuyên viên chính)/ 2 năm (chuyên viên) kinh nghiệm làm việc;tại các vị trí liên quan trong lĩnh vực tài chính ngân hàng hoặc nhóm ngành công nghệ thông tin;thành thạo sql và các ngôn ngữ lập trình khác (python, r, scala, java, …);\n",
      "am hiểu kĩ thuật etl và có kinh nghiệm thực tế xây dựng datamart;\n",
      "kinh nghiệm về công nghệ big data (hadoop, spark) và kiến thức chuyên sâu về các loại cơ sở dữ liệu khác nhau (sql & nosql database); \n",
      "kinh nghiệm trong kiến trúc xử lý big data trên nền tảng cloud; \n",
      "\n",
      "================================================\n",
      "data-02-06/2656/data.html\n",
      "mô tả công việc\n",
      "-\txây dựng, phát triển các hệ thống lưu trữ, xử lý dữ liệu lớn (big data)- xây dựng các giải pháp etl có khả năng mở rộng linh hoạt với độ tin cậy cao, phục vụ cho việc khai thác/ ingest các loại dữ liệu (cấu trúc, lưu lượng, tốc độ) từ nhiều nguồn khác nhau\n",
      "-\txây dựng, phát triển các công cụ khai thác dữ liệu, quản trị dữ liệu\n",
      "-\tthiết kế chi tiết giải pháp cho các luồng thu thập, chuẩn hóa, làm sạch, làm giàu, lưu trữ, xử lý, phân tích và hiển thị dữ liệu lớn-\tphối hợp, hỗ trợ data scientist trong việc chuyển đổi các mô hình, thuật toán học máy, khai phá dữ liệu thành các bản đặc tả, thiết kế phần mềm đảm bảo chúng có thể được cài đặt, triển khai hiệu quả trên môi trường tính toán phân tán và có khả năng mở rộng tốt khi tập dữ liệu đầu vào tăng trưởng nhanh\n",
      "-\tthiết kế giải pháp và trực tiếp phát triển các module, thư viện có tính chất nền tảng, có khả năng tái sử dụng cao, ảnh hưởng diện rộng\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "-\ttốt nghiệp đh chính quy loại khá trở lên chuyên ngành khoa học dữ liệu, khoa học máy tính, cntt, toán học ứng dụng, điện tử viễn thông hoặc liên quan\n",
      "-\ttrình độ tiếng anh: toeic tối thiểu 550\n",
      "-\tkiến thức về lập trình, cấu trúc dữ liệu & giải thuật\n",
      "-\tkiến thức về lập trình lưu trữ, xử lý dữ liệu phân tán, xử lý dữ liệu lớn (hadoop, spark, elastic search…\n",
      "-\tkiến thức về xây dựng luồng xử lý dữ liệu (batch processing, stream procesing, ...)\n",
      "-\tkiển thức về các loại csdl (rdbms, graph databases, nosql products, ...)\n",
      "-\tkỹ năng sử dụng ngôn ngữ lập trình (java, scala, ...), sql\n",
      "-\tk ỹ năng thành thạo một trong các framework, thư viện lưu trữ, xử lý dữ liệu lớn (hadoop,spark, kafka, zookeeper, ...)\n",
      "-\tkỹ năng sử dụng một trong các loại csdl (oracle, neo4j, hbase, cassandra, mongodb, ..)\n",
      "\n",
      "quyền lợi\n",
      "- thu nhập cao tương xứng với trình độ. lên tới 50.000.000/tháng-\tmôi trường làm việc trẻ trung, năng động\n",
      "-\ttham dự các dự án lớn, ứng dụng các công nghệ hàng đầu\n",
      "-\ttham dự hội thảo chuyên ngành trên toàn thế giới\n",
      "-\tlộ trình thăng tiến và phát triển sự nghiệp\n",
      "-\tthu nhập hấp dẫn tùy theo năng lực của từng cá nhân\n",
      "-\tchế độ nghỉ mát và khám sức khỏe, đóng bhxh theo quy định của luật lao động.\n",
      "\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 30/06/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/1736/data.html\n",
      "================================================\n",
      "data-02-06/774/data.html\n",
      "description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact info\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "position overview: the primary value is minimizing risk while maximizing returns for our clients.\n",
      "\n",
      "\n",
      "multiple tasks include:\n",
      "\n",
      "support market studies. collate information and develop financial modelling.\n",
      "in-depth due diligence analysis and market advisory.\n",
      "assess project viability or property value.\n",
      "manage reports, data, outtakes and ‘highest and best use’ development recommendations.\n",
      "interact with various cultures and clients at all levels.\n",
      "\n",
      "\n",
      "\n",
      "interns' duties:\n",
      "\n",
      "gather required information via calls, internet search, and other sources.\n",
      "draft and/or translate reports when required.\n",
      "prepare financial models under team supervision.\n",
      "support and assist project administration.\n",
      "\n",
      "apply now\n",
      "please fill out our presurvey and attach your cv here:\n",
      "https://www.savills.com.vn/forms/internship-program-application-form.aspx\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hanh luu tuyet\n",
      "\n",
      "\n",
      "hr senior managerhr & administrationhanoi\n",
      "\n",
      "+84 24 7301 9888\n",
      "\n",
      "\n",
      "contact now\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3096/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "● tham gia phát triển nền tảng quản lý dữ liệu lớn.● tham gia vào hiệu suất tối ưu cho các truy vấn data trên lượng dự liệu lớn.● xử lý các yêu cầu trung bình đến khó trong dự án.● đưa ra các ý tưởng cải tiến hiệu năng, tối ưu chi phí cho toàn hệ thống.● thời gian làm việc: thứ 2 – thứ 6 (sáng: 8h00-12h00; chiều: 13h30-17h30).\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "● kiến thức:- tốt nghiệp cử nhân chuyên ngành công nghệ thông tin, điện tử viễn thông, tài chính, ngân hàng, kinh tế hoặc tương đương. ưu tiên ứng viên có bằng tốt nghiệp loại giỏi hoặc tốt nghiệp tại nước ngoài- ưu tiên có các chứng chỉ chuyên nghành data engineer, data analytics, data science cho xử lý dữ liệu lớn● kinh nghiệm:- tối thiểu 2 năm kinh nghiệm làm việc trực tiếp tại các công ty, dự án về ds- có kiến thức cơ bản về data mining- có kiến thức về phân tích và visualization dữ liệu- có kiến thức về machine learning, deep machine learning- biết cài đặt trên hadoop eco-sys, aws, gcp,… cùng các tech stack thông dụng như sparkml, jupiternotebook, airflow, vs code với các thuật toán, thư viện thông dụng hiện nay- sử dụng thành thạo python, scala và java là lợi thế- có kinh nghiệm làm việc theo mô hình agile- có kinh nghiệm trong lĩnh vực tài chính ngân hàng- có khả năng đọc viết tiếng anh (cơ bản) nghe nói (nếu có thể).\n",
      "quyền lợi\n",
      "● thu nhập cực hấp dẫn: upto 32m gross ( thỏa thuận mức lương tương xứng với năng lực và kinh nghiệm làm việc)● hỗ trợ kí hợp đồng chính thức, nhận 100% lương và đóng bảo hiểm từ ngày đầu tiên đi làm● thưởng dự án, gói thưởng lễ tết lên đến 14m/year (bonus at tết dương lịch, tết âm lịch, lễ 2/9, quà tết, quà trung thu, sinh nhật công ty, tập đoàn,. )● xét tăng lương cố định hàng năm hoặc 6 tháng/ năm theo đánh giá năng lực● được hưởng bhxh, bhyt, bhtn theo chế độ nhà nước ban hành và tặng thêm gói bhxh sức khỏe “nms care” cho nhân viên● tận hưởng nhiều sự kiện của công ty, từ thi đấu thể thao, tiệc sinh nhật hàng tháng, xây dựng đội ngũ hàng quý đến tiệc năm mới, chuyến đi công ty, du lịch hè, teambuilding, liên hoan, gala định kì gắn kết tình cảm\n",
      "================================================\n",
      "data-02-06/843/data.html\n",
      "descriptionresponsible for day-to-day master data management of all business systems (including but not limited to finance systems) and master data improvement initiatives, you are:gatekeeper to ensure the quality of master data created/ updated in the system. responsible for and controlling an ongoing master data creation and maintenance (e.g., item master, purchase price, recommended selling price). any master data update must be verified and approved by the approved authorization matrix analyze changes in master data that impact operations and prepare master data reports as required on a frequent and ad hoc basis. carry out master data review and coordinate with master data person-in-charge to update and clean up timely where requested, initiate and facilitate system changes to adapt to business changes. participate in business system changes (upgrade or implementation) and act as sme (subject matter expert) in the master data management area. prepare and upload master data based on business requirements.\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2098/data.html\n",
      "================================================\n",
      "data-02-06/2570/data.html\n",
      "mô tả công việc1. phân tích hiệu quả đầu tư:- phối hợp với kế toán tổng hợp phân tích, đối chiếu các chỉ số tài chính của toàn công ty;- xác định cơ hội cải thiện tiềm năng, bao gồm hiệu quả thu hồi nợ.2. xây dựng kế hoạch ngân sách lãi lỗ công ty:- định kỳ xây dựng kế hoạch ngân sách của công ty, dự báo doanh thu và chi phí tổng hợp từ cáccông trình và mức lãi/lỗ cho các giai đoạn, làm nền tảng đưa ra các chính sách điều hành doanhnghiệp.- thẩm định – tư vấn xây dựng dự báo lãi/lỗ và dòng tiền dự án (kiểm soát trước).3. phân tích điểm võng dòng tiền.4. phân tích kế hoạch và thực tế.5. phân tích hiệu quả dự án:- tổ chức đánh giá hiệu quả tài chính của dự án sau khi hoàn thành.- phối hợp với kế toán tổng hợp phân tích, đối chiếu các chỉ số tài chính của dự án.- rà soát tính chính xác và tính hiệu quả chi phí trong việc xây dựng dòng tiền dự án trước khitriển khai thi công\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2336/data.html\n",
      "description:\n",
      "          \n",
      "about the company: \n",
      "this position is for a client of nodeflair vietnam, which develops and deploys systematic financial strategies across a broad range of asset classes and global markets. the company seeks to produce high-quality predictive signals (alphas) through its proprietary research platform to employ financial strategies focused on market inefficiencies. the teams work collaboratively to drive the production of alphas and financial strategies the foundation of a balanced, global investment platform.\n",
      "job responsibilities: \n",
      "the data engineer will be responsible for ensuring the reliability and performance of the company's data platform. they will collaborate with researchers, operations, and technology teams to establish a smooth functioning data pipeline sourced from a vast and continuously updated catalog of vendor and market data. the key responsibilities include developing and maintaining the data pipeline, overseeing the daily operation and monitoring of the pipeline, ensuring the reliability of new data pipeline components, and addressing user concerns and queries related to data availability and quality. participation in periodic on-call duties and collaboration with peers are also expected.\n",
      "requirements: \n",
      "strong \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2536/data.html\n",
      "mô tả công việc\n",
      "1. nội dung công việc• phối hợp xây dựng khung báo cáo định kỳ (tháng/quý/năm) về các chỉ số rủi ro trọng yếu (kris) của f88 nhằm nhận diện, đánh giá và giám sát các rủi ro trong hoạt động của f88• trực tiếp khai thác dữ liệu từ hệ thống, xây dựng các báo cáo, mô hình, dashboard liên quan tới hoạt động giải ngân, quản lý tài sản, tài chính, nhân sự, truyền thông thương hiệu, v.v nhằm đưa ra các cảnh báo sớm về rủi ro hoạt động cũng như rủi ro khác thông qua hoạt động phân tích dữ liệu.• đưa ra các đề xuất về xây dựng và cải tiến quy trình, quy định nhằm ngăn ngừa, giảm thiểu rủi ro khi phát hiện những nguy cơ phát sinh rủi ro. • phối hợp với các bộ phận trong phòng rủi ro hoạt động và trung tâm quản trị rủi ro phân tích & tổng hợp các báo cáo liên quan. • kiểm soát việc triển khai chính sách và quy trình rủi ro tại các đơn vị trong toàn hệ thống• thực hiện các công việc khác theo phân công2. thời gian làm việc: 08h30 - 17h30 (thứ hai - thứ sáu)3. địa điểm làm việc: tòa n01a - 275 nguyễn trãi, thanh xuân, hn\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "• tốt nghiệp đại học, cao đằng các chuyên ngành: công nghệ thông tin, hệ thống thông tin, dữ liệu, toán tin, thống kê, kinh tế, tài chính – ngân hàng …;• tối thiểu 2 năm kinh nghiệm về kiểm toán, quản trị rủi ro, trong đó tối thiểu 06 tháng 1 năm kinh\n",
      "================================================\n",
      "data-02-06/2895/data.html\n",
      "================================================\n",
      "data-02-06/1832/data.html\n",
      "description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "skills required\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "details\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- thống kê công đoạn sản xuất, bán thành phẩm và thành phẩm của công ty\n",
      "- kiểm soát công đoạn, chất lượng, kích thước, mẫu mã sản phẩm\n",
      "- báo cáo các sự cố, rủi ro gây ảnh hưởng đến chất lượng sản phẩm để có hành động khắc phục.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "required \n",
      "-----------------------------------------------\n",
      "experience / skills detail\n",
      "\n",
      "\n",
      "\n",
      "- tốt nghiệp trung cấp trở lên\n",
      "- chịu khó và ham học hỏi\n",
      "- có khả năng giải quyết công việc được giao\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job detail\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "position type\n",
      "\n",
      "full-time\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "career level\n",
      "\n",
      "staff\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "education level\n",
      "\n",
      "associate degree\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gender\n",
      "\n",
      "male / female\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job categories\n",
      "\n",
      "\n",
      "qa / qc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "information\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "name:\n",
      "\n",
      "\n",
      "phòng hcns\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "phạm ngũ lão, xã xuân dục\n",
      "\n",
      ", \n",
      "\n",
      "my hao district\n",
      "\n",
      ", \n",
      "\n",
      "hung yen\n",
      "\n",
      ", \n",
      "\n",
      "viet nam\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- các ứng viên quan tâm vui lòng gửi hồ sơ trực tuyến qua hệ thống careerlink, gửi kèm file hoặc trực tiếp đến tại công ty\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "application language:\n",
      "vietnamese\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "công ty tnhh may cao cấp việt hào\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100 - 499 employees\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact: phòng hcns\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "công ty tnhh may cao cấp việt hào là một thành viên của tập đoàn rsi đa quốc gia chuyên ngành may, với nhu cầu phát triển thị trường, công ty chúng tôi cần bổ sung nhân sự như sau;\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "see more\n",
      "\n",
      "\n",
      "\n",
      "see less\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "other jobs from this company\n",
      "\n",
      "|\n",
      "\n",
      "see all\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nhân viên giác sơ đồ\n",
      "\n",
      "\n",
      "công ty tnhh may cao cấp việt hào\n",
      "\n",
      "\n",
      "\n",
      "hung yen\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nhân viên qc - kiểm hàng\n",
      "\n",
      "\n",
      "công ty tnhh may cao cấp việt hào\n",
      "\n",
      "\n",
      "\n",
      "hung yen\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nhân viên vận hành sản xuất\n",
      "\n",
      "\n",
      "công ty tnhh may cao cấp việt hào\n",
      "\n",
      "\n",
      "\n",
      "hung yen\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nhân viên  văn phòng tiếng trung\n",
      "\n",
      "\n",
      "công ty tnhh may cao cấp việt hào\n",
      "\n",
      "\n",
      "\n",
      "hung yen\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tags\n",
      "\n",
      "\n",
      "\n",
      "qc\n",
      "sewing\n",
      "statistics\n",
      "urgent\n",
      "huyện mỹ hào\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "share\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "copied\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/1676/data.html\n",
      "================================================\n",
      "data-02-06/90/data.html\n",
      "responsibilitiesselect optimization methods, build algorithms, test and deploy models based on insights discovered from ninjavan data systems to meet operational goals and improve results. activity resultsanalyze data for different purposes to provide valuable information to help support important decisions.optimizing and automating the processes of various departmentscollect and process data to ensure smooth operation of data processing syste\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2100/data.html\n",
      "================================================\n",
      "data-02-06/363/data.html\n",
      "================================================\n",
      "data-02-06/1634/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "tổng hợp sản lượng hằng ngày của doanh nghiệptheo dõi khách hàng mới, tạo mới mã khách hàngnhập báo cáo hàng ngày của kinh doanh và telesalescuối tháng làm bảng thống kê kết quả kinh doanh, bảng chấm thưởng kinh doanh giờ hành chánh: 7:00 – 16:30 \n",
      "quyền lợi được hưởng\n",
      "đến với thái sơn, ngoài thu nhập, chúng tôi cam kết các giá trị của bạn tạo ra sẽ được công nhận bằng việc không ngừng tạo ra các giá trị gia tăng cho nhân sự cụ thể như:môi trường làm việc chuyên nghiệp, năng động, thân thiện, hòa đồng;đào tạo và định kỳ nâng cao trình độ nghiệp vụ, kỹ năng, kiến thức và thái độ làm việc cho nhân sự;chia sẻ tất cả những \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1217/data.html\n",
      "================================================\n",
      "data-02-06/1628/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- work with cross-functional teams to understand and deep-dive into business objectives and translate and prioritize into analytics requirements - model business problems into practical analysis and achieve solutions and recommendations design and deliver solutions from start to end for a defined data - analysis problem - present results to project stakeholders with good communication and good data visualization - proactively be involved in the bidding process to turn potential leads into projects - create reusable documentation, presentations and code libraries during projects - participate in internal education and research tasks - mentor junior data analysts - lead data analysis initiatives within synodus - proactively enrich organizational data and discover new insights* benefits:- attractive salary and package. offer max 30m for member, min 30m for lead- working time: 8:30-18:00 (off 1.5h from 12h to 13h30 for lunch) from monday to friday - opportunities to be a part of interesting and challenging projects salary review twice a year- flat structure - self-management is appreciated - psychological safety; your ideas are always welcomed - friendly, innovative, and supportive environment 1- 3th month salary, annual heath-check, insurance under vietnamese labor law, monthly teambuilding. - bic health insurance package.\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2120/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "                                    • designing and building scalable data models.\n",
      "• cleaning and transforming data.\n",
      "• develop records management processes and policies\n",
      "• identify areas to increase efficiency and automation of processes\n",
      "• set up and maintain automated data processes\n",
      "• identify, evaluate, and implement external services and tools to support data validation and cleansing\n",
      "• produce and track key performance indicators\n",
      "• develop and support reporting processes\n",
      "• monitor and audit data quality\n",
      "• liaise with internal and external clients to fully understand data content\n",
      "• gather, understand, and document detailed business requirements using appropriate tools and techniques\n",
      "• design and carry out surveys and analyse survey data\n",
      "• manipulate, analyse, and interpret complex data sets relating to the employer's business\n",
      "• prepare reports for internal and external audiences using business analytics reporting tools\n",
      "• create data dashboards, graphs, and visualisations\n",
      "• provide sector and competitor benchmarking\n",
      "• mine and analyse large datasets, draw valid inferences, and present them successfully to management using a reporting tool.\n",
      "• enabling advanced analytics capabilities that provide meaningful business value through easy-to-understand data visualizations.\n",
      "                                \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3066/data.html\n",
      "description\n",
      "\n",
      "\n",
      "life at agoda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "all teams\n",
      "contentcustomer \n",
      "-----------------------------------------------\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data architect (bangkok based, relocation provided)\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "================================================\n",
      "data-02-06/2577/data.html\n",
      "================================================\n",
      "data-02-06/2157/data.html\n",
      "description\n",
      "\n",
      "\n",
      "life at agoda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "all teams\n",
      "contentcustomer \n",
      "-----------------------------------------------\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "senior dwh/bi developer (bangkok based, relocation provided)\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "================================================\n",
      "data-02-06/2391/data.html\n",
      "description\n",
      "\n",
      "job #: 89751\n",
      "\n",
      "\n",
      "            you can easily engage stakeholders, think critically about issues, and come up with innovative solutions, all while working well with others in a team setting to solve complex business problems. if this describes you, a role at epam vietnam as a senior data software engineer could be perfect.we expect a senior to be involved from the beginning and to serve as a trusted advisor to clients and epam teams as they attempt to bridge the it-business divide and to be capable of leading a team of 2 to 5 analysts.\n",
      "        \n",
      "\n",
      "what you’ll do\n",
      "\n",
      "design and implement innovative analytical solution using nosql & sql and other big data (hadoop, spark) related technologies, evaluating new features and architecture in cloud (aws, azure…)/ on premise/ hybrid solutions\n",
      "work with product and engineering teams\n",
      "build collaborative partnerships with architects, technical leads and key individuals within other functional groups\n",
      "participate in code review and test solutions\n",
      "write project documentation\n",
      "\n",
      "what you have\n",
      "\n",
      "at least 5 years of working \n",
      "-----------------------------------------------\n",
      "experience in big data technologies with a bachelor’s degree in computer science, information technology, software engineering or equivalent\n",
      "solid skills in infrastructure troubleshooting, support and practical experience in performance tuning and optimization, bottleneck problem analysis\n",
      "strong experience with python, sql, apache spark\n",
      "familiar with aws cloud  data services (or azure, gcp, v.v.)\n",
      "good understanding of data structures, data modeling and software architecture.\n",
      "experience in queues and  stream processing (kafka, flink)\n",
      "experience scheduler (airflow, aws glue, azure data factory, …)\n",
      "experience in designing and building etl processes (extractions, data load, aggregation, talend, etc.)\n",
      "time-series/analytics databases, such as elasticsearch\n",
      "test driven development methods: tdd, bdd, ddd & testing: component/ integration testing, unit testing\n",
      "experience in various messaging systems\n",
      "english proficiency\n",
      "\n",
      "nice to have\n",
      "\n",
      "skills in search: solr, elk\n",
      "experience with technologies like spark, kubernetes, docker, jenkins, hive, terraform\n",
      "\n",
      "why epam\n",
      "\n",
      "by choosing epam, you're getting a job at one of the most loved workplaces according to newsweek 2021 & 2022\n",
      "employee ideas are the main driver of our business. we have a very supportive environment where your voice matters\n",
      "you will be challenged while working side-by-side with the best talent globally. we work with top-notch technologies, constantly seeking new industry trends and best practices\n",
      "we offer a transparent career path and an individual roadmap to engineer your future & accelerate your journey\n",
      "at epam, you can find vast opportunities for self-development: online courses and libraries, mentoring programs, partial grants of certification, and experience exchange with colleagues around the world. you will learn, contribute, and grow with us\n",
      "\n",
      "life at epam\n",
      "\n",
      "epam is a leading global provider of digital platform engineering and development services. epam has been named the top it services company on the fortune ‘100 fastest-growing companies’ list (2019-2021)\n",
      "established in 2019, epam vietnam has more than 200 employees and is still expanding rapidly. we offer a multicultural environment where our tech talents can proactively develop world-class solutions directly with international clients. we support the sustainable development of our employees through a clear career path and provide a professional working environment and knowledge upgrading with internal learning solutions and external educational resources. epam vietnam has been recognized by the great place to work™ institute as one of vietnam’s best workplaces™ in 2022\n",
      " \n",
      "\n",
      "how we hire\n",
      "\n",
      "not sure if you meet all the requirements? no problem. let’s talk anyway and find out more! it takes 1 min of application to start the journey with us. apply now!\n",
      "apply and tell us about yourself\n",
      "go through some standard interviews:\n",
      "                        \n",
      "general interview with a recruiter\n",
      "technical interview with our technology experts\n",
      "manager interview or offer interview with a hiring manager\n",
      "\n",
      "\n",
      "get ready to join the team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                apply\n",
      "            \n",
      "\n",
      "                apply\n",
      "            \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "apply for\n",
      "senior data software engineer (python, sql, spark)\n",
      "\n",
      "        \n",
      "        vietnam\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thank you for your submission!\n",
      "\n",
      "\n",
      "                    our talent acquisition team will contact you with further details.\n",
      "                    \n",
      "\n",
      "    \n",
      "        \n",
      "            submit again\n",
      "        \n",
      "        \n",
      "    \n",
      "\n",
      "    \n",
      "        \n",
      "            \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "oops...\n",
      "something went wrong. please try again.\n",
      "\n",
      "    \n",
      "        \n",
      "            submit again\n",
      "        \n",
      "        \n",
      "    \n",
      "\n",
      "    \n",
      "        \n",
      "            \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "it's highly important for us to get your cv. if you are unable to attach a document through your mobile device, please leave us the link where we can find your resume online.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        first name*\n",
      "    \n",
      "\n",
      "\n",
      "first name\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        last name*\n",
      "    \n",
      "\n",
      "\n",
      "last name\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        email*\n",
      "    \n",
      "\n",
      "\n",
      "email\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        location*\n",
      "        \n",
      "\n",
      "\n",
      "location\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                afghanistan\n",
      "            \n",
      "\n",
      "                albania\n",
      "            \n",
      "\n",
      "                algeria\n",
      "            \n",
      "\n",
      "                american samoa\n",
      "            \n",
      "\n",
      "                andorra\n",
      "            \n",
      "\n",
      "                angola\n",
      "            \n",
      "\n",
      "                anguilla\n",
      "            \n",
      "\n",
      "                antarctica\n",
      "            \n",
      "\n",
      "                antigua\n",
      "            \n",
      "\n",
      "                argentina\n",
      "            \n",
      "\n",
      "                armenia\n",
      "            \n",
      "\n",
      "                aruba\n",
      "            \n",
      "\n",
      "                australia\n",
      "            \n",
      "\n",
      "                austria\n",
      "            \n",
      "\n",
      "                azerbaijan\n",
      "            \n",
      "\n",
      "                bahamas\n",
      "            \n",
      "\n",
      "                bahrain\n",
      "            \n",
      "\n",
      "                bangladesh\n",
      "            \n",
      "\n",
      "                barbados\n",
      "            \n",
      "\n",
      "                belarus\n",
      "            \n",
      "\n",
      "                belgium\n",
      "            \n",
      "\n",
      "                belize\n",
      "            \n",
      "\n",
      "                benin\n",
      "            \n",
      "\n",
      "                bermuda\n",
      "            \n",
      "\n",
      "                bhutan\n",
      "            \n",
      "\n",
      "                bolivia\n",
      "            \n",
      "\n",
      "                bosnia\n",
      "            \n",
      "\n",
      "                botswana\n",
      "            \n",
      "\n",
      "                brazil\n",
      "            \n",
      "\n",
      "                brunei darussalam\n",
      "            \n",
      "\n",
      "                bulgaria\n",
      "            \n",
      "\n",
      "                burkina faso\n",
      "            \n",
      "\n",
      "                burundi\n",
      "            \n",
      "\n",
      "                cambodia\n",
      "            \n",
      "\n",
      "                cameroon\n",
      "            \n",
      "\n",
      "                canada\n",
      "            \n",
      "\n",
      "                cayman islands\n",
      "            \n",
      "\n",
      "                chad\n",
      "            \n",
      "\n",
      "                chile\n",
      "            \n",
      "\n",
      "                china\n",
      "            \n",
      "\n",
      "                colombia\n",
      "            \n",
      "\n",
      "                comoros\n",
      "            \n",
      "\n",
      "                congo\n",
      "            \n",
      "\n",
      "                costa rica\n",
      "            \n",
      "\n",
      "                croatia\n",
      "            \n",
      "\n",
      "                cuba\n",
      "            \n",
      "\n",
      "                cyprus\n",
      "            \n",
      "\n",
      "                czech republic\n",
      "            \n",
      "\n",
      "                democratic republic of the congo\n",
      "            \n",
      "\n",
      "                denmark\n",
      "            \n",
      "\n",
      "                dominica\n",
      "            \n",
      "\n",
      "                dominican republic\n",
      "            \n",
      "\n",
      "                ecuador\n",
      "            \n",
      "\n",
      "                egypt\n",
      "            \n",
      "\n",
      "                el salvador\n",
      "            \n",
      "\n",
      "                england\n",
      "            \n",
      "\n",
      "                equatorial guinea\n",
      "            \n",
      "\n",
      "                eritrea\n",
      "            \n",
      "\n",
      "                estonia\n",
      "            \n",
      "\n",
      "                ethiopia\n",
      "            \n",
      "\n",
      "                fiji\n",
      "            \n",
      "\n",
      "                finland\n",
      "            \n",
      "\n",
      "                france\n",
      "            \n",
      "\n",
      "                gabon\n",
      "            \n",
      "\n",
      "                gambia\n",
      "            \n",
      "\n",
      "                georgia\n",
      "            \n",
      "\n",
      "                germany\n",
      "            \n",
      "\n",
      "                ghana\n",
      "            \n",
      "\n",
      "                greece\n",
      "            \n",
      "\n",
      "                greenland\n",
      "            \n",
      "\n",
      "                grenada\n",
      "            \n",
      "\n",
      "                guadeloupe\n",
      "            \n",
      "\n",
      "                guam\n",
      "            \n",
      "\n",
      "                guatemala\n",
      "            \n",
      "\n",
      "                guinea\n",
      "            \n",
      "\n",
      "                guyana\n",
      "            \n",
      "\n",
      "                haiti\n",
      "            \n",
      "\n",
      "                honduras\n",
      "            \n",
      "\n",
      "                hong kong sar\n",
      "            \n",
      "\n",
      "                hungary\n",
      "            \n",
      "\n",
      "                iceland\n",
      "            \n",
      "\n",
      "                india\n",
      "            \n",
      "\n",
      "                indonesia\n",
      "            \n",
      "\n",
      "                iran\n",
      "            \n",
      "\n",
      "                iraq\n",
      "            \n",
      "\n",
      "                ireland\n",
      "            \n",
      "\n",
      "                israel\n",
      "            \n",
      "\n",
      "                italy\n",
      "            \n",
      "\n",
      "                jamaica\n",
      "            \n",
      "\n",
      "                japan\n",
      "            \n",
      "\n",
      "                jordan\n",
      "            \n",
      "\n",
      "                kazakhstan\n",
      "            \n",
      "\n",
      "                kenya\n",
      "            \n",
      "\n",
      "                korea, north\n",
      "            \n",
      "\n",
      "                korea, south\n",
      "            \n",
      "\n",
      "                kuwait\n",
      "            \n",
      "\n",
      "                kyrgyzstan\n",
      "            \n",
      "\n",
      "                lao democratic republic\n",
      "            \n",
      "\n",
      "                latvia\n",
      "            \n",
      "\n",
      "                lebanon\n",
      "            \n",
      "\n",
      "                liberia\n",
      "            \n",
      "\n",
      "                libya\n",
      "            \n",
      "\n",
      "                liechtenstein\n",
      "            \n",
      "\n",
      "                lithuania\n",
      "            \n",
      "\n",
      "                luxembourg\n",
      "            \n",
      "\n",
      "                macao sar\n",
      "            \n",
      "\n",
      "                macedonia\n",
      "            \n",
      "\n",
      "                madagascar\n",
      "            \n",
      "\n",
      "                malawi\n",
      "            \n",
      "\n",
      "                malaysia\n",
      "            \n",
      "\n",
      "                maldives\n",
      "            \n",
      "\n",
      "                malta\n",
      "            \n",
      "\n",
      "                mexico\n",
      "            \n",
      "\n",
      "                micronesia\n",
      "            \n",
      "\n",
      "                moldova\n",
      "            \n",
      "\n",
      "                monaco\n",
      "            \n",
      "\n",
      "                mongolia\n",
      "            \n",
      "\n",
      "                montenegro\n",
      "            \n",
      "\n",
      "                morocco\n",
      "            \n",
      "\n",
      "                mozambique\n",
      "            \n",
      "\n",
      "                myanmar\n",
      "            \n",
      "\n",
      "                namibia\n",
      "            \n",
      "\n",
      "                nepal\n",
      "            \n",
      "\n",
      "                netherlands\n",
      "            \n",
      "\n",
      "                new zealand\n",
      "            \n",
      "\n",
      "                nicaragua\n",
      "            \n",
      "\n",
      "                niger\n",
      "            \n",
      "\n",
      "                nigeria\n",
      "            \n",
      "\n",
      "                norway\n",
      "            \n",
      "\n",
      "                oman\n",
      "            \n",
      "\n",
      "                pakistan\n",
      "            \n",
      "\n",
      "                palau\n",
      "            \n",
      "\n",
      "                palestine\n",
      "            \n",
      "\n",
      "                panama\n",
      "            \n",
      "\n",
      "                papua new guinea\n",
      "            \n",
      "\n",
      "                paraguay\n",
      "            \n",
      "\n",
      "                peru\n",
      "            \n",
      "\n",
      "                philippines\n",
      "            \n",
      "\n",
      "                poland\n",
      "            \n",
      "\n",
      "                portugal\n",
      "            \n",
      "\n",
      "                puerto rico\n",
      "            \n",
      "\n",
      "                qatar\n",
      "            \n",
      "\n",
      "                romania\n",
      "            \n",
      "\n",
      "                russian federation\n",
      "            \n",
      "\n",
      "                rwanda\n",
      "            \n",
      "\n",
      "                saint lucia\n",
      "            \n",
      "\n",
      "                saint vincent grenadines\n",
      "            \n",
      "\n",
      "                samoa\n",
      "            \n",
      "\n",
      "                san marino\n",
      "            \n",
      "\n",
      "                sao tome and principe\n",
      "            \n",
      "\n",
      "                saudi arabia\n",
      "            \n",
      "\n",
      "                scotland\n",
      "            \n",
      "\n",
      "                senegal\n",
      "            \n",
      "\n",
      "                serbia\n",
      "            \n",
      "\n",
      "                sierra leone\n",
      "            \n",
      "\n",
      "                singapore\n",
      "            \n",
      "\n",
      "                slovakia\n",
      "            \n",
      "\n",
      "                slovenia\n",
      "            \n",
      "\n",
      "                somalia\n",
      "            \n",
      "\n",
      "                south africa\n",
      "            \n",
      "\n",
      "                spain\n",
      "            \n",
      "\n",
      "                sri lanka\n",
      "            \n",
      "\n",
      "                sudan\n",
      "            \n",
      "\n",
      "                suriname\n",
      "            \n",
      "\n",
      "                sweden\n",
      "            \n",
      "\n",
      "                switzerland\n",
      "            \n",
      "\n",
      "                syria\n",
      "            \n",
      "\n",
      "                taiwan\n",
      "            \n",
      "\n",
      "                taiwan, china\n",
      "            \n",
      "\n",
      "                tajikistan\n",
      "            \n",
      "\n",
      "                tanzania\n",
      "            \n",
      "\n",
      "                thailand\n",
      "            \n",
      "\n",
      "                togo\n",
      "            \n",
      "\n",
      "                trinidad and tobago\n",
      "            \n",
      "\n",
      "                tunisia\n",
      "            \n",
      "\n",
      "                türkiye\n",
      "            \n",
      "\n",
      "                turkmenistan\n",
      "            \n",
      "\n",
      "                tuvalu\n",
      "            \n",
      "\n",
      "                uganda\n",
      "            \n",
      "\n",
      "                ukraine\n",
      "            \n",
      "\n",
      "                united arab emirates\n",
      "            \n",
      "\n",
      "                united kingdom\n",
      "            \n",
      "\n",
      "                united states\n",
      "            \n",
      "\n",
      "                uruguay\n",
      "            \n",
      "\n",
      "                uzbekistan\n",
      "            \n",
      "\n",
      "                vatican\n",
      "            \n",
      "\n",
      "                venezuela\n",
      "            \n",
      "\n",
      "                vietnam\n",
      "            \n",
      "\n",
      "                yemen\n",
      "            \n",
      "\n",
      "                zambia\n",
      "            \n",
      "\n",
      "                zimbabwe\n",
      "            \n",
      "\n",
      "\n",
      "location\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        state/province*\n",
      "        \n",
      "\n",
      "\n",
      "state/province\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "state/province\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        city*\n",
      "        \n",
      "\n",
      "\n",
      "city\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "city\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        zip code*\n",
      "        \n",
      "\n",
      "\n",
      "zip code\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "zip code\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        need visa sponsorship?*\n",
      "        \n",
      "\n",
      "\n",
      "need visa sponsorship?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "yes\n",
      "            \n",
      "no\n",
      "            \n",
      "\n",
      "\n",
      "\n",
      "need visa sponsorship?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "need visa sponsorship?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "upload your file\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "drag & drop your resume or browse files\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cancel upload\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "path to selected file\n",
      "\n",
      "\n",
      "browse...\n",
      "\n",
      "\n",
      "upload your file\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        copy & paste your cover letter, cv link or message\n",
      "    \n",
      "\n",
      "\n",
      "copy & paste your cover letter, cv link or message\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        linkedin summary\n",
      "    \n",
      "\n",
      "edit summary\n",
      "\n",
      "\n",
      "\n",
      "edit summary\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cancel\n",
      "save\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "warning\n",
      "are you sure you want to leave, all modified information will be lost?\n",
      "\n",
      "no\n",
      "yes\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "please note that by proceeding, you consent to epam processing your personal data as set forth in our\n",
      "================================================\n",
      "data-02-06/834/data.html\n",
      "================================================\n",
      "data-02-06/2297/data.html\n",
      "descriptioncolliers group inc. (nasdaq: cigi; tsx: cig) is an industry leading global real estate services company with more than 15,000 skilled professionals operating in 68 countries. with an enterprising culture and significant employee ownership, colliers professionals provide a full range of services to real estate occupiers, owners and investors worldwide. services include strategic advice and execution for property sales, leasing and finance; global corporate solutions; property, facility and project management; workplace solutions; appraisal, valuation and tax consulting; customized research; and thought leadership consulting.job description- provide exceptional analytical support to clients;- perform in-depth due diligence analysis and market advisory; undertaking feasibility studies and valuations of real estate developments and projects;- work primarily in the areas of valuation, financial analysis, and in the preparation of relevant presentation material for pitches and proposals;- undertaking feasibility studies and valuations of real estate developments and projects;- the applicant should have \n",
      "-----------------------------------------------\n",
      "experience and knowledge in creating an excel spreadsheets to identify the npv and irr of a development project;- understanding of the property market throughout vietnam, in particular the development process, construction cost, far and taxation is a benefit;- working closely with and support the investment teams;- researching and developing assumptions required for the development of values such as market growth rates, rents, construction costs, lease rates;- developing opinions and recommendations on potential development opportunities through analysis of various inputs that affect overall value and liquidity of assets;- identifying factors that may materially affect value and liquidity of an asset;- analysing property values relative to market conditions and recent sales data;- conducting scenario analysis (e.g. lease restructuring – buy-outs, renewal vs. relocation scenarios);qualifications- graduated in valuation or real estate;- good understanding of the residential property sector in hcmc;- good understanding of property market principles;- computer literacy with good ms office skills;- minimum 02 years of experience;- good english skills;- be able to conduct site inspections;- high sense of responsibility, trustworthy.additional informationthis is a great opportunity to work under innovative, confident and experienced professionals in contributing the growing business in vietnam. the position requires your enthusiasm, confidence, honesty, dedication and flexibility. the ideal candidate will be oriented and have abilities to work under pressure, and demonstrate capabilities to take over new unfamiliar tasks, also be a centralization of clear communication between the executive and others. you will need to be clear on information, communication, and then plan and schedule all of necessary meetings\n",
      "================================================\n",
      "data-02-06/3045/data.html\n",
      "description\n",
      "\n",
      "for credit card portfolio management, our mission is to optimize credit line management, credit limit setting, and collections. we utilize our expertise in data science to develop predictive models and analytics that forecast customer behavior and credit risk. additionally, we leverage machine learning and ai techniques to identify patterns and insights in transaction data, customer behavior, and marketing campaigns. by collaborating with other teams, such as product development, marketing, and customer service, we aim to deliver a seamless and personalized customer \n",
      "-----------------------------------------------\n",
      "experience across all touch points. ultimately, our goal is to minimize risk and optimize portfolio performance metrics for the benefit of our customers.responsibilitiesthe ideal candidate will have a passion for utilizing data and analytics to optimize portfolio performance. the successful candidate will be responsible for analyzing large datasets, developing predictive models, and generating actionable insights for credit card portfolio management.\n",
      "developing and implementing credit risk models and analytical tools to assess portfolio performance, credit risk, and profitability.\n",
      "analyzing and interpreting data to identify trends, patterns, and insights that drive portfolio management decisions.\n",
      "conducting ad-hoc analysis and data mining to support portfolio optimization and strategy development.\n",
      "collaborating with business stakeholders to understand their needs and requirements, and to develop and implement solutions that meet their needs.\n",
      "creating and maintaining reports and dashboards that provide insights into portfolio performance and key performance indicators (kpis).\n",
      "designing and conducting a/b tests to evaluate the impact of new portfolio strategies and tactics.\n",
      "maintaining up-to-date knowledge of industry trends, best practices, and regulatory requirements related to credit card portfolio management.\n",
      "communicating complex analytical findings and recommendations to non-technical stakeholders, including senior management.\n",
      "mentoring and coaching junior analysts and data scientists on the team.\n",
      "partnering with data engineers and other technical teams to ensure data quality, availability, and scalability.\n",
      "conducting competitive research to stay informed of market trends, customer preferences, and emerging technologies that may impact the credit card portfolio.\n",
      "perform highly complex activities related to financial products, business analysis, and build dashboards for portfolio monitoring.\n",
      "utilize statistical and machine learning techniques to identify patterns and trends in financial data\n",
      "develop and implement data-driven investment strategies that optimize portfolio performance\n",
      "\n",
      "\n",
      "your skills and experience\n",
      "\n",
      "requirements\n",
      "post graduate degree (masters\n",
      "================================================\n",
      "data-02-06/2858/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- thực hiện việc trích xuất và xử lý dữ liệu từ database, google sheet,...- trực quan hóa dữ liệu bằng các dashboards, reports.- phân tích và sử dụng dữ liệu vào tình hình hoạt động, các chiến lược của công ty để có những đề xuất giúp tối ưu hóa chi phí, có các chiến lược phát triển phù hợp, ...- thực hiện nhiệm vụ học tập:+ đọc sách.+ thực hành mô hình teach2learn (dạy để học).- thực hiện các tasks khác theo yêu cầu.- có thể làm việc part time/full time.* quyền lợi:- thời gian thực tập sinh (nhiệm vụ học) hỗ trợ 500.000đ/tháng.- sau chương trình học, có thể làm việc với mức lương thỏa thuận trong khung giờ hành chính. lương part-time trên 2.000.000 vnđ- định vị, sau khi tốt nghiệp sẽ trở thành một nhân sự có kỹ năng giải quyết vấn đề & có thể tìm được định hướng chuyên môn của mình.\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2939/data.html\n",
      "mô tả công việc\n",
      "\n",
      "collaborate with the team to design, develop, and maintain data pipelines and etl processes.utilize programming languages such as python, java, or scala for data manipulation, transformation, and analysis tasks.gain exposure to containerization technologies like docker and orchestration frameworks like kubernetes.assist in implementing and optimizing ci/cd practices for data engineering workflows.learn and gain knowledge of various database systems, including rdbms, no-sql, distributed sql, and their usage in data engineering.explore and understand distributed systems and their applications in data engineering.assist in data validation and quality assurance activities to ensure accurate and reliable data.collaborate with team members to troubleshoot and resolve data-related issues.participate in documentation and knowledge sharing within the team.stay updated with the latest trends and advancements in data engineering technologies.\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3117/data.html\n",
      "mô tả công việc\n",
      "● nghiên cứu, khảo sát các hành vi, hoạt động, mong muốn về dịch vụ của khách hàng đối với công ty. đề xuất hướng cung cấp sản phẩm dịch vụ phù hợp nhất.● nghiên cứu, khảo sát đối thủ cạnh tranh và thị trường, từ đó đề xuất phương án cạnh tranh, phát triển cho công ty.● phân tích chuyên sâu các chủ đề liên quan đến các dịch vụ công ty cung cấp hoặc vận hành để đưa ra các giải pháp nhằm khắc phục các vấn đề đang bị tồn đọng hoặc các phương án để tăng hiệu quả.● phân tích dữ liệu, cung cấp báo cáo và phân tích kinh doanh phục vụ cho việc ra quyết định của các cấp quản lý, lãnh đạo của các khối chức năng; thúc đẩy việc sử dụng số liệu làm cơ sở ra quyết định● thực hiện các công việc khác theo yêu cầu của cấp trên trực tiếp.(thông tin chi tiết về công việc sẽ được trao đổi tại buổi phỏng vấn)\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "đại học các chuyên ngành qtkd, logistics, marketing hoặc các ngành liên quan.có kinh nghiệm tối thiểu 3 năm trở lên.có kinh nghiệm thiết lập và tính toán tính khả thi của dự án: tính dòng tiền, hiệu suất đầu tư như irr, npv…để triển khai dự án một cách hiệu quả nhất. viết báo cáo dự án. có hiểu biết về địa lý địa phương.có khả năng sử dụng các công cụ quản lý dữ liệu.ưu tiên ứng viên có khả năng báo cáo, phân tích sử dụng đa công cụ (excel, power bi tools…)có kỹ năng tổng hợp, phân tích số liệu, data, thông tin, lên báo cáocó kiến thức về tiếng anh tốt, ielts 6.0, tiếng hoa hsk 3 hoặc các chứng chỉ tương đương.yêu cầu tính cẩn thận, chính xác cao và luôn học hỏi, có ý chí cầu tiến trong công việc.\n",
      "quyền lợi\n",
      "● làm việc trong môi trường chuyên nghiệp, năng động và nhiều cơ hội thăng tiến.● được cung cấp đầy đủ phương tiện làm việc: laptop, điện thoại và các công cụ cần thiết phục vụ cho từng dự án.\n",
      "================================================\n",
      "data-02-06/2369/data.html\n",
      "description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "benefits\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "skills required\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "details\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- thiết kế, xây dựng và bảo trì đường ống dữ liệu (pipeline). - thực hiện chuẩn hóa và làm sạch dữ liệu.- thiết kế, xây dựng và bảo trì datawarehouse.- xây dựng và bảo trì các báo cáo vận hành trên các hệ thống, web report.- viết các script để tự động hóa các tác vụ liên quan đến cung cấp dữ liệu cho các phòng ban.- cộng tác với data analyst và các phòng ban để nắm được nhu cầu về dữ liệu.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job benefits\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cung cấp máy tính cho nhân viên\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bhxh, bảo hiểm sức khoẻ cá nhân pvi\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "năng động, nhiệt tình và teamwork tốt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "required experience / skills detail\n",
      "\n",
      "\n",
      "\n",
      "- trình độ đại học các ngành liên quan đến cntt, kinh tế.- có \n",
      "-----------------------------------------------\n",
      "kinh nghiệm trên 6 tháng ở vị trí kỹ sư dữ liệu.- có kiến thức về cơ sở dữ liệu (sql), hệ thống và lập trình.- có kinh nghiệm về việc sử dụng các công cụ tích hợp dữ liệu etl (ssis, azure data factory, informatica, odi, pentaho,…..).- có kinh nghiệm xây dựng data model.- có kinh nghiệm sử dụng ngôn ngữ lập trình (python, r, …), công cụ bi (power bi, ssas, …) là một lợi thế- tư duy logic, khả năng làm việc độc lập và làm việc nhóm hiệu quả.- có khả năng đọc các tài liệu chuyên ngành bằng tiếng anh.- có tinh thần học hỏi và sẵn sàng tiếp thu kiến thức mới- năng động, chăm chỉ, cẩn thận, kiên nhẫn, thân thiện.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job detail\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "position type\n",
      "\n",
      "full-time\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "career level\n",
      "\n",
      "technical / engineer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "education level\n",
      "\n",
      "bachelor's degree\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gender\n",
      "\n",
      "male / female\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "age\n",
      "\n",
      "22 - 30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job categories\n",
      "\n",
      "\n",
      "it - software\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "information\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "name:\n",
      "\n",
      "\n",
      "phòng hcns\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "62 trần quang khải, tân định\n",
      "\n",
      ", \n",
      "\n",
      "district 1\n",
      "\n",
      ", \n",
      "\n",
      "ho chi minh\n",
      "\n",
      ", \n",
      "\n",
      "viet nam\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- các ứng viên quan tâm vui lòng gửi hồ sơ trực tuyến, gửi kèm file hoặc trực tiếp đến tại công ty \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "application language:\n",
      "vietnamese\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "công ty tnhh routine việt nam\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "https://routine.vn/\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100 - 499 employees\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact: phòng hcns\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "routine\n",
      "================================================\n",
      "data-02-06/2833/data.html\n",
      "================================================\n",
      "data-02-06/3056/data.html\n",
      "description\n",
      "\n",
      "we are seeking a talented and \n",
      "-----------------------------------------------\n",
      "experienced deep learning engineer to join our team for an exciting smart ocr project. as a deep learning engineer, you will play a pivotal role in designing, training, and optimizing neural network models to develop a cutting-edge ocr system.\n",
      "================================================\n",
      "data-02-06/2014/data.html\n",
      "description\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "data warehouse:\n",
      "• tham gia thiết kế/ xây dựng các kho dữ liệu, mô hình dữ liệu (datamart) và khai thác dữ liệu. làm việc trên các phần mềm etl (extract, transform, load).xây dựng các etl jobs, procedure\n",
      " . net:  \n",
      "• tham gia thiết kế/xây dựng/các ứng dụng lõi trong ngân hàng như corebanking, báo cáo, …\n",
      "• viết các interface vào corebanking cho các hệ thống khác gọi đến.\n",
      "• phát triển các module trong corebanking.\n",
      "• etl số liệu từ corebanking và các hệ thống khác về warehouse.\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2597/data.html\n",
      "responsibilities\n",
      "create baseline cost models by season: vendor info, seasonal/annual volumes, landed costs, terms, freight and other cost drivers.develop and roll out fact-based analytical tools and models to identify, quantify, validate cost saving and consolidation opportunities arising from ongoing analysis.align with wider sourcing teams to drive and deliver cost saving initiatives through structured price performance and should cost metrics across multiple material categories.provide project management support for larger cost initiatives pursued by sourcing.5support management and materials teams during seasonal material negotiations aligned with costing calendar.maintain database of potential suppliers by category and region.maintain historical price database and manage change/savings trackers.prepare and validate seasonal and yoy volume, spend and price analytics to stakeholders.track and monitor monthly commodities guidance and publish to stakeholders.partner with costing department to track lop and other overhead cost drivers to update should cost monitors.\n",
      "\n",
      "-----------------------------------------------\n",
      "experience requirements\n",
      "8+ years working experience in strategic procurement, costing and analytics fields.working knowledge in upper shoe materials & footwear manufacturing industries are preferred.motivated self-starterexcellent analytical, negotiation and organizational skills.strong bias for results and attention to detailhighly effective communicator with ability to foster relationships at all management levels and cross-culturally.must be fluent in written & spoken english & vietnamesecomputer literate: ms office applications, power point, analytic and procurement platforms. education requirements\n",
      "bachelors of business or analytics fieldplease contact ms. linh hoang at linh.hoang@adecco.com or +tel: +84 28 3636 5811 – ext : 710 for further discussion on the role. contact person\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2971/data.html\n",
      "================================================\n",
      "data-02-06/1083/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      " hỗ trợ nhóm thực hiện các nghiên cứu cho khách hàng.\n",
      "hỗ trợ nhóm nghiên cứu thu thập và phân tích dữ liệu\n",
      "tham gia các hoạt động khảo sát, thu thập số liệu khảo sát\n",
      "thực hiện các công việc khác theo yêu cầu của trưởng nhóm. \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1426/data.html\n",
      "descriptionreiz tech is expanding and hiring globally! growth is in our dna and we will help you grow! \n",
      "about the client\n",
      " \n",
      "our client is one of the largest worldwide accounting, tax, audit and consultancy companies operating in more than 160 countries.\n",
      "\n",
      "about the role\n",
      "this role will focus on the architecture of data services developed and the solution architect is a member of the architecture team. the sa is responsible for designing new solutions, redesigning existing solutions and vetting solutions proposed by integration partners while adhering to the global it architecture standards defined.the sa is also responsible for maintaining, creating and or updating the architecture artifacts like documentation in functional, non-functional and technical areas per solution as well as providing input into overarching architecture documentation. key to this role will be the ability to manage all the architectural guidance in projects and the ability to drive the architectural governance of projects to the desired outcome that is in line with the longer-term architectural vision and standards.responsibilities\n",
      "performance and progress in the following areas will be the priorities for this position:•\tarchitecting and designing solutions in a cloud data environment.•\tguide coach the development teams and data engineers around architectural data topics.•\tadhere and contribute to the company's secure development policies and play a proactive role in making sure application are secure by design.•\tadhere to the company's change management procedures.•\tadhere and contribute to the company's architecture standards and guidelines.•\tcommunicating effectively with the company's lead solution architect, product manager, architecture & infrastructure manager, program manager global it and other key stakeholders.•\tsupport level 3 investigations•\tprovide leadership to other team members working in an agile environment\n",
      "-----------------------------------------------\n",
      "job requirements1.\tcollege diploma or university degree in the field of computer science.\n",
      "2.\texpert skill level with 2 to 5 years experience with the following technologies:\n",
      "•\tazure paas data services\n",
      "•\tobject oriented analysis and design\n",
      "•\tci/cd and source control\n",
      "•\tetl techniques and principles\n",
      "•\tdata modelling\n",
      "•\tmaster data management\n",
      "•\tdata visualization\n",
      "3.\texperienced in designing and implementing data platform, reporting and analytics solutions in the microsoft azure ecosystem.\n",
      "4.\tfamiliarity with agile project management and methodologies desired.\n",
      "5.\table to exercise independent judgement and take action on it.\n",
      "6.\texcellent analytical and creative problem-solving skills.\n",
      "7.\texcellent listening, written, and oral communication skills.\n",
      "8.\tstrong relationship, interpersonal, and team skills.\n",
      "9.\thighly self-motivated and directed.\n",
      "10.\texperience working in a team-oriented, collaborative environment.\n",
      "\n",
      "this role is only open to applicants residing nearshore and offshore. we're currently not processing applicants from lithuania for this role\n",
      "================================================\n",
      "data-02-06/832/data.html\n",
      "================================================\n",
      "data-02-06/2522/data.html\n",
      "mô tả công việc\n",
      "- thiết kế, xây dựng, tối ưu hệ thống thu thập số liệu, tổ chức nhà kho dữ liệu, xử lý batch/streaming data.- tham gia phát triển, triển khai, vận hành các dịch vụ/giải pháp trên nền tảng dữ liệu lớn, cấu trúc phức tạp.- tham tích hợp, triển khai, vận hành, hỗ trợ các dịch vụ khai thác số liệu.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "- nắm vững các kiến thức về cơ sở dữ liệu có cấu trúc và phi cấu trúc- có tư duy hệ thống, có khả năng chủ động giải quyết vấn đề- có kinh nghiệm, am hiểu về big data, xử lý tốt data cấu trúc phức tạpưu tiên ứng viên:- có thể làm việc với cường độ và áp lực cao.- tiếng anh chuyển nghành đọc hiểu tốt.\n",
      "quyền lợi\n",
      "mức thu nhập cạnh tranh, upto 25 mils cho vị trí de, thưởng performance năm.bảo hiểm sức khỏe dành cho cbnv, các chương trình team building, happy friday hàng tháng, tháng kỉ niệm thành lập công tythưởng ngày sinh nhật công ty, sinh nhật, các ngày hiếu hỉ của bản thân và gia đìnhlàm việc trong tổ chức xem trọng learning & development với các chương trình học tập\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 30/06/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2664/data.html\n",
      "responsibilities\n",
      "design and develop etl pipelines with external services, including client wrappers.participate in designing and implementing foundational layers, including data models, workflow, and storage systems.perform dataops, including data correction and schema evolution migration.\n",
      "\n",
      "-----------------------------------------------\n",
      "job requirements:\n",
      "3 year+ in python, a basic understanding of java.well-grasped understanding of a fundamental data stack, including etl pipelines, workflow orchestrators, and data transformation.basic knowledge of git, *nix; kubernetes is a plus.a good writer and personal information manager. you will be the subject matter expert at a variety of external integrated services. adaptability and a strong sense of quality communication and documentation will be a considerable edge.have an appreciation of sound and evolvable data schema design. in other words, have a great sense of spotting schema design smells.\n",
      "special benefits:\n",
      "chance to become an expert in the new trendy domain: ai-driven personalized marketing, personalized customer experience, data analytics, and platform.modern tech & innovative environment.\n",
      "================================================\n",
      "data-02-06/2827/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            position: commerical finance executive \n",
      "department: finance\n",
      "report to: commercial finance supervisor\n",
      "\n",
      "job purpose\n",
      "this position opens for freshmen/ entry level.\n",
      "your role is responsible for assisting commercial finance supervisor in partnering with the commercial and marketing team, in both short-term and long-term strategies ensuring performance from gross to net sales and a&p spending to provide insightful highlights on potential opportunities and risks for the business, as well and driving mitigations for gap closure.\n",
      "\n",
      "main responsibilities:\n",
      "- involve in sales & marketing business partnering: \n",
      "o\tsupport sales & marketing team for a&p day to day budget controlling\n",
      "o\tcampaign budget & payment tracking\n",
      "o\tsupporting documents review\n",
      "o\tassist in roi pre and post-evaluation support for big and key promotion campaigns and recommendation proposals for improvements. \n",
      "- support on volume projection included volume forecast, latest estimate (le), and budget\n",
      "- system reporting for commercial part: volume, net sales, a&p on prisma, polaris, jde including master data maintenance\n",
      "- support providing insightful financial analysis on business performance, in detail of various aspects (channel mix/product mix/market outlook)\n",
      "- assist in managing and monitoring sale reductions (a&d) accruals for channel/brands/customer\n",
      "- reporting factory: volumes, net sales, a&p by brand, by the customer, by region monthly for bom and brand owner presentation\n",
      "- apply power bi for commercial analysis reports\n",
      "- perform other related duties and assists in ad hoc project\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2908/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            don't miss out on this incredible opportunity! join us at the geocomply talents meet and greet 2023 - the ideal event for software engineers who aspire to grow their careers and make and impact. our event is designed to equip you with the expertise and resources essential to excel in your field, particularly at leading global organizations like geocomply.\n",
      "\n",
      "at geocomply, we embrace diversity, equity, and inclusion (dei) as a core part of our organizational culture. we are passionate about fostering an inclusive environment where everyone feels valued, respected, and empowered to contribute their unique perspectives and talents. we believe that by prioritizing dei, we can drive innovation, creativity, and growth.\n",
      "\n",
      "by attending this event, you will have the chance to network with like-minded tech industry experts, connect with fellow professionals who share your passion for innovation, and participate in insightful discussions on a range of relevant topics.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2007/data.html\n",
      "================================================\n",
      "data-02-06/2062/data.html\n",
      "description: ·         collaborate with customer to gather requirements and to understand their business processes.·         create and maintain optimal data pipeline architecture, assemble large, complex data sets that meet functional / non-functional business requirements.·         identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.·         build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using spark, sql and azure ‘big data’ technologies.·         build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.·         use tools to deploy and monitor the performance of the systems in production.·         demonstrate knowledge and real-world \n",
      "-----------------------------------------------\n",
      "experience on big data technologies. a successful history of manipulating, processing and extracting value from large datasets.·\n",
      "================================================\n",
      "data-02-06/2072/data.html\n",
      "descriptionthe bosch group is a leading global supplier of technology and services. it employs roughly 394,500 associates worldwide (as of december 31, 2020). according to preliminary figures, the company generated sales of 71.6 billion euros in 2020. its operations are divided into four business sectors: mobility solutions, industrial technology, consumer goods, and energy and building technology.the bosch group comprises robert bosch gmbh and its roughly 440 subsidiaries and regional companies in some 60 countries. if its sales and service partners are included, then bosch is represented in roughly 126 locations. this worldwide development, manufacturing, and sales network is the foundation for further growth.rbvh - robert bosch engineering and business solutions vietnam company limited is 100% owned subsidiary of robert bosch gmbh. rbvh has started its operations from 19th october, 2010 at e-town2 in hcmc. this engineering development center will be engaged in developing embedded systems and software, mechanical design and simulation, and will provide it (sap consulting, java development….) and business services (finance and accounting, economics, purchasing, logistics, translations japanese-english-japanese, information security ) solutions to the bosch group of companies globally. job descriptiondo you want beneficial technologies being shapes by your ideas? whether in the area of mobility solutions, consumer goods, industrial technology of energy and building technology – with us, you will have the chance to improve quality of life all across the globe. welcome to bosch.robert bosch engineering and business solutions vietnam company limited (rbvh), is a 100% owned subsidiary of robert bosch gmbh, one of the world’s leading global supplier of technology and services, offering end to end engineering, it and business solutions. founded in october 2010 at ho chi minh city, rbvh is the first state-of-the-art software development center of bosch in the south east asian region. rbvh provides solutions for businesses in the following areas: engineering services, it services, business services.over 1000 highly skilled and competent employees, work towards creating products that spark enthusiasm, improve the quality of life, and conserve natural resources. in this way, the company offers technology that is ‘invented for life’.build and ensure internal control system is operate effectivelyinitiate, prepare variance analysis reports to measure actual against planned performance and suggest the improvementdevelop automated/ dashboard reporting to transform data into valuable insights and real-time analysisfull understand about integrated billing system and ensure harmonized projects rolled out smoothlydetermine complex pricing model approach, recommend scenarios to enhance project margin through price setting, process and governancebe responsible as billing/ pricing partners with departments to extend the support to all related topicprovide information to management by reconciling and summarizing data; preparing reports; making presentations of findings, analyses, and recommendationsother tasks as required by manager from time to time\n",
      "-----------------------------------------------\n",
      "qualificationsmust have strong analytical (quantitative as well as qualitative) skills including building models, prior data miningself-starter with the ability to streamline functions and passion to learn and growstrong financial analysis foundation creating forecasts and modelsproficiency with microsoft excel is required; familiarity with sap, finance systemsmust possess excellent communication and presentation skills, and be comfortable interacting with executive-level managementwork and collaborate well with team-mates\n",
      "================================================\n",
      "data-02-06/3116/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "                                                                                            we are looking for new team members ! be part of our talented team if you want to develop yourself a career in logistics sector under a global brand with great career opportunities. you will be responsible for analyzing our pricing datas, preparing reports and dashboard to support our overseas offices, pricing and sales teams.\n",
      "\n",
      "• analyze, organize and share data with relevant business units and overseas offices \n",
      "• review data and dashboard periodically to make sure all reports are up-to-date and accurate\n",
      "• collaborate with cross-functional teams to collect data and coordinate activities\n",
      "• stay up-to-date with industry trends and best practices\n",
      "• monitor/alert efficiency and business trends in deep level.\n",
      "• answer all inquiries related to reports from local and overseas offices\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2712/data.html\n",
      "================================================\n",
      "data-02-06/1088/data.html\n",
      "responsibilities and salary with our company will only be limited by your determination, hard work and performanc\n",
      "-----------------------------------------------\n",
      "experience (0-2 years) but has demonstrated excellence in one or several projects: we will prioritize your motivation, ambition and quality of work over your prior experience. if you have never worked before, just share with us some projects you implemented where you demonstrated what we are looking foris comfortable working in english in an international environmentis proficient in excel and google sheet. having prior experience in automating data-oriented process through vba, scripts or any other tool is a plusworking for us means:you are joining a very young and ambitious company: we created the company in january 2019 and have very ambitious fundraising and business targets. we plan to start opening new countries in sea (south east asia) in 12-18 month and will always push to overachieve our high targets and strict deadlinesyou are willing to become the best at what you do in south east asia: we have extremely strong expectations in the quality of work we produce and want to ensure our clients know they are dealing with the best in their fields. as a junior newcomer, this means you want to boost yourself to learn how to become the best at what you do following our teaching, methodology, and paceyou are excited by the idea of writing your own career path: if you expect to know the exact content of your job and career steps, you should look elsewhere. the possibilities to grow in responsibilities and salary with our company will only be limited by your determination, hard work and performanc\n",
      "================================================\n",
      "data-02-06/1702/data.html\n",
      "descriptionabout the job as the world's largest research organization, nielsen iq is powered by talented creative scientists. our data scientist business leaders come from diverse disciplines such as statistics, research methodology, mathematics, psychology, business, engineering, physics and demography. these professionals drive innovation, new product ideation, develops complex analysis and delivery of data insights to measure what consumers buy.responsibilities own data science solutions for client requests and provide initial recommendations for complex client raised issues.  support internal and external clients with the understanding of data science design and methodology. accompanied senior leaders meet with clients to understand business needs and help offer innovative solutions. work on creating new solutions use cases, proof of concept and prototypes by exploring diverse data sets using tools such as python/r. understand nielsen products and services to suggest new solutions for client challenges. collaborate with other data science team units.  automate and develop solutions for existing processes.  innovate and create out of the box solutions by leveraging large and diverse data sets and state of the art technologies.qualificationsabout you you’ve dabbled in data. you’ve perused python. and you have the communication chops to translate it all into conversation or presentations. while you’ve worked with global cross-functional teams, you can also put your head down and focus on independent projects. seeing the big picture takes attention to detail. you know what’s happening in big data and you’re ready to influence what’s next. qualificationsprofessionals with degrees (either bachelor/master) in maths, data science, statistics, or related fields involving statistical analysis of large data sets. 1 year of \n",
      "-----------------------------------------------\n",
      "experience in market research or relevant fields, however, open for fresh graduate. \n",
      "================================================\n",
      "data-02-06/2677/data.html\n",
      "================================================\n",
      "data-02-06/2734/data.html\n",
      "================================================\n",
      "data-02-06/3083/data.html\n",
      "responsibilities·          software integration, bug fixes, validation, and release by working  with team.·          pipeline demo maintenance, optimization for model app and gstreamer  x86.·          integrate ai solution with support from software team.·          optimize pipeline performance and stability.·          verification whole pipeline quality and external release documentations for software  user guide​\n",
      "-----------------------------------------------\n",
      "job requirement·\n",
      "================================================\n",
      "data-02-06/2145/data.html\n",
      "description\n",
      "\n",
      "intrepid is currently looking for a data engineer to be based in vietnam. as a data engineer, you are pivotal in building out intrepid martech, our key marketing solution for brands. you are responsible for expanding, optimizing, and integrating our data from external sources into a common data warehouse model. you manage the data pipeline architecture, as well as optimize our data flow and collection for the product. you work closely with our strong engineering team, as well as our bi and product team on data initiatives and ensure an optimal data delivery architecture. you will be excited by the prospect of turning a vast amount of data into actionable insights and finding new ways to get data that can give our clients an edge over their competition\n",
      "design, and develop crawler system, data pipelines, data governance compliance, procedures, and tooling to scrape login required & open api from ecommerce websites.\n",
      "take initiative to bypass obstacles from anti-crawling system / captcha for platforms\n",
      "own the creation and maintenance processes of these tools, services, and workflows to improve crawl/scrape analysis, reports and data management.\n",
      "test the data from api and the scraping to ensure accuracy and quality\n",
      "work closely with the team leader and follow the guideline to accomplish assigned tasks\n",
      "\n",
      "\n",
      "your skills and \n",
      "-----------------------------------------------\n",
      "experience\n",
      "\n",
      "\n",
      "experience running large scale web scrapes\n",
      "familiarity with techniques and tools for crawling, extracting and processing data\n",
      "3-5 years of hands-on experience of writing code, scripts and apis (python, golang)\n",
      "familiarity with linux, http, html, javascript and networking\n",
      "experience with serverless compute components, bigquery, cloud functions, cloud storage\n",
      "experience with system monitoring/administration tools\n",
      "proficient understanding of code versioning tools, such as git\n",
      "experience following agile methodology\n",
      "ability to dive into technical details and design analytics solutions to meet business needs\n",
      "strong understanding of data flow and system integrations\n",
      "good verbal, written communication skills in english\n",
      "experience or understanding marketing/ ecommerce (metrics) is a plus\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "what we offer● excellent and competitive salary package with immediate opportunity to earn incentives.● competitive salary package, performance-based● key internal facing position in a fast-growing international ecommerce company that has strong momentum and strong competitive differentiators (team, technology, regional footprint), this role offers an exciting growth journey and opportunity to co-create our success story.● you will work with a leading team of e-commerce leaders and aspiring movers and shakers to positively shape all ecommerce platforms in the years to come, and will have a broad view on the latest developments in the south east asian ecommerce ecosystem.● ample opportunity for personal and professional development, both on the job and through regular training.● opportunities to work on regional projects with other countries’ offices, in philippines, thailand, singapore, indonesia and malaysiacompany benefit● an attractive salary package with ample opportunities for professional growth.● 2 months probationary period with 100% of gross salary● up to 15 days off per year● working remote from home flexibly● annual health check-up & premium healthcare insurance● social, health, and unemployment insurance based on full salary.● 2 performance review times per year● team building monthly, company trip every year, 13th salary.● on-the-job training and coaching with smart and friendly experts● union and other activities every month (8/3, 20/10, mid-autumn, year-end party, v.v...)● free tea, coffee, snacks for member every day● free parking fee every month\n",
      "\n",
      "================================================\n",
      "data-02-06/2772/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "                                                                                            what is “fresh minds”?\n",
      "\n",
      "sony fresh minds program invites young and vibrant graduates into sony’s workforce enabling fresh spirited ideas and creativities to be entrenched throughout a mutual journey of success.\n",
      "successful candidates shall go through a 12-month mentorship program starting from aug 2023 to july 2024 which will bring you through a journey of developing career skills including retailing, marketing, sales and etc. in sony electronics vietnam.\n",
      "\n",
      "“fresh minds” development rotation\n",
      "\n",
      "• sales& marketing: sales, marketing, brand activation\n",
      "\n",
      "• non sales & marketing: business control, service; logistic/accounting\n",
      "\n",
      "sev’s selection process\n",
      "\n",
      "• round 1 : application\n",
      "• round 2 : online test\n",
      "• round 3 : hr interivew\n",
      "• round 4 : assessment center\n",
      "• round 5 : panel interview (case study & presentation)\n",
      "• onboarding: august 2023\n",
      "\n",
      "working location: 93 nguyen du, ben nghe ward, district 1, hcmc\n",
      "working time: 9:00 am - 6:15 pm, mon-fri\n",
      "\n",
      "please send your resume to mrs. huong - hr department\n",
      "subject:[sony vietnam – 2023] fresh minds program – full name\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1734/data.html\n",
      "================================================\n",
      "data-02-06/1938/data.html\n",
      "responsibilities: \n",
      "chịu trách nhiệm thiết kế chính cơ sở dữ liệu của hệ thống.\n",
      "luôn theo sát và hiểu rõ sản phẩm để từ đó phân tích và cung cấp thiết kế phù hợp.\n",
      "xây dựng và quản trị hệ csdl thông qua các monitor tool. đảm bảo tính ổn định (availability) và tính cân bằng (load balancing).\n",
      "đảm bảo csdl được lưu trữ và backup thường xuyên.\n",
      "kiểm tra, tối ưu hiệu suất và xử lý các sự cố phát sinh của csdl.\n",
      "hiểu rõ thành viên trong team, phân công tasks và ước lượng deadline chính xác. kiểm tra, theo dõi, đánh giá chất lượng công việc của thành viên trong nhóm.\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/946/data.html\n",
      "================================================\n",
      "data-02-06/805/data.html\n",
      "responsibilities:\n",
      "\n",
      "work with relevant departments to complete specific business analysis for each project\n",
      "act as a focal point in proposing data requirements necessary for business analysis\n",
      "evaluate problems, points for improvement and make recommendations based on analysis results\n",
      "building management reports, business reports for effective administration for the project owner and related departments\n",
      "monitor system performance and review, recommend, and apply new tools\n",
      "monitor development and ensure adherence to schedules and timeframes.\n",
      "collaborate with finance to make impact forecasts based on impact actions\n",
      "determine pricing policies and the financial effectiveness of those pricing policies.\n",
      "comply with applicable compliance standards.\n",
      "comply with service standards for performance.\n",
      "perform other duties as assigned.\n",
      "\n",
      "knowledge, skills and abilities\n",
      "\n",
      "work with relevant departments to complete specific business analysis for each project\n",
      "knowledge of statistical and quantitative data analysis methodologies. general knowledge of business administration activities, business models\n",
      "having in-depth understanding of the price/fee model of products in vietnam‘s priority banking service.\n",
      "analytical skills, planning skills, statistics, data synthesis, business thinking\n",
      "ability to interpret data, results, analytical reports in business language\n",
      "skilled in working and communicating with stakeholders, logical thinking, problem solving skills\n",
      "highly self-directed and self-organized\n",
      "ability to communicate and operate professionally with all levels of personnel and other departments throughout the organization\n",
      "familiar with many concepts and practices of the field.\n",
      "critical thinking: can process data in such a way as to make recommendations that require critical thinking\n",
      "\n",
      "training and \n",
      "-----------------------------------------------\n",
      "experience\n",
      "\n",
      "graduated from university or higher with a focus on finance, banking, business administration,\n",
      "minimum of 8 years of professional experience in the financial/banking field\n",
      "minimum 5 years business analysis experience.\n",
      "experience in building and managing financial models\n",
      "proficient in power bi, excel, spss, python…\n",
      "\n",
      "================================================\n",
      "data-02-06/1922/data.html\n",
      "================================================\n",
      "data-02-06/2682/data.html\n",
      "================================================\n",
      "data-02-06/2809/data.html\n",
      "================================================\n",
      "data-02-06/2713/data.html\n",
      "mô tả công việc\n",
      "1. thực hiện thiết kế, xây dựng và quản trị hệ thống datawarehouse, hệ thống báo cáo của công ty, cụ thểhiểu được cấu trúc dữ liệu từ source, cần thực hiện phân tích và thiết kế cơ sở dữ liệu, làm nền tảng cho data engineer thực hiện tổ chức dữ liệu vào datawarehouse, đảm bảo tính logic và nhất quán với dữ liệu đã có trong datawarehouse.xây dựng được các bộ rule check dữ liệu đầu vào dựa trên những yêu cầu nghiệp vụ và cài đặt từ hệ thống nhằm đảm bảo việc kiểm tra dữ liệu, làm sạch dữ liệu.xây dựng data dictionary nhằm ghi nhận các trường dữ liệu từ source, đảm bảo khoa học, logic và tính thống nhất của dữ liệu.2. xây dựng và maintain các dataset, hướng dẫn các phòng ban liên quan sử dụng các dataset trong phân tích dữ liệu.3. xây dựng các data model và business model phục vụ cho các mục tiêu theo yêu cầu của ban lãnh đạo.4. xây dựng và maintain các tài liệu codebook, tài liệu yêu cầu và tài liệu model đảm bảo các tài liệu up to date và được lưu trữ khoa học, bảo mật\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "sử dụng tốt một trong các phần mềm thống kê/ xây dựng mô hình/ quản lý dữ liệu: spss, sql, oracle, r, python,vvsử dụng tốt excelcó kiến thức về thống kê, kinh tế lượng..ưu tiên ứng viên biết thực hiện/ xây dựng các báo cáo quản trị trong ngành tài chính ngân hàng;ưu tiên ứng viên có kinh nghiệm xây dựng các mô hình bằng phương pháp định lượng (mô hình tài chính/ mô hình rủi ro/ mô hình phân tích, dự báo);thu thập, xử lý nhiều loại dữ liệu từ nhiều nguồn khác nhau;kinh nghiệm tạo báo cáo obi nâng cao, có kiến thức về tableau nâng caocó đức tính cẩn thận, trách nhiệm\n",
      "quyền lợi\n",
      "thu nhập thỏa thuận, tương xứng với năng lựcđược training về các kiến thức và kỹ năng marketingcơ hội trở thành nhân viên chính thức và phát triển dài hạn trong lĩnh vực của tương lai: công nghệ - tài chínhmôi trường năng động, trẻ trung, khuyến khích ý tưởng phá cách, sáng tạocơ hội được học hỏi từ các chuyên gia trong lĩnh vực tài chính, công nghệ, quản trị.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "hết hạn nộp đơn\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/628/data.html\n",
      "description\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "job requirement\n",
      "\n",
      "job responsibilities\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "report this job\n",
      "\n",
      "\n",
      "apply this job\n",
      "\n",
      "================================================\n",
      "data-02-06/2260/data.html\n",
      "description\n",
      "\n",
      "all level developer\n",
      "participate in solution design and development of database solutions.\n",
      "extract and mine data using sql.\n",
      "optimize and streamline stored procedures and views.\n",
      "provide technical assistance, troubleshooting and resolutions to data-related issues for new and existing systems.\n",
      "working as part of a larger db team to provide ongoing production support to our customers and internal staff. this involves with investigate production issues, find root cause, apply the appropriate fixes or change requests and documentation.\n",
      "working as part of a larger conversion team to convert data from a legacy system to the current database\n",
      "assess the impact of change requests, and develop solutions and mitigation strategies\n",
      "interpret business requirements and provide systems/technical documentation\n",
      "\n",
      "\n",
      "your skills and \n",
      "-----------------------------------------------\n",
      "experience\n",
      "\n",
      "technical attributes:\n",
      "2+ years experience in sql.\n",
      "experience in legacy database conversion/ data mapping/ performance tuning/ data fixing\n",
      "worked in production environment, manage large and complex volume of data\n",
      "tools: sql server 2012/2014 and visual studio, data integration tool ssis\n",
      "has strong data analysis skills.\n",
      "understand performance tuning, monitoring, indexing strategies\n",
      "can admin sql servers instances\n",
      "understand powershell, agent jobs, performance tuning, backup/recovery.\n",
      "strong in writing large stored procedures\n",
      "\n",
      "additional attributes (preferred not required):\n",
      "knowledge and skills in .net frameworks and .net development tools\n",
      "familiar with c# language\n",
      "testing, integrating, writing, troubleshooting and debugging software applications\n",
      "working knowledge of or experience in erp type system.\n",
      "working knowledge of or experience in accounting or retail pos systems\n",
      "experience in agile development methodologies\n",
      "excellent academic and tertiary qualifications\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "we are our people, and whilst as a business we make software, as an organization, we make some of the industry’s best!\n",
      "================================================\n",
      "data-02-06/2921/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description\n",
      "\n",
      "\n",
      "collaborate with the credit risk team to understand their data engineering requirements and design scalable data pipelines.\n",
      "build and maintain etl workflows using airflow to ensure efficient and reliable credit risk reporting.\n",
      "ensure data quality and accuracy by implementing data validation and monitoring processes within key credit risk pipelines\n",
      "develop and maintain data models to support the credit risk team's analytical and reporting needs.\n",
      "deploy and manage data infrastructure on aws using kubernetes.\n",
      "stay up to date with the latest industry trends, tools, and technologies related to data engineering and credit risk.\n",
      "\n",
      "\n",
      "your skills and \n",
      "-----------------------------------------------\n",
      "experience\n",
      "\n",
      "\n",
      "at least 3-5 years of experience as a data engineer, preferably in the financial services industry with a focus on credit risk.\n",
      "strong experience with python, pandas, pyspark, airflow, and building etl workflows.\n",
      "the ideal candidate has strong experience with aws, including s3, iam, and athena.\n",
      "experience with running containerized workloads on kubernetes\n",
      "worked in an agile environment with continuous delivery\n",
      "strong sql skills and experience with relational and non-relational databases.\n",
      "knowledge of data modeling, data warehousing, and bi concepts.\n",
      "excellent problem-solving and communication skills.\n",
      "ability to work effectively in a team-oriented environment and collaborate with cross-functional teams.\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "hr benefits\n",
      "competitive salary\n",
      "salary band per level and employee benefits are reviewed once per year\n",
      "13th month salary pro rata depending on the employee’s length of service (within a calender year), paid with the december salary\n",
      "monthly lunch allowance: 700,000 vnd/employee\n",
      "parking: gft covers the monthly parking fee for employee motorbikes\n",
      "performance evaluation is once per year, for 2 purposes:\n",
      "================================================\n",
      "data-02-06/2818/data.html\n",
      "responsibilities:\n",
      "develop and implement comprehensive growth strategies, focusing on both the top of the funnel.establish, monitor, and manage key growth metrics, utilizing data to drive strategic direction and operational decision-making.lead and collaborate with the sales team to refine sales strategies, improve conversion rates, and maximize customer lifetime value.guide the marketing team in developing impactful campaigns across various channels to reach target audiences.work with the school relations team to foster partnerships and enhance engagement with schools.work closely with the operation and academic teams to align growth initiatives with service development.identify and pursue new markets and partnership opportunities to expand our user base and increase engagement.monitor and report on the effectiveness of growth strategies to the executive team and the board.\n",
      "qualifications:\n",
      "bachelor's degree in business, marketing, or a related field. an mba or relevant advanced degree is preferred.minimum of 7-10 years of experience in a growth-focused role in a fast-paced, high-growth environment.proven track record of driving user growth and engagement through innovative strategies.strong understanding of growth marketing tools and best practices.excellent analytical and quantitative skills, with a deep understanding of data-driven decision-making.experience leading and collaborating with sales, marketing, and partner relation teams.ability to work cross-functionally with multiple teams to execute growth strategies.exceptional communication and presentation skills\n",
      "-----------------------------------------------\n",
      "experienced head of growth to lead our growth strategies across the organization. the ideal candidate will have a proven track record of driving user acquisition, and revenue growth. as the head of growth, you will lead and collaborate with the sales, marketing, and school relations teams to design and execute growth initiatives.\n",
      "responsibilities:\n",
      "develop and implement comprehensive growth strategies, focusing on both the top of the funnel.establish, monitor, and manage key growth metrics, utilizing data to drive strategic direction and operational decision-making.lead and collaborate with the sales team to refine sales strategies, improve conversion rates, and maximize customer lifetime value.guide the marketing team in developing impactful campaigns across various channels to reach target audiences.work with the school relations team to foster partnerships and enhance engagement with schools.work closely with the operation and academic teams to align growth initiatives with service development.identify and pursue new markets and partnership opportunities to expand our user base and increase engagement.monitor and report on the effectiveness of growth strategies to the executive team and the board.\n",
      "qualifications:\n",
      "bachelor's degree in business, marketing, or a related field. an mba or relevant advanced degree is preferred.minimum of 7-10 years of experience in a growth-focused role in a fast-paced, high-growth environment.proven track record of driving user growth and engagement through innovative strategies.strong understanding of growth marketing tools and best practices.excellent analytical and quantitative skills, with a deep understanding of data-driven decision-making.experience leading and collaborating with sales, marketing, and partner relation teams.ability to work cross-functionally with multiple teams to execute growth strategies.exceptional communication and presentation skills\n",
      "================================================\n",
      "data-02-06/1148/data.html\n",
      "================================================\n",
      "data-02-06/1729/data.html\n",
      "responsible for innovation project management, conducting or monitoring research to understand the market & competitor status deeply, thereby developing and initiating new competitive adverti...\n",
      "                                \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/362/data.html\n",
      "================================================\n",
      "data-02-06/1807/data.html\n",
      "mô tả công việc\n",
      "thiết kế, tối ưu hóa data engineer pipeline để trích xuất dữ liệu từ các ứng dụng và nguồn khác nhau và lưu trữ chúngphối hợp chặt chẽ với data engineer và data analyst trong việc xây dựng, thử nghiệm và sản xuất khai thác dữ liệu, chuyển đổi và cung cấp dữ liệu trên nền tảng cloud bằng cách quản lý và vận hành chúngcung cấp thông tin chính xác và kịp thời có thể được sử dụng trong hoạt động dữ liệu hàng ngày và tham vấn các quyết định chiến lược về dữ liệunhiệm vụ vận hành khác được cấp trên giao phó            \n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "tốt nghiệp đại học / cao đẳng hoặc tương đương về khoa học máy tính hoặc kỹ thuật3-5 năm trở lên kinh nghiệm làm việc với các nền tảng cloud, đặc biệt là gcp và có kinh nghiệm với databasehiểu biết về cách thức triển khai giải pháp etl/elt có khả năng mở rộng dữ liệu trên gcphiểu biết về xử lý dữ liệu với python và các nền tảng saashiểu biết về các quy chuẩn về chính sách dữ liệuhiểu biết về hạ tầng cloud (gcp) & onprem: kubernetes, bigquery, airflowhiểu biết về văn hóa devopscó khả năng sử dụng các toolset iaas như terraform, ansible, docker, helm...có khả năng sử dụng và phát triển các toolset về tự động hóa: gitlabcikhả năng quản lý và sắp xếp công việc tốtchủ động, có trách nhiệm, sáng tạo và teamwork tốt\n",
      "================================================\n",
      "data-02-06/734/data.html\n",
      "descriptionavery dennison rbis, a global leader in apparel and footwear industry solutions, is a $1.6 billion division of avery dennison (nyse: avy). avery dennison rbis provides intelligent creative and sustainable solutions that elevate brands and accelerate performance throughout the global retail supply chain. we elevate brands through graphic tickets, tags and labels, embellishments and packaging solutions that enhance consumer appeal. we accelerate performance through rfid enabled inventory and loss prevention solutions, price management, global compliance, and brand security solutions. based in westborough, massachusetts avery dennison rbis responsibly serves the global marketplace with operations in 115 locations, 50 countries, across 6 continents. for more information, visit www.rbis.averydennison.com.job description- import/export data in production team and send the data to planning sections- contact and coordinate with sections concerning as it, planning, cs#… to resolve issue as miss take, error data, error system….- daily monitor production schedule of planning team and coordinate with concerning sections in production to solve the issues to make sure the orders are delivered on time as plan.- improve production efficiency, reduce scrap by optimizing the schedule plan and production processes.- follow agreed leadtimes to prioritize and utilize production capacity to achieve reliability&flexibility,uee(utilization of equipment efficiency )targets.- working with planning team to support urgent orders for customer requirements.- making daily output & yeild report for production manager- others tasks as supervisor required.qualifications- high school diploma- at least 2+ years working \n",
      "-----------------------------------------------\n",
      "experience- good team-leader skills & control, working in high pressure environment.- good microsoft office such as word, excel- team work- good communication.additional informationrecruiter in charge:ms. huong pham ([email\n",
      "================================================\n",
      "data-02-06/59/data.html\n",
      "descriptions\n",
      "a - demand planning:\n",
      "\n",
      " develop the deep understanding of demand input factors (seasonality as an example, distributor‘s inventory policy as another example) as well as the effect of demand on the downstream factors (inventory, capacity, lead time, cost...)\n",
      " build the mathematical model for demand forecasting and planning for each of the skus. sensitivity analysis included.\n",
      " in collaboration with sales, finance and operations during the monthly meeting and update/fill out/adjust the demand plan in accordance with the consensus.\n",
      " create a robust planning function to support continuous improvement for the business.\n",
      " provide insights to conduct fact-based portfolio management and to implement a yearly sku portfolio review cycle\n",
      "\n",
      "b – supply planning:\n",
      "\n",
      " manage the inventory status at each node of the supply chain, build the replenishment model based on the demand forecast and inventory policy to decide the stock move or po quality to offer the optimal stock level and purchasing cost (container/pallet utilization as an example).\n",
      " develop the understanding of supplier lead time and capacity/throughput and how fast they can react with change in y4a demand. create supply scenarios to prepare reaction plan for each of the demand/supply variation occurs\n",
      " build monitoring mechanism to tracking actual outcome and demand insights from other departments. lead solutions findings and execution of demand and supply imbalances.\n",
      "\n",
      "c – supply chain analytic:\n",
      "\n",
      " providing analytical, strategic, and operational support across the organization with the primary objective of enhancing our supply chain responsiveness, agility and optimization\n",
      " assisting or leading on-going supply chain projects under the supervision of supply chain manager\n",
      "\n",
      "ii. skill and experience\n",
      "\n",
      "we are looking for supply chain lover so please be ready to show that.\n",
      "both the theory-driven and data-driven approaches in solving problems.\n",
      "strong mathematical and analytical skills. hands on experience with applying analytical techniques to solve supply chain problems. fluent one or multiple analytic languages (r, mysql, python, …) is priority.\n",
      "possess excellent verbal and written communication skills as well as presentation skills.\n",
      "intellectual curiosity & honesty.\n",
      "team player with high ownership.\n",
      "good at time managing, speed, teamwork, and multitasking.\n",
      "willing to learn, thrive in a fast-paced environment and have a can-do attitude.\n",
      "at least 2-3 years of experiences in planning, supply chain/business/data analytics or similar roles. retail supply chain, e-commerce experience is priority.\n",
      "\n",
      "iii. why you will love joining us?\n",
      "for you to join\n",
      "\n",
      "financial well-being: a competitive salary with 13th month salary, annual performance bonus and a variety of allowances.\n",
      "salary review: annually or on excellent performance.\n",
      "activities: company trips, team-building, and other customized monthly bonding events.\n",
      "annual leaves: 16 days off and 01 birthday leave per year.\n",
      "healthcare: annual health check, insurance according to labor law and extra bao viet insurance package.\n",
      "working environment: dynamic, friendly environments with working time flexibility (mon-fri) and other perks include snacks, coffee, and healthy food provided daily suited for hardworking, fun, and team collaboration.\n",
      "\n",
      "for you to grow\n",
      "\n",
      "ambition: we are now keeping on with our hyper growth to multicategory, multichannel, multimarket, and expanding into the world largest e-commerce enabler. hence, there will continuously be opportunities to challenge yourself, learn new skills and knowledge.\n",
      "challenges: your voice can always be heard as we embrace the eagerness of learning and sharing. you can be your own boss and create your own value with the ability to take initiative and make decisions in all aspects of work.\n",
      "chances: be led and coached by experienced and inspirational leaders and participate in various training courses where you can enlarge your knowledge and experience in the e-commerce and supply chain industry.\n",
      "\n",
      "for you to stay\n",
      "\n",
      "people: having a headquarter in the us and an operation office in vietnam, our team is young and highly motivated. you will be working with and alongside members having experiences from international corporations or high profile from vietnam that share the same passion and dedication.\n",
      "culture: our working environment is humble, collaborative and 100% healthy. we promote exchange & speak out, you can receive transparent and supportive feedback so you can perform the best.\n",
      "career path: provide you a great career path, open to rotating for your better understanding of the company and contribute across many of our functions.\n",
      "\n",
      "and much more, join us and let yourself explore other fantastic things!\n",
      "-----------------------------------------------\n",
      "experience in the e-commerce industry.\n",
      "we are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end-to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\n",
      "i. job descriptions\n",
      "a - demand planning:\n",
      "\n",
      " develop the deep understanding of demand input factors (seasonality as an example, distributor‘s inventory policy as another example) as well as the effect of demand on the downstream factors (inventory, capacity, lead time, cost...)\n",
      " build the mathematical model for demand forecasting and planning for each of the skus. sensitivity analysis included.\n",
      " in collaboration with sales, finance and operations during the monthly meeting and update/fill out/adjust the demand plan in accordance with the consensus.\n",
      " create a robust planning function to support continuous improvement for the business.\n",
      " provide insights to conduct fact-based portfolio management and to implement a yearly sku portfolio review cycle\n",
      "\n",
      "b – supply planning:\n",
      "\n",
      " manage the inventory status at each node of the supply chain, build the replenishment model based on the demand forecast and inventory policy to decide the stock move or po quality to offer the optimal stock level and purchasing cost (container/pallet utilization as an example).\n",
      " develop the understanding of supplier lead time and capacity/throughput and how fast they can react with change in y4a demand. create supply scenarios to prepare reaction plan for each of the demand/supply variation occurs\n",
      " build monitoring mechanism to tracking actual outcome and demand insights from other departments. lead solutions findings and execution of demand and supply imbalances.\n",
      "\n",
      "c – supply chain analytic:\n",
      "\n",
      " providing analytical, strategic, and operational support across the organization with the primary objective of enhancing our supply chain responsiveness, agility and optimization\n",
      " assisting or leading on-going supply chain projects under the supervision of supply chain manager\n",
      "\n",
      "ii. skill and experience\n",
      "\n",
      "we are looking for supply chain lover so please be ready to show that.\n",
      "both the theory-driven and data-driven approaches in solving problems.\n",
      "strong mathematical and analytical skills. hands on experience with applying analytical techniques to solve supply chain problems. fluent one or multiple analytic languages (r, mysql, python, …) is priority.\n",
      "possess excellent verbal and written communication skills as well as presentation skills.\n",
      "intellectual curiosity & honesty.\n",
      "team player with high ownership.\n",
      "good at time managing, speed, teamwork, and multitasking.\n",
      "willing to learn, thrive in a fast-paced environment and have a can-do attitude.\n",
      "at least 2-3 years of experiences in planning, supply chain/business/data analytics or similar roles. retail supply chain, e-commerce experience is priority.\n",
      "\n",
      "iii. why you will love joining us?\n",
      "for you to join\n",
      "\n",
      "financial well-being: a competitive salary with 13th month salary, annual performance bonus and a variety of allowances.\n",
      "salary review: annually or on excellent performance.\n",
      "activities: company trips, team-building, and other customized monthly bonding events.\n",
      "annual leaves: 16 days off and 01 birthday leave per year.\n",
      "healthcare: annual health check, insurance according to labor law and extra bao viet insurance package.\n",
      "working environment: dynamic, friendly environments with working time flexibility (mon-fri) and other perks include snacks, coffee, and healthy food provided daily suited for hardworking, fun, and team collaboration.\n",
      "\n",
      "for you to grow\n",
      "\n",
      "ambition: we are now keeping on with our hyper growth to multicategory, multichannel, multimarket, and expanding into the world largest e-commerce enabler. hence, there will continuously be opportunities to challenge yourself, learn new skills and knowledge.\n",
      "challenges: your voice can always be heard as we embrace the eagerness of learning and sharing. you can be your own boss and create your own value with the ability to take initiative and make decisions in all aspects of work.\n",
      "chances: be led and coached by experienced and inspirational leaders and participate in various training courses where you can enlarge your knowledge and experience in the e-commerce and supply chain industry.\n",
      "\n",
      "for you to stay\n",
      "\n",
      "people: having a headquarter in the us and an operation office in vietnam, our team is young and highly motivated. you will be working with and alongside members having experiences from international corporations or high profile from vietnam that share the same passion and dedication.\n",
      "culture: our working environment is humble, collaborative and 100% healthy. we promote exchange & speak out, you can receive transparent and supportive feedback so you can perform the best.\n",
      "career path: provide you a great career path, open to rotating for your better understanding of the company and contribute across many of our functions.\n",
      "\n",
      "and much more, join us and let yourself explore other fantastic things!\n",
      "================================================\n",
      "data-02-06/1917/data.html\n",
      "mô tả công việc\n",
      "\n",
      "công việc chính (90%)nghiên cứu, tìm hiểu nhu cầu khách hàng, tình hình thị trường, xu hướng dịch vụ phần mềm quản trị doanh nghiệp trong nước, quốc tế để đề xuất cho các sản phẩm dịch vụ của misalên kế hoạch và triển khai hoạt động khảo sát, nghiên cứu khách hàng & đối thủ cạnh tranh để đưa ra đề xuất cải tiến, nâng cấp và phát triển sản phẩm phù hợp với nhu cầu thị trường và sự phát triển của ngành phần mềmtìm hiểu các mô hình định giá sản phẩm, dịch vụ phần mềm triển khai áp dụng để định giá cho các dịch vụ phần mềm của misaliên tục cập nhật xu hướng thị trường và nghiên cứu của các công ty kháccông việc khác (10%)chuẩn bị tài liệu, slide, nghiên cứu, phân tích các thông tin cần thiết theo yêu cầu của phó tgđtruyền đạt thông tin từ hội đồng quản trị & ban điều hành đến các phòng ban, bộ phận liên quan và gửi phản hồi trực tiếp đến hội đồng quản trị & ban điều hànhcác công việc khác theo sự phân công của phó tổng giám đốc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2554/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "\n",
      "                                                                                            about us\n",
      "since 1976, vinamilk has grown from a reconstructed facility in a war-ridden country to become world’s top 50 dairy company, with an unwavering commitment for health and wellness through nutrition. our mission is to nurture the next generation. we will continue to set the standards for food quality, engage deeply with our customers, deliver personalized and sustainable solutions, and exercise greater corporate and social responsibility, all powered by r&d and technology disruption.\n",
      "\n",
      "the data science & analytics team within the strategy & innovation office is searching for an \n",
      "-----------------------------------------------\n",
      "experienced business intelligence engineer/data analyst to join our team. you will generate insights that will guide product (physical and tech) development and operational excellence and for our customers. data analysis will the core of what we do, and your work will have a direct impact on decision making and strategy for our team. you will gather customer data, mine those data, generate insights, and make recommendations to help senior leaders make key business decisions.\n",
      "\n",
      "main responsibilities \n",
      "define\n",
      "•\tinterface with internal business teams to gather analytics & decision-making requirements\n",
      "•\tconduct deep dive analyses of business problems and data issues\n",
      "•\tanalyze customer and product trends to determine drivers of growth and performance\n",
      "•\twork closely with stakeholders to translate business needs into analytical needs, including identifying critical metrics and kpis, and deliver actionable insights to relevant decision-makers\n",
      "•\town the definition, design, and requirements for team’s bi tools and reports\n",
      "design\n",
      "•\tdesign, implement and support a platform that can provide ad-hoc access to large data-sets\n",
      "•\tidentify and investigate new data sources that can be used to build a holistic view for customer engagement. partner with technology teams to define, extract, transform, and load data from many data sources using sql and other tools\n",
      "•\tdefine and implement data acquisition and integration logic, selecting appropriate combination of methods and tools within defined technology stack to ensure optimal scalability and performance of the solution\n",
      "•\tdevelop and maintain databases by defining data schema, acquiring data from primary and secondary sources, and build scripts that will make our data evaluation process more flexible or scalable across data sets\n",
      "deliver\n",
      "•\tmodel data and metadata to support ad-hoc and pre-built reporting\n",
      "•\town the design, implementation, and maintenance of ongoing metrics, reports, analyses, and dashboards, to drive key business decisions.\n",
      "•\tautomate and simplify self-service or reporting pipelines, including improving etl workflows, automatic alarming, prototyping data science models and performance tuning.\n",
      "•\tcreate and maintain rich interactive visualizations through data interpretation and analysis integrating various reporting components from multiple data sources\n",
      "decide\n",
      "•\tparticipate in strategic and tactical planning discussions and provide data insights. challenge business teams to think differently about how they digest and use the data insights to make informed decisions\n",
      "•\tproactively analyze data to answer key questions from stakeholders or out of self-initiated curiosity with an eye for what drives business performance, investigating and communicating areas for improvement in efficiency and productivity\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "================================================\n",
      "data-02-06/2987/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            1. analysis:\n",
      "- make and collect sales analysis related to market/competitor/customer.\n",
      "- make analysis related to the sales system & sales force.\n",
      "2. identify sales situation and gap vs business needs.\n",
      "3. propose solutions for sales effectiveness/efficiency/ and development. make plans, lead deployment and assess the effectiveness & efficiency of improvement programs and activities:\n",
      "- successfully develop key performance indicators (kpis) for gt, mt, and sales support which will drive the sales team to higher motivation and business results.\n",
      "- create a report to support business needs.\n",
      "- propose dms system enhancements and modifications to meet changing business requirements and ensure system readiness for future requirements.\n",
      "- develop systems and tools to support sales organization and sales process to ensure operational effectiveness.\n",
      "- responsible for all sales projects.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3020/data.html\n",
      "responsibilities:the role is critical as it helps integrate, organize, monitor, scale and analyze the health & performance datas on which rely our patients and partners.collecting and analyzing large health-related data sets to identify trends, patterns, and insights that inform business decisions.creating and maintaining reports, dashboards, and data visualizations that provide clear and concise insights to business partners.working with cross-functional teams to identify opportunities for improving health outcomes, patient \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1943/data.html\n",
      "================================================\n",
      "data-02-06/2539/data.html\n",
      "mô tả công việc\n",
      "1. phân tích – xây dựng khung giá mua đầu vào cho các loại đá§ xây dựng ,kiểm tra quản lý khung giá mua cho từng ncc.§ phân tích lợi nhuận , xây dựng khung giá mua , kiểm tra so sánh giá cả của các ncc, phân tích làm cơ sở cho cấp trên quyết định lựa chọn ncc phù hợp .§ kiểm soát thông tin giá mua của tất cả các loại nguyên liệu§ theo dõi tình hình thị trường đá quý, đá bán quý,... cập nhật các thông tin mới về giá cả, mẫu mã sản phẩm…2. phụ trách xử lý mài đá thanh lý. làm việc – theo dõi và thanh toán công nợ mài đá cho ncc§ phân tích tỷ suất giá công mài và giá vốn đá để quyết định các loại đá cần mài§ liên hệ với ncc để xử lý đá mài.§ theo dõi, đôn đốc tiến độ mài đá của ncc theo thời gian hẹn.§ thanh toán công nợ cho ncc sau khi đá mài lại đạt chất lượng được nhập kho, theo hạn thanh toán ncc§ hàng tháng theo dõi và đối chiếu công nợ với ncc§ rà soát và tái ký hợp đồng theo định kỳ3. tham mưu cho cấp trên về việc đánh giá chất lượng, định giá đá mua lại không hóa đơn.§ xác định giá trị thu lại cho đối với hàng hóa nằm trong phạm vi chức năng theo đúng quy định.§ đối với các mặt hàng nằm ngoài chức năng sẽ tiến hành phân tích giá, lập tờ trình đề xuất giá mua lên giám đốc/qlcc nguồn hàng duyệt theo đúng quy định của công ty.4. thực hiện kiểm tra đá theo yêu cầu của cơ quan nhà nước về xác định giá trị tang vật và cung cấp các thông tin liên quan.§ thực hiện các bước để giám định, xác định giá trị các tang vật (các loại đá) do các cơ quan nhà nước cung cấp.§ lập biên bản báo cáo và cung cấp đầy đủ các thông tin liên quan trong phạm vi cho phép khi có yêu cầu.5. thực hiện các công việc do cấp trên giao\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "trình độ học vấn· \n",
      "================================================\n",
      "data-02-06/809/data.html\n",
      "description summary similar job\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2527/data.html\n",
      "mô tả công việc\n",
      "- nghiên cứu và phát triển các thuật toán, mô hình nhận dạng ảnh về lĩnh vực thị giác máy tính, xử lý hình ảnh, xử lý ngôn ngữ tự nhiên.- nghiên cứu và áp dụng các công nghệ mới nhất trong lĩnh vực thị giác máy tính vào các bài toán ứng dụng trong lĩnh vực giáo dục, y tế, giám sát an ninh...- tham gia vào đội triển khai và cải tiến các thuật toán và mô hình theo yêu cầu ứng dụng trong thực tế.- kết hợp với team ai của công ty và của đối tác viettel tiến hành các nội dung nghiên cứu và phát triển sản phẩm ai.- giải quyết các bài toán về machine learning, deep learning, bigdata khác.- các công việc liên quan khác theo yêu cầu của trưởng bộ phận.\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "+ nam/nữ; tốt nghiệp các trường đại học chuyên ngành cntt hoặc các ngành khác có liên quan+ có từ 6 tháng - 1 năm kinh nghiệm làm việc ở vị trí tương đương+ có kiến thức cơ sở về các thuật toán ai, machine learning+ biết lập trình một trong các ngôn ngữ python, c/c+++ nhanh nhẹn, chủ động và có khả năng làm việc nhóm\n",
      "quyền lợi\n",
      "+ thu nhập 8-20m/tháng, 2-6 tháng xét tăng lương 1 lần\n",
      "================================================\n",
      "data-02-06/1837/data.html\n",
      "description: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1009/data.html\n",
      "responsible for leading governance, the annual planning cycle, quarterly strategy refresh, and our competitive strategy and response.          additionally, the team is uniquely positioned as an incubator for strategic bets which historically have involved launching key products and partnerships.what the candidate will do          this role reports to the vp of delivery. s/he will have high visibility with senior leadership and a seat at the table for critical meetings and decisions          s/he will be a key partner to the vp of delivery as a facilitator, advisor, creator, and executor of corporate, operating, and competitive strategy. s/he will be at the nexus of information within internal business partners at a global, regional and local level. key responsibilities will include:strategy: work closely with the leadership team to co-create, align and iterate on the overall vision & strategy for the delivery department.planning: support annual and quarterly planning while working to build out operational reporting, objectives and key results, projections, and key business metrics to inform the leadership and the entire org of where the business stands.competitive analysis: support full lifecycle of competitive data tracking and analysis for the region, from data vendor procurement and insights generation to understanding of regional and market-level competitor strategiesgovernance: support nationwide governance, including monthly and quarterly business reviewsprogram / project management: support the growth of strategic bets that are being incubated or require strategic leadership and support across the countryleadership stakeholder management: foster strong working relationships with leaders from cross-functional teams (marketing, finance, hr, engineering, product, etc.) and help elevate delivery department’s priorities on their agendawhat the candidate will need5+ years of robust work \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3107/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi tiết công việc quantitative researcher tại pi associate\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2399/data.html\n",
      "description\n",
      "\n",
      "\n",
      "tham gia trực tiếp vào team dự án phát triển và triển khai hệ thống odoo nội bộ và dự án cho các khách hàng (là các doanh nghiệp nhật tại việt nam và các doanh nghiệp, tập đoàn lớn tại nhật bản (tập đoàn sojitz, tập đoàn nissho japan)).\n",
      "hiện tại công ty đang nhận hơn 40 request dự án từ các doanh nghiệp lớn của nhật bản, với nghiệp vụ đa dạng và phức tạp (chủ yếu về lĩnh vực hrm)\n",
      "công việc cụ thể:\n",
      "phụ trách thiết kế chi tiết, lập trình, unit test, xử lý lỗi của chương trình sử dụng ngôn ngữ lập trình python trên framework odoo.\n",
      "kết hợp với ba, tester, operator và các bên liên quan để xây dựng hệ thống cho khách hàng, giải quyết các nhu cầu chuyển đổi số, phục vụ sự phát triển kinh doanh của khách hàng.\n",
      "thực hiện coding, lập trình các module, fix bugs,..  theo \n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "các công việc khác được giao bởi project manager và group leader.\n",
      "\n",
      "\n",
      "your skills and experience\n",
      "\n",
      "\n",
      "thành thạo ngôn ngữ python. có từ\n",
      "================================================\n",
      "data-02-06/1140/data.html\n",
      "mô tả công việc\n",
      "a. bạn sẽ được làm gì:\n",
      "• thu thập, phân tích và diễn giải các bộ dữ liệu lớn để xác định xu hướng, mẫu và thông tin chi tiết.\n",
      "• thiết kế, phát triển và thực hiện trực quan hóa dữ liệu, bảng chỉ số và báo cáo để hỗ trợ các quyết định kinh doanh và truyền đạt thông tin chi tiết cho các bên liên quan nội bộ và bên ngoài.\n",
      "• viết và xuất bản các bài báo, sách trắng và các bản thuyết trình để quảng bá các sản phẩm và giải pháp công nghệ tài chính.\n",
      "• cộng tác với các nhóm liên chức năng để xác định và ưu tiên các nhu cầu phân tích dữ liệu.\n",
      "• luôn cập nhật những phát triển của ngành, xu hướng thị trường và các công nghệ mới.\n",
      "• trình bày các phát hiện và khuyến nghị cho quản lý cấp cao, các bên liên quan và khách hàng.\n",
      "• hỗ trợ quản lý cấp cao soạn thảo đề xuất, gặp gỡ khách hàng và các công việc phát triển kinh doanh khác.\n",
      "b. bạn sẽ được học gì/ thử thách gì\n",
      "• cơ hội được đào tạo nâng cao nghiệp vụ thường xuyên.\n",
      "• có cơ hội tiếp cận, làm việc và đào tạo về tài chính, chứng khoán.\n",
      "yêu cầu\n",
      "• tốt nghiệp đại học chuyên ngành tài chính, đầu tư, kiểm toán & kế toán, kinh tế hoặc lĩnh vực liên quan.\n",
      "• có ít nhất 3 năm \n",
      "-----------------------------------------------\n",
      "kinh nghiệm trong lĩnh vực phân tích và trình bày dữ liệu tài chính.\n",
      "• kỹ năng giao tiếp bằng văn bản và bằng lời nói xuất sắc (đặc biệt là bằng tiếng anh), với khả năng truyền đạt rõ ràng thông tin chi tiết về dữ liệu phức tạp cho các bên liên quan phi kỹ thuật.\n",
      "• khả năng làm việc độc lập đã được chứng minh và là một phần của nhóm.\n",
      "• kỹ năng giải quyết vấn đề và tư duy phản biện mạnh mẽ.\n",
      "• kiến thức về sql, python và kho dữ liệu là một lợi thế.\n",
      "• kiến thức về các công cụ báo cáo và trực quan hóa dữ liệu như power point, tableau, powerbi hoặc tương tự là một lợi thế.\n",
      "• có kinh nghiệm tư vấn, tư vấn và nghiên cứu là một lợi thế.\n",
      "• acca/cfa là một lợi thế.\n",
      "chế độ\n",
      "• thu nhập hàng tháng: theo năng lực, có thể thỏa thuận. tháng lương 13.\n",
      "• thưởng năm theo năng lực, thưởng dự án và các mức thưởng khác theo quy chế thu nhập.\n",
      "• các khoản phúc lợi: thưởng lễ, tết, … bằng tiền theo thỏa ước lao động tập thể.\n",
      "• chính sách bhxh, bhyt, bhtn, kpcđ và các phúc lợi khác theo đúng quy định của luật lao động và của công ty.\n",
      "• 14-16 ngày phép/ năm so với trung bình 12 ngày phép/năm trên thị trường.\n",
      "• làm việc trong môi trường năng động, có cơ hội được đào tạo nâng cao nghiệp vụ thường xuyên.\n",
      "• có cơ hội tiếp cận, làm việc trong môi trường tài chính, chứng khoán.\n",
      "• được đào tạo về kỹ năng chuyên môn và kiến thức kinh tế, tài chính, hàng hóa.\n",
      "• trợ cấp internet khi làm việc tại nhà do ảnh hưởng của dịch bệnh covid.\n",
      "• đối với senior: được đóng bảo hiểm y tế của bảo hiểm bưu điện\n",
      "• cơ hội thăng tiến sớm cho cá nhân tiêu biểu.\n",
      "• khung giờ làm việc linh hoạt.\n",
      "• trợ cấp các loại tuỳ theo đối tượng: phụ cấp điện thoại, phụ cấp gửi xe ô tô, trợ cấp kết hôn.\n",
      "gửi cv\n",
      " email liên hệ: talents@fiingroup.vn \n",
      "================================================\n",
      "data-02-06/1784/data.html\n",
      "description\n",
      "\n",
      "\n",
      "life at agoda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "all teams\n",
      "contentcustomer \n",
      "-----------------------------------------------\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "people analytics manager (bangkok based, relocation provided)\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "================================================\n",
      "data-02-06/2635/data.html\n",
      "================================================\n",
      "data-02-06/2515/data.html\n",
      "description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "view all jobs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "view our website\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about the companyglobal fashion group (gfg) is the leading fashion and lifestyle retail destination in asia pacific, latin america and cis. we connect over 10,000 global, local and own brands to a market of more than one billion consumers through four established e-commerce platforms: the iconic, zalora, dafiti and lamoda.through an inspiring and seamless customer \n",
      "-----------------------------------------------\n",
      "experience enabled by our own technology ecosystem and operational infrastructure, we are setting the benchmark in online fashion & lifestyle in our markets, and our vision is to be the #1 online destination for fashion & lifestyle in growth markets.\n",
      "================================================\n",
      "data-02-06/1968/data.html\n",
      "================================================\n",
      "data-02-06/2425/data.html\n",
      "================================================\n",
      "data-02-06/1030/data.html\n",
      "mô tả công việc:\n",
      "\n",
      "\n",
      "\n",
      "- nghiên cứu dữ liệu nghiệp vụ, phân tích dữ liệu \n",
      "-----------------------------------------------\n",
      "kinh nghiệm. xử lý dữ liệu. trực quan hóa các kết quả phân tích dữ liệu.\n",
      "- giải quyết các vấn đề như phát hiện gian lận, cho điểm tín nhiệm, …\n",
      "- kiểm thử hệ thống. xử lý các vấn đề liên quan đến kiểm thử.\n",
      "- phát triển các công cụ tự động hóa cho kiểm thử, kiểm tra xử lý dữ liệu và các công việc liên quan khác.\n",
      "- tham gia các công việc phân tích dữ liệu kinh nghiệm, lập các báo cáo phân tích tài chính, mô hình hóa sản phẩm theo các yêu cầu nghiệp vụ trên hệ thống phần mềm prophet chuyên biệt.\n",
      "- hỗ trợ các công việc phân tích kỹ thuật nghiệp vụ bảo hiểm nhân thọ, thực hiện các công việc liên quan đến xây dựng các tính năng kỹ thuật của sản phẩm trên hệ thống cntt\n",
      "\n",
      "================================================\n",
      "data-02-06/2122/data.html\n",
      "mô tả công việc- tham gia các cuộc họp và tham vấn cùng các cấp quản lý các chiến lược kinh doanh dựa trên các báo cáo, nghiên cứu thị trường, v.v.\n",
      "- khảo sát trên thị trường, phân tích đối thủ, bài toán kinh doanh, thực hiện các báo cáo liên quan\n",
      "- lập kế hoạch kinh doanh chi tiết\n",
      "- theo dõi kế hoạch và thực hiện báo cáo đánh giá hiệu quả kinh doanh định kỳ\n",
      "- nghiên cứu và phát hiện kịp thời các nhận định đặc biệt về thị trường, khách hàng, hàng hóa và đề xuất hướng xử lý\n",
      "- là đầu mối làm việc của bods với các phòng/ban, đốc thúc và theo dõi các dự án và mục tiêu kinh doanh đúng tiến độ và chất lượng theo yêu cầu.\n",
      "- phối hợp với các phòng ban supply chain, vận hành, marketing… để đảm bảo việc hỗ trợ các team\n",
      "- xử lý các công việc khác theo hướng dẫn của giám đốc.\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2142/data.html\n",
      "description\n",
      "\n",
      "\n",
      "research, understand and propose novel methods for computer vision tasks related to 3d space\n",
      "research, propose, implement, and test 3d mapping algorithms\n",
      "catch up and understand the state-of-the-art studies, especially in the 3d domain\n",
      "analyze the issues and give ideas to improve the current system\n",
      "survey and understand the advantage/disadvantages of competitors\n",
      "\n",
      "\n",
      "your skills and \n",
      "-----------------------------------------------\n",
      "experience\n",
      "\n",
      "\n",
      "the ideal candidate should have a degree in computer science, mathematics, or a related field, with a minimum of 3 years of experience in machine learning and deep learning\n",
      "at least 3 years of experience working as an ai engineer, ai researcher, or data scientist position\n",
      "at least 2 years of experience working on 3d computer vision domains such as 3d object detection, depth estimation, or 3d mesh reconstruction\n",
      "experience in 3d data processing such as depth information, point cloud, etc.\n",
      "solid foundation in probability, linear algebra, and space geometry\n",
      "deep understanding of the multi-view geometry of the camera, a variety of matrix factorization algorithms, linear equation solutions, and spatial coordinate transformations in different coordinate systems\n",
      "experience in deploying deep learning models onto real environments such as edge devices\n",
      "proficient in frameworks such as pytorch or tensorflow\n",
      "proficient in python. c/c++ is a plus\n",
      "good logical and critical thinking skills, hard-working and responsible at work\n",
      "able to communicate and work in a team\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "\n",
      "competitive salary: up to $2500\n",
      "14 months' salary a year\n",
      "opportunity to receive bonus shares.\n",
      "to fully participate in the regimes prescribed by the state such as social insurance, health insurance, unemployment insurance, and annual leave.\n",
      "be trained and work directly with experienced experts in the field of ai.\n",
      "have the opportunity to do challenging things, develop your full potential\n",
      "participate in team building sessions, travel 2-3 times/year, and have fun monthly with the company;\n",
      "enjoy full benefits (happiness, birthday...);\n",
      "young, comfortable working environment, dynamic startup spirit.\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/670/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responsibilities\n",
      "attend all courses and complete all tasks assigned by team leaders. \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2303/data.html\n",
      "mô tả công việc\n",
      "\n",
      "we are building a collaborative activation platform to connect high-profile social media users with fortune 500 brands, and deliver effective authentic content to target market demographics. we are looking for a data engineer with a passion for getting things done, to join our team based in ho chi minh. while this is an individual contributor role, you’ll be involved in many aspects– helping evolve our existing architecture, working with teams to improve operations, and implementing new features and functionality.duties & responsibilities\n",
      "build and maintain optimal data pipeline architecture.\n",
      "build infrastructure to acquire, enrich and analyze data to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\n",
      "develop one-off and on-going crawlers system to acquire data from social networks.\n",
      "integrate machine learning/deep-learning predictive models from data science team into data pipelines.\n",
      "implement basic/naive text-based detectors/classifiers.\n",
      "continuously improve the system: performance, availability, scalability, ...\n",
      "transform and export data to data analysts, data science team for internal processes.\n",
      "generate reports based on requirements from business side.\n",
      "“you build it, you run it”: configure, deploy and monitor the data pipelines with support from its/devops build and maintain optimal data pipeline architecture.\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "\n",
      "solid knowledge and experience working with relation databases.\n",
      "\n",
      "strong knowledge and experience working with python programming language.\n",
      "experience working with linux/unix, google cloud platform environment.\n",
      "working knowledge of message queue, stream processing, and highly scalable data storage.\n",
      "experience working with celery, elasticsearch or flask is a plus.\n",
      "experience working with git is a plus.\n",
      "\n",
      "\n",
      "tại sao bạn sẽ yêu thích làm việc tại đây\n",
      "\n",
      "\n",
      "opportunity to be onsite in us\n",
      "company-sponsored macbook\n",
      "flexible vacation schedule\n",
      "flexible work hours\n",
      "office happy hours\n",
      "a family of exceptional developers\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/773/data.html\n",
      "description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact info\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "position overview: the core function is tracking quarterly price movements, primary and secondary supply in all property market asset classes.\n",
      "\n",
      "\n",
      "multiple tasks include:\n",
      "\n",
      "variable population growth forecast modelling: provincial, district and development area level.\n",
      "analyze projected office and residential demand and supply gaps.\n",
      "support demand forecasts on related property segments: resort, residential, retail etc.\n",
      "analysis of asking and sold price deviation.\n",
      "monthly updates of price band by asset class.\n",
      "\n",
      "\n",
      "\n",
      "interns' duties:\n",
      "\n",
      "update market information via calls, internet search, site inspections and other sources.\n",
      "assist in the preparation of departmental events, and support event reception.\n",
      "support analysis.\n",
      "translation.\n",
      "\n",
      "apply now\n",
      "please fill out our presurvey and attach your cv here:\n",
      "https://www.savills.com.vn/forms/internship-program-application-form.aspx\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hanh luu tuyet\n",
      "\n",
      "\n",
      "hr senior managerhr & administrationhanoi\n",
      "\n",
      "+84 24 7301 9888\n",
      "\n",
      "\n",
      "contact now\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2268/data.html\n",
      "mô tả công việc\n",
      "\n",
      "\n",
      "manage forecast process and demand plan kpis.\n",
      "monitor actual sales performance to plan and communicate as appropriate.\n",
      "manage demand plan database to ensure the integrity of data used for analysis.\n",
      "monitor and reviews historical sales and promotion impact, as well as pipelining assumptions, to continuously improve forecast accuracy, and to provide contingency plans for management teams.\n",
      "manage supply planning and inventory control to ensure stock availability and adequate stock as target.\n",
      "manage and collaborate with replenishment team to develop replenishment strategies\n",
      "manage the demand plan and align to the consumption-based planning to drive forecast error improvements.\n",
      "proactively manage forecast changes, identify root cause for what is happening to variances and how to correct it\n",
      "analyse forecast accuracy, ensuring seasonal forecasts/builds are correctly input in the board planning system. specific activities to include, but not limited to seasonal/event programs, never out of stock programs, new item configurations and replenishment profiles.\n",
      "analyse sales and inventory performance to identify trends and proactively correct systems disconnects, before out-of-stock instances occur.\n",
      "lead meetings with the replenishment team to ensure all key metrics are achieved along with planning for future sales and key moments.\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu công việc\n",
      "\n",
      "\n",
      "university graduate or equivalent\n",
      "fluent in english speaking and writing. good office computer skills and data management.\n",
      "demonstrated strong ability to manage and analyze and interpret complex problems/data gathered from a variety of sources and, through effective decision-making and planning, delivers superior business solutions.\n",
      "understand organizational structure, operating culture, effective work styles, and achieving results in a changing environment.\n",
      "\n",
      "\n",
      "\n",
      "job tags:\n",
      "replenishment analyst\n",
      "replenishment analyst\n",
      "analyst\n",
      "merchandise\n",
      "\n",
      "================================================\n",
      "data-02-06/1942/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            - identifying growth insights & opportunities which lead to transformational actions\n",
      "- distilling insight from primary and secondary research/data to drive growth in the business.\n",
      "- build and give a clear point of view from analyses as well as the outcome of research studies. you should then be able to articulate this point of view to key stakeholders and drive recommendations going forward.\n",
      "- independently manage conversations with marketers and senior cmi colleagues, to land/persuade on key business recommendations.\n",
      "- building knowledge of key markets, the category and consumers to inspire and inform projects; including bringing in and feeding the nuances of the local culture.\n",
      "- work closely with agency partners, using various sources of data (includingdigital/social) to identify trends, opportunities and threats.\n",
      "- developing your own research skills, making full use of: cmi portal, cmi guidelines tools and templates, \n",
      "-training opportunities, coaching/ mentoring from line manager\n",
      "- building own understanding of key business processes e.g. category/brand strategy,\n",
      "- integrated brand planning (ibp), innovation and renovation (ipm), communication (ibc)\n",
      "- be able to work and build a relationship with teams and colleagues within vietnam beauty & wellbeing\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2375/data.html\n",
      "mô tả công việc\n",
      " we are looking for a talented data engineer to join our team and work on developing an internal enterprise chatbot using gpt and llama models.the ideal candidate will be responsible for designing, building, and maintaining the data pipeline for the project, ensuring that data is available, reliable, and accurate for machine learning models.key responsibilities:design, build, and maintain the data pipeline for machine learning modelsdevelop and maintain data pipelines for processing and storing large amounts of datacollaborate with data scientists and machine learning engineers to ensure data is ready for use by the chatbot.design and implement data models and schema to support the chatbot's natural language processing capabilities.develop and maintain data quality standards and processes to ensure data accuracy and completeness.ensure data security and compliance with data privacy regulations.continuously monitor and optimize the performance of the data infrastructure and pipelinesprovide technical guidance and support to other team members as needed. \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2237/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việc\n",
      "build, develop and optimize data storage systems: datawarehouse, data lake, data model, bi,downstream system, ....- integrate all data sources from application systems into data warehouse/data lake.- support business units when there is a need to exploit data from the mis/dw system.- perform analysis of data models, prediction, forecast, analysis reports, etc.- report periodically as prescribed or the request of direct manager.- participate in data warehouse/data lake projects as assigned\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "graduated from a regular university, with priority in it, computer science, information systems,economic informatics, finance – banking, ...- have 2+ years of experience in data warehouse construction.- have good knowledge of database management systems and data modeling.\n",
      "quyền lợi\n",
      "salary: negotiable (unlimited)- competitive and fair environment, promoting multi-capacity.- salary review: 02 times/year, fixed in april and october every year; sudden increase in salary...- insurance regime: social insurance, health insurance, unemployment insurance fully according to theregulations of the state- annual health check-up- annual vbi health care insurance.- various bonuses: money saving, 13th month bonus, lunar new year bonus, holiday/tet bonus, lastbusiness bonus years, excellent staff, deep knowledge, initiative....- support for parking, laptop, personal computer....- working time: from monday to friday; saturday morning is not required to go to the timekeepingoffice.- participate in activities: events, conferences, seminars on technology... and internal programs set atthe office.- training mode: to participate in internal training programs, certificates according to demand to serveundertaking work.- tourism and vacation activities: 01 time/year. team building: 02 times/year- free tea, coffee, snacks at the office\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 08/06/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2770/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            job summary:\n",
      "\n",
      "this job is to collect data relating to real estate project, legal update, infrastructure development by contacting sales agents, agencies or using personal network. senior market intelligence executive are also responsible for conducting research on appropriate investments, running feasibility study of project.\n",
      "\n",
      "key responsibilities :\n",
      "\n",
      "- collect data on real estate sectors and analysis data for pricing trend, demand & supply, legal updates, etc.\n",
      "- conducting extensive research on competitors' products and services\n",
      "- conduct pre-feasibility analysis of site - real estate factors, business estimate, suitability of project requirement\n",
      "- perform duties as assigned by line management\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/546/data.html\n",
      "mô tả công việc:- chịu trách nhiệm (i) hỗ trợ xây dựng, triển khai cơ sở dữ liệu, báo cáo; (ii) thực hiện báo cáo định kỳ và theo yêu cầu; (iii) phân tích dữ liệu phục vụ công tác quản trị.\n",
      "- thực hiện các báo định kỳ/đột xuất;\n",
      "- phân tích dữ liệu phục vụ công tác quản trị;\n",
      "- đóng góp cải tiến việc tự động hóa thu thập và xử lý, dữ liệu;\n",
      "- định kỳ kiểm tra dữ liệu từ các hệ thống để đảm bảo tính chính xác của báo cáo;\n",
      "- thực hiện các nhiệm vụ khác theo phân công của cấp quản lý.yêu cầu:- trình độ cử nhân trở lên, ưu tiên chuyên ngành tài chính, ngân hàng, kinh tế, kế toán, công nghệ thông tin, tin học;\n",
      "- tối thiểu 7 năm (chuyên gia)/ 5 năm (chuyên viên cao cấp)/ 3 năm (chuyên viên chính)/ 2 năm (chuyên viên)/ưu tiên có (nhân viên) \n",
      "-----------------------------------------------\n",
      "kinh nghiệm làm việc trong lĩnh vực tài chính, ngân hàng tại các tổ chức dịch vụ tài chính liên quan đến xử lý dữ liệu hệ thống, phân tích dữ liệu, lập báo cáo;\n",
      "- tối thiểu 1 năm kinh nghiệm làm việc trong lĩnh vực lập trình vba trên excel: khả năng advance/excellent;\n",
      "- kinh nghiệm lập trình và cấu trúc dữ liệu cơ bản;\n",
      "- kiến thức sql căn bản;\n",
      "- kỹ năng phân tích, quản lý hoạt động và quản lý thời gian tốt; tư duy logic;\n",
      "- kỹ năng tiếng anh cơ bản (ưu tiên).\n",
      "================================================\n",
      "data-02-06/2805/data.html\n",
      "responsible for human resource management, including personnel recruitment, training new employees opex team;evaluate plans and strategies in the production and service provision of enterprises;direct activities to improve productivity and quality of products and services;manage the process of using products, services, and equipment in the enterprise;optimize the process related to transportation issues;plan and budget for each year and come up with solutions to overcome financial problems;resolving issues related to internal complaints\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/521/data.html\n",
      "description summary similar job\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/200/data.html\n",
      "responsible for developing programs, algorithms and automated processes to cleanse, integrate and evaluate large datasets from disparate sources and implement complex business logic as needed with the available data processing tools.- the job holder will be responsible for helping build a reliable, sustainable and scalable data processing platform, working with other tribe members to support data pipelines, convert models to machine learning codes and recommend big data reporting and visualization applications\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1700/data.html\n",
      "description\n",
      "enabled\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sap as service provider\n",
      "we use the following session cookies, which are all required to enable the website to function:\"route\" is used for session stickiness\"careersitecompanyid\" is used to send the request to the correct data center\"jsessionid\" is placed on the visitor's device during the session so the server can identify the visitor\"load balancer cookie\" (actual cookie name may vary)  prevents a visitor from bouncing from one instance to another\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/3134/data.html\n",
      "mô tả công việc\n",
      "the data validation specialist is responsible for ensuring the accuracy and consistency of data related to orders and payments.- verify the accuracy of order data between our system and payment providers.- ensure completeness of payment transfers and identify any discrepancies.- conduct regular checks to maintain data accuracy and resolve any errors.- collaborate with teams to address data issues and improve accuracy.- maintain records of data validation processes.- generate reports on data accuracy.this position is based in district 7. standard working hours are from 09:00-18:00 from monday to friday. \n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "- excellent attention to detail and analytical skills.- strong communication and collaboration skills.- ability to work independently and meet deadlines.\n",
      "quyền lợi\n",
      "12 annual days off a year.salary review once a year.birthday party monthly.gifts on international/national holidays. (women's day, valentines,..)annual health check.social security.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 31/07/2023\n",
      "\n",
      "\n",
      "\n",
      "================================================\n",
      "data-02-06/2720/data.html\n",
      "mô tả công việc\n",
      "● tham gia phát triển nền tảng quản lý dữ liệu lớn.● tham gia vào hiệu suất tối ưu cho các truy vấn data trên lượng dự liệu lớn.● xử lý các yêu cầu trung bình đến khó trong dự án.● đưa ra các ý tưởng cải tiến hiệu năng, tối ưu chi phí cho toàn hệ thống.● thời gian làm việc: thứ 2 – thứ 6 (sáng: 8h00-12h00; chiều: 13h30-17h30)\n",
      "\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên\n",
      "● kiến thức:- tốt nghiệp cử nhân chuyên ngành công nghệ thông tin, điện tử viễn thông, tài chính, ngân hàng, kinh tế hoặc tương đương. ưu tiên ứng viên có bằng tốt nghiệp loại giỏi hoặc tốt nghiệp tại nước ngoài- ưu tiên có các chứng chỉ chuyên nghành data engineer, data analytics, data science cho xử lý dữ liệu lớn● kinh nghiệm:- tối thiểu 1.5 năm kinh nghiệm làm việc trực tiếp tại các công ty, dự án về de- có kiến thức về kiến trúc vật lý, kiến trúc logic, thành phần cơ bản của hadoop eco-sys: tầng ingesstion, tầng processing, tầng consumtion- có kiến thức và kinh nghiệm sử dụng spark etl with scala, python trên hadoo eco-sys- có kiến thức và kinh nghiệm tối ưu luồng xử lí data: landing zone, working zone, gold zone, các kỹ thuật thiết kế job tối ưu cho dữ liệu lớn, kỹ thuật orchestration luồng job- có kiến thức và kinh nghiệm về các db sau: sql, nosql, graph- có kiến thức và kinh nghiệm flask, fastapi, gunicorn- có kiến thức và kinh nghiệm tableau/ powerbi- có kiến thức và kinh nghiệm unit testing, integration testing, functional testing, a/b testing, \n",
      "================================================\n",
      "data-02-06/1899/data.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mô tả công việctham gia nghiên cứu, phát triển các sản phẩm của công ty trong lĩnh vực computer vision, đặc biệt với ai art generator, stable diffusionxây dựng, phát triển team aitích hợp ai vào các sản phẩm thương mại (xử lý video, image) của công tynghiên cứu, update công nghệ mớicác công việc khác liên quan đến lĩnh vực computer vision\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viêntốt nghiệp master ngành computer visionít nhất 2-3 năm kinh nghiệm làm sản phẩm thực tế trong ngành computer visionquen thuộc với pytorch, keras, tensorflowcó kinh nghiệm finetune, tối ưu modeltrung thực, trách nhiệm, có khả năng làm việc độc lập tốt và có tinh thần làm việc nhómquyền lợimức offer upto 3000 usdcontribute vào sản phẩm công nghệ có vision tầm cỡ thế giớiđược quyền quyết định, định hướng công nghệtham gia trực tiếp nghiên cứu, định hướng, phát triển sản phẩmcơ chế đãi ngộ tập trung vào phát triển nhân tài và xây dựng theo concept gia tốc: nhân sự top đầu tăng lương gấp 6 lần nhân sự top dưới.thưởng 4-6 tháng lương 1 năm với nhân sự top đầu.bổ nhiệm ngay khi có chiến công đặc biệt.tham gia đầy đủ các chế độ bhxh, bhyt, bhtn.các gói bảo hiểm ngoài bhxh: bảo hiểm pti, khám sức khỏe định kỳ hàng nămvăn hóa làm việc genz,môi trường làm việc trẻ trung, sáng tạo, dám nghĩ - dám làm, trà đá, bàn tròn, ném đá sếp, áp dụng triệt để văn hóa 6k startup, tsb3c.thực chiến cùng quản lý, chuyên gia từ các tập đoàn lớn: topica, vng, samsung,...du lịch hàng năm, team building, tea break hàng tuầncách thức ứng tuyểnứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.hạn nộp hồ sơ: 08/05/202\n",
      "================================================\n",
      "data-02-06/2989/data.html\n",
      "mô tả công việc• build financial models to review profitability.\n",
      "• coordinate management team with current/potential investors which include to prepare pitch deck & update monthly/yearly reports to investors.\n",
      "• participate in setting and budgeting for each bu; group.\n",
      "• prepare and check period-end data from accountants to make periodical reports.\n",
      "• ensure payment records are in line and within budget\n",
      "• monitor and update cash flow monthly.\n",
      "• support finance manager to optimize cash flow.\n",
      "-----------------------------------------------\n",
      "yêu cầu công việcuniversity degree in finance, accounting or related disciplines\n",
      "have at least 4 years of experience\n",
      "systematic thinking\n",
      "excellent communication, grasping and problem-solving skills\n",
      "preference will be given to candidates who are proficient at power bi, vba, excel at excel\n",
      "having experience in building process, work management system such as: oracle, sap, base, 1office is an advantageđịa điểm làm việc35/2 nguyễn văn hưởng, phường thảo điền - quận 2 - thành phố thủ đức, hcm\n",
      "================================================\n",
      "data-02-06/791/data.html\n",
      "description \n",
      "\n",
      "job responsibilities (include, but not limited to the following):\n",
      "– participate in architecture, design and implementation of large-scale distributed system that extract data.\n",
      "– perform data scraping, cleansing, curation, parsing, integration, semantic mapping and enrichment.\n",
      "– create and maintain documentation and technical specs.\n",
      "– perform analysis and monitoring on datasets to ensure completeness and integrity.\n",
      "– coordinate project-related work with researchers and engineering teams.\n",
      "– manage, monitor and mentor the effort of data pipeline including agent configuration and data publishing.\n",
      "job qualifications:\n",
      "– exceptional academic background with bachelor’s degree or higher in computer science or computer engineering.\n",
      "– \n",
      "-----------------------------------------------\n",
      "experience in web crawling and/or scraping skills with or without a framework\n",
      "– experience in software development life cycle and developing large scale software systems\n",
      "– proficiency in high level language such as python, java or perl\n",
      "– proficiency in a query language and using sql\n",
      "– experience in programming and working in aws infrastructure\n",
      "– excellent verbal and written communication skills in both vietnamese and english\n",
      "– machine learning research and nlp experience is a great plus\n",
      "rewards:\n",
      "– competitive compensation package\n",
      "– collaborating with talented software engineers\n",
      "– formulate and execute projects that will have a real impact\n",
      "– improve your personal and technical skills\n",
      "\n",
      "================================================\n",
      "data-02-06/1499/data.html\n",
      "responsibilities:\n",
      "\n",
      "\n",
      "you are an \n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/1180/data.html\n",
      "================================================\n",
      "data-02-06/2573/data.html\n",
      "mô tả công việc\n",
      "\n",
      "                                                                                            objectives\n",
      "•\tthực hiện quá trình số hóa công tác quản trị rủi ro \n",
      "•\ttối ưu hóa hiệu quả nguồn lực và năng suất quản trị rủi ro. \n",
      "•\tđẩy mạnh sự chủ động trong công tác phát hiện và phòng ngừa gian lận\n",
      "\n",
      "responsibilities\n",
      "•\txây dựng phương pháp luận, quy định, quy trình phân tích dữ liệu để phát hiện gian lận. \n",
      "•\txây dựng các kịch bản/ mô hình phân tích dữ liệu để phát hiện gian lận. \n",
      "•\tphối hợp triển khai, giám sát việc xây dựng mô hình dữ liệu bao gồm luồng dữ liệu, tiêu chí, quản trị dữ liệu, …\n",
      "•\tquản lý, theo dõi tính hiệu quả/ phù hợp và cải tiến liên tục các kịch bản/mô hình phân tích dữ liệu để phát hiện gian lận.\n",
      "•\tvận hành/ triển khai các giải pháp/ hệ thống/ công cụ công nghệ phòng chống gian lận, tự động hóa và hệ thống hóa các cảnh báo/ giới hạn rủi ro\n",
      "•\tcải tiến hệ thống dữ liệu dựa trên những phát hiện trong quá trình quản trị rủi ro.\n",
      "•\tphân tích, đánh giá các tác động đến mô hình dữ liệu của trung tâm quản trị rủi ro và tuân thủ khi có thay đổi về mặt chính sách, quy trình liên quan\n",
      "•\tphát triển các thành viên trong nhóm về các kỹ năng mềm và chuyên môn của họ để xác định, phân tích, đánh giá và ứng phó với rủi ro\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "-----------------------------------------------\n",
      "\n",
      "================================================\n",
      "data-02-06/2645/data.html\n",
      "================================================\n",
      "data-02-06/1898/data.html\n",
      "mô tả công việc- interpret data, analyze results using statistical techniques and provide ongoing reports\n",
      "- develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality\n",
      "- acquire data from primary or secondary data sources and maintain databases/data systems\n",
      "- identify, analyze, and interpret trends or patterns in complex data sets\n",
      "- filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems\n",
      "- work with management to prioritize business and information needs\n",
      "- locate and define new process improvement opportunities\n",
      "-----------------------------------------------\n",
      "yêu cầu ứng viên- proven working experience as a data analyst or business data analyst\n",
      "- technical expertise regarding data models, database design development, data mining and segmentation techniques\n",
      "- strong knowledge of and experience with reporting packages (business objects etc), databases (sql etc), programming (xml, javascript, or etl frameworks)\n",
      "- knowledge of statistics and experience using statistical packages for analyzing datasets (excel, spss, sas etc)\n",
      "- strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy- adept at queries, report writing and presenting findings\n",
      "- bs in mathematics, economics, computer science, information management or statisticsquyền lợi- attractive salary from 1,000 - 2,000$\n",
      "- the remuneration mechanism focuses on talent development and builds on the concept of acceleration: the top employees will have the opportunities to increase their salary 6 times more than the underrated employees.\n",
      "- bonus 4-6 months salary per year for top employees.\n",
      "- promoted as soon as there is a special achievement in work.\n",
      "- fully benefits in social insurance, health insurance and unemployment insurance regimes.\n",
      "- extra insurance packages: pti insurance, annual health check per year\n",
      "- genz working culture: young, creative working environment, dare to think - dare to do, dynamic discussion , round table discussion, completely straight discussion with boss, \n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47f8f26f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86dc8dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DataFrame in module pandas.core.frame:\n",
      "\n",
      "class DataFrame(pandas.core.generic.NDFrame, pandas.core.arraylike.OpsMixin)\n",
      " |  DataFrame(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, copy: 'bool | None' = None) -> 'None'\n",
      " |  \n",
      " |  Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
      " |  \n",
      " |  Data structure also contains labeled axes (rows and columns).\n",
      " |  Arithmetic operations align on both row and column labels. Can be\n",
      " |  thought of as a dict-like container for Series objects. The primary\n",
      " |  pandas data structure.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
      " |      Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
      " |      data is a dict, column order follows insertion-order. If a dict contains Series\n",
      " |      which have an index defined, it is aligned by its index. This alignment also\n",
      " |      occurs if data is a Series or a DataFrame itself. Alignment is done on\n",
      " |      Series/DataFrame inputs.\n",
      " |  \n",
      " |      If data is a list of dicts, column order follows insertion-order.\n",
      " |  \n",
      " |  index : Index or array-like\n",
      " |      Index to use for resulting frame. Will default to RangeIndex if\n",
      " |      no indexing information part of input data and no index provided.\n",
      " |  columns : Index or array-like\n",
      " |      Column labels to use for resulting frame when data does not have them,\n",
      " |      defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
      " |      will perform column selection instead.\n",
      " |  dtype : dtype, default None\n",
      " |      Data type to force. Only a single dtype is allowed. If None, infer.\n",
      " |  copy : bool or None, default None\n",
      " |      Copy data from inputs.\n",
      " |      For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
      " |      or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
      " |      If data is a dict containing one or more Series (possibly of different dtypes),\n",
      " |      ``copy=False`` will ensure that these inputs are not copied.\n",
      " |  \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  DataFrame.from_records : Constructor from tuples, also record arrays.\n",
      " |  DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
      " |  read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      " |  read_table : Read general delimited file into DataFrame.\n",
      " |  read_clipboard : Read text from clipboard into DataFrame.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  Please reference the :ref:`User Guide <basics.dataframe>` for more information.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  Constructing DataFrame from a dictionary.\n",
      " |  \n",
      " |  >>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |  >>> df = pd.DataFrame(data=d)\n",
      " |  >>> df\n",
      " |     col1  col2\n",
      " |  0     1     3\n",
      " |  1     2     4\n",
      " |  \n",
      " |  Notice that the inferred dtype is int64.\n",
      " |  \n",
      " |  >>> df.dtypes\n",
      " |  col1    int64\n",
      " |  col2    int64\n",
      " |  dtype: object\n",
      " |  \n",
      " |  To enforce a single dtype:\n",
      " |  \n",
      " |  >>> df = pd.DataFrame(data=d, dtype=np.int8)\n",
      " |  >>> df.dtypes\n",
      " |  col1    int8\n",
      " |  col2    int8\n",
      " |  dtype: object\n",
      " |  \n",
      " |  Constructing DataFrame from a dictionary including Series:\n",
      " |  \n",
      " |  >>> d = {'col1': [0, 1, 2, 3], 'col2': pd.Series([2, 3], index=[2, 3])}\n",
      " |  >>> pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
      " |     col1  col2\n",
      " |  0     0   NaN\n",
      " |  1     1   NaN\n",
      " |  2     2   2.0\n",
      " |  3     3   3.0\n",
      " |  \n",
      " |  Constructing DataFrame from numpy ndarray:\n",
      " |  \n",
      " |  >>> df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
      " |  ...                    columns=['a', 'b', 'c'])\n",
      " |  >>> df2\n",
      " |     a  b  c\n",
      " |  0  1  2  3\n",
      " |  1  4  5  6\n",
      " |  2  7  8  9\n",
      " |  \n",
      " |  Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
      " |  \n",
      " |  >>> data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
      " |  ...                 dtype=[(\"a\", \"i4\"), (\"b\", \"i4\"), (\"c\", \"i4\")])\n",
      " |  >>> df3 = pd.DataFrame(data, columns=['c', 'a'])\n",
      " |  ...\n",
      " |  >>> df3\n",
      " |     c  a\n",
      " |  0  3  1\n",
      " |  1  6  4\n",
      " |  2  9  7\n",
      " |  \n",
      " |  Constructing DataFrame from dataclass:\n",
      " |  \n",
      " |  >>> from dataclasses import make_dataclass\n",
      " |  >>> Point = make_dataclass(\"Point\", [(\"x\", int), (\"y\", int)])\n",
      " |  >>> pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
      " |     x  y\n",
      " |  0  0  0\n",
      " |  1  0  3\n",
      " |  2  2  3\n",
      " |  \n",
      " |  Constructing DataFrame from Series/DataFrame:\n",
      " |  \n",
      " |  >>> ser = pd.Series([1, 2, 3], index=[\"a\", \"b\", \"c\"])\n",
      " |  >>> df = pd.DataFrame(data=ser, index=[\"a\", \"c\"])\n",
      " |  >>> df\n",
      " |     0\n",
      " |  a  1\n",
      " |  c  3\n",
      " |  \n",
      " |  >>> df1 = pd.DataFrame([1, 2, 3], index=[\"a\", \"b\", \"c\"], columns=[\"x\"])\n",
      " |  >>> df2 = pd.DataFrame(data=df1, index=[\"a\", \"c\"])\n",
      " |  >>> df2\n",
      " |     x\n",
      " |  a  1\n",
      " |  c  3\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataFrame\n",
      " |      pandas.core.generic.NDFrame\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.indexing.IndexingMixin\n",
      " |      pandas.core.arraylike.OpsMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __dataframe__(self, nan_as_null: 'bool' = False, allow_copy: 'bool' = True) -> 'DataFrameXchg'\n",
      " |      Return the dataframe interchange object implementing the interchange protocol.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      nan_as_null : bool, default False\n",
      " |          Whether to tell the DataFrame to overwrite null values in the data\n",
      " |          with ``NaN`` (or ``NaT``).\n",
      " |      allow_copy : bool, default True\n",
      " |          Whether to allow memory copying when exporting. If set to False\n",
      " |          it would cause non-zero-copy exports to fail.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame interchange object\n",
      " |          The object which consuming library can use to ingress the dataframe.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Details on the interchange protocol:\n",
      " |      https://data-apis.org/dataframe-protocol/latest/index.html\n",
      " |      \n",
      " |      `nan_as_null` currently has no effect; once support for nullable extension\n",
      " |      dtypes is added, this value should be propagated to columns.\n",
      " |  \n",
      " |  __divmod__(self, other) -> 'tuple[DataFrame, DataFrame]'\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  __init__(self, data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, copy: 'bool | None' = None) -> 'None'\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __len__(self) -> 'int'\n",
      " |      Returns length of info axis, but here we use the index.\n",
      " |  \n",
      " |  __matmul__(self, other: 'AnyArrayLike | DataFrame') -> 'DataFrame | Series'\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5.\n",
      " |  \n",
      " |  __rdivmod__(self, other) -> 'tuple[DataFrame, DataFrame]'\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return a string representation for a particular DataFrame.\n",
      " |  \n",
      " |  __rmatmul__(self, other) -> 'DataFrame'\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5.\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  add(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None)\n",
      " |      Get Addition of dataframe and other, element-wise (binary operator `add`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe + other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `radd`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  agg = aggregate(self, func=None, axis: 'Axis' = 0, *args, **kwargs)\n",
      " |  \n",
      " |  aggregate(self, func=None, axis: 'Axis' = 0, *args, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list or dict\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list of functions and/or function names, e.g. ``[np.sum, 'mean']``\n",
      " |          - dict of axis labels -> functions, function names or list of such.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |              If 0 or 'index': apply function to each column.\n",
      " |              If 1 or 'columns': apply function to each row.\n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series or DataFrame\n",
      " |      \n",
      " |          The return can be:\n",
      " |      \n",
      " |          * scalar : when Series.agg is called with single function\n",
      " |          * Series : when DataFrame.agg is called with a single function\n",
      " |          * DataFrame : when DataFrame.agg is called with several functions\n",
      " |      \n",
      " |          Return scalar, Series or DataFrame.\n",
      " |      \n",
      " |      The aggregation operations are always performed over an axis, either the\n",
      " |      index (default) or the column axis. This behavior is different from\n",
      " |      `numpy` aggregation functions (`mean`, `median`, `prod`, `sum`, `std`,\n",
      " |      `var`), where the default is to compute the aggregation of the flattened\n",
      " |      array, e.g., ``numpy.mean(arr_2d)`` as opposed to\n",
      " |      ``numpy.mean(arr_2d, axis=0)``.\n",
      " |      \n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Perform any type of operations.\n",
      " |      DataFrame.transform : Perform transformation type operations.\n",
      " |      core.groupby.GroupBy : Perform operations over groups.\n",
      " |      core.resample.Resampler : Perform operations over resampled bins.\n",
      " |      core.window.Rolling : Perform operations over rolling window.\n",
      " |      core.window.Expanding : Perform operations over expanding window.\n",
      " |      core.window.ExponentialMovingWindow : Perform operation over exponential weighted\n",
      " |          window.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      A passed user-defined-function will be passed a Series for evaluation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2, 3],\n",
      " |      ...                    [4, 5, 6],\n",
      " |      ...                    [7, 8, 9],\n",
      " |      ...                    [np.nan, np.nan, np.nan]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      \n",
      " |      Aggregate these functions over the rows.\n",
      " |      \n",
      " |      >>> df.agg(['sum', 'min'])\n",
      " |              A     B     C\n",
      " |      sum  12.0  15.0  18.0\n",
      " |      min   1.0   2.0   3.0\n",
      " |      \n",
      " |      Different aggregations per column.\n",
      " |      \n",
      " |      >>> df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})\n",
      " |              A    B\n",
      " |      sum  12.0  NaN\n",
      " |      min   1.0  2.0\n",
      " |      max   NaN  8.0\n",
      " |      \n",
      " |      Aggregate different functions over the columns and rename the index of the resulting\n",
      " |      DataFrame.\n",
      " |      \n",
      " |      >>> df.agg(x=('A', max), y=('B', 'min'), z=('C', np.mean))\n",
      " |           A    B    C\n",
      " |      x  7.0  NaN  NaN\n",
      " |      y  NaN  2.0  NaN\n",
      " |      z  NaN  NaN  6.0\n",
      " |      \n",
      " |      Aggregate over the columns.\n",
      " |      \n",
      " |      >>> df.agg(\"mean\", axis=\"columns\")\n",
      " |      0    2.0\n",
      " |      1    5.0\n",
      " |      2    8.0\n",
      " |      3    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  align(self, other: 'DataFrame', join: 'AlignJoin' = 'outer', axis: 'Axis | None' = None, level: 'Level' = None, copy: 'bool | None' = None, fill_value=None, method: 'FillnaOptions | None' = None, limit: 'int | None' = None, fill_axis: 'Axis' = 0, broadcast_axis: 'Axis | None' = None) -> 'DataFrame'\n",
      " |      Align two objects on their axes with the specified join method.\n",
      " |      \n",
      " |      Join method is specified for each axis Index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series\n",
      " |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      " |      axis : allowed axis of the other object, default None\n",
      " |          Align on index (0), columns (1), or both (None).\n",
      " |      level : int or level name, default None\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      copy : bool, default True\n",
      " |          Always returns new objects. If copy=False and no reindexing is\n",
      " |          required then original objects are returned.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series:\n",
      " |      \n",
      " |          - pad / ffill: propagate last valid observation forward to next valid.\n",
      " |          - backfill / bfill: use NEXT valid observation to fill gap.\n",
      " |      \n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      fill_axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Filling axis, method and limit.\n",
      " |      broadcast_axis : {0 or 'index', 1 or 'columns'}, default None\n",
      " |          Broadcast values along this axis, if aligning two objects of\n",
      " |          different dimensions.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      tuple of (DataFrame, type of other)\n",
      " |          Aligned objects.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     [[1, 2, 3, 4], [6, 7, 8, 9]], columns=[\"D\", \"B\", \"E\", \"A\"], index=[1, 2]\n",
      " |      ... )\n",
      " |      >>> other = pd.DataFrame(\n",
      " |      ...     [[10, 20, 30, 40], [60, 70, 80, 90], [600, 700, 800, 900]],\n",
      " |      ...     columns=[\"A\", \"B\", \"C\", \"D\"],\n",
      " |      ...     index=[2, 3, 4],\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |         D  B  E  A\n",
      " |      1  1  2  3  4\n",
      " |      2  6  7  8  9\n",
      " |      >>> other\n",
      " |          A    B    C    D\n",
      " |      2   10   20   30   40\n",
      " |      3   60   70   80   90\n",
      " |      4  600  700  800  900\n",
      " |      \n",
      " |      Align on columns:\n",
      " |      \n",
      " |      >>> left, right = df.align(other, join=\"outer\", axis=1)\n",
      " |      >>> left\n",
      " |         A  B   C  D  E\n",
      " |      1  4  2 NaN  1  3\n",
      " |      2  9  7 NaN  6  8\n",
      " |      >>> right\n",
      " |          A    B    C    D   E\n",
      " |      2   10   20   30   40 NaN\n",
      " |      3   60   70   80   90 NaN\n",
      " |      4  600  700  800  900 NaN\n",
      " |      \n",
      " |      We can also align on the index:\n",
      " |      \n",
      " |      >>> left, right = df.align(other, join=\"outer\", axis=0)\n",
      " |      >>> left\n",
      " |          D    B    E    A\n",
      " |      1  1.0  2.0  3.0  4.0\n",
      " |      2  6.0  7.0  8.0  9.0\n",
      " |      3  NaN  NaN  NaN  NaN\n",
      " |      4  NaN  NaN  NaN  NaN\n",
      " |      >>> right\n",
      " |          A      B      C      D\n",
      " |      1    NaN    NaN    NaN    NaN\n",
      " |      2   10.0   20.0   30.0   40.0\n",
      " |      3   60.0   70.0   80.0   90.0\n",
      " |      4  600.0  700.0  800.0  900.0\n",
      " |      \n",
      " |      Finally, the default `axis=None` will align on both index and columns:\n",
      " |      \n",
      " |      >>> left, right = df.align(other, join=\"outer\", axis=None)\n",
      " |      >>> left\n",
      " |           A    B   C    D    E\n",
      " |      1  4.0  2.0 NaN  1.0  3.0\n",
      " |      2  9.0  7.0 NaN  6.0  8.0\n",
      " |      3  NaN  NaN NaN  NaN  NaN\n",
      " |      4  NaN  NaN NaN  NaN  NaN\n",
      " |      >>> right\n",
      " |             A      B      C      D   E\n",
      " |      1    NaN    NaN    NaN    NaN NaN\n",
      " |      2   10.0   20.0   30.0   40.0 NaN\n",
      " |      3   60.0   70.0   80.0   90.0 NaN\n",
      " |      4  600.0  700.0  800.0  900.0 NaN\n",
      " |  \n",
      " |  all(self, axis: 'Axis' = 0, bool_only=None, skipna: 'bool_t' = True, **kwargs)\n",
      " |      Return whether all elements are True, potentially over an axis.\n",
      " |      \n",
      " |      Returns True unless there at least one element within a series or\n",
      " |      along a Dataframe axis that is False or equivalent (e.g. zero or\n",
      " |      empty).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced. For `Series` this parameter\n",
      " |          is unused and defaults to 0.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      bool_only : bool, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire row/column is NA and skipna is\n",
      " |          True, then the result will be True, as for an empty row/column.\n",
      " |          If skipna is False, then NA are treated as True, because these are not\n",
      " |          equal to zero.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If level is specified, then, DataFrame is returned; otherwise, Series\n",
      " |          is returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.all : Return True if all elements are True.\n",
      " |      DataFrame.any : Return True if one (or more) elements are True.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> pd.Series([True, True]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([True, False]).all()\n",
      " |      False\n",
      " |      >>> pd.Series([], dtype=\"float64\").all()\n",
      " |      True\n",
      " |      >>> pd.Series([np.nan]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([np.nan]).all(skipna=False)\n",
      " |      True\n",
      " |      \n",
      " |      **DataFrames**\n",
      " |      \n",
      " |      Create a dataframe from a dictionary.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})\n",
      " |      >>> df\n",
      " |         col1   col2\n",
      " |      0  True   True\n",
      " |      1  True  False\n",
      " |      \n",
      " |      Default behaviour checks if values in each column all return True.\n",
      " |      \n",
      " |      >>> df.all()\n",
      " |      col1     True\n",
      " |      col2    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Specify ``axis='columns'`` to check if values in each row all return True.\n",
      " |      \n",
      " |      >>> df.all(axis='columns')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Or ``axis=None`` for whether every value is True.\n",
      " |      \n",
      " |      >>> df.all(axis=None)\n",
      " |      False\n",
      " |  \n",
      " |  any(self, *, axis: 'Axis' = 0, bool_only=None, skipna: 'bool_t' = True, **kwargs)\n",
      " |      Return whether any element is True, potentially over an axis.\n",
      " |      \n",
      " |      Returns False unless there is at least one element within a series or\n",
      " |      along a Dataframe axis that is True or equivalent (e.g. non-zero or\n",
      " |      non-empty).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced. For `Series` this parameter\n",
      " |          is unused and defaults to 0.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      bool_only : bool, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire row/column is NA and skipna is\n",
      " |          True, then the result will be False, as for an empty row/column.\n",
      " |          If skipna is False, then NA are treated as True, because these are not\n",
      " |          equal to zero.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If level is specified, then, DataFrame is returned; otherwise, Series\n",
      " |          is returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.any : Numpy version of this method.\n",
      " |      Series.any : Return whether any element is True.\n",
      " |      Series.all : Return whether all elements are True.\n",
      " |      DataFrame.any : Return whether any element is True over requested axis.\n",
      " |      DataFrame.all : Return whether all elements are True over requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      For Series input, the output is a scalar indicating whether any element\n",
      " |      is True.\n",
      " |      \n",
      " |      >>> pd.Series([False, False]).any()\n",
      " |      False\n",
      " |      >>> pd.Series([True, False]).any()\n",
      " |      True\n",
      " |      >>> pd.Series([], dtype=\"float64\").any()\n",
      " |      False\n",
      " |      >>> pd.Series([np.nan]).any()\n",
      " |      False\n",
      " |      >>> pd.Series([np.nan]).any(skipna=False)\n",
      " |      True\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Whether each column contains at least one True element (the default).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [0, 2], \"C\": [0, 0]})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  1  0  0\n",
      " |      1  2  2  0\n",
      " |      \n",
      " |      >>> df.any()\n",
      " |      A     True\n",
      " |      B     True\n",
      " |      C    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 2]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  2\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 0]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  0\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the entire DataFrame with ``axis=None``.\n",
      " |      \n",
      " |      >>> df.any(axis=None)\n",
      " |      True\n",
      " |      \n",
      " |      `any` for an empty DataFrame is an empty Series.\n",
      " |      \n",
      " |      >>> pd.DataFrame([]).any()\n",
      " |      Series([], dtype: bool)\n",
      " |  \n",
      " |  apply(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type: \"Literal[('expand', 'reduce', 'broadcast')] | None\" = None, args=(), **kwargs)\n",
      " |      Apply a function along an axis of the DataFrame.\n",
      " |      \n",
      " |      Objects passed to the function are Series objects whose index is\n",
      " |      either the DataFrame's index (``axis=0``) or the DataFrame's columns\n",
      " |      (``axis=1``). By default (``result_type=None``), the final return type\n",
      " |      is inferred from the return type of the applied function. Otherwise,\n",
      " |      it depends on the `result_type` argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Function to apply to each column or row.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis along which the function is applied:\n",
      " |      \n",
      " |          * 0 or 'index': apply function to each column.\n",
      " |          * 1 or 'columns': apply function to each row.\n",
      " |      \n",
      " |      raw : bool, default False\n",
      " |          Determines if row or column is passed as a Series or ndarray object:\n",
      " |      \n",
      " |          * ``False`` : passes each row or column as a Series to the\n",
      " |            function.\n",
      " |          * ``True`` : the passed function will receive ndarray objects\n",
      " |            instead.\n",
      " |            If you are just applying a NumPy reduction function this will\n",
      " |            achieve much better performance.\n",
      " |      \n",
      " |      result_type : {'expand', 'reduce', 'broadcast', None}, default None\n",
      " |          These only act when ``axis=1`` (columns):\n",
      " |      \n",
      " |          * 'expand' : list-like results will be turned into columns.\n",
      " |          * 'reduce' : returns a Series if possible rather than expanding\n",
      " |            list-like results. This is the opposite of 'expand'.\n",
      " |          * 'broadcast' : results will be broadcast to the original shape\n",
      " |            of the DataFrame, the original index and columns will be\n",
      " |            retained.\n",
      " |      \n",
      " |          The default behaviour (None) depends on the return value of the\n",
      " |          applied function: list-like results will be returned as a Series\n",
      " |          of those. However if the apply function returns a Series these\n",
      " |          are expanded to columns.\n",
      " |      args : tuple\n",
      " |          Positional arguments to pass to `func` in addition to the\n",
      " |          array/series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to pass as keywords arguments to\n",
      " |          `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Result of applying ``func`` along the given axis of the\n",
      " |          DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.applymap: For elementwise operations.\n",
      " |      DataFrame.aggregate: Only perform aggregating type operations.\n",
      " |      DataFrame.transform: Only perform transforming type operations.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  4  9\n",
      " |      1  4  9\n",
      " |      2  4  9\n",
      " |      \n",
      " |      Using a numpy universal function (in this case the same as\n",
      " |      ``np.sqrt(df)``):\n",
      " |      \n",
      " |      >>> df.apply(np.sqrt)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  2.0  3.0\n",
      " |      2  2.0  3.0\n",
      " |      \n",
      " |      Using a reducing function on either axis\n",
      " |      \n",
      " |      >>> df.apply(np.sum, axis=0)\n",
      " |      A    12\n",
      " |      B    27\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.apply(np.sum, axis=1)\n",
      " |      0    13\n",
      " |      1    13\n",
      " |      2    13\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Returning a list-like will result in a Series\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1)\n",
      " |      0    [1, 2]\n",
      " |      1    [1, 2]\n",
      " |      2    [1, 2]\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Passing ``result_type='expand'`` will expand list-like results\n",
      " |      to columns of a Dataframe\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
      " |         0  1\n",
      " |      0  1  2\n",
      " |      1  1  2\n",
      " |      2  1  2\n",
      " |      \n",
      " |      Returning a Series inside the function is similar to passing\n",
      " |      ``result_type='expand'``. The resulting column names\n",
      " |      will be the Series index.\n",
      " |      \n",
      " |      >>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n",
      " |         foo  bar\n",
      " |      0    1    2\n",
      " |      1    1    2\n",
      " |      2    1    2\n",
      " |      \n",
      " |      Passing ``result_type='broadcast'`` will ensure the same shape\n",
      " |      result, whether list-like or scalar is returned by the function,\n",
      " |      and broadcast it along the axis. The resulting column names will\n",
      " |      be the originals.\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  1  2\n",
      " |      2  1  2\n",
      " |  \n",
      " |  applymap(self, func: 'PythonFuncType', na_action: 'str | None' = None, **kwargs) -> 'DataFrame'\n",
      " |      Apply a function to a Dataframe elementwise.\n",
      " |      \n",
      " |      This method applies a function that accepts and returns a scalar\n",
      " |      to every element of a DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable\n",
      " |          Python function, returns a single value from a single value.\n",
      " |      na_action : {None, 'ignore'}, default None\n",
      " |          If ‘ignore’, propagate NaN values, without passing them to func.\n",
      " |      \n",
      " |          .. versionadded:: 1.2\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to pass as keywords arguments to\n",
      " |          `func`.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Transformed DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Apply a function along input axis of DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n",
      " |      >>> df\n",
      " |             0      1\n",
      " |      0  1.000  2.120\n",
      " |      1  3.356  4.567\n",
      " |      \n",
      " |      >>> df.applymap(lambda x: len(str(x)))\n",
      " |         0  1\n",
      " |      0  3  4\n",
      " |      1  5  5\n",
      " |      \n",
      " |      Like Series.map, NA values can be ignored:\n",
      " |      \n",
      " |      >>> df_copy = df.copy()\n",
      " |      >>> df_copy.iloc[0, 0] = pd.NA\n",
      " |      >>> df_copy.applymap(lambda x: len(str(x)), na_action='ignore')\n",
      " |           0  1\n",
      " |      0  NaN  4\n",
      " |      1  5.0  5\n",
      " |      \n",
      " |      Note that a vectorized version of `func` often exists, which will\n",
      " |      be much faster. You could square each number elementwise.\n",
      " |      \n",
      " |      >>> df.applymap(lambda x: x**2)\n",
      " |                 0          1\n",
      " |      0   1.000000   4.494400\n",
      " |      1  11.262736  20.857489\n",
      " |      \n",
      " |      But it's better to avoid applymap in that case.\n",
      " |      \n",
      " |      >>> df ** 2\n",
      " |                 0          1\n",
      " |      0   1.000000   4.494400\n",
      " |      1  11.262736  20.857489\n",
      " |  \n",
      " |  asfreq(self, freq: 'Frequency', method: 'FillnaOptions | None' = None, how: 'str | None' = None, normalize: 'bool' = False, fill_value: 'Hashable' = None) -> 'DataFrame'\n",
      " |      Convert time series to specified frequency.\n",
      " |      \n",
      " |      Returns the original data conformed to a new index with the specified\n",
      " |      frequency.\n",
      " |      \n",
      " |      If the index of this DataFrame is a :class:`~pandas.PeriodIndex`, the new index\n",
      " |      is the result of transforming the original index with\n",
      " |      :meth:`PeriodIndex.asfreq <pandas.PeriodIndex.asfreq>` (so the original index\n",
      " |      will map one-to-one to the new index).\n",
      " |      \n",
      " |      Otherwise, the new index will be equivalent to ``pd.date_range(start, end,\n",
      " |      freq=freq)`` where ``start`` and ``end`` are, respectively, the first and\n",
      " |      last entries in the original index (see :func:`pandas.date_range`). The\n",
      " |      values corresponding to any timesteps in the new index which were not present\n",
      " |      in the original index will be null (``NaN``), unless a method for filling\n",
      " |      such unknowns is provided (see the ``method`` parameter below).\n",
      " |      \n",
      " |      The :meth:`resample` method is more appropriate if an operation on each group of\n",
      " |      timesteps (such as an aggregate) is necessary to represent the data at the new\n",
      " |      frequency.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : DateOffset or str\n",
      " |          Frequency DateOffset or string.\n",
      " |      method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
      " |          Method to use for filling holes in reindexed Series (note this\n",
      " |          does not fill NaNs that already were present):\n",
      " |      \n",
      " |          * 'pad' / 'ffill': propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * 'backfill' / 'bfill': use NEXT valid observation to fill.\n",
      " |      how : {'start', 'end'}, default end\n",
      " |          For PeriodIndex only (see PeriodIndex.asfreq).\n",
      " |      normalize : bool, default False\n",
      " |          Whether to reset output index to midnight.\n",
      " |      fill_value : scalar, optional\n",
      " |          Value to use for missing values, applied during upsampling (note\n",
      " |          this does not fill NaNs that already were present).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame object reindexed to the specified frequency.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex : Conform DataFrame to new index with optional filling logic.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To learn more about the frequency strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Start by creating a series with 4 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      " |      >>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
      " |      >>> df = pd.DataFrame({'s': series})\n",
      " |      >>> df\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    NaN\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``fill value``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', fill_value=9.0)\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    9.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    9.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    9.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``method``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', method='bfill')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    2.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    3.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |  \n",
      " |  assign(self, **kwargs) -> 'DataFrame'\n",
      " |      Assign new columns to a DataFrame.\n",
      " |      \n",
      " |      Returns a new object with all original columns in addition to new ones.\n",
      " |      Existing columns that are re-assigned will be overwritten.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **kwargs : dict of {str: callable or Series}\n",
      " |          The column names are keywords. If the values are\n",
      " |          callable, they are computed on the DataFrame and\n",
      " |          assigned to the new columns. The callable must not\n",
      " |          change input DataFrame (though pandas doesn't check it).\n",
      " |          If the values are not callable, (e.g. a Series, scalar, or array),\n",
      " |          they are simply assigned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A new DataFrame with the new columns in addition to\n",
      " |          all the existing columns.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Assigning multiple columns within the same ``assign`` is possible.\n",
      " |      Later items in '\\*\\*kwargs' may refer to newly created or modified\n",
      " |      columns in 'df'; items are computed and assigned into 'df' in order.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'temp_c': [17.0, 25.0]},\n",
      " |      ...                   index=['Portland', 'Berkeley'])\n",
      " |      >>> df\n",
      " |                temp_c\n",
      " |      Portland    17.0\n",
      " |      Berkeley    25.0\n",
      " |      \n",
      " |      Where the value is a callable, evaluated on `df`:\n",
      " |      \n",
      " |      >>> df.assign(temp_f=lambda x: x.temp_c * 9 / 5 + 32)\n",
      " |                temp_c  temp_f\n",
      " |      Portland    17.0    62.6\n",
      " |      Berkeley    25.0    77.0\n",
      " |      \n",
      " |      Alternatively, the same behavior can be achieved by directly\n",
      " |      referencing an existing Series or sequence:\n",
      " |      \n",
      " |      >>> df.assign(temp_f=df['temp_c'] * 9 / 5 + 32)\n",
      " |                temp_c  temp_f\n",
      " |      Portland    17.0    62.6\n",
      " |      Berkeley    25.0    77.0\n",
      " |      \n",
      " |      You can create multiple columns within the same assign where one\n",
      " |      of the columns depends on another one defined within the same assign:\n",
      " |      \n",
      " |      >>> df.assign(temp_f=lambda x: x['temp_c'] * 9 / 5 + 32,\n",
      " |      ...           temp_k=lambda x: (x['temp_f'] + 459.67) * 5 / 9)\n",
      " |                temp_c  temp_f  temp_k\n",
      " |      Portland    17.0    62.6  290.15\n",
      " |      Berkeley    25.0    77.0  298.15\n",
      " |  \n",
      " |  bfill(self, *, axis: 'None | Axis' = None, inplace: 'bool' = False, limit: 'None | int' = None, downcast=None) -> 'DataFrame | None'\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='bfill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  boxplot = boxplot_frame(self, column=None, by=None, ax=None, fontsize=None, rot: 'int' = 0, grid: 'bool' = True, figsize=None, layout=None, return_type=None, backend=None, **kwargs)\n",
      " |      Make a box plot from DataFrame columns.\n",
      " |      \n",
      " |      Make a box-and-whisker plot from DataFrame columns, optionally grouped\n",
      " |      by some other columns. A box plot is a method for graphically depicting\n",
      " |      groups of numerical data through their quartiles.\n",
      " |      The box extends from the Q1 to Q3 quartile values of the data,\n",
      " |      with a line at the median (Q2). The whiskers extend from the edges\n",
      " |      of box to show the range of the data. By default, they extend no more than\n",
      " |      `1.5 * IQR (IQR = Q3 - Q1)` from the edges of the box, ending at the farthest\n",
      " |      data point within that interval. Outliers are plotted as separate dots.\n",
      " |      \n",
      " |      For further details see\n",
      " |      Wikipedia's entry for `boxplot <https://en.wikipedia.org/wiki/Box_plot>`_.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      column : str or list of str, optional\n",
      " |          Column name or list of names, or vector.\n",
      " |          Can be any valid input to :meth:`pandas.DataFrame.groupby`.\n",
      " |      by : str or array-like, optional\n",
      " |          Column in the DataFrame to :meth:`pandas.DataFrame.groupby`.\n",
      " |          One box-plot will be done per value of columns in `by`.\n",
      " |      ax : object of class matplotlib.axes.Axes, optional\n",
      " |          The matplotlib axes to be used by boxplot.\n",
      " |      fontsize : float or str\n",
      " |          Tick label font size in points or as a string (e.g., `large`).\n",
      " |      rot : float, default 0\n",
      " |          The rotation angle of labels (in degrees)\n",
      " |          with respect to the screen coordinate system.\n",
      " |      grid : bool, default True\n",
      " |          Setting this to True will show the grid.\n",
      " |      figsize : A tuple (width, height) in inches\n",
      " |          The size of the figure to create in matplotlib.\n",
      " |      layout : tuple (rows, columns), optional\n",
      " |          For example, (3, 5) will display the subplots\n",
      " |          using 3 rows and 5 columns, starting from the top-left.\n",
      " |      return_type : {'axes', 'dict', 'both'} or None, default 'axes'\n",
      " |          The kind of object to return. The default is ``axes``.\n",
      " |      \n",
      " |          * 'axes' returns the matplotlib axes the boxplot is drawn on.\n",
      " |          * 'dict' returns a dictionary whose values are the matplotlib\n",
      " |            Lines of the boxplot.\n",
      " |          * 'both' returns a namedtuple with the axes and dict.\n",
      " |          * when grouping with ``by``, a Series mapping columns to\n",
      " |            ``return_type`` is returned.\n",
      " |      \n",
      " |            If ``return_type`` is `None`, a NumPy array\n",
      " |            of axes with the same shape as ``layout`` is returned.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :func:`matplotlib.pyplot.boxplot`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result\n",
      " |          See Notes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.plot.hist: Make a histogram.\n",
      " |      matplotlib.pyplot.boxplot : Matplotlib equivalent plot.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The return type depends on the `return_type` parameter:\n",
      " |      \n",
      " |      * 'axes' : object of class matplotlib.axes.Axes\n",
      " |      * 'dict' : dict of matplotlib.lines.Line2D objects\n",
      " |      * 'both' : a namedtuple with structure (ax, lines)\n",
      " |      \n",
      " |      For data grouped with ``by``, return a Series of the above or a numpy\n",
      " |      array:\n",
      " |      \n",
      " |      * :class:`~pandas.Series`\n",
      " |      * :class:`~numpy.array` (for ``return_type = None``)\n",
      " |      \n",
      " |      Use ``return_type='dict'`` when you want to tweak the appearance\n",
      " |      of the lines after plotting. In this case a dict containing the Lines\n",
      " |      making up the boxes, caps, fliers, medians, and whiskers is returned.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Boxplots can be created for every column in the dataframe\n",
      " |      by ``df.boxplot()`` or indicating the columns to be used:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> np.random.seed(1234)\n",
      " |          >>> df = pd.DataFrame(np.random.randn(10, 4),\n",
      " |          ...                   columns=['Col1', 'Col2', 'Col3', 'Col4'])\n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2', 'Col3'])  # doctest: +SKIP\n",
      " |      \n",
      " |      Boxplots of variables distributions grouped by the values of a third\n",
      " |      variable can be created using the option ``by``. For instance:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame(np.random.randn(10, 2),\n",
      " |          ...                   columns=['Col1', 'Col2'])\n",
      " |          >>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',\n",
      " |          ...                      'B', 'B', 'B', 'B', 'B'])\n",
      " |          >>> boxplot = df.boxplot(by='X')\n",
      " |      \n",
      " |      A list of strings (i.e. ``['X', 'Y']``) can be passed to boxplot\n",
      " |      in order to group the data by combination of the variables in the x-axis:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame(np.random.randn(10, 3),\n",
      " |          ...                   columns=['Col1', 'Col2', 'Col3'])\n",
      " |          >>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',\n",
      " |          ...                      'B', 'B', 'B', 'B', 'B'])\n",
      " |          >>> df['Y'] = pd.Series(['A', 'B', 'A', 'B', 'A',\n",
      " |          ...                      'B', 'A', 'B', 'A', 'B'])\n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by=['X', 'Y'])\n",
      " |      \n",
      " |      The layout of boxplot can be adjusted giving a tuple to ``layout``:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      layout=(2, 1))\n",
      " |      \n",
      " |      Additional formatting can be done to the boxplot, like suppressing the grid\n",
      " |      (``grid=False``), rotating the labels in the x-axis (i.e. ``rot=45``)\n",
      " |      or changing the fontsize (i.e. ``fontsize=15``):\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(grid=False, rot=45, fontsize=15)  # doctest: +SKIP\n",
      " |      \n",
      " |      The parameter ``return_type`` can be used to select the type of element\n",
      " |      returned by `boxplot`.  When ``return_type='axes'`` is selected,\n",
      " |      the matplotlib axes on which the boxplot is drawn are returned:\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], return_type='axes')\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'matplotlib.axes._subplots.AxesSubplot'>\n",
      " |      \n",
      " |      When grouping with ``by``, a Series mapping columns to ``return_type``\n",
      " |      is returned:\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      return_type='axes')\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'pandas.core.series.Series'>\n",
      " |      \n",
      " |      If ``return_type`` is `None`, a NumPy array of axes with the same shape\n",
      " |      as ``layout`` is returned:\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      return_type=None)\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'numpy.ndarray'>\n",
      " |  \n",
      " |  clip(self: 'DataFrame', lower: 'float | None' = None, upper: 'float | None' = None, *, axis: 'Axis | None' = None, inplace: 'bool' = False, **kwargs) -> 'DataFrame | None'\n",
      " |      Trim values at input threshold(s).\n",
      " |      \n",
      " |      Assigns values outside boundary to boundary values. Thresholds\n",
      " |      can be singular values or array like, and in the latter case\n",
      " |      the clipping is performed element-wise in the specified axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lower : float or array-like, default None\n",
      " |          Minimum threshold value. All values below this\n",
      " |          threshold will be set to it. A missing\n",
      " |          threshold (e.g `NA`) will not clip the value.\n",
      " |      upper : float or array-like, default None\n",
      " |          Maximum threshold value. All values above this\n",
      " |          threshold will be set to it. A missing\n",
      " |          threshold (e.g `NA`) will not clip the value.\n",
      " |      axis : {{0 or 'index', 1 or 'columns', None}}, default None\n",
      " |          Align object with lower and upper along the given axis.\n",
      " |          For `Series` this parameter is unused and defaults to `None`.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted\n",
      " |          for compatibility with numpy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame or None\n",
      " |          Same type as calling object with the values outside the\n",
      " |          clip boundaries replaced or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.clip : Trim values at input threshold in series.\n",
      " |      DataFrame.clip : Trim values at input threshold in dataframe.\n",
      " |      numpy.clip : Clip (limit) the values in an array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df\n",
      " |         col_0  col_1\n",
      " |      0      9     -2\n",
      " |      1     -3     -7\n",
      " |      2      0      6\n",
      " |      3     -1      8\n",
      " |      4      5     -5\n",
      " |      \n",
      " |      Clips per column using lower and upper thresholds:\n",
      " |      \n",
      " |      >>> df.clip(-4, 6)\n",
      " |         col_0  col_1\n",
      " |      0      6     -2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3     -1      6\n",
      " |      4      5     -4\n",
      " |      \n",
      " |      Clips using specific lower and upper thresholds per column element:\n",
      " |      \n",
      " |      >>> t = pd.Series([2, -4, -1, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2\n",
      " |      1   -4\n",
      " |      2   -1\n",
      " |      3    6\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.clip(t, t + 4, axis=0)\n",
      " |         col_0  col_1\n",
      " |      0      6      2\n",
      " |      1     -3     -4\n",
      " |      2      0      3\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |      \n",
      " |      Clips using specific lower threshold per column element, with missing values:\n",
      " |      \n",
      " |      >>> t = pd.Series([2, -4, np.NaN, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2.0\n",
      " |      1   -4.0\n",
      " |      2    NaN\n",
      " |      3    6.0\n",
      " |      4    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> df.clip(t, axis=0)\n",
      " |      col_0  col_1\n",
      " |      0      9      2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |  \n",
      " |  combine(self, other: 'DataFrame', func: 'Callable[[Series, Series], Series | Hashable]', fill_value=None, overwrite: 'bool' = True) -> 'DataFrame'\n",
      " |      Perform column-wise combine with another DataFrame.\n",
      " |      \n",
      " |      Combines a DataFrame with `other` DataFrame using `func`\n",
      " |      to element-wise combine columns. The row and column indexes of the\n",
      " |      resulting DataFrame will be the union of the two.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |          The DataFrame to merge column-wise.\n",
      " |      func : function\n",
      " |          Function that takes two series as inputs and return a Series or a\n",
      " |          scalar. Used to merge the two dataframes column by columns.\n",
      " |      fill_value : scalar value, default None\n",
      " |          The value to fill NaNs with prior to passing any column to the\n",
      " |          merge func.\n",
      " |      overwrite : bool, default True\n",
      " |          If True, columns in `self` that do not exist in `other` will be\n",
      " |          overwritten with NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Combination of the provided DataFrames.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.combine_first : Combine two DataFrame objects and default to\n",
      " |          non-null values in frame calling the method.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Combine using a simple function that chooses the smaller column.\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> take_smaller = lambda s1, s2: s1 if s1.sum() < s2.sum() else s2\n",
      " |      >>> df1.combine(df2, take_smaller)\n",
      " |         A  B\n",
      " |      0  0  3\n",
      " |      1  0  3\n",
      " |      \n",
      " |      Example using a true element-wise combine function.\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [5, 0], 'B': [2, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> df1.combine(df2, np.minimum)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  0  3\n",
      " |      \n",
      " |      Using `fill_value` fills Nones prior to passing the column to the\n",
      " |      merge function.\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> df1.combine(df2, take_smaller, fill_value=-5)\n",
      " |         A    B\n",
      " |      0  0 -5.0\n",
      " |      1  0  4.0\n",
      " |      \n",
      " |      However, if the same element in both dataframes is None, that None\n",
      " |      is preserved\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [None, 3]})\n",
      " |      >>> df1.combine(df2, take_smaller, fill_value=-5)\n",
      " |          A    B\n",
      " |      0  0 -5.0\n",
      " |      1  0  3.0\n",
      " |      \n",
      " |      Example that demonstrates the use of `overwrite` and behavior when\n",
      " |      the axis differ between the dataframes.\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [-10, 1], }, index=[1, 2])\n",
      " |      >>> df1.combine(df2, take_smaller)\n",
      " |           A    B     C\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  NaN  3.0 -10.0\n",
      " |      2  NaN  3.0   1.0\n",
      " |      \n",
      " |      >>> df1.combine(df2, take_smaller, overwrite=False)\n",
      " |           A    B     C\n",
      " |      0  0.0  NaN   NaN\n",
      " |      1  0.0  3.0 -10.0\n",
      " |      2  NaN  3.0   1.0\n",
      " |      \n",
      " |      Demonstrating the preference of the passed in dataframe.\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1], }, index=[1, 2])\n",
      " |      >>> df2.combine(df1, take_smaller)\n",
      " |         A    B   C\n",
      " |      0  0.0  NaN NaN\n",
      " |      1  0.0  3.0 NaN\n",
      " |      2  NaN  3.0 NaN\n",
      " |      \n",
      " |      >>> df2.combine(df1, take_smaller, overwrite=False)\n",
      " |           A    B   C\n",
      " |      0  0.0  NaN NaN\n",
      " |      1  0.0  3.0 1.0\n",
      " |      2  NaN  3.0 1.0\n",
      " |  \n",
      " |  combine_first(self, other: 'DataFrame') -> 'DataFrame'\n",
      " |      Update null elements with value in the same location in `other`.\n",
      " |      \n",
      " |      Combine two DataFrame objects by filling null values in one DataFrame\n",
      " |      with non-null values from other DataFrame. The row and column indexes\n",
      " |      of the resulting DataFrame will be the union of the two. The resulting\n",
      " |      dataframe contains the 'first' dataframe values and overrides the\n",
      " |      second one values where both first.loc[index, col] and\n",
      " |      second.loc[index, col] are not missing values, upon calling\n",
      " |      first.combine_first(second).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |          Provided DataFrame to use to fill null values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The result of combining the provided DataFrame with the other object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.combine : Perform series-wise operation on two DataFrames\n",
      " |          using a given function.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame({'A': [None, 0], 'B': [None, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> df1.combine_first(df2)\n",
      " |           A    B\n",
      " |      0  1.0  3.0\n",
      " |      1  0.0  4.0\n",
      " |      \n",
      " |      Null values still persist if the location of that null value\n",
      " |      does not exist in `other`\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [None, 0], 'B': [4, None]})\n",
      " |      >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1]}, index=[1, 2])\n",
      " |      >>> df1.combine_first(df2)\n",
      " |           A    B    C\n",
      " |      0  NaN  4.0  NaN\n",
      " |      1  0.0  3.0  1.0\n",
      " |      2  NaN  3.0  1.0\n",
      " |  \n",
      " |  compare(self, other: 'DataFrame', align_axis: 'Axis' = 1, keep_shape: 'bool' = False, keep_equal: 'bool' = False, result_names: 'Suffixes' = ('self', 'other')) -> 'DataFrame'\n",
      " |      Compare to another DataFrame and show the differences.\n",
      " |      \n",
      " |      .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |          Object to compare with.\n",
      " |      \n",
      " |      align_axis : {0 or 'index', 1 or 'columns'}, default 1\n",
      " |          Determine which axis to align the comparison on.\n",
      " |      \n",
      " |          * 0, or 'index' : Resulting differences are stacked vertically\n",
      " |              with rows drawn alternately from self and other.\n",
      " |          * 1, or 'columns' : Resulting differences are aligned horizontally\n",
      " |              with columns drawn alternately from self and other.\n",
      " |      \n",
      " |      keep_shape : bool, default False\n",
      " |          If true, all rows and columns are kept.\n",
      " |          Otherwise, only the ones with different values are kept.\n",
      " |      \n",
      " |      keep_equal : bool, default False\n",
      " |          If true, the result keeps values that are equal.\n",
      " |          Otherwise, equal values are shown as NaNs.\n",
      " |      \n",
      " |      result_names : tuple, default ('self', 'other')\n",
      " |          Set the dataframes names in the comparison.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame that shows the differences stacked side by side.\n",
      " |      \n",
      " |          The resulting index will be a MultiIndex with 'self' and 'other'\n",
      " |          stacked alternately at the inner level.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When the two DataFrames don't have identical labels or shape.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.compare : Compare with another Series and show differences.\n",
      " |      DataFrame.equals : Test whether two objects contain the same elements.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Matching NaNs will not appear as a difference.\n",
      " |      \n",
      " |      Can only compare identically-labeled\n",
      " |      (i.e. same shape, identical row and column labels) DataFrames\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"col1\": [\"a\", \"a\", \"b\", \"b\", \"a\"],\n",
      " |      ...         \"col2\": [1.0, 2.0, 3.0, np.nan, 5.0],\n",
      " |      ...         \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0]\n",
      " |      ...     },\n",
      " |      ...     columns=[\"col1\", \"col2\", \"col3\"],\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |        col1  col2  col3\n",
      " |      0    a   1.0   1.0\n",
      " |      1    a   2.0   2.0\n",
      " |      2    b   3.0   3.0\n",
      " |      3    b   NaN   4.0\n",
      " |      4    a   5.0   5.0\n",
      " |      \n",
      " |      >>> df2 = df.copy()\n",
      " |      >>> df2.loc[0, 'col1'] = 'c'\n",
      " |      >>> df2.loc[2, 'col3'] = 4.0\n",
      " |      >>> df2\n",
      " |        col1  col2  col3\n",
      " |      0    c   1.0   1.0\n",
      " |      1    a   2.0   2.0\n",
      " |      2    b   3.0   4.0\n",
      " |      3    b   NaN   4.0\n",
      " |      4    a   5.0   5.0\n",
      " |      \n",
      " |      Align the differences on columns\n",
      " |      \n",
      " |      >>> df.compare(df2)\n",
      " |        col1       col3\n",
      " |        self other self other\n",
      " |      0    a     c  NaN   NaN\n",
      " |      2  NaN   NaN  3.0   4.0\n",
      " |      \n",
      " |      Assign result_names\n",
      " |      \n",
      " |      >>> df.compare(df2, result_names=(\"left\", \"right\"))\n",
      " |        col1       col3\n",
      " |        left right left right\n",
      " |      0    a     c  NaN   NaN\n",
      " |      2  NaN   NaN  3.0   4.0\n",
      " |      \n",
      " |      Stack the differences on rows\n",
      " |      \n",
      " |      >>> df.compare(df2, align_axis=0)\n",
      " |              col1  col3\n",
      " |      0 self     a   NaN\n",
      " |        other    c   NaN\n",
      " |      2 self   NaN   3.0\n",
      " |        other  NaN   4.0\n",
      " |      \n",
      " |      Keep the equal values\n",
      " |      \n",
      " |      >>> df.compare(df2, keep_equal=True)\n",
      " |        col1       col3\n",
      " |        self other self other\n",
      " |      0    a     c  1.0   1.0\n",
      " |      2    b     b  3.0   4.0\n",
      " |      \n",
      " |      Keep all original rows and columns\n",
      " |      \n",
      " |      >>> df.compare(df2, keep_shape=True)\n",
      " |        col1       col2       col3\n",
      " |        self other self other self other\n",
      " |      0    a     c  NaN   NaN  NaN   NaN\n",
      " |      1  NaN   NaN  NaN   NaN  NaN   NaN\n",
      " |      2  NaN   NaN  NaN   NaN  3.0   4.0\n",
      " |      3  NaN   NaN  NaN   NaN  NaN   NaN\n",
      " |      4  NaN   NaN  NaN   NaN  NaN   NaN\n",
      " |      \n",
      " |      Keep all original rows and columns and also all original values\n",
      " |      \n",
      " |      >>> df.compare(df2, keep_shape=True, keep_equal=True)\n",
      " |        col1       col2       col3\n",
      " |        self other self other self other\n",
      " |      0    a     c  1.0   1.0  1.0   1.0\n",
      " |      1    a     a  2.0   2.0  2.0   2.0\n",
      " |      2    b     b  3.0   3.0  3.0   4.0\n",
      " |      3    b     b  NaN   NaN  4.0   4.0\n",
      " |      4    a     a  5.0   5.0  5.0   5.0\n",
      " |  \n",
      " |  corr(self, method: 'CorrelationMethod' = 'pearson', min_periods: 'int' = 1, numeric_only: 'bool' = False) -> 'DataFrame'\n",
      " |      Compute pairwise correlation of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          Method of correlation:\n",
      " |      \n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float. Note that the returned matrix from corr\n",
      " |              will have 1 along the diagonals and will be symmetric\n",
      " |              regardless of the callable's behavior.\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result. Currently only available for Pearson\n",
      " |          and Spearman correlation.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |              The default value of ``numeric_only`` is now ``False``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Correlation matrix.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corrwith : Compute pairwise correlation with another\n",
      " |          DataFrame or Series.\n",
      " |      Series.corr : Compute the correlation between two Series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Pearson, Kendall and Spearman correlation are currently computed using pairwise complete observations.\n",
      " |      \n",
      " |      * `Pearson correlation coefficient <https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>`_\n",
      " |      * `Kendall rank correlation coefficient <https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient>`_\n",
      " |      * `Spearman's rank correlation coefficient <https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient>`_\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> def histogram_intersection(a, b):\n",
      " |      ...     v = np.minimum(a, b).sum().round(decimals=1)\n",
      " |      ...     return v\n",
      " |      >>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.corr(method=histogram_intersection)\n",
      " |            dogs  cats\n",
      " |      dogs   1.0   0.3\n",
      " |      cats   0.3   1.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([(1, 1), (2, np.nan), (np.nan, 3), (4, 4)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.corr(min_periods=3)\n",
      " |            dogs  cats\n",
      " |      dogs   1.0   NaN\n",
      " |      cats   NaN   1.0\n",
      " |  \n",
      " |  corrwith(self, other: 'DataFrame | Series', axis: 'Axis' = 0, drop: 'bool' = False, method: 'CorrelationMethod' = 'pearson', numeric_only: 'bool' = False) -> 'Series'\n",
      " |      Compute pairwise correlation.\n",
      " |      \n",
      " |      Pairwise correlation is computed between rows or columns of\n",
      " |      DataFrame with rows or columns of Series or DataFrame. DataFrames\n",
      " |      are first aligned along both axes before computing the\n",
      " |      correlations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series\n",
      " |          Object with which to compute correlations.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' to compute row-wise, 1 or 'columns' for\n",
      " |          column-wise.\n",
      " |      drop : bool, default False\n",
      " |          Drop missing indices from result.\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          Method of correlation:\n",
      " |      \n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float.\n",
      " |      \n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |              The default value of ``numeric_only`` is now ``False``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Pairwise correlations.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corr : Compute pairwise correlation of columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
      " |      >>> columns = [\"one\", \"two\", \"three\", \"four\"]\n",
      " |      >>> df1 = pd.DataFrame(np.arange(20).reshape(5, 4), index=index, columns=columns)\n",
      " |      >>> df2 = pd.DataFrame(np.arange(16).reshape(4, 4), index=index[:4], columns=columns)\n",
      " |      >>> df1.corrwith(df2)\n",
      " |      one      1.0\n",
      " |      two      1.0\n",
      " |      three    1.0\n",
      " |      four     1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> df2.corrwith(df1, axis=1)\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  count(self, axis: 'Axis' = 0, numeric_only: 'bool' = False)\n",
      " |      Count non-NA cells for each column or row.\n",
      " |      \n",
      " |      The values `None`, `NaN`, `NaT`, and optionally `numpy.inf` (depending\n",
      " |      on `pandas.options.mode.use_inf_as_na`) are considered NA.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          If 0 or 'index' counts are generated for each column.\n",
      " |          If 1 or 'columns' counts are generated for each row.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          For each column/row the number of non-NA/null entries.\n",
      " |          If `level` is specified returns a `DataFrame`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.count: Number of non-NA elements in a Series.\n",
      " |      DataFrame.value_counts: Count unique combinations of columns.\n",
      " |      DataFrame.shape: Number of DataFrame rows and columns (including NA\n",
      " |          elements).\n",
      " |      DataFrame.isna: Boolean same-sized DataFrame showing places of NA\n",
      " |          elements.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Constructing DataFrame from a dictionary:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"Person\":\n",
      " |      ...                    [\"John\", \"Myla\", \"Lewis\", \"John\", \"Myla\"],\n",
      " |      ...                    \"Age\": [24., np.nan, 21., 33, 26],\n",
      " |      ...                    \"Single\": [False, True, True, True, False]})\n",
      " |      >>> df\n",
      " |         Person   Age  Single\n",
      " |      0    John  24.0   False\n",
      " |      1    Myla   NaN    True\n",
      " |      2   Lewis  21.0    True\n",
      " |      3    John  33.0    True\n",
      " |      4    Myla  26.0   False\n",
      " |      \n",
      " |      Notice the uncounted NA values:\n",
      " |      \n",
      " |      >>> df.count()\n",
      " |      Person    5\n",
      " |      Age       4\n",
      " |      Single    5\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Counts for each **row**:\n",
      " |      \n",
      " |      >>> df.count(axis='columns')\n",
      " |      0    3\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    3\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  cov(self, min_periods: 'int | None' = None, ddof: 'int | None' = 1, numeric_only: 'bool' = False) -> 'DataFrame'\n",
      " |      Compute pairwise covariance of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Compute the pairwise covariance among the series of a DataFrame.\n",
      " |      The returned data frame is the `covariance matrix\n",
      " |      <https://en.wikipedia.org/wiki/Covariance_matrix>`__ of the columns\n",
      " |      of the DataFrame.\n",
      " |      \n",
      " |      Both NA and null values are automatically excluded from the\n",
      " |      calculation. (See the note below about bias from missing values.)\n",
      " |      A threshold can be set for the minimum number of\n",
      " |      observations for each value created. Comparisons with observations\n",
      " |      below this threshold will be returned as ``NaN``.\n",
      " |      \n",
      " |      This method is generally used for the analysis of time series data to\n",
      " |      understand the relationship between different measures\n",
      " |      across time.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result.\n",
      " |      \n",
      " |      ddof : int, default 1\n",
      " |          Delta degrees of freedom.  The divisor used in calculations\n",
      " |          is ``N - ddof``, where ``N`` represents the number of elements.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |              The default value of ``numeric_only`` is now ``False``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The covariance matrix of the series of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.cov : Compute covariance with another Series.\n",
      " |      core.window.ewm.ExponentialMovingWindow.cov : Exponential weighted sample\n",
      " |          covariance.\n",
      " |      core.window.expanding.Expanding.cov : Expanding sample covariance.\n",
      " |      core.window.rolling.Rolling.cov : Rolling sample covariance.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Returns the covariance matrix of the DataFrame's time series.\n",
      " |      The covariance is normalized by N-ddof.\n",
      " |      \n",
      " |      For DataFrames that have Series that are missing data (assuming that\n",
      " |      data is `missing at random\n",
      " |      <https://en.wikipedia.org/wiki/Missing_data#Missing_at_random>`__)\n",
      " |      the returned covariance matrix will be an unbiased estimate\n",
      " |      of the variance and covariance between the member Series.\n",
      " |      \n",
      " |      However, for many applications this estimate may not be acceptable\n",
      " |      because the estimate covariance matrix is not guaranteed to be positive\n",
      " |      semi-definite. This could lead to estimate correlations having\n",
      " |      absolute values which are greater than one, and/or a non-invertible\n",
      " |      covariance matrix. See `Estimation of covariance matrices\n",
      " |      <https://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_\n",
      " |      matrices>`__ for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.cov()\n",
      " |                dogs      cats\n",
      " |      dogs  0.666667 -1.000000\n",
      " |      cats -1.000000  1.666667\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(1000, 5),\n",
      " |      ...                   columns=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> df.cov()\n",
      " |                a         b         c         d         e\n",
      " |      a  0.998438 -0.020161  0.059277 -0.008943  0.014144\n",
      " |      b -0.020161  1.059352 -0.008543 -0.024738  0.009826\n",
      " |      c  0.059277 -0.008543  1.010670 -0.001486 -0.000271\n",
      " |      d -0.008943 -0.024738 -0.001486  0.921297 -0.013692\n",
      " |      e  0.014144  0.009826 -0.000271 -0.013692  0.977795\n",
      " |      \n",
      " |      **Minimum number of periods**\n",
      " |      \n",
      " |      This method also supports an optional ``min_periods`` keyword\n",
      " |      that specifies the required minimum number of non-NA observations for\n",
      " |      each column pair in order to have a valid result:\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(20, 3),\n",
      " |      ...                   columns=['a', 'b', 'c'])\n",
      " |      >>> df.loc[df.index[:5], 'a'] = np.nan\n",
      " |      >>> df.loc[df.index[5:10], 'b'] = np.nan\n",
      " |      >>> df.cov(min_periods=12)\n",
      " |                a         b         c\n",
      " |      a  0.316741       NaN -0.150812\n",
      " |      b       NaN  1.248003  0.191417\n",
      " |      c -0.150812  0.191417  0.895202\n",
      " |  \n",
      " |  cummax(self, axis: 'Axis | None' = None, skipna: 'bool_t' = True, *args, **kwargs)\n",
      " |      Return cumulative maximum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      maximum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative maximum of Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.expanding.Expanding.max : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.max : Return the maximum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummax()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3    5.0\n",
      " |      4    5.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummax(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                   columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the maximum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummax()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  3.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the maximum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummax(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |  \n",
      " |  cummin(self, axis: 'Axis | None' = None, skipna: 'bool_t' = True, *args, **kwargs)\n",
      " |      Return cumulative minimum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      minimum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative minimum of Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.expanding.Expanding.min : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.min : Return the minimum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummin()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    2.0\n",
      " |      3   -1.0\n",
      " |      4   -1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummin(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                   columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the minimum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummin()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  2.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the minimum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummin(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |  \n",
      " |  cumprod(self, axis: 'Axis | None' = None, skipna: 'bool_t' = True, *args, **kwargs)\n",
      " |      Return cumulative product over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      product.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative product of Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.expanding.Expanding.prod : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.prod : Return the product over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumprod()\n",
      " |      0     2.0\n",
      " |      1     NaN\n",
      " |      2    10.0\n",
      " |      3   -10.0\n",
      " |      4    -0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumprod(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                   columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the product\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumprod()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  6.0  NaN\n",
      " |      2  6.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the product in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumprod(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |  \n",
      " |  cumsum(self, axis: 'Axis | None' = None, skipna: 'bool_t' = True, *args, **kwargs)\n",
      " |      Return cumulative sum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      sum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative sum of Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.expanding.Expanding.sum : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.sum : Return the sum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumsum()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    7.0\n",
      " |      3    6.0\n",
      " |      4    6.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumsum(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                   columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the sum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumsum()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  5.0  NaN\n",
      " |      2  6.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the sum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumsum(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |  \n",
      " |  diff(self, periods: 'int' = 1, axis: 'Axis' = 0) -> 'DataFrame'\n",
      " |      First discrete difference of element.\n",
      " |      \n",
      " |      Calculates the difference of a DataFrame element compared with another\n",
      " |      element in the DataFrame (default is element in previous row).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative\n",
      " |          values.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Take difference over rows (0) or columns (1).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          First differences of the Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pct_change: Percent change over given number of periods.\n",
      " |      DataFrame.shift: Shift index by desired number of periods with an\n",
      " |          optional time freq.\n",
      " |      Series.diff: First discrete difference of object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For boolean dtypes, this uses :meth:`operator.xor` rather than\n",
      " |      :meth:`operator.sub`.\n",
      " |      The result is calculated according to current dtype in DataFrame,\n",
      " |      however dtype of the result is always float64.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Difference with previous row\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'b': [1, 1, 2, 3, 5, 8],\n",
      " |      ...                    'c': [1, 4, 9, 16, 25, 36]})\n",
      " |      >>> df\n",
      " |         a  b   c\n",
      " |      0  1  1   1\n",
      " |      1  2  1   4\n",
      " |      2  3  2   9\n",
      " |      3  4  3  16\n",
      " |      4  5  5  25\n",
      " |      5  6  8  36\n",
      " |      \n",
      " |      >>> df.diff()\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  1.0  0.0   3.0\n",
      " |      2  1.0  1.0   5.0\n",
      " |      3  1.0  1.0   7.0\n",
      " |      4  1.0  2.0   9.0\n",
      " |      5  1.0  3.0  11.0\n",
      " |      \n",
      " |      Difference with previous column\n",
      " |      \n",
      " |      >>> df.diff(axis=1)\n",
      " |          a  b   c\n",
      " |      0 NaN  0   0\n",
      " |      1 NaN -1   3\n",
      " |      2 NaN -1   7\n",
      " |      3 NaN -1  13\n",
      " |      4 NaN  0  20\n",
      " |      5 NaN  2  28\n",
      " |      \n",
      " |      Difference with 3rd previous row\n",
      " |      \n",
      " |      >>> df.diff(periods=3)\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  NaN  NaN   NaN\n",
      " |      2  NaN  NaN   NaN\n",
      " |      3  3.0  2.0  15.0\n",
      " |      4  3.0  4.0  21.0\n",
      " |      5  3.0  6.0  27.0\n",
      " |      \n",
      " |      Difference with following row\n",
      " |      \n",
      " |      >>> df.diff(periods=-1)\n",
      " |           a    b     c\n",
      " |      0 -1.0  0.0  -3.0\n",
      " |      1 -1.0 -1.0  -5.0\n",
      " |      2 -1.0 -1.0  -7.0\n",
      " |      3 -1.0 -2.0  -9.0\n",
      " |      4 -1.0 -3.0 -11.0\n",
      " |      5  NaN  NaN   NaN\n",
      " |      \n",
      " |      Overflow in input dtype\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [1, 0]}, dtype=np.uint8)\n",
      " |      >>> df.diff()\n",
      " |             a\n",
      " |      0    NaN\n",
      " |      1  255.0\n",
      " |  \n",
      " |  div = truediv(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  divide = truediv(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  dot(self, other: 'AnyArrayLike | DataFrame') -> 'DataFrame | Series'\n",
      " |      Compute the matrix multiplication between the DataFrame and other.\n",
      " |      \n",
      " |      This method computes the matrix product between the DataFrame and the\n",
      " |      values of an other Series, DataFrame or a numpy array.\n",
      " |      \n",
      " |      It can also be called using ``self @ other`` in Python >= 3.5.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame or array-like\n",
      " |          The other object to compute the matrix product with.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If other is a Series, return the matrix product between self and\n",
      " |          other as a Series. If other is a DataFrame or a numpy.array, return\n",
      " |          the matrix product of self and other in a DataFrame of a np.array.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.dot: Similar method for Series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The dimensions of DataFrame and other must be compatible in order to\n",
      " |      compute the matrix multiplication. In addition, the column names of\n",
      " |      DataFrame and the index of other must contain the same values, as they\n",
      " |      will be aligned prior to the multiplication.\n",
      " |      \n",
      " |      The dot method for Series computes the inner product, instead of the\n",
      " |      matrix product here.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Here we multiply a DataFrame with a Series.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[0, 1, -2, -1], [1, 1, 1, 1]])\n",
      " |      >>> s = pd.Series([1, 1, 2, 1])\n",
      " |      >>> df.dot(s)\n",
      " |      0    -4\n",
      " |      1     5\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Here we multiply a DataFrame with another DataFrame.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame([[0, 1], [1, 2], [-1, -1], [2, 0]])\n",
      " |      >>> df.dot(other)\n",
      " |          0   1\n",
      " |      0   1   4\n",
      " |      1   2   2\n",
      " |      \n",
      " |      Note that the dot method give the same result as @\n",
      " |      \n",
      " |      >>> df @ other\n",
      " |          0   1\n",
      " |      0   1   4\n",
      " |      1   2   2\n",
      " |      \n",
      " |      The dot method works also if other is an np.array.\n",
      " |      \n",
      " |      >>> arr = np.array([[0, 1], [1, 2], [-1, -1], [2, 0]])\n",
      " |      >>> df.dot(arr)\n",
      " |          0   1\n",
      " |      0   1   4\n",
      " |      1   2   2\n",
      " |      \n",
      " |      Note how shuffling of the objects does not change the result.\n",
      " |      \n",
      " |      >>> s2 = s.reindex([1, 0, 2, 3])\n",
      " |      >>> df.dot(s2)\n",
      " |      0    -4\n",
      " |      1     5\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  drop(self, labels: 'IndexLabel' = None, *, axis: 'Axis' = 0, index: 'IndexLabel' = None, columns: 'IndexLabel' = None, level: 'Level' = None, inplace: 'bool' = False, errors: 'IgnoreRaise' = 'raise') -> 'DataFrame | None'\n",
      " |      Drop specified labels from rows or columns.\n",
      " |      \n",
      " |      Remove rows or columns by specifying label names and corresponding\n",
      " |      axis, or by specifying directly index or column names. When using a\n",
      " |      multi-index, labels on different levels can be removed by specifying\n",
      " |      the level. See the :ref:`user guide <advanced.shown_levels>`\n",
      " |      for more information about the now unused levels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : single label or list-like\n",
      " |          Index or column labels to drop. A tuple will be used as a single\n",
      " |          label and not treated as a list-like.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Whether to drop labels from the index (0 or 'index') or\n",
      " |          columns (1 or 'columns').\n",
      " |      index : single label or list-like\n",
      " |          Alternative to specifying axis (``labels, axis=0``\n",
      " |          is equivalent to ``index=labels``).\n",
      " |      columns : single label or list-like\n",
      " |          Alternative to specifying axis (``labels, axis=1``\n",
      " |          is equivalent to ``columns=labels``).\n",
      " |      level : int or level name, optional\n",
      " |          For MultiIndex, level from which the labels will be removed.\n",
      " |      inplace : bool, default False\n",
      " |          If False, return a copy. Otherwise, do operation\n",
      " |          inplace and return None.\n",
      " |      errors : {'ignore', 'raise'}, default 'raise'\n",
      " |          If 'ignore', suppress error and only existing labels are\n",
      " |          dropped.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame without the removed index or column labels or\n",
      " |          None if ``inplace=True``.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any of the labels is not found in the selected axis.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Label-location based indexer for selection by label.\n",
      " |      DataFrame.dropna : Return DataFrame with labels on given axis omitted\n",
      " |          where (all or any) data are missing.\n",
      " |      DataFrame.drop_duplicates : Return DataFrame with duplicate rows\n",
      " |          removed, optionally only considering certain columns.\n",
      " |      Series.drop : Return Series with specified index labels removed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.arange(12).reshape(3, 4),\n",
      " |      ...                   columns=['A', 'B', 'C', 'D'])\n",
      " |      >>> df\n",
      " |         A  B   C   D\n",
      " |      0  0  1   2   3\n",
      " |      1  4  5   6   7\n",
      " |      2  8  9  10  11\n",
      " |      \n",
      " |      Drop columns\n",
      " |      \n",
      " |      >>> df.drop(['B', 'C'], axis=1)\n",
      " |         A   D\n",
      " |      0  0   3\n",
      " |      1  4   7\n",
      " |      2  8  11\n",
      " |      \n",
      " |      >>> df.drop(columns=['B', 'C'])\n",
      " |         A   D\n",
      " |      0  0   3\n",
      " |      1  4   7\n",
      " |      2  8  11\n",
      " |      \n",
      " |      Drop a row by index\n",
      " |      \n",
      " |      >>> df.drop([0, 1])\n",
      " |         A  B   C   D\n",
      " |      2  8  9  10  11\n",
      " |      \n",
      " |      Drop columns and/or rows of MultiIndex DataFrame\n",
      " |      \n",
      " |      >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n",
      " |      ...                              ['speed', 'weight', 'length']],\n",
      " |      ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
      " |      ...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
      " |      >>> df = pd.DataFrame(index=midx, columns=['big', 'small'],\n",
      " |      ...                   data=[[45, 30], [200, 100], [1.5, 1], [30, 20],\n",
      " |      ...                         [250, 150], [1.5, 0.8], [320, 250],\n",
      " |      ...                         [1, 0.8], [0.3, 0.2]])\n",
      " |      >>> df\n",
      " |                      big     small\n",
      " |      lama    speed   45.0    30.0\n",
      " |              weight  200.0   100.0\n",
      " |              length  1.5     1.0\n",
      " |      cow     speed   30.0    20.0\n",
      " |              weight  250.0   150.0\n",
      " |              length  1.5     0.8\n",
      " |      falcon  speed   320.0   250.0\n",
      " |              weight  1.0     0.8\n",
      " |              length  0.3     0.2\n",
      " |      \n",
      " |      Drop a specific index combination from the MultiIndex\n",
      " |      DataFrame, i.e., drop the combination ``'falcon'`` and\n",
      " |      ``'weight'``, which deletes only the corresponding row\n",
      " |      \n",
      " |      >>> df.drop(index=('falcon', 'weight'))\n",
      " |                      big     small\n",
      " |      lama    speed   45.0    30.0\n",
      " |              weight  200.0   100.0\n",
      " |              length  1.5     1.0\n",
      " |      cow     speed   30.0    20.0\n",
      " |              weight  250.0   150.0\n",
      " |              length  1.5     0.8\n",
      " |      falcon  speed   320.0   250.0\n",
      " |              length  0.3     0.2\n",
      " |      \n",
      " |      >>> df.drop(index='cow', columns='small')\n",
      " |                      big\n",
      " |      lama    speed   45.0\n",
      " |              weight  200.0\n",
      " |              length  1.5\n",
      " |      falcon  speed   320.0\n",
      " |              weight  1.0\n",
      " |              length  0.3\n",
      " |      \n",
      " |      >>> df.drop(index='length', level=1)\n",
      " |                      big     small\n",
      " |      lama    speed   45.0    30.0\n",
      " |              weight  200.0   100.0\n",
      " |      cow     speed   30.0    20.0\n",
      " |              weight  250.0   150.0\n",
      " |      falcon  speed   320.0   250.0\n",
      " |              weight  1.0     0.8\n",
      " |  \n",
      " |  drop_duplicates(self, subset: 'Hashable | Sequence[Hashable] | None' = None, *, keep: 'DropKeep' = 'first', inplace: 'bool' = False, ignore_index: 'bool' = False) -> 'DataFrame | None'\n",
      " |      Return DataFrame with duplicate rows removed.\n",
      " |      \n",
      " |      Considering certain columns is optional. Indexes, including time indexes\n",
      " |      are ignored.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Only consider certain columns for identifying duplicates, by\n",
      " |          default use all of the columns.\n",
      " |      keep : {'first', 'last', ``False``}, default 'first'\n",
      " |          Determines which duplicates (if any) to keep.\n",
      " |      \n",
      " |          - 'first' : Drop duplicates except for the first occurrence.\n",
      " |          - 'last' : Drop duplicates except for the last occurrence.\n",
      " |          - ``False`` : Drop all duplicates.\n",
      " |      \n",
      " |      inplace : bool, default ``False``\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |      ignore_index : bool, default ``False``\n",
      " |          If ``True``, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with duplicates removed or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.value_counts: Count unique combinations of columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider dataset containing ramen rating.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
      " |      ...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
      " |      ...     'rating': [4, 4, 3.5, 15, 5]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      1  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      3  Indomie  pack    15.0\n",
      " |      4  Indomie  pack     5.0\n",
      " |      \n",
      " |      By default, it removes duplicate rows based on all columns.\n",
      " |      \n",
      " |      >>> df.drop_duplicates()\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      3  Indomie  pack    15.0\n",
      " |      4  Indomie  pack     5.0\n",
      " |      \n",
      " |      To remove duplicates on specific column(s), use ``subset``.\n",
      " |      \n",
      " |      >>> df.drop_duplicates(subset=['brand'])\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      \n",
      " |      To remove duplicates and keep last occurrences, use ``keep``.\n",
      " |      \n",
      " |      >>> df.drop_duplicates(subset=['brand', 'style'], keep='last')\n",
      " |          brand style  rating\n",
      " |      1  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      4  Indomie  pack     5.0\n",
      " |  \n",
      " |  dropna(self, *, axis: 'Axis' = 0, how: 'AnyAll | NoDefault' = <no_default>, thresh: 'int | NoDefault' = <no_default>, subset: 'IndexLabel' = None, inplace: 'bool' = False, ignore_index: 'bool' = False) -> 'DataFrame | None'\n",
      " |      Remove missing values.\n",
      " |      \n",
      " |      See the :ref:`User Guide <missing_data>` for more on which values are\n",
      " |      considered missing, and how to work with missing data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Determine if rows or columns which contain missing values are\n",
      " |          removed.\n",
      " |      \n",
      " |          * 0, or 'index' : Drop rows which contain missing values.\n",
      " |          * 1, or 'columns' : Drop columns which contain missing value.\n",
      " |      \n",
      " |          Pass tuple or list to drop on multiple axes.\n",
      " |          Only a single axis is allowed.\n",
      " |      \n",
      " |      how : {'any', 'all'}, default 'any'\n",
      " |          Determine if row or column is removed from DataFrame, when we have\n",
      " |          at least one NA or all NA.\n",
      " |      \n",
      " |          * 'any' : If any NA values are present, drop that row or column.\n",
      " |          * 'all' : If all values are NA, drop that row or column.\n",
      " |      \n",
      " |      thresh : int, optional\n",
      " |          Require that many non-NA values. Cannot be combined with how.\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Labels along other axis to consider, e.g. if you are dropping rows\n",
      " |          these would be a list of columns to include.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |      ignore_index : bool, default ``False``\n",
      " |          If ``True``, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 2.0.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with NA entries dropped from it or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isna: Indicate missing values.\n",
      " |      DataFrame.notna : Indicate existing (non-missing) values.\n",
      " |      DataFrame.fillna : Replace missing values.\n",
      " |      Series.dropna : Drop missing values.\n",
      " |      Index.dropna : Drop missing indices.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
      " |      ...                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
      " |      ...                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n",
      " |      ...                             pd.NaT]})\n",
      " |      >>> df\n",
      " |             name        toy       born\n",
      " |      0    Alfred        NaN        NaT\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Drop the rows where at least one element is missing.\n",
      " |      \n",
      " |      >>> df.dropna()\n",
      " |           name        toy       born\n",
      " |      1  Batman  Batmobile 1940-04-25\n",
      " |      \n",
      " |      Drop the columns where at least one element is missing.\n",
      " |      \n",
      " |      >>> df.dropna(axis='columns')\n",
      " |             name\n",
      " |      0    Alfred\n",
      " |      1    Batman\n",
      " |      2  Catwoman\n",
      " |      \n",
      " |      Drop the rows where all elements are missing.\n",
      " |      \n",
      " |      >>> df.dropna(how='all')\n",
      " |             name        toy       born\n",
      " |      0    Alfred        NaN        NaT\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Keep only the rows with at least 2 non-NA values.\n",
      " |      \n",
      " |      >>> df.dropna(thresh=2)\n",
      " |             name        toy       born\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Define in which columns to look for missing values.\n",
      " |      \n",
      " |      >>> df.dropna(subset=['name', 'toy'])\n",
      " |             name        toy       born\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |  \n",
      " |  duplicated(self, subset: 'Hashable | Sequence[Hashable] | None' = None, keep: 'DropKeep' = 'first') -> 'Series'\n",
      " |      Return boolean Series denoting duplicate rows.\n",
      " |      \n",
      " |      Considering certain columns is optional.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Only consider certain columns for identifying duplicates, by\n",
      " |          default use all of the columns.\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          Determines which duplicates (if any) to mark.\n",
      " |      \n",
      " |          - ``first`` : Mark duplicates as ``True`` except for the first occurrence.\n",
      " |          - ``last`` : Mark duplicates as ``True`` except for the last occurrence.\n",
      " |          - False : Mark all duplicates as ``True``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Boolean series for each duplicated rows.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.duplicated : Equivalent method on index.\n",
      " |      Series.duplicated : Equivalent method on Series.\n",
      " |      Series.drop_duplicates : Remove duplicate values from Series.\n",
      " |      DataFrame.drop_duplicates : Remove duplicate values from DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider dataset containing ramen rating.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
      " |      ...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
      " |      ...     'rating': [4, 4, 3.5, 15, 5]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      1  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      3  Indomie  pack    15.0\n",
      " |      4  Indomie  pack     5.0\n",
      " |      \n",
      " |      By default, for each set of duplicated values, the first occurrence\n",
      " |      is set on False and all others on True.\n",
      " |      \n",
      " |      >>> df.duplicated()\n",
      " |      0    False\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      By using 'last', the last occurrence of each set of duplicated values\n",
      " |      is set on False and all others on True.\n",
      " |      \n",
      " |      >>> df.duplicated(keep='last')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      By setting ``keep`` on False, all duplicates are True.\n",
      " |      \n",
      " |      >>> df.duplicated(keep=False)\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      To find duplicates on specific column(s), use ``subset``.\n",
      " |      \n",
      " |      >>> df.duplicated(subset=['brand'])\n",
      " |      0    False\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      3     True\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  eq(self, other, axis: 'Axis' = 'columns', level=None)\n",
      " |      Get Equal to of dataframe and other, element-wise (binary operator `eq`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  eval(self, expr: 'str', *, inplace: 'bool' = False, **kwargs) -> 'Any | None'\n",
      " |      Evaluate a string describing operations on DataFrame columns.\n",
      " |      \n",
      " |      Operates on columns only, not specific rows or elements.  This allows\n",
      " |      `eval` to run arbitrary code, which can make you vulnerable to code\n",
      " |      injection if you pass user input to this function.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      expr : str\n",
      " |          The expression string to evaluate.\n",
      " |      inplace : bool, default False\n",
      " |          If the expression contains an assignment, whether to perform the\n",
      " |          operation inplace and mutate the existing DataFrame. Otherwise,\n",
      " |          a new DataFrame is returned.\n",
      " |      **kwargs\n",
      " |          See the documentation for :func:`eval` for complete details\n",
      " |          on the keyword arguments accepted by\n",
      " |          :meth:`~pandas.DataFrame.query`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray, scalar, pandas object, or None\n",
      " |          The result of the evaluation or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.query : Evaluates a boolean expression to query the columns\n",
      " |          of a frame.\n",
      " |      DataFrame.assign : Can evaluate an expression or function to create new\n",
      " |          values for a column.\n",
      " |      eval : Evaluate a Python expression as a string using various\n",
      " |          backends.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For more details see the API documentation for :func:`~eval`.\n",
      " |      For detailed examples see :ref:`enhancing performance with eval\n",
      " |      <enhancingperf.eval>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(1, 6), 'B': range(10, 0, -2)})\n",
      " |      >>> df\n",
      " |         A   B\n",
      " |      0  1  10\n",
      " |      1  2   8\n",
      " |      2  3   6\n",
      " |      3  4   4\n",
      " |      4  5   2\n",
      " |      >>> df.eval('A + B')\n",
      " |      0    11\n",
      " |      1    10\n",
      " |      2     9\n",
      " |      3     8\n",
      " |      4     7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Assignment is allowed though by default the original DataFrame is not\n",
      " |      modified.\n",
      " |      \n",
      " |      >>> df.eval('C = A + B')\n",
      " |         A   B   C\n",
      " |      0  1  10  11\n",
      " |      1  2   8  10\n",
      " |      2  3   6   9\n",
      " |      3  4   4   8\n",
      " |      4  5   2   7\n",
      " |      >>> df\n",
      " |         A   B\n",
      " |      0  1  10\n",
      " |      1  2   8\n",
      " |      2  3   6\n",
      " |      3  4   4\n",
      " |      4  5   2\n",
      " |      \n",
      " |      Multiple columns can be assigned to using multi-line expressions:\n",
      " |      \n",
      " |      >>> df.eval(\n",
      " |      ...     '''\n",
      " |      ... C = A + B\n",
      " |      ... D = A - B\n",
      " |      ... '''\n",
      " |      ... )\n",
      " |         A   B   C  D\n",
      " |      0  1  10  11 -9\n",
      " |      1  2   8  10 -6\n",
      " |      2  3   6   9 -3\n",
      " |      3  4   4   8  0\n",
      " |      4  5   2   7  3\n",
      " |  \n",
      " |  explode(self, column: 'IndexLabel', ignore_index: 'bool' = False) -> 'DataFrame'\n",
      " |      Transform each element of a list-like to a row, replicating index values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      column : IndexLabel\n",
      " |          Column(s) to explode.\n",
      " |          For multiple columns, specify a non-empty list with each element\n",
      " |          be str or tuple, and all specified columns their list-like data\n",
      " |          on same row of the frame must have matching length.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |              Multi-column explode\n",
      " |      \n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting index will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Exploded lists to rows of the subset columns;\n",
      " |          index will be duplicated for these rows.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError :\n",
      " |          * If columns of the frame are not unique.\n",
      " |          * If specified columns to explode is empty list.\n",
      " |          * If specified columns to explode have not matching count of\n",
      " |            elements rowwise in the frame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.unstack : Pivot a level of the (necessarily hierarchical)\n",
      " |          index labels.\n",
      " |      DataFrame.melt : Unpivot a DataFrame from wide format to long format.\n",
      " |      Series.explode : Explode a DataFrame from list-like columns to long format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This routine will explode list-likes including lists, tuples, sets,\n",
      " |      Series, and np.ndarray. The result dtype of the subset rows will\n",
      " |      be object. Scalars will be returned unchanged, and empty list-likes will\n",
      " |      result in a np.nan for that row. In addition, the ordering of rows in the\n",
      " |      output will be non-deterministic when exploding sets.\n",
      " |      \n",
      " |      Reference :ref:`the user guide <reshaping.explode>` for more examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [[0, 1, 2], 'foo', [], [3, 4]],\n",
      " |      ...                    'B': 1,\n",
      " |      ...                    'C': [['a', 'b', 'c'], np.nan, [], ['d', 'e']]})\n",
      " |      >>> df\n",
      " |                 A  B          C\n",
      " |      0  [0, 1, 2]  1  [a, b, c]\n",
      " |      1        foo  1        NaN\n",
      " |      2         []  1         []\n",
      " |      3     [3, 4]  1     [d, e]\n",
      " |      \n",
      " |      Single-column explode.\n",
      " |      \n",
      " |      >>> df.explode('A')\n",
      " |           A  B          C\n",
      " |      0    0  1  [a, b, c]\n",
      " |      0    1  1  [a, b, c]\n",
      " |      0    2  1  [a, b, c]\n",
      " |      1  foo  1        NaN\n",
      " |      2  NaN  1         []\n",
      " |      3    3  1     [d, e]\n",
      " |      3    4  1     [d, e]\n",
      " |      \n",
      " |      Multi-column explode.\n",
      " |      \n",
      " |      >>> df.explode(list('AC'))\n",
      " |           A  B    C\n",
      " |      0    0  1    a\n",
      " |      0    1  1    b\n",
      " |      0    2  1    c\n",
      " |      1  foo  1  NaN\n",
      " |      2  NaN  1  NaN\n",
      " |      3    3  1    d\n",
      " |      3    4  1    e\n",
      " |  \n",
      " |  ffill(self, *, axis: 'None | Axis' = None, inplace: 'bool' = False, limit: 'None | int' = None, downcast: 'dict | None' = None) -> 'DataFrame | None'\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='ffill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  fillna(self, value: 'Hashable | Mapping | Series | DataFrame' = None, *, method: 'FillnaOptions | None' = None, axis: 'Axis | None' = None, inplace: 'bool' = False, limit: 'int | None' = None, downcast: 'dict | None' = None) -> 'DataFrame | None'\n",
      " |      Fill NA/NaN values using the specified method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame).  Values not\n",
      " |          in the dict/Series/DataFrame will not be filled. This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series:\n",
      " |      \n",
      " |          * ffill: propagate last valid observation forward to next valid.\n",
      " |          * backfill / bfill: use next valid observation to fill gap.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Axis along which to fill missing values. For `Series`\n",
      " |          this parameter is unused and defaults to 0.\n",
      " |      inplace : bool, default False\n",
      " |          If True, fill in-place. Note: this will modify any\n",
      " |          other views on this object (e.g., a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          A dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      interpolate : Fill NaN values using interpolation.\n",
      " |      reindex : Conform object to new index.\n",
      " |      asfreq : Convert TimeSeries to specified frequency.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, np.nan],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                   columns=list(\"ABCD\"))\n",
      " |      >>> df\n",
      " |           A    B   C    D\n",
      " |      0  NaN  2.0 NaN  0.0\n",
      " |      1  3.0  4.0 NaN  1.0\n",
      " |      2  NaN  NaN NaN  NaN\n",
      " |      3  NaN  3.0 NaN  4.0\n",
      " |      \n",
      " |      Replace all NaN elements with 0s.\n",
      " |      \n",
      " |      >>> df.fillna(0)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  0.0  0.0\n",
      " |      1  3.0  4.0  0.0  1.0\n",
      " |      2  0.0  0.0  0.0  0.0\n",
      " |      3  0.0  3.0  0.0  4.0\n",
      " |      \n",
      " |      We can also propagate non-null values forward or backward.\n",
      " |      \n",
      " |      >>> df.fillna(method=\"ffill\")\n",
      " |           A    B   C    D\n",
      " |      0  NaN  2.0 NaN  0.0\n",
      " |      1  3.0  4.0 NaN  1.0\n",
      " |      2  3.0  4.0 NaN  1.0\n",
      " |      3  3.0  3.0 NaN  4.0\n",
      " |      \n",
      " |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      " |      2, and 3 respectively.\n",
      " |      \n",
      " |      >>> values = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
      " |      >>> df.fillna(value=values)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  2.0  0.0\n",
      " |      1  3.0  4.0  2.0  1.0\n",
      " |      2  0.0  1.0  2.0  3.0\n",
      " |      3  0.0  3.0  2.0  4.0\n",
      " |      \n",
      " |      Only replace the first NaN element.\n",
      " |      \n",
      " |      >>> df.fillna(value=values, limit=1)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  2.0  0.0\n",
      " |      1  3.0  4.0  NaN  1.0\n",
      " |      2  NaN  1.0  NaN  3.0\n",
      " |      3  NaN  3.0  NaN  4.0\n",
      " |      \n",
      " |      When filling using a DataFrame, replacement happens along\n",
      " |      the same column names and same indices\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame(np.zeros((4, 4)), columns=list(\"ABCE\"))\n",
      " |      >>> df.fillna(df2)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  0.0  0.0\n",
      " |      1  3.0  4.0  0.0  1.0\n",
      " |      2  0.0  0.0  0.0  NaN\n",
      " |      3  0.0  3.0  0.0  4.0\n",
      " |      \n",
      " |      Note that column D is not affected since it is not present in df2.\n",
      " |  \n",
      " |  floordiv(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None)\n",
      " |      Get Integer division of dataframe and other, element-wise (binary operator `floordiv`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe // other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rfloordiv`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  ge(self, other, axis: 'Axis' = 'columns', level=None)\n",
      " |      Get Greater than or equal to of dataframe and other, element-wise (binary operator `ge`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  groupby(self, by=None, axis: 'Axis' = 0, level: 'IndexLabel | None' = None, as_index: 'bool' = True, sort: 'bool' = True, group_keys: 'bool' = True, observed: 'bool' = False, dropna: 'bool' = True) -> 'DataFrameGroupBy'\n",
      " |      Group DataFrame using a mapper or by a Series of columns.\n",
      " |      \n",
      " |      A groupby operation involves some combination of splitting the\n",
      " |      object, applying a function, and combining the results. This can be\n",
      " |      used to group large amounts of data and compute operations on these\n",
      " |      groups.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : mapping, function, label, pd.Grouper or list of such\n",
      " |          Used to determine the groups for the groupby.\n",
      " |          If ``by`` is a function, it's called on each value of the object's\n",
      " |          index. If a dict or Series is passed, the Series or dict VALUES\n",
      " |          will be used to determine the groups (the Series' values are first\n",
      " |          aligned; see ``.align()`` method). If a list or ndarray of length\n",
      " |          equal to the selected axis is passed (see the `groupby user guide\n",
      " |          <https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#splitting-an-object-into-groups>`_),\n",
      " |          the values are used as-is to determine the groups. A label or list\n",
      " |          of labels may be passed to group by the columns in ``self``.\n",
      " |          Notice that a tuple is interpreted as a (single) key.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Split along rows (0) or columns (1). For `Series` this parameter\n",
      " |          is unused and defaults to 0.\n",
      " |      level : int, level name, or sequence of such, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      " |          level or levels. Do not specify both ``by`` and ``level``.\n",
      " |      as_index : bool, default True\n",
      " |          For aggregated output, return object with group labels as the\n",
      " |          index. Only relevant for DataFrame input. as_index=False is\n",
      " |          effectively \"SQL-style\" grouped output.\n",
      " |      sort : bool, default True\n",
      " |          Sort group keys. Get better performance by turning this off.\n",
      " |          Note this does not influence the order of observations within each\n",
      " |          group. Groupby preserves the order of rows within each group.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              Specifying ``sort=False`` with an ordered categorical grouper will no\n",
      " |              longer sort the values.\n",
      " |      \n",
      " |      group_keys : bool, default True\n",
      " |          When calling apply and the ``by`` argument produces a like-indexed\n",
      " |          (i.e. :ref:`a transform <groupby.transform>`) result, add group keys to\n",
      " |          index to identify pieces. By default group keys are not included\n",
      " |          when the result's index (and column) labels match the inputs, and\n",
      " |          are included otherwise.\n",
      " |      \n",
      " |          .. versionchanged:: 1.5.0\n",
      " |      \n",
      " |             Warns that ``group_keys`` will no longer be ignored when the\n",
      " |             result from ``apply`` is a like-indexed Series or DataFrame.\n",
      " |             Specify ``group_keys`` explicitly to include the group keys or\n",
      " |             not.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |             ``group_keys`` now defaults to ``True``.\n",
      " |      \n",
      " |      observed : bool, default False\n",
      " |          This only applies if any of the groupers are Categoricals.\n",
      " |          If True: only show observed values for categorical groupers.\n",
      " |          If False: show all values for categorical groupers.\n",
      " |      dropna : bool, default True\n",
      " |          If True, and if group keys contain NA values, NA values together\n",
      " |          with row/column will be dropped.\n",
      " |          If False, NA values will also be treated as the key in groups.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrameGroupBy\n",
      " |          Returns a groupby object that contains information about the groups.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      resample : Convenience method for frequency conversion and resampling\n",
      " |          of time series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/groupby.html>`__ for more\n",
      " |      detailed usage and examples, including splitting an object into groups,\n",
      " |      iterating through groups, selecting a group, aggregation, and more.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',\n",
      " |      ...                               'Parrot', 'Parrot'],\n",
      " |      ...                    'Max Speed': [380., 370., 24., 26.]})\n",
      " |      >>> df\n",
      " |         Animal  Max Speed\n",
      " |      0  Falcon      380.0\n",
      " |      1  Falcon      370.0\n",
      " |      2  Parrot       24.0\n",
      " |      3  Parrot       26.0\n",
      " |      >>> df.groupby(['Animal']).mean()\n",
      " |              Max Speed\n",
      " |      Animal\n",
      " |      Falcon      375.0\n",
      " |      Parrot       25.0\n",
      " |      \n",
      " |      **Hierarchical Indexes**\n",
      " |      \n",
      " |      We can groupby different levels of a hierarchical index\n",
      " |      using the `level` parameter:\n",
      " |      \n",
      " |      >>> arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
      " |      ...           ['Captive', 'Wild', 'Captive', 'Wild']]\n",
      " |      >>> index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))\n",
      " |      >>> df = pd.DataFrame({'Max Speed': [390., 350., 30., 20.]},\n",
      " |      ...                   index=index)\n",
      " |      >>> df\n",
      " |                      Max Speed\n",
      " |      Animal Type\n",
      " |      Falcon Captive      390.0\n",
      " |             Wild         350.0\n",
      " |      Parrot Captive       30.0\n",
      " |             Wild          20.0\n",
      " |      >>> df.groupby(level=0).mean()\n",
      " |              Max Speed\n",
      " |      Animal\n",
      " |      Falcon      370.0\n",
      " |      Parrot       25.0\n",
      " |      >>> df.groupby(level=\"Type\").mean()\n",
      " |               Max Speed\n",
      " |      Type\n",
      " |      Captive      210.0\n",
      " |      Wild         185.0\n",
      " |      \n",
      " |      We can also choose to include NA in group keys or not by setting\n",
      " |      `dropna` parameter, the default setting is `True`.\n",
      " |      \n",
      " |      >>> l = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\n",
      " |      >>> df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\n",
      " |      \n",
      " |      >>> df.groupby(by=[\"b\"]).sum()\n",
      " |          a   c\n",
      " |      b\n",
      " |      1.0 2   3\n",
      " |      2.0 2   5\n",
      " |      \n",
      " |      >>> df.groupby(by=[\"b\"], dropna=False).sum()\n",
      " |          a   c\n",
      " |      b\n",
      " |      1.0 2   3\n",
      " |      2.0 2   5\n",
      " |      NaN 1   4\n",
      " |      \n",
      " |      >>> l = [[\"a\", 12, 12], [None, 12.3, 33.], [\"b\", 12.3, 123], [\"a\", 1, 1]]\n",
      " |      >>> df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\n",
      " |      \n",
      " |      >>> df.groupby(by=\"a\").sum()\n",
      " |          b     c\n",
      " |      a\n",
      " |      a   13.0   13.0\n",
      " |      b   12.3  123.0\n",
      " |      \n",
      " |      >>> df.groupby(by=\"a\", dropna=False).sum()\n",
      " |          b     c\n",
      " |      a\n",
      " |      a   13.0   13.0\n",
      " |      b   12.3  123.0\n",
      " |      NaN 12.3   33.0\n",
      " |      \n",
      " |      When using ``.apply()``, use ``group_keys`` to include or exclude the group keys.\n",
      " |      The ``group_keys`` argument defaults to ``True`` (include).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',\n",
      " |      ...                               'Parrot', 'Parrot'],\n",
      " |      ...                    'Max Speed': [380., 370., 24., 26.]})\n",
      " |      >>> df.groupby(\"Animal\", group_keys=True).apply(lambda x: x)\n",
      " |                Animal  Max Speed\n",
      " |      Animal\n",
      " |      Falcon 0  Falcon      380.0\n",
      " |             1  Falcon      370.0\n",
      " |      Parrot 2  Parrot       24.0\n",
      " |             3  Parrot       26.0\n",
      " |      \n",
      " |      >>> df.groupby(\"Animal\", group_keys=False).apply(lambda x: x)\n",
      " |         Animal  Max Speed\n",
      " |      0  Falcon      380.0\n",
      " |      1  Falcon      370.0\n",
      " |      2  Parrot       24.0\n",
      " |      3  Parrot       26.0\n",
      " |  \n",
      " |  gt(self, other, axis: 'Axis' = 'columns', level=None)\n",
      " |      Get Greater than of dataframe and other, element-wise (binary operator `gt`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  hist = hist_frame(data: 'DataFrame', column: 'IndexLabel' = None, by=None, grid: 'bool' = True, xlabelsize: 'int | None' = None, xrot: 'float | None' = None, ylabelsize: 'int | None' = None, yrot: 'float | None' = None, ax=None, sharex: 'bool' = False, sharey: 'bool' = False, figsize: 'tuple[int, int] | None' = None, layout: 'tuple[int, int] | None' = None, bins: 'int | Sequence[int]' = 10, backend: 'str | None' = None, legend: 'bool' = False, **kwargs)\n",
      " |      Make a histogram of the DataFrame's columns.\n",
      " |      \n",
      " |      A `histogram`_ is a representation of the distribution of data.\n",
      " |      This function calls :meth:`matplotlib.pyplot.hist`, on each series in\n",
      " |      the DataFrame, resulting in one histogram per column.\n",
      " |      \n",
      " |      .. _histogram: https://en.wikipedia.org/wiki/Histogram\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |          The pandas object holding the data.\n",
      " |      column : str or sequence, optional\n",
      " |          If passed, will be used to limit data to a subset of columns.\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups.\n",
      " |      grid : bool, default True\n",
      " |          Whether to show axis grid lines.\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size.\n",
      " |      xrot : float, default None\n",
      " |          Rotation of x axis labels. For example, a value of 90 displays the\n",
      " |          x labels rotated 90 degrees clockwise.\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size.\n",
      " |      yrot : float, default None\n",
      " |          Rotation of y axis labels. For example, a value of 90 displays the\n",
      " |          y labels rotated 90 degrees clockwise.\n",
      " |      ax : Matplotlib axes object, default None\n",
      " |          The axes to plot the histogram on.\n",
      " |      sharex : bool, default True if ax is None else False\n",
      " |          In case subplots=True, share x axis and set some x axis labels to\n",
      " |          invisible; defaults to True if ax is None otherwise False if an ax\n",
      " |          is passed in.\n",
      " |          Note that passing in both an ax and sharex=True will alter all x axis\n",
      " |          labels for all subplots in a figure.\n",
      " |      sharey : bool, default False\n",
      " |          In case subplots=True, share y axis and set some y axis labels to\n",
      " |          invisible.\n",
      " |      figsize : tuple, optional\n",
      " |          The size in inches of the figure to create. Uses the value in\n",
      " |          `matplotlib.rcParams` by default.\n",
      " |      layout : tuple, optional\n",
      " |          Tuple of (rows, columns) for the layout of the histograms.\n",
      " |      bins : int or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |      \n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |      legend : bool, default False\n",
      " |          Whether to show the legend.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :meth:`matplotlib.pyplot.hist`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      matplotlib.AxesSubplot or numpy.ndarray of them\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.pyplot.hist : Plot a histogram using matplotlib.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This example draws a histogram based on the length and width of\n",
      " |      some animals, displayed in three bins\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame({\n",
      " |          ...     'length': [1.5, 0.5, 1.2, 0.9, 3],\n",
      " |          ...     'width': [0.7, 0.2, 0.15, 0.2, 1.1]\n",
      " |          ...     }, index=['pig', 'rabbit', 'duck', 'chicken', 'horse'])\n",
      " |          >>> hist = df.hist(bins=3)\n",
      " |  \n",
      " |  idxmax(self, axis: 'Axis' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False) -> 'Series'\n",
      " |      Return index of first occurrence of maximum over requested axis.\n",
      " |      \n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Indexes of maxima along the specified axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmax : Return index of the maximum element.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmax``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider a dataset containing food consumption in Argentina.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n",
      " |      ...                     'co2_emissions': [37.2, 19.66, 1712]},\n",
      " |      ...                   index=['Pork', 'Wheat Products', 'Beef'])\n",
      " |      \n",
      " |      >>> df\n",
      " |                      consumption  co2_emissions\n",
      " |      Pork                  10.51         37.20\n",
      " |      Wheat Products       103.11         19.66\n",
      " |      Beef                  55.48       1712.00\n",
      " |      \n",
      " |      By default, it returns the index for the maximum value in each column.\n",
      " |      \n",
      " |      >>> df.idxmax()\n",
      " |      consumption     Wheat Products\n",
      " |      co2_emissions             Beef\n",
      " |      dtype: object\n",
      " |      \n",
      " |      To return the index for the maximum value in each row, use ``axis=\"columns\"``.\n",
      " |      \n",
      " |      >>> df.idxmax(axis=\"columns\")\n",
      " |      Pork              co2_emissions\n",
      " |      Wheat Products     consumption\n",
      " |      Beef              co2_emissions\n",
      " |      dtype: object\n",
      " |  \n",
      " |  idxmin(self, axis: 'Axis' = 0, skipna: 'bool' = True, numeric_only: 'bool' = False) -> 'Series'\n",
      " |      Return index of first occurrence of minimum over requested axis.\n",
      " |      \n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Indexes of minima along the specified axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmin : Return index of the minimum element.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmin``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider a dataset containing food consumption in Argentina.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n",
      " |      ...                     'co2_emissions': [37.2, 19.66, 1712]},\n",
      " |      ...                   index=['Pork', 'Wheat Products', 'Beef'])\n",
      " |      \n",
      " |      >>> df\n",
      " |                      consumption  co2_emissions\n",
      " |      Pork                  10.51         37.20\n",
      " |      Wheat Products       103.11         19.66\n",
      " |      Beef                  55.48       1712.00\n",
      " |      \n",
      " |      By default, it returns the index for the minimum value in each column.\n",
      " |      \n",
      " |      >>> df.idxmin()\n",
      " |      consumption                Pork\n",
      " |      co2_emissions    Wheat Products\n",
      " |      dtype: object\n",
      " |      \n",
      " |      To return the index for the minimum value in each row, use ``axis=\"columns\"``.\n",
      " |      \n",
      " |      >>> df.idxmin(axis=\"columns\")\n",
      " |      Pork                consumption\n",
      " |      Wheat Products    co2_emissions\n",
      " |      Beef                consumption\n",
      " |      dtype: object\n",
      " |  \n",
      " |  info(self, verbose: 'bool | None' = None, buf: 'WriteBuffer[str] | None' = None, max_cols: 'int | None' = None, memory_usage: 'bool | str | None' = None, show_counts: 'bool | None' = None) -> 'None'\n",
      " |      Print a concise summary of a DataFrame.\n",
      " |      \n",
      " |      This method prints information about a DataFrame including\n",
      " |      the index dtype and columns, non-null values and memory usage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      verbose : bool, optional\n",
      " |          Whether to print the full summary. By default, the setting in\n",
      " |          ``pandas.options.display.max_info_columns`` is followed.\n",
      " |      buf : writable buffer, defaults to sys.stdout\n",
      " |          Where to send the output. By default, the output is printed to\n",
      " |          sys.stdout. Pass a writable buffer if you need to further process\n",
      " |          the output.\n",
      " |      max_cols : int, optional\n",
      " |          When to switch from the verbose to the truncated output. If the\n",
      " |          DataFrame has more than `max_cols` columns, the truncated output\n",
      " |          is used. By default, the setting in\n",
      " |          ``pandas.options.display.max_info_columns`` is used.\n",
      " |      memory_usage : bool, str, optional\n",
      " |          Specifies whether total memory usage of the DataFrame\n",
      " |          elements (including the index) should be displayed. By default,\n",
      " |          this follows the ``pandas.options.display.memory_usage`` setting.\n",
      " |      \n",
      " |          True always show memory usage. False never shows memory usage.\n",
      " |          A value of 'deep' is equivalent to \"True with deep introspection\".\n",
      " |          Memory usage is shown in human-readable units (base-2\n",
      " |          representation). Without deep introspection a memory estimation is\n",
      " |          made based in column dtype and number of rows assuming values\n",
      " |          consume the same memory amount for corresponding dtypes. With deep\n",
      " |          memory introspection, a real memory usage calculation is performed\n",
      " |          at the cost of computational resources. See the\n",
      " |          :ref:`Frequently Asked Questions <df-memory-usage>` for more\n",
      " |          details.\n",
      " |      show_counts : bool, optional\n",
      " |          Whether to show the non-null counts. By default, this is shown\n",
      " |          only if the DataFrame is smaller than\n",
      " |          ``pandas.options.display.max_info_rows`` and\n",
      " |          ``pandas.options.display.max_info_columns``. A value of True always\n",
      " |          shows the counts, and False never shows the counts.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None\n",
      " |          This method prints a summary of a DataFrame and returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.describe: Generate descriptive statistics of DataFrame\n",
      " |          columns.\n",
      " |      DataFrame.memory_usage: Memory usage of DataFrame columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> int_values = [1, 2, 3, 4, 5]\n",
      " |      >>> text_values = ['alpha', 'beta', 'gamma', 'delta', 'epsilon']\n",
      " |      >>> float_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
      " |      >>> df = pd.DataFrame({\"int_col\": int_values, \"text_col\": text_values,\n",
      " |      ...                   \"float_col\": float_values})\n",
      " |      >>> df\n",
      " |          int_col text_col  float_col\n",
      " |      0        1    alpha       0.00\n",
      " |      1        2     beta       0.25\n",
      " |      2        3    gamma       0.50\n",
      " |      3        4    delta       0.75\n",
      " |      4        5  epsilon       1.00\n",
      " |      \n",
      " |      Prints information of all columns:\n",
      " |      \n",
      " |      >>> df.info(verbose=True)\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 5 entries, 0 to 4\n",
      " |      Data columns (total 3 columns):\n",
      " |       #   Column     Non-Null Count  Dtype\n",
      " |      ---  ------     --------------  -----\n",
      " |       0   int_col    5 non-null      int64\n",
      " |       1   text_col   5 non-null      object\n",
      " |       2   float_col  5 non-null      float64\n",
      " |      dtypes: float64(1), int64(1), object(1)\n",
      " |      memory usage: 248.0+ bytes\n",
      " |      \n",
      " |      Prints a summary of columns count and its dtypes but not per column\n",
      " |      information:\n",
      " |      \n",
      " |      >>> df.info(verbose=False)\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 5 entries, 0 to 4\n",
      " |      Columns: 3 entries, int_col to float_col\n",
      " |      dtypes: float64(1), int64(1), object(1)\n",
      " |      memory usage: 248.0+ bytes\n",
      " |      \n",
      " |      Pipe output of DataFrame.info to buffer instead of sys.stdout, get\n",
      " |      buffer content and writes to a text file:\n",
      " |      \n",
      " |      >>> import io\n",
      " |      >>> buffer = io.StringIO()\n",
      " |      >>> df.info(buf=buffer)\n",
      " |      >>> s = buffer.getvalue()\n",
      " |      >>> with open(\"df_info.txt\", \"w\",\n",
      " |      ...           encoding=\"utf-8\") as f:  # doctest: +SKIP\n",
      " |      ...     f.write(s)\n",
      " |      260\n",
      " |      \n",
      " |      The `memory_usage` parameter allows deep introspection mode, specially\n",
      " |      useful for big DataFrames and fine-tune memory optimization:\n",
      " |      \n",
      " |      >>> random_strings_array = np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'column_1': np.random.choice(['a', 'b', 'c'], 10 ** 6),\n",
      " |      ...     'column_2': np.random.choice(['a', 'b', 'c'], 10 ** 6),\n",
      " |      ...     'column_3': np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      " |      ... })\n",
      " |      >>> df.info()\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 1000000 entries, 0 to 999999\n",
      " |      Data columns (total 3 columns):\n",
      " |       #   Column    Non-Null Count    Dtype\n",
      " |      ---  ------    --------------    -----\n",
      " |       0   column_1  1000000 non-null  object\n",
      " |       1   column_2  1000000 non-null  object\n",
      " |       2   column_3  1000000 non-null  object\n",
      " |      dtypes: object(3)\n",
      " |      memory usage: 22.9+ MB\n",
      " |      \n",
      " |      >>> df.info(memory_usage='deep')\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 1000000 entries, 0 to 999999\n",
      " |      Data columns (total 3 columns):\n",
      " |       #   Column    Non-Null Count    Dtype\n",
      " |      ---  ------    --------------    -----\n",
      " |       0   column_1  1000000 non-null  object\n",
      " |       1   column_2  1000000 non-null  object\n",
      " |       2   column_3  1000000 non-null  object\n",
      " |      dtypes: object(3)\n",
      " |      memory usage: 165.9 MB\n",
      " |  \n",
      " |  insert(self, loc: 'int', column: 'Hashable', value: 'Scalar | AnyArrayLike', allow_duplicates: 'bool | lib.NoDefault' = <no_default>) -> 'None'\n",
      " |      Insert column into DataFrame at specified location.\n",
      " |      \n",
      " |      Raises a ValueError if `column` is already contained in the DataFrame,\n",
      " |      unless `allow_duplicates` is set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      loc : int\n",
      " |          Insertion index. Must verify 0 <= loc <= len(columns).\n",
      " |      column : str, number, or hashable object\n",
      " |          Label of the inserted column.\n",
      " |      value : Scalar, Series, or array-like\n",
      " |      allow_duplicates : bool, optional, default lib.no_default\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.insert : Insert new item by index.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |      >>> df.insert(1, \"newcol\", [99, 99])\n",
      " |      >>> df\n",
      " |         col1  newcol  col2\n",
      " |      0     1      99     3\n",
      " |      1     2      99     4\n",
      " |      >>> df.insert(0, \"col1\", [100, 100], allow_duplicates=True)\n",
      " |      >>> df\n",
      " |         col1  col1  newcol  col2\n",
      " |      0   100     1      99     3\n",
      " |      1   100     2      99     4\n",
      " |      \n",
      " |      Notice that pandas uses index alignment in case of `value` from type `Series`:\n",
      " |      \n",
      " |      >>> df.insert(0, \"col0\", pd.Series([5, 6], index=[1, 2]))\n",
      " |      >>> df\n",
      " |         col0  col1  col1  newcol  col2\n",
      " |      0   NaN   100     1      99     3\n",
      " |      1   5.0   100     2      99     4\n",
      " |  \n",
      " |  interpolate(self: 'DataFrame', method: 'str' = 'linear', *, axis: 'Axis' = 0, limit: 'int | None' = None, inplace: 'bool' = False, limit_direction: 'str | None' = None, limit_area: 'str | None' = None, downcast: 'str | None' = None, **kwargs) -> 'DataFrame | None'\n",
      " |      Fill NaN values using an interpolation method.\n",
      " |      \n",
      " |      Please note that only ``method='linear'`` is supported for\n",
      " |      DataFrame/Series with a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str, default 'linear'\n",
      " |          Interpolation technique to use. One of:\n",
      " |      \n",
      " |          * 'linear': Ignore the index and treat the values as equally\n",
      " |            spaced. This is the only method supported on MultiIndexes.\n",
      " |          * 'time': Works on daily and higher resolution data to interpolate\n",
      " |            given length of interval.\n",
      " |          * 'index', 'values': use the actual numerical values of the index.\n",
      " |          * 'pad': Fill in NaNs using existing values.\n",
      " |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
      " |            'barycentric', 'polynomial': Passed to\n",
      " |            `scipy.interpolate.interp1d`, whereas 'spline' is passed to\n",
      " |            `scipy.interpolate.UnivariateSpline`. These methods use the numerical\n",
      " |            values of the index.  Both 'polynomial' and 'spline' require that\n",
      " |            you also specify an `order` (int), e.g.\n",
      " |            ``df.interpolate(method='polynomial', order=5)``. Note that,\n",
      " |            `slinear` method in Pandas refers to the Scipy first order `spline`\n",
      " |            instead of Pandas first order `spline`.\n",
      " |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip', 'akima',\n",
      " |            'cubicspline': Wrappers around the SciPy interpolation methods of\n",
      " |            similar names. See `Notes`.\n",
      " |          * 'from_derivatives': Refers to\n",
      " |            `scipy.interpolate.BPoly.from_derivatives` which\n",
      " |            replaces 'piecewise_polynomial' interpolation method in\n",
      " |            scipy 0.18.\n",
      " |      \n",
      " |      axis : {{0 or 'index', 1 or 'columns', None}}, default None\n",
      " |          Axis to interpolate along. For `Series` this parameter is unused\n",
      " |          and defaults to 0.\n",
      " |      limit : int, optional\n",
      " |          Maximum number of consecutive NaNs to fill. Must be greater than\n",
      " |          0.\n",
      " |      inplace : bool, default False\n",
      " |          Update the data in place if possible.\n",
      " |      limit_direction : {{'forward', 'backward', 'both'}}, Optional\n",
      " |          Consecutive NaNs will be filled in this direction.\n",
      " |      \n",
      " |          If limit is specified:\n",
      " |              * If 'method' is 'pad' or 'ffill', 'limit_direction' must be 'forward'.\n",
      " |              * If 'method' is 'backfill' or 'bfill', 'limit_direction' must be\n",
      " |                'backwards'.\n",
      " |      \n",
      " |          If 'limit' is not specified:\n",
      " |              * If 'method' is 'backfill' or 'bfill', the default is 'backward'\n",
      " |              * else the default is 'forward'\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |              raises ValueError if `limit_direction` is 'forward' or 'both' and\n",
      " |                  method is 'backfill' or 'bfill'.\n",
      " |              raises ValueError if `limit_direction` is 'backward' or 'both' and\n",
      " |                  method is 'pad' or 'ffill'.\n",
      " |      \n",
      " |      limit_area : {{`None`, 'inside', 'outside'}}, default None\n",
      " |          If limit is specified, consecutive NaNs will be filled with this\n",
      " |          restriction.\n",
      " |      \n",
      " |          * ``None``: No fill restriction.\n",
      " |          * 'inside': Only fill NaNs surrounded by valid values\n",
      " |            (interpolate).\n",
      " |          * 'outside': Only fill NaNs outside valid values (extrapolate).\n",
      " |      \n",
      " |      downcast : optional, 'infer' or None, defaults to None\n",
      " |          Downcast dtypes if possible.\n",
      " |      ``**kwargs`` : optional\n",
      " |          Keyword arguments to pass on to the interpolating function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame or None\n",
      " |          Returns the same object type as the caller, interpolated at\n",
      " |          some or all ``NaN`` values or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      fillna : Fill missing values using different methods.\n",
      " |      scipy.interpolate.Akima1DInterpolator : Piecewise cubic polynomials\n",
      " |          (Akima interpolator).\n",
      " |      scipy.interpolate.BPoly.from_derivatives : Piecewise polynomial in the\n",
      " |          Bernstein basis.\n",
      " |      scipy.interpolate.interp1d : Interpolate a 1-D function.\n",
      " |      scipy.interpolate.KroghInterpolator : Interpolate polynomial (Krogh\n",
      " |          interpolator).\n",
      " |      scipy.interpolate.PchipInterpolator : PCHIP 1-d monotonic cubic\n",
      " |          interpolation.\n",
      " |      scipy.interpolate.CubicSpline : Cubic spline data interpolator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      " |      methods are wrappers around the respective SciPy implementations of\n",
      " |      similar names. These use the actual numerical values of the index.\n",
      " |      For more information on their behavior, see the\n",
      " |      `SciPy documentation\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Filling in ``NaN`` in a :class:`~pandas.Series` via linear\n",
      " |      interpolation.\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      " |      >>> s\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    NaN\n",
      " |      3    3.0\n",
      " |      dtype: float64\n",
      " |      >>> s.interpolate()\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Filling in ``NaN`` in a Series by padding, but filling at most two\n",
      " |      consecutive ``NaN`` at a time.\n",
      " |      \n",
      " |      >>> s = pd.Series([np.nan, \"single_one\", np.nan,\n",
      " |      ...                \"fill_two_more\", np.nan, np.nan, np.nan,\n",
      " |      ...                4.71, np.nan])\n",
      " |      >>> s\n",
      " |      0              NaN\n",
      " |      1       single_one\n",
      " |      2              NaN\n",
      " |      3    fill_two_more\n",
      " |      4              NaN\n",
      " |      5              NaN\n",
      " |      6              NaN\n",
      " |      7             4.71\n",
      " |      8              NaN\n",
      " |      dtype: object\n",
      " |      >>> s.interpolate(method='pad', limit=2)\n",
      " |      0              NaN\n",
      " |      1       single_one\n",
      " |      2       single_one\n",
      " |      3    fill_two_more\n",
      " |      4    fill_two_more\n",
      " |      5    fill_two_more\n",
      " |      6              NaN\n",
      " |      7             4.71\n",
      " |      8             4.71\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Filling in ``NaN`` in a Series via polynomial interpolation or splines:\n",
      " |      Both 'polynomial' and 'spline' methods require that you also specify\n",
      " |      an ``order`` (int).\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 2, np.nan, 8])\n",
      " |      >>> s.interpolate(method='polynomial', order=2)\n",
      " |      0    0.000000\n",
      " |      1    2.000000\n",
      " |      2    4.666667\n",
      " |      3    8.000000\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Fill the DataFrame forward (that is, going down) along each column\n",
      " |      using linear interpolation.\n",
      " |      \n",
      " |      Note how the last entry in column 'a' is interpolated differently,\n",
      " |      because there is no entry after it to use for interpolation.\n",
      " |      Note how the first entry in column 'b' remains ``NaN``, because there\n",
      " |      is no entry before it to use for interpolation.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([(0.0, np.nan, -1.0, 1.0),\n",
      " |      ...                    (np.nan, 2.0, np.nan, np.nan),\n",
      " |      ...                    (2.0, 3.0, np.nan, 9.0),\n",
      " |      ...                    (np.nan, 4.0, -4.0, 16.0)],\n",
      " |      ...                   columns=list('abcd'))\n",
      " |      >>> df\n",
      " |           a    b    c     d\n",
      " |      0  0.0  NaN -1.0   1.0\n",
      " |      1  NaN  2.0  NaN   NaN\n",
      " |      2  2.0  3.0  NaN   9.0\n",
      " |      3  NaN  4.0 -4.0  16.0\n",
      " |      >>> df.interpolate(method='linear', limit_direction='forward', axis=0)\n",
      " |           a    b    c     d\n",
      " |      0  0.0  NaN -1.0   1.0\n",
      " |      1  1.0  2.0 -2.0   5.0\n",
      " |      2  2.0  3.0 -3.0   9.0\n",
      " |      3  2.0  4.0 -4.0  16.0\n",
      " |      \n",
      " |      Using polynomial interpolation.\n",
      " |      \n",
      " |      >>> df['d'].interpolate(method='polynomial', order=2)\n",
      " |      0     1.0\n",
      " |      1     4.0\n",
      " |      2     9.0\n",
      " |      3    16.0\n",
      " |      Name: d, dtype: float64\n",
      " |  \n",
      " |  isetitem(self, loc, value) -> 'None'\n",
      " |      Set the given value in the column with position `loc`.\n",
      " |      \n",
      " |      This is a positional analogue to ``__setitem__``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      loc : int or sequence of ints\n",
      " |          Index position for the column.\n",
      " |      value : scalar or arraylike\n",
      " |          Value(s) for the column.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      ``frame.isetitem(loc, value)`` is an in-place method as it will\n",
      " |      modify the DataFrame in place (not returning a new object). In contrast to\n",
      " |      ``frame.iloc[:, i] = value`` which will try to update the existing values in\n",
      " |      place, ``frame.isetitem(loc, value)`` will not update the values of the column\n",
      " |      itself in place, it will instead insert a new array.\n",
      " |      \n",
      " |      In cases where ``frame.columns`` is unique, this is equivalent to\n",
      " |      ``frame[frame.columns[i]] = value``.\n",
      " |  \n",
      " |  isin(self, values: 'Series | DataFrame | Sequence | Mapping') -> 'DataFrame'\n",
      " |      Whether each element in the DataFrame is contained in values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : iterable, Series, DataFrame or dict\n",
      " |          The result will only be true at a location if all the\n",
      " |          labels match. If `values` is a Series, that's the index. If\n",
      " |          `values` is a dict, the keys must be the column names,\n",
      " |          which must match. If `values` is a DataFrame,\n",
      " |          then both the index and column labels must match.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame of booleans showing whether each element in the DataFrame\n",
      " |          is contained in values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq: Equality test for DataFrame.\n",
      " |      Series.isin: Equivalent method on Series.\n",
      " |      Series.str.contains: Test if pattern or regex is contained within a\n",
      " |          string of a Series or Index.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4], 'num_wings': [2, 0]},\n",
      " |      ...                   index=['falcon', 'dog'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings\n",
      " |      falcon         2          2\n",
      " |      dog            4          0\n",
      " |      \n",
      " |      When ``values`` is a list check whether every value in the DataFrame\n",
      " |      is present in the list (which animals have 0 or 2 legs or wings)\n",
      " |      \n",
      " |      >>> df.isin([0, 2])\n",
      " |              num_legs  num_wings\n",
      " |      falcon      True       True\n",
      " |      dog        False       True\n",
      " |      \n",
      " |      To check if ``values`` is *not* in the DataFrame, use the ``~`` operator:\n",
      " |      \n",
      " |      >>> ~df.isin([0, 2])\n",
      " |              num_legs  num_wings\n",
      " |      falcon     False      False\n",
      " |      dog         True      False\n",
      " |      \n",
      " |      When ``values`` is a dict, we can pass values to check for each\n",
      " |      column separately:\n",
      " |      \n",
      " |      >>> df.isin({'num_wings': [0, 3]})\n",
      " |              num_legs  num_wings\n",
      " |      falcon     False      False\n",
      " |      dog        False       True\n",
      " |      \n",
      " |      When ``values`` is a Series or DataFrame the index and column must\n",
      " |      match. Note that 'falcon' does not match based on the number of legs\n",
      " |      in other.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'num_legs': [8, 3], 'num_wings': [0, 2]},\n",
      " |      ...                      index=['spider', 'falcon'])\n",
      " |      >>> df.isin(other)\n",
      " |              num_legs  num_wings\n",
      " |      falcon     False       True\n",
      " |      dog        False      False\n",
      " |  \n",
      " |  isna(self) -> 'DataFrame'\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isnull : Alias of isna.\n",
      " |      DataFrame.notna : Boolean inverse of isna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      isna : Top-level isna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
      " |      ...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                              pd.Timestamp('1940-04-25')],\n",
      " |      ...                        name=['Alfred', 'Batman', ''],\n",
      " |      ...                        toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  isnull(self) -> 'DataFrame'\n",
      " |      DataFrame.isnull is an alias for DataFrame.isna.\n",
      " |      \n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isnull : Alias of isna.\n",
      " |      DataFrame.notna : Boolean inverse of isna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      isna : Top-level isna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
      " |      ...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                              pd.Timestamp('1940-04-25')],\n",
      " |      ...                        name=['Alfred', 'Batman', ''],\n",
      " |      ...                        toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  items(self) -> 'Iterable[tuple[Hashable, Series]]'\n",
      " |      Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      Iterates over the DataFrame columns, returning a tuple with\n",
      " |      the column name and the content as a Series.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      label : object\n",
      " |          The column names for the DataFrame being iterated over.\n",
      " |      content : Series\n",
      " |          The column entries belonging to each label, as a Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as\n",
      " |          (index, Series) pairs.\n",
      " |      DataFrame.itertuples : Iterate over DataFrame rows as namedtuples\n",
      " |          of the values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'species': ['bear', 'bear', 'marsupial'],\n",
      " |      ...                   'population': [1864, 22000, 80000]},\n",
      " |      ...                   index=['panda', 'polar', 'koala'])\n",
      " |      >>> df\n",
      " |              species   population\n",
      " |      panda   bear      1864\n",
      " |      polar   bear      22000\n",
      " |      koala   marsupial 80000\n",
      " |      >>> for label, content in df.items():\n",
      " |      ...     print(f'label: {label}')\n",
      " |      ...     print(f'content: {content}', sep='\\n')\n",
      " |      ...\n",
      " |      label: species\n",
      " |      content:\n",
      " |      panda         bear\n",
      " |      polar         bear\n",
      " |      koala    marsupial\n",
      " |      Name: species, dtype: object\n",
      " |      label: population\n",
      " |      content:\n",
      " |      panda     1864\n",
      " |      polar    22000\n",
      " |      koala    80000\n",
      " |      Name: population, dtype: int64\n",
      " |  \n",
      " |  iterrows(self) -> 'Iterable[tuple[Hashable, Series]]'\n",
      " |      Iterate over DataFrame rows as (index, Series) pairs.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      index : label or tuple of label\n",
      " |          The index of the row. A tuple for a `MultiIndex`.\n",
      " |      data : Series\n",
      " |          The data of the row as a Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.itertuples : Iterate over DataFrame rows as namedtuples of the values.\n",
      " |      DataFrame.items : Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      1. Because ``iterrows`` returns a Series for each row,\n",
      " |         it does **not** preserve dtypes across the rows (dtypes are\n",
      " |         preserved across columns for DataFrames). For example,\n",
      " |      \n",
      " |         >>> df = pd.DataFrame([[1, 1.5]], columns=['int', 'float'])\n",
      " |         >>> row = next(df.iterrows())[1]\n",
      " |         >>> row\n",
      " |         int      1.0\n",
      " |         float    1.5\n",
      " |         Name: 0, dtype: float64\n",
      " |         >>> print(row['int'].dtype)\n",
      " |         float64\n",
      " |         >>> print(df['int'].dtype)\n",
      " |         int64\n",
      " |      \n",
      " |         To preserve dtypes while iterating over the rows, it is better\n",
      " |         to use :meth:`itertuples` which returns namedtuples of the values\n",
      " |         and which is generally faster than ``iterrows``.\n",
      " |      \n",
      " |      2. You should **never modify** something you are iterating over.\n",
      " |         This is not guaranteed to work in all cases. Depending on the\n",
      " |         data types, the iterator returns a copy and not a view, and writing\n",
      " |         to it will have no effect.\n",
      " |  \n",
      " |  itertuples(self, index: 'bool' = True, name: 'str | None' = 'Pandas') -> 'Iterable[tuple[Any, ...]]'\n",
      " |      Iterate over DataFrame rows as namedtuples.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          If True, return the index as the first element of the tuple.\n",
      " |      name : str or None, default \"Pandas\"\n",
      " |          The name of the returned namedtuples or None to return regular\n",
      " |          tuples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterator\n",
      " |          An object to iterate over namedtuples for each row in the\n",
      " |          DataFrame with the first field possibly being the index and\n",
      " |          following fields being the column values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as (index, Series)\n",
      " |          pairs.\n",
      " |      DataFrame.items : Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The column names will be renamed to positional names if they are\n",
      " |      invalid Python identifiers, repeated, or start with an underscore.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [4, 2], 'num_wings': [0, 2]},\n",
      " |      ...                   index=['dog', 'hawk'])\n",
      " |      >>> df\n",
      " |            num_legs  num_wings\n",
      " |      dog          4          0\n",
      " |      hawk         2          2\n",
      " |      >>> for row in df.itertuples():\n",
      " |      ...     print(row)\n",
      " |      ...\n",
      " |      Pandas(Index='dog', num_legs=4, num_wings=0)\n",
      " |      Pandas(Index='hawk', num_legs=2, num_wings=2)\n",
      " |      \n",
      " |      By setting the `index` parameter to False we can remove the index\n",
      " |      as the first element of the tuple:\n",
      " |      \n",
      " |      >>> for row in df.itertuples(index=False):\n",
      " |      ...     print(row)\n",
      " |      ...\n",
      " |      Pandas(num_legs=4, num_wings=0)\n",
      " |      Pandas(num_legs=2, num_wings=2)\n",
      " |      \n",
      " |      With the `name` parameter set we set a custom name for the yielded\n",
      " |      namedtuples:\n",
      " |      \n",
      " |      >>> for row in df.itertuples(name='Animal'):\n",
      " |      ...     print(row)\n",
      " |      ...\n",
      " |      Animal(Index='dog', num_legs=4, num_wings=0)\n",
      " |      Animal(Index='hawk', num_legs=2, num_wings=2)\n",
      " |  \n",
      " |  join(self, other: 'DataFrame | Series | Iterable[DataFrame | Series]', on: 'IndexLabel | None' = None, how: 'MergeHow' = 'left', lsuffix: 'str' = '', rsuffix: 'str' = '', sort: 'bool' = False, validate: 'str | None' = None) -> 'DataFrame'\n",
      " |      Join columns of another DataFrame.\n",
      " |      \n",
      " |      Join columns with `other` DataFrame either on index or on a key\n",
      " |      column. Efficiently join multiple DataFrame objects by index at once by\n",
      " |      passing a list.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series, or a list containing any combination of them\n",
      " |          Index should be similar to one of the columns in this one. If a\n",
      " |          Series is passed, its name attribute must be set, and that will be\n",
      " |          used as the column name in the resulting joined DataFrame.\n",
      " |      on : str, list of str, or array-like, optional\n",
      " |          Column or index level name(s) in the caller to join on the index\n",
      " |          in `other`, otherwise joins index-on-index. If multiple\n",
      " |          values given, the `other` DataFrame must have a MultiIndex. Can\n",
      " |          pass an array as the join key if it is not already contained in\n",
      " |          the calling DataFrame. Like an Excel VLOOKUP operation.\n",
      " |      how : {'left', 'right', 'outer', 'inner', 'cross'}, default 'left'\n",
      " |          How to handle the operation of the two objects.\n",
      " |      \n",
      " |          * left: use calling frame's index (or column if on is specified)\n",
      " |          * right: use `other`'s index.\n",
      " |          * outer: form union of calling frame's index (or column if on is\n",
      " |            specified) with `other`'s index, and sort it.\n",
      " |            lexicographically.\n",
      " |          * inner: form intersection of calling frame's index (or column if\n",
      " |            on is specified) with `other`'s index, preserving the order\n",
      " |            of the calling's one.\n",
      " |          * cross: creates the cartesian product from both frames, preserves the order\n",
      " |            of the left keys.\n",
      " |      \n",
      " |            .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      lsuffix : str, default ''\n",
      " |          Suffix to use from left frame's overlapping columns.\n",
      " |      rsuffix : str, default ''\n",
      " |          Suffix to use from right frame's overlapping columns.\n",
      " |      sort : bool, default False\n",
      " |          Order result DataFrame lexicographically by the join key. If False,\n",
      " |          the order of the join key depends on the join type (how keyword).\n",
      " |      validate : str, optional\n",
      " |          If specified, checks if join is of specified type.\n",
      " |          * \"one_to_one\" or \"1:1\": check if join keys are unique in both left\n",
      " |          and right datasets.\n",
      " |          * \"one_to_many\" or \"1:m\": check if join keys are unique in left dataset.\n",
      " |          * \"many_to_one\" or \"m:1\": check if join keys are unique in right dataset.\n",
      " |          * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A dataframe containing columns from both the caller and `other`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.merge : For column(s)-on-column(s) operations.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Parameters `on`, `lsuffix`, and `rsuffix` are not supported when\n",
      " |      passing a list of `DataFrame` objects.\n",
      " |      \n",
      " |      Support for specifying index levels as the `on` parameter was added\n",
      " |      in version 0.23.0.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],\n",
      " |      ...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
      " |      \n",
      " |      >>> df\n",
      " |        key   A\n",
      " |      0  K0  A0\n",
      " |      1  K1  A1\n",
      " |      2  K2  A2\n",
      " |      3  K3  A3\n",
      " |      4  K4  A4\n",
      " |      5  K5  A5\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],\n",
      " |      ...                       'B': ['B0', 'B1', 'B2']})\n",
      " |      \n",
      " |      >>> other\n",
      " |        key   B\n",
      " |      0  K0  B0\n",
      " |      1  K1  B1\n",
      " |      2  K2  B2\n",
      " |      \n",
      " |      Join DataFrames using their indexes.\n",
      " |      \n",
      " |      >>> df.join(other, lsuffix='_caller', rsuffix='_other')\n",
      " |        key_caller   A key_other    B\n",
      " |      0         K0  A0        K0   B0\n",
      " |      1         K1  A1        K1   B1\n",
      " |      2         K2  A2        K2   B2\n",
      " |      3         K3  A3       NaN  NaN\n",
      " |      4         K4  A4       NaN  NaN\n",
      " |      5         K5  A5       NaN  NaN\n",
      " |      \n",
      " |      If we want to join using the key columns, we need to set key to be\n",
      " |      the index in both `df` and `other`. The joined DataFrame will have\n",
      " |      key as its index.\n",
      " |      \n",
      " |      >>> df.set_index('key').join(other.set_index('key'))\n",
      " |            A    B\n",
      " |      key\n",
      " |      K0   A0   B0\n",
      " |      K1   A1   B1\n",
      " |      K2   A2   B2\n",
      " |      K3   A3  NaN\n",
      " |      K4   A4  NaN\n",
      " |      K5   A5  NaN\n",
      " |      \n",
      " |      Another option to join using the key columns is to use the `on`\n",
      " |      parameter. DataFrame.join always uses `other`'s index but we can use\n",
      " |      any column in `df`. This method preserves the original DataFrame's\n",
      " |      index in the result.\n",
      " |      \n",
      " |      >>> df.join(other.set_index('key'), on='key')\n",
      " |        key   A    B\n",
      " |      0  K0  A0   B0\n",
      " |      1  K1  A1   B1\n",
      " |      2  K2  A2   B2\n",
      " |      3  K3  A3  NaN\n",
      " |      4  K4  A4  NaN\n",
      " |      5  K5  A5  NaN\n",
      " |      \n",
      " |      Using non-unique key values shows how they are matched.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'key': ['K0', 'K1', 'K1', 'K3', 'K0', 'K1'],\n",
      " |      ...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
      " |      \n",
      " |      >>> df\n",
      " |        key   A\n",
      " |      0  K0  A0\n",
      " |      1  K1  A1\n",
      " |      2  K1  A2\n",
      " |      3  K3  A3\n",
      " |      4  K0  A4\n",
      " |      5  K1  A5\n",
      " |      \n",
      " |      >>> df.join(other.set_index('key'), on='key', validate='m:1')\n",
      " |        key   A    B\n",
      " |      0  K0  A0   B0\n",
      " |      1  K1  A1   B1\n",
      " |      2  K1  A2   B1\n",
      " |      3  K3  A3  NaN\n",
      " |      4  K0  A4   B0\n",
      " |      5  K1  A5   B1\n",
      " |  \n",
      " |  kurt(self, axis: 'Axis | None' = 0, skipna: 'bool_t' = True, numeric_only: 'bool_t' = False, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis.\n",
      " |      \n",
      " |      Kurtosis obtained using Fisher's definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |      \n",
      " |          .. versionadded:: 2.0.0\n",
      " |      \n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or scalar\n",
      " |  \n",
      " |  kurtosis = kurt(self, axis: 'Axis | None' = 0, skipna: 'bool_t' = True, numeric_only: 'bool_t' = False, **kwargs)\n",
      " |  \n",
      " |  le(self, other, axis: 'Axis' = 'columns', level=None)\n",
      " |      Get Less than or equal to of dataframe and other, element-wise (binary operator `le`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  lt(self, other, axis: 'Axis' = 'columns', level=None)\n",
      " |      Get Less than of dataframe and other, element-wise (binary operator `lt`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  mask(self, cond, other=<no_default>, *, inplace: 'bool' = False, axis: 'Axis | None' = None, level: 'Level' = None) -> 'DataFrame | None'\n",
      " |      Replace values where the condition is True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : bool Series/DataFrame, array-like, or callable\n",
      " |          Where `cond` is False, keep the original value. Where\n",
      " |          True, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the Series/DataFrame and\n",
      " |          should return boolean Series/DataFrame or array. The callable must\n",
      " |          not change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      other : scalar, Series/DataFrame, or callable\n",
      " |          Entries where `cond` is True are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the Series/DataFrame and\n",
      " |          should return scalar or Series/DataFrame. The callable must not\n",
      " |          change input Series/DataFrame (though pandas doesn't check it).\n",
      " |          If not specified, entries will be filled with the corresponding\n",
      " |          NULL value (``np.nan`` for numpy dtypes, ``pd.NA`` for extension\n",
      " |          dtypes).\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      axis : int, default None\n",
      " |          Alignment axis if needed. For `Series` this parameter is\n",
      " |          unused and defaults to 0.\n",
      " |      level : int, default None\n",
      " |          Alignment level if needed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as caller or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.where` : Return an object of same shape as\n",
      " |          self.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The mask method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``False`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used. If the axis of ``other`` does not align with axis of\n",
      " |      ``cond`` Series/DataFrame, the misaligned index positions will be filled with\n",
      " |      True.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``mask`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      The dtype of the object takes precedence. The fill value is casted to\n",
      " |      the object's dtype, if this can be done losslessly.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      dtype: float64\n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> t = pd.Series([True, False])\n",
      " |      >>> s.where(t, 99)\n",
      " |      0     0\n",
      " |      1    99\n",
      " |      2    99\n",
      " |      3    99\n",
      " |      4    99\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(t, 99)\n",
      " |      0    99\n",
      " |      1     1\n",
      " |      2    99\n",
      " |      3    99\n",
      " |      4    99\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(s > 1, 10)\n",
      " |      0     0\n",
      " |      1     1\n",
      " |      2    10\n",
      " |      3    10\n",
      " |      4    10\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  2  3\n",
      " |      2  4  5\n",
      " |      3  6  7\n",
      " |      4  8  9\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |  \n",
      " |  max(self, axis: 'AxisInt | None' = 0, skipna: 'bool_t' = True, numeric_only: 'bool_t' = False, **kwargs)\n",
      " |      Return the maximum of the values over the requested axis.\n",
      " |      \n",
      " |      If you want the *index* of the maximum, use ``idxmax``. This is the equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |      \n",
      " |          .. versionadded:: 2.0.0\n",
      " |      \n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or scalar\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.max()\n",
      " |      8\n",
      " |  \n",
      " |  mean(self, axis: 'AxisInt | None' = 0, skipna: 'bool_t' = True, numeric_only: 'bool_t' = False, **kwargs)\n",
      " |      Return the mean of the values over the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |      \n",
      " |          .. versionadded:: 2.0.0\n",
      " |      \n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or scalar\n",
      " |  \n",
      " |  median(self, axis: 'AxisInt | None' = 0, skipna: 'bool_t' = True, numeric_only: 'bool_t' = False, **kwargs)\n",
      " |      Return the median of the values over the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |      \n",
      " |          .. versionadded:: 2.0.0\n",
      " |      \n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or scalar\n",
      " |  \n",
      " |  melt(self, id_vars=None, value_vars=None, var_name=None, value_name: 'Hashable' = 'value', col_level: 'Level' = None, ignore_index: 'bool' = True) -> 'DataFrame'\n",
      " |      Unpivot a DataFrame from wide to long format, optionally leaving identifiers set.\n",
      " |      \n",
      " |      This function is useful to massage a DataFrame into a format where one\n",
      " |      or more columns are identifier variables (`id_vars`), while all other\n",
      " |      columns, considered measured variables (`value_vars`), are \"unpivoted\" to\n",
      " |      the row axis, leaving just two non-identifier columns, 'variable' and\n",
      " |      'value'.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      id_vars : tuple, list, or ndarray, optional\n",
      " |          Column(s) to use as identifier variables.\n",
      " |      value_vars : tuple, list, or ndarray, optional\n",
      " |          Column(s) to unpivot. If not specified, uses all columns that\n",
      " |          are not set as `id_vars`.\n",
      " |      var_name : scalar\n",
      " |          Name to use for the 'variable' column. If None it uses\n",
      " |          ``frame.columns.name`` or 'variable'.\n",
      " |      value_name : scalar, default 'value'\n",
      " |          Name to use for the 'value' column.\n",
      " |      col_level : int or str, optional\n",
      " |          If columns are a MultiIndex then use this level to melt.\n",
      " |      ignore_index : bool, default True\n",
      " |          If True, original index is ignored. If False, the original index is retained.\n",
      " |          Index labels will be repeated as necessary.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Unpivoted DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      melt : Identical method.\n",
      " |      pivot_table : Create a spreadsheet-style pivot table as a DataFrame.\n",
      " |      DataFrame.pivot : Return reshaped DataFrame organized\n",
      " |          by given index / column values.\n",
      " |      DataFrame.explode : Explode a DataFrame from list-like\n",
      " |              columns to long format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Reference :ref:`the user guide <reshaping.melt>` for more examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},\n",
      " |      ...                    'B': {0: 1, 1: 3, 2: 5},\n",
      " |      ...                    'C': {0: 2, 1: 4, 2: 6}})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  a  1  2\n",
      " |      1  b  3  4\n",
      " |      2  c  5  6\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B', 'C'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      3  a        C      2\n",
      " |      4  b        C      4\n",
      " |      5  c        C      6\n",
      " |      \n",
      " |      The names of 'variable' and 'value' columns can be customized:\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B'],\n",
      " |      ...         var_name='myVarname', value_name='myValname')\n",
      " |         A myVarname  myValname\n",
      " |      0  a         B          1\n",
      " |      1  b         B          3\n",
      " |      2  c         B          5\n",
      " |      \n",
      " |      Original index values can be kept around:\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B', 'C'], ignore_index=False)\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      0  a        C      2\n",
      " |      1  b        C      4\n",
      " |      2  c        C      6\n",
      " |      \n",
      " |      If you have multi-index columns:\n",
      " |      \n",
      " |      >>> df.columns = [list('ABC'), list('DEF')]\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |         D  E  F\n",
      " |      0  a  1  2\n",
      " |      1  b  3  4\n",
      " |      2  c  5  6\n",
      " |      \n",
      " |      >>> df.melt(col_level=0, id_vars=['A'], value_vars=['B'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      \n",
      " |      >>> df.melt(id_vars=[('A', 'D')], value_vars=[('B', 'E')])\n",
      " |        (A, D) variable_0 variable_1  value\n",
      " |      0      a          B          E      1\n",
      " |      1      b          B          E      3\n",
      " |      2      c          B          E      5\n",
      " |  \n",
      " |  memory_usage(self, index: 'bool' = True, deep: 'bool' = False) -> 'Series'\n",
      " |      Return the memory usage of each column in bytes.\n",
      " |      \n",
      " |      The memory usage can optionally include the contribution of\n",
      " |      the index and elements of `object` dtype.\n",
      " |      \n",
      " |      This value is displayed in `DataFrame.info` by default. This can be\n",
      " |      suppressed by setting ``pandas.options.display.memory_usage`` to False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Specifies whether to include the memory usage of the DataFrame's\n",
      " |          index in returned Series. If ``index=True``, the memory usage of\n",
      " |          the index is the first item in the output.\n",
      " |      deep : bool, default False\n",
      " |          If True, introspect the data deeply by interrogating\n",
      " |          `object` dtypes for system-level memory consumption, and include\n",
      " |          it in the returned values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          A Series whose index is the original column names and whose values\n",
      " |          is the memory usage of each column in bytes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.nbytes : Total bytes consumed by the elements of an\n",
      " |          ndarray.\n",
      " |      Series.memory_usage : Bytes consumed by a Series.\n",
      " |      Categorical : Memory-efficient array for string values with\n",
      " |          many repeated values.\n",
      " |      DataFrame.info : Concise summary of a DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the :ref:`Frequently Asked Questions <df-memory-usage>` for more\n",
      " |      details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> dtypes = ['int64', 'float64', 'complex128', 'object', 'bool']\n",
      " |      >>> data = dict([(t, np.ones(shape=5000, dtype=int).astype(t))\n",
      " |      ...              for t in dtypes])\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df.head()\n",
      " |         int64  float64            complex128  object  bool\n",
      " |      0      1      1.0              1.0+0.0j       1  True\n",
      " |      1      1      1.0              1.0+0.0j       1  True\n",
      " |      2      1      1.0              1.0+0.0j       1  True\n",
      " |      3      1      1.0              1.0+0.0j       1  True\n",
      " |      4      1      1.0              1.0+0.0j       1  True\n",
      " |      \n",
      " |      >>> df.memory_usage()\n",
      " |      Index           128\n",
      " |      int64         40000\n",
      " |      float64       40000\n",
      " |      complex128    80000\n",
      " |      object        40000\n",
      " |      bool           5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.memory_usage(index=False)\n",
      " |      int64         40000\n",
      " |      float64       40000\n",
      " |      complex128    80000\n",
      " |      object        40000\n",
      " |      bool           5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The memory footprint of `object` dtype columns is ignored by default:\n",
      " |      \n",
      " |      >>> df.memory_usage(deep=True)\n",
      " |      Index            128\n",
      " |      int64          40000\n",
      " |      float64        40000\n",
      " |      complex128     80000\n",
      " |      object        180000\n",
      " |      bool            5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Use a Categorical for efficient storage of an object-dtype column with\n",
      " |      many repeated values.\n",
      " |      \n",
      " |      >>> df['object'].astype('category').memory_usage(deep=True)\n",
      " |      5244\n",
      " |  \n",
      " |  merge(self, right: 'DataFrame | Series', how: 'MergeHow' = 'inner', on: 'IndexLabel | None' = None, left_on: 'IndexLabel | None' = None, right_on: 'IndexLabel | None' = None, left_index: 'bool' = False, right_index: 'bool' = False, sort: 'bool' = False, suffixes: 'Suffixes' = ('_x', '_y'), copy: 'bool | None' = None, indicator: 'str | bool' = False, validate: 'str | None' = None) -> 'DataFrame'\n",
      " |      Merge DataFrame or named Series objects with a database-style join.\n",
      " |      \n",
      " |      A named Series object is treated as a DataFrame with a single named column.\n",
      " |      \n",
      " |      The join is done on columns or indexes. If joining columns on\n",
      " |      columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes\n",
      " |      on indexes or indexes on a column or columns, the index will be passed on.\n",
      " |      When performing a cross merge, no column specifications to merge on are\n",
      " |      allowed.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |          If both key columns contain rows where the key is a null value, those\n",
      " |          rows will be matched against each other. This is different from usual SQL\n",
      " |          join behaviour and can lead to unexpected results.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      right : DataFrame or named Series\n",
      " |          Object to merge with.\n",
      " |      how : {'left', 'right', 'outer', 'inner', 'cross'}, default 'inner'\n",
      " |          Type of merge to be performed.\n",
      " |      \n",
      " |          * left: use only keys from left frame, similar to a SQL left outer join;\n",
      " |            preserve key order.\n",
      " |          * right: use only keys from right frame, similar to a SQL right outer join;\n",
      " |            preserve key order.\n",
      " |          * outer: use union of keys from both frames, similar to a SQL full outer\n",
      " |            join; sort keys lexicographically.\n",
      " |          * inner: use intersection of keys from both frames, similar to a SQL inner\n",
      " |            join; preserve the order of the left keys.\n",
      " |          * cross: creates the cartesian product from both frames, preserves the order\n",
      " |            of the left keys.\n",
      " |      \n",
      " |            .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      on : label or list\n",
      " |          Column or index level names to join on. These must be found in both\n",
      " |          DataFrames. If `on` is None and not merging on indexes then this defaults\n",
      " |          to the intersection of the columns in both DataFrames.\n",
      " |      left_on : label or list, or array-like\n",
      " |          Column or index level names to join on in the left DataFrame. Can also\n",
      " |          be an array or list of arrays of the length of the left DataFrame.\n",
      " |          These arrays are treated as if they are columns.\n",
      " |      right_on : label or list, or array-like\n",
      " |          Column or index level names to join on in the right DataFrame. Can also\n",
      " |          be an array or list of arrays of the length of the right DataFrame.\n",
      " |          These arrays are treated as if they are columns.\n",
      " |      left_index : bool, default False\n",
      " |          Use the index from the left DataFrame as the join key(s). If it is a\n",
      " |          MultiIndex, the number of keys in the other DataFrame (either the index\n",
      " |          or a number of columns) must match the number of levels.\n",
      " |      right_index : bool, default False\n",
      " |          Use the index from the right DataFrame as the join key. Same caveats as\n",
      " |          left_index.\n",
      " |      sort : bool, default False\n",
      " |          Sort the join keys lexicographically in the result DataFrame. If False,\n",
      " |          the order of the join keys depends on the join type (how keyword).\n",
      " |      suffixes : list-like, default is (\"_x\", \"_y\")\n",
      " |          A length-2 sequence where each element is optionally a string\n",
      " |          indicating the suffix to add to overlapping column names in\n",
      " |          `left` and `right` respectively. Pass a value of `None` instead\n",
      " |          of a string to indicate that the column name from `left` or\n",
      " |          `right` should be left as-is, with no suffix. At least one of the\n",
      " |          values must not be None.\n",
      " |      copy : bool, default True\n",
      " |          If False, avoid copy if possible.\n",
      " |      indicator : bool or str, default False\n",
      " |          If True, adds a column to the output DataFrame called \"_merge\" with\n",
      " |          information on the source of each row. The column can be given a different\n",
      " |          name by providing a string argument. The column will have a Categorical\n",
      " |          type with the value of \"left_only\" for observations whose merge key only\n",
      " |          appears in the left DataFrame, \"right_only\" for observations\n",
      " |          whose merge key only appears in the right DataFrame, and \"both\"\n",
      " |          if the observation's merge key is found in both DataFrames.\n",
      " |      \n",
      " |      validate : str, optional\n",
      " |          If specified, checks if merge is of specified type.\n",
      " |      \n",
      " |          * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\n",
      " |            left and right datasets.\n",
      " |          * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\n",
      " |            dataset.\n",
      " |          * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\n",
      " |            dataset.\n",
      " |          * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A DataFrame of the two merged objects.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_ordered : Merge with optional filling/interpolation.\n",
      " |      merge_asof : Merge on nearest keys.\n",
      " |      DataFrame.join : Similar method using indices.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Support for specifying index levels as the `on`, `left_on`, and\n",
      " |      `right_on` parameters was added in version 0.23.0\n",
      " |      Support for merging named Series objects was added in version 0.24.0\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n",
      " |      ...                     'value': [1, 2, 3, 5]})\n",
      " |      >>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\n",
      " |      ...                     'value': [5, 6, 7, 8]})\n",
      " |      >>> df1\n",
      " |          lkey value\n",
      " |      0   foo      1\n",
      " |      1   bar      2\n",
      " |      2   baz      3\n",
      " |      3   foo      5\n",
      " |      >>> df2\n",
      " |          rkey value\n",
      " |      0   foo      5\n",
      " |      1   bar      6\n",
      " |      2   baz      7\n",
      " |      3   foo      8\n",
      " |      \n",
      " |      Merge df1 and df2 on the lkey and rkey columns. The value columns have\n",
      " |      the default suffixes, _x and _y, appended.\n",
      " |      \n",
      " |      >>> df1.merge(df2, left_on='lkey', right_on='rkey')\n",
      " |        lkey  value_x rkey  value_y\n",
      " |      0  foo        1  foo        5\n",
      " |      1  foo        1  foo        8\n",
      " |      2  foo        5  foo        5\n",
      " |      3  foo        5  foo        8\n",
      " |      4  bar        2  bar        6\n",
      " |      5  baz        3  baz        7\n",
      " |      \n",
      " |      Merge DataFrames df1 and df2 with specified left and right suffixes\n",
      " |      appended to any overlapping columns.\n",
      " |      \n",
      " |      >>> df1.merge(df2, left_on='lkey', right_on='rkey',\n",
      " |      ...           suffixes=('_left', '_right'))\n",
      " |        lkey  value_left rkey  value_right\n",
      " |      0  foo           1  foo            5\n",
      " |      1  foo           1  foo            8\n",
      " |      2  foo           5  foo            5\n",
      " |      3  foo           5  foo            8\n",
      " |      4  bar           2  bar            6\n",
      " |      5  baz           3  baz            7\n",
      " |      \n",
      " |      Merge DataFrames df1 and df2, but raise an exception if the DataFrames have\n",
      " |      any overlapping columns.\n",
      " |      \n",
      " |      >>> df1.merge(df2, left_on='lkey', right_on='rkey', suffixes=(False, False))\n",
      " |      Traceback (most recent call last):\n",
      " |      ...\n",
      " |      ValueError: columns overlap but no suffix specified:\n",
      " |          Index(['value'], dtype='object')\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]})\n",
      " |      >>> df2 = pd.DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]})\n",
      " |      >>> df1\n",
      " |            a  b\n",
      " |      0   foo  1\n",
      " |      1   bar  2\n",
      " |      >>> df2\n",
      " |            a  c\n",
      " |      0   foo  3\n",
      " |      1   baz  4\n",
      " |      \n",
      " |      >>> df1.merge(df2, how='inner', on='a')\n",
      " |            a  b  c\n",
      " |      0   foo  1  3\n",
      " |      \n",
      " |      >>> df1.merge(df2, how='left', on='a')\n",
      " |            a  b  c\n",
      " |      0   foo  1  3.0\n",
      " |      1   bar  2  NaN\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'left': ['foo', 'bar']})\n",
      " |      >>> df2 = pd.DataFrame({'right': [7, 8]})\n",
      " |      >>> df1\n",
      " |          left\n",
      " |      0   foo\n",
      " |      1   bar\n",
      " |      >>> df2\n",
      " |          right\n",
      " |      0   7\n",
      " |      1   8\n",
      " |      \n",
      " |      >>> df1.merge(df2, how='cross')\n",
      " |         left  right\n",
      " |      0   foo      7\n",
      " |      1   foo      8\n",
      " |      2   bar      7\n",
      " |      3   bar      8\n",
      " |  \n",
      " |  min(self, axis: 'AxisInt | None' = 0, skipna: 'bool_t' = True, numeric_only: 'bool_t' = False, **kwargs)\n",
      " |      Return the minimum of the values over the requested axis.\n",
      " |      \n",
      " |      If you want the *index* of the minimum, use ``idxmin``. This is the equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |      \n",
      " |          .. versionadded:: 2.0.0\n",
      " |      \n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or scalar\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.min()\n",
      " |      0\n",
      " |  \n",
      " |  mod(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None)\n",
      " |      Get Modulo of dataframe and other, element-wise (binary operator `mod`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe % other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rmod`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  mode(self, axis: 'Axis' = 0, numeric_only: 'bool' = False, dropna: 'bool' = True) -> 'DataFrame'\n",
      " |      Get the mode(s) of each element along the selected axis.\n",
      " |      \n",
      " |      The mode of a set of values is the value that appears most often.\n",
      " |      It can be multiple values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to iterate over while searching for the mode:\n",
      " |      \n",
      " |          * 0 or 'index' : get mode of each column\n",
      " |          * 1 or 'columns' : get mode of each row.\n",
      " |      \n",
      " |      numeric_only : bool, default False\n",
      " |          If True, only apply to numeric columns.\n",
      " |      dropna : bool, default True\n",
      " |          Don't consider counts of NaN/NaT.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The modes of each column or row.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.mode : Return the highest frequency value in a Series.\n",
      " |      Series.value_counts : Return the counts of values in a Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('bird', 2, 2),\n",
      " |      ...                    ('mammal', 4, np.nan),\n",
      " |      ...                    ('arthropod', 8, 0),\n",
      " |      ...                    ('bird', 2, np.nan)],\n",
      " |      ...                   index=('falcon', 'horse', 'spider', 'ostrich'),\n",
      " |      ...                   columns=('species', 'legs', 'wings'))\n",
      " |      >>> df\n",
      " |                 species  legs  wings\n",
      " |      falcon        bird     2    2.0\n",
      " |      horse       mammal     4    NaN\n",
      " |      spider   arthropod     8    0.0\n",
      " |      ostrich       bird     2    NaN\n",
      " |      \n",
      " |      By default, missing values are not considered, and the mode of wings\n",
      " |      are both 0 and 2. Because the resulting DataFrame has two rows,\n",
      " |      the second row of ``species`` and ``legs`` contains ``NaN``.\n",
      " |      \n",
      " |      >>> df.mode()\n",
      " |        species  legs  wings\n",
      " |      0    bird   2.0    0.0\n",
      " |      1     NaN   NaN    2.0\n",
      " |      \n",
      " |      Setting ``dropna=False`` ``NaN`` values are considered and they can be\n",
      " |      the mode (like for wings).\n",
      " |      \n",
      " |      >>> df.mode(dropna=False)\n",
      " |        species  legs  wings\n",
      " |      0    bird     2    NaN\n",
      " |      \n",
      " |      Setting ``numeric_only=True``, only the mode of numeric columns is\n",
      " |      computed, and columns of other types are ignored.\n",
      " |      \n",
      " |      >>> df.mode(numeric_only=True)\n",
      " |         legs  wings\n",
      " |      0   2.0    0.0\n",
      " |      1   NaN    2.0\n",
      " |      \n",
      " |      To compute the mode over columns and not rows, use the axis parameter:\n",
      " |      \n",
      " |      >>> df.mode(axis='columns', numeric_only=True)\n",
      " |                 0    1\n",
      " |      falcon   2.0  NaN\n",
      " |      horse    4.0  NaN\n",
      " |      spider   0.0  8.0\n",
      " |      ostrich  2.0  NaN\n",
      " |  \n",
      " |  mul(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None)\n",
      " |      Get Multiplication of dataframe and other, element-wise (binary operator `mul`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe * other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rmul`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  multiply = mul(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  ne(self, other, axis: 'Axis' = 'columns', level=None)\n",
      " |      Get Not equal to of dataframe and other, element-wise (binary operator `ne`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  nlargest(self, n: 'int', columns: 'IndexLabel', keep: 'str' = 'first') -> 'DataFrame'\n",
      " |      Return the first `n` rows ordered by `columns` in descending order.\n",
      " |      \n",
      " |      Return the first `n` rows with the largest values in `columns`, in\n",
      " |      descending order. The columns that are not specified are returned as\n",
      " |      well, but not used for ordering.\n",
      " |      \n",
      " |      This method is equivalent to\n",
      " |      ``df.sort_values(columns, ascending=False).head(n)``, but more\n",
      " |      performant.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Number of rows to return.\n",
      " |      columns : label or list of labels\n",
      " |          Column label(s) to order by.\n",
      " |      keep : {'first', 'last', 'all'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |      \n",
      " |          - ``first`` : prioritize the first occurrence(s)\n",
      " |          - ``last`` : prioritize the last occurrence(s)\n",
      " |          - ``all`` : do not drop any duplicates, even it means\n",
      " |            selecting more than `n` items.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The first `n` rows ordered by the given columns in descending\n",
      " |          order.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.nsmallest : Return the first `n` rows ordered by `columns` in\n",
      " |          ascending order.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the values.\n",
      " |      DataFrame.head : Return the first `n` rows without re-ordering.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function cannot be used with all column types. For example, when\n",
      " |      specifying columns with `object` or `category` dtypes, ``TypeError`` is\n",
      " |      raised.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,\n",
      " |      ...                                   434000, 434000, 337000, 11300,\n",
      " |      ...                                   11300, 11300],\n",
      " |      ...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\n",
      " |      ...                            17036, 182, 38, 311],\n",
      " |      ...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\n",
      " |      ...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\n",
      " |      ...                   index=[\"Italy\", \"France\", \"Malta\",\n",
      " |      ...                          \"Maldives\", \"Brunei\", \"Iceland\",\n",
      " |      ...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])\n",
      " |      >>> df\n",
      " |                population      GDP alpha-2\n",
      " |      Italy       59000000  1937894      IT\n",
      " |      France      65000000  2583560      FR\n",
      " |      Malta         434000    12011      MT\n",
      " |      Maldives      434000     4520      MV\n",
      " |      Brunei        434000    12128      BN\n",
      " |      Iceland       337000    17036      IS\n",
      " |      Nauru          11300      182      NR\n",
      " |      Tuvalu         11300       38      TV\n",
      " |      Anguilla       11300      311      AI\n",
      " |      \n",
      " |      In the following example, we will use ``nlargest`` to select the three\n",
      " |      rows having the largest values in column \"population\".\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'population')\n",
      " |              population      GDP alpha-2\n",
      " |      France    65000000  2583560      FR\n",
      " |      Italy     59000000  1937894      IT\n",
      " |      Malta       434000    12011      MT\n",
      " |      \n",
      " |      When using ``keep='last'``, ties are resolved in reverse order:\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'population', keep='last')\n",
      " |              population      GDP alpha-2\n",
      " |      France    65000000  2583560      FR\n",
      " |      Italy     59000000  1937894      IT\n",
      " |      Brunei      434000    12128      BN\n",
      " |      \n",
      " |      When using ``keep='all'``, all duplicate items are maintained:\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'population', keep='all')\n",
      " |                population      GDP alpha-2\n",
      " |      France      65000000  2583560      FR\n",
      " |      Italy       59000000  1937894      IT\n",
      " |      Malta         434000    12011      MT\n",
      " |      Maldives      434000     4520      MV\n",
      " |      Brunei        434000    12128      BN\n",
      " |      \n",
      " |      To order by the largest values in column \"population\" and then \"GDP\",\n",
      " |      we can specify multiple columns like in the next example.\n",
      " |      \n",
      " |      >>> df.nlargest(3, ['population', 'GDP'])\n",
      " |              population      GDP alpha-2\n",
      " |      France    65000000  2583560      FR\n",
      " |      Italy     59000000  1937894      IT\n",
      " |      Brunei      434000    12128      BN\n",
      " |  \n",
      " |  notna(self) -> 'DataFrame'\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.notnull : Alias of notna.\n",
      " |      DataFrame.isna : Boolean inverse of notna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      notna : Top-level notna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
      " |      ...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                              pd.Timestamp('1940-04-25')],\n",
      " |      ...                        name=['Alfred', 'Batman', ''],\n",
      " |      ...                        toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  notnull(self) -> 'DataFrame'\n",
      " |      DataFrame.notnull is an alias for DataFrame.notna.\n",
      " |      \n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.notnull : Alias of notna.\n",
      " |      DataFrame.isna : Boolean inverse of notna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      notna : Top-level notna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
      " |      ...                        born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                              pd.Timestamp('1940-04-25')],\n",
      " |      ...                        name=['Alfred', 'Batman', ''],\n",
      " |      ...                        toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  nsmallest(self, n: 'int', columns: 'IndexLabel', keep: 'str' = 'first') -> 'DataFrame'\n",
      " |      Return the first `n` rows ordered by `columns` in ascending order.\n",
      " |      \n",
      " |      Return the first `n` rows with the smallest values in `columns`, in\n",
      " |      ascending order. The columns that are not specified are returned as\n",
      " |      well, but not used for ordering.\n",
      " |      \n",
      " |      This method is equivalent to\n",
      " |      ``df.sort_values(columns, ascending=True).head(n)``, but more\n",
      " |      performant.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Number of items to retrieve.\n",
      " |      columns : list or str\n",
      " |          Column name or names to order by.\n",
      " |      keep : {'first', 'last', 'all'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |      \n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |          - ``all`` : do not drop any duplicates, even it means\n",
      " |            selecting more than `n` items.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.nlargest : Return the first `n` rows ordered by `columns` in\n",
      " |          descending order.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the values.\n",
      " |      DataFrame.head : Return the first `n` rows without re-ordering.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,\n",
      " |      ...                                   434000, 434000, 337000, 337000,\n",
      " |      ...                                   11300, 11300],\n",
      " |      ...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\n",
      " |      ...                            17036, 182, 38, 311],\n",
      " |      ...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\n",
      " |      ...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\n",
      " |      ...                   index=[\"Italy\", \"France\", \"Malta\",\n",
      " |      ...                          \"Maldives\", \"Brunei\", \"Iceland\",\n",
      " |      ...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])\n",
      " |      >>> df\n",
      " |                population      GDP alpha-2\n",
      " |      Italy       59000000  1937894      IT\n",
      " |      France      65000000  2583560      FR\n",
      " |      Malta         434000    12011      MT\n",
      " |      Maldives      434000     4520      MV\n",
      " |      Brunei        434000    12128      BN\n",
      " |      Iceland       337000    17036      IS\n",
      " |      Nauru         337000      182      NR\n",
      " |      Tuvalu         11300       38      TV\n",
      " |      Anguilla       11300      311      AI\n",
      " |      \n",
      " |      In the following example, we will use ``nsmallest`` to select the\n",
      " |      three rows having the smallest values in column \"population\".\n",
      " |      \n",
      " |      >>> df.nsmallest(3, 'population')\n",
      " |                population    GDP alpha-2\n",
      " |      Tuvalu         11300     38      TV\n",
      " |      Anguilla       11300    311      AI\n",
      " |      Iceland       337000  17036      IS\n",
      " |      \n",
      " |      When using ``keep='last'``, ties are resolved in reverse order:\n",
      " |      \n",
      " |      >>> df.nsmallest(3, 'population', keep='last')\n",
      " |                population  GDP alpha-2\n",
      " |      Anguilla       11300  311      AI\n",
      " |      Tuvalu         11300   38      TV\n",
      " |      Nauru         337000  182      NR\n",
      " |      \n",
      " |      When using ``keep='all'``, all duplicate items are maintained:\n",
      " |      \n",
      " |      >>> df.nsmallest(3, 'population', keep='all')\n",
      " |                population    GDP alpha-2\n",
      " |      Tuvalu         11300     38      TV\n",
      " |      Anguilla       11300    311      AI\n",
      " |      Iceland       337000  17036      IS\n",
      " |      Nauru         337000    182      NR\n",
      " |      \n",
      " |      To order by the smallest values in column \"population\" and then \"GDP\", we can\n",
      " |      specify multiple columns like in the next example.\n",
      " |      \n",
      " |      >>> df.nsmallest(3, ['population', 'GDP'])\n",
      " |                population  GDP alpha-2\n",
      " |      Tuvalu         11300   38      TV\n",
      " |      Anguilla       11300  311      AI\n",
      " |      Nauru         337000  182      NR\n",
      " |  \n",
      " |  nunique(self, axis: 'Axis' = 0, dropna: 'bool' = True) -> 'Series'\n",
      " |      Count number of distinct elements in specified axis.\n",
      " |      \n",
      " |      Return Series with number of distinct elements. Can ignore NaN\n",
      " |      values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for\n",
      " |          column-wise.\n",
      " |      dropna : bool, default True\n",
      " |          Don't include NaN in the counts.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nunique: Method nunique for Series.\n",
      " |      DataFrame.count: Count non-NA cells for each column or row.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [4, 5, 6], 'B': [4, 1, 1]})\n",
      " |      >>> df.nunique()\n",
      " |      A    3\n",
      " |      B    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.nunique(axis=1)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    2\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  pivot(self, *, columns, index=typing.Literal[<no_default>], values=typing.Literal[<no_default>]) -> 'DataFrame'\n",
      " |      Return reshaped DataFrame organized by given index / column values.\n",
      " |      \n",
      " |      Reshape data (produce a \"pivot\" table) based on column values. Uses\n",
      " |      unique values from specified `index` / `columns` to form axes of the\n",
      " |      resulting DataFrame. This function does not support data\n",
      " |      aggregation, multiple values will result in a MultiIndex in the\n",
      " |      columns. See the :ref:`User Guide <reshaping>` for more on reshaping.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      columns : str or object or a list of str\n",
      " |          Column to use to make new frame's columns.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |             Also accept list of columns names.\n",
      " |      \n",
      " |      index : str or object or a list of str, optional\n",
      " |          Column to use to make new frame's index. If not given, uses existing index.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |             Also accept list of index names.\n",
      " |      \n",
      " |      values : str, object or a list of the previous, optional\n",
      " |          Column(s) to use for populating new frame's values. If not\n",
      " |          specified, all remaining columns will be used and the result will\n",
      " |          have hierarchically indexed columns.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Returns reshaped DataFrame.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError:\n",
      " |          When there are any `index`, `columns` combinations with multiple\n",
      " |          values. `DataFrame.pivot_table` when you need to aggregate.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pivot_table : Generalization of pivot that can handle\n",
      " |          duplicate values for one index/column pair.\n",
      " |      DataFrame.unstack : Pivot based on the index values instead of a\n",
      " |          column.\n",
      " |      wide_to_long : Wide panel to long format. Less flexible but more\n",
      " |          user-friendly than melt.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For finer-tuned control, see hierarchical indexing documentation along\n",
      " |      with the related stack/unstack methods.\n",
      " |      \n",
      " |      Reference :ref:`the user guide <reshaping.pivot>` for more examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',\n",
      " |      ...                            'two'],\n",
      " |      ...                    'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
      " |      ...                    'baz': [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'zoo': ['x', 'y', 'z', 'q', 'w', 't']})\n",
      " |      >>> df\n",
      " |          foo   bar  baz  zoo\n",
      " |      0   one   A    1    x\n",
      " |      1   one   B    2    y\n",
      " |      2   one   C    3    z\n",
      " |      3   two   A    4    q\n",
      " |      4   two   B    5    w\n",
      " |      5   two   C    6    t\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values='baz')\n",
      " |      bar  A   B   C\n",
      " |      foo\n",
      " |      one  1   2   3\n",
      " |      two  4   5   6\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar')['baz']\n",
      " |      bar  A   B   C\n",
      " |      foo\n",
      " |      one  1   2   3\n",
      " |      two  4   5   6\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values=['baz', 'zoo'])\n",
      " |            baz       zoo\n",
      " |      bar   A  B  C   A  B  C\n",
      " |      foo\n",
      " |      one   1  2  3   x  y  z\n",
      " |      two   4  5  6   q  w  t\n",
      " |      \n",
      " |      You could also assign a list of column names or a list of index names.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...        \"lev1\": [1, 1, 1, 2, 2, 2],\n",
      " |      ...        \"lev2\": [1, 1, 2, 1, 1, 2],\n",
      " |      ...        \"lev3\": [1, 2, 1, 2, 1, 2],\n",
      " |      ...        \"lev4\": [1, 2, 3, 4, 5, 6],\n",
      " |      ...        \"values\": [0, 1, 2, 3, 4, 5]})\n",
      " |      >>> df\n",
      " |          lev1 lev2 lev3 lev4 values\n",
      " |      0   1    1    1    1    0\n",
      " |      1   1    1    2    2    1\n",
      " |      2   1    2    1    3    2\n",
      " |      3   2    1    2    4    3\n",
      " |      4   2    1    1    5    4\n",
      " |      5   2    2    2    6    5\n",
      " |      \n",
      " |      >>> df.pivot(index=\"lev1\", columns=[\"lev2\", \"lev3\"], values=\"values\")\n",
      " |      lev2    1         2\n",
      " |      lev3    1    2    1    2\n",
      " |      lev1\n",
      " |      1     0.0  1.0  2.0  NaN\n",
      " |      2     4.0  3.0  NaN  5.0\n",
      " |      \n",
      " |      >>> df.pivot(index=[\"lev1\", \"lev2\"], columns=[\"lev3\"], values=\"values\")\n",
      " |            lev3    1    2\n",
      " |      lev1  lev2\n",
      " |         1     1  0.0  1.0\n",
      " |               2  2.0  NaN\n",
      " |         2     1  4.0  3.0\n",
      " |               2  NaN  5.0\n",
      " |      \n",
      " |      A ValueError is raised if there are any duplicates.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"foo\": ['one', 'one', 'two', 'two'],\n",
      " |      ...                    \"bar\": ['A', 'A', 'B', 'C'],\n",
      " |      ...                    \"baz\": [1, 2, 3, 4]})\n",
      " |      >>> df\n",
      " |         foo bar  baz\n",
      " |      0  one   A    1\n",
      " |      1  one   A    2\n",
      " |      2  two   B    3\n",
      " |      3  two   C    4\n",
      " |      \n",
      " |      Notice that the first two rows are the same for our `index`\n",
      " |      and `columns` arguments.\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values='baz')\n",
      " |      Traceback (most recent call last):\n",
      " |         ...\n",
      " |      ValueError: Index contains duplicate entries, cannot reshape\n",
      " |  \n",
      " |  pivot_table(self, values=None, index=None, columns=None, aggfunc: 'AggFuncType' = 'mean', fill_value=None, margins: 'bool' = False, dropna: 'bool' = True, margins_name: 'Level' = 'All', observed: 'bool' = False, sort: 'bool' = True) -> 'DataFrame'\n",
      " |      Create a spreadsheet-style pivot table as a DataFrame.\n",
      " |      \n",
      " |      The levels in the pivot table will be stored in MultiIndex objects\n",
      " |      (hierarchical indexes) on the index and columns of the result DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : list-like or scalar, optional\n",
      " |          Column or columns to aggregate.\n",
      " |      index : column, Grouper, array, or list of the previous\n",
      " |          If an array is passed, it must be the same length as the data. The\n",
      " |          list can contain any of the other types (except list).\n",
      " |          Keys to group by on the pivot table index.  If an array is passed,\n",
      " |          it is being used as the same manner as column values.\n",
      " |      columns : column, Grouper, array, or list of the previous\n",
      " |          If an array is passed, it must be the same length as the data. The\n",
      " |          list can contain any of the other types (except list).\n",
      " |          Keys to group by on the pivot table column.  If an array is passed,\n",
      " |          it is being used as the same manner as column values.\n",
      " |      aggfunc : function, list of functions, dict, default numpy.mean\n",
      " |          If list of functions passed, the resulting pivot table will have\n",
      " |          hierarchical columns whose top level are the function names\n",
      " |          (inferred from the function objects themselves)\n",
      " |          If dict is passed, the key is column to aggregate and value\n",
      " |          is function or list of functions. If ``margin=True``,\n",
      " |          aggfunc will be used to calculate the partial aggregates.\n",
      " |      fill_value : scalar, default None\n",
      " |          Value to replace missing values with (in the resulting pivot table,\n",
      " |          after aggregation).\n",
      " |      margins : bool, default False\n",
      " |          If ``margins=True``, special ``All`` columns and rows\n",
      " |          will be added with partial group aggregates across the categories\n",
      " |          on the rows and columns.\n",
      " |      dropna : bool, default True\n",
      " |          Do not include columns whose entries are all NaN. If True,\n",
      " |          rows with a NaN value in any column will be omitted before\n",
      " |          computing margins.\n",
      " |      margins_name : str, default 'All'\n",
      " |          Name of the row / column that will contain the totals\n",
      " |          when margins is True.\n",
      " |      observed : bool, default False\n",
      " |          This only applies if any of the groupers are Categoricals.\n",
      " |          If True: only show observed values for categorical groupers.\n",
      " |          If False: show all values for categorical groupers.\n",
      " |      \n",
      " |      sort : bool, default True\n",
      " |          Specifies if the result should be sorted.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          An Excel style pivot table.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pivot : Pivot without aggregation that can handle\n",
      " |          non-numeric data.\n",
      " |      DataFrame.melt: Unpivot a DataFrame from wide to long format,\n",
      " |          optionally leaving identifiers set.\n",
      " |      wide_to_long : Wide panel to long format. Less flexible but more\n",
      " |          user-friendly than melt.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Reference :ref:`the user guide <reshaping.pivot>` for more examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
      " |      ...                          \"bar\", \"bar\", \"bar\", \"bar\"],\n",
      " |      ...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
      " |      ...                          \"one\", \"one\", \"two\", \"two\"],\n",
      " |      ...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
      " |      ...                          \"small\", \"large\", \"small\", \"small\",\n",
      " |      ...                          \"large\"],\n",
      " |      ...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
      " |      ...                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
      " |      >>> df\n",
      " |           A    B      C  D  E\n",
      " |      0  foo  one  small  1  2\n",
      " |      1  foo  one  large  2  4\n",
      " |      2  foo  one  large  2  5\n",
      " |      3  foo  two  small  3  5\n",
      " |      4  foo  two  small  3  6\n",
      " |      5  bar  one  large  4  6\n",
      " |      6  bar  one  small  5  8\n",
      " |      7  bar  two  small  6  9\n",
      " |      8  bar  two  large  7  9\n",
      " |      \n",
      " |      This first example aggregates values by taking the sum.\n",
      " |      \n",
      " |      >>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      " |      ...                        columns=['C'], aggfunc=np.sum)\n",
      " |      >>> table\n",
      " |      C        large  small\n",
      " |      A   B\n",
      " |      bar one    4.0    5.0\n",
      " |          two    7.0    6.0\n",
      " |      foo one    4.0    1.0\n",
      " |          two    NaN    6.0\n",
      " |      \n",
      " |      We can also fill missing values using the `fill_value` parameter.\n",
      " |      \n",
      " |      >>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      " |      ...                        columns=['C'], aggfunc=np.sum, fill_value=0)\n",
      " |      >>> table\n",
      " |      C        large  small\n",
      " |      A   B\n",
      " |      bar one      4      5\n",
      " |          two      7      6\n",
      " |      foo one      4      1\n",
      " |          two      0      6\n",
      " |      \n",
      " |      The next example aggregates by taking the mean across multiple columns.\n",
      " |      \n",
      " |      >>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      " |      ...                        aggfunc={'D': np.mean, 'E': np.mean})\n",
      " |      >>> table\n",
      " |                      D         E\n",
      " |      A   C\n",
      " |      bar large  5.500000  7.500000\n",
      " |          small  5.500000  8.500000\n",
      " |      foo large  2.000000  4.500000\n",
      " |          small  2.333333  4.333333\n",
      " |      \n",
      " |      We can also calculate multiple types of aggregations for any given\n",
      " |      value column.\n",
      " |      \n",
      " |      >>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      " |      ...                        aggfunc={'D': np.mean,\n",
      " |      ...                                 'E': [min, max, np.mean]})\n",
      " |      >>> table\n",
      " |                        D   E\n",
      " |                     mean max      mean  min\n",
      " |      A   C\n",
      " |      bar large  5.500000   9  7.500000    6\n",
      " |          small  5.500000   9  8.500000    8\n",
      " |      foo large  2.000000   5  4.500000    4\n",
      " |          small  2.333333   6  4.333333    2\n",
      " |  \n",
      " |  pop(self, item: 'Hashable') -> 'Series'\n",
      " |      Return item and drop from frame. Raise KeyError if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      item : label\n",
      " |          Label of column to be popped.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      " |      ...                    ('parrot', 'bird', 24.0),\n",
      " |      ...                    ('lion', 'mammal', 80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=('name', 'class', 'max_speed'))\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      3  monkey  mammal        NaN\n",
      " |      \n",
      " |      >>> df.pop('class')\n",
      " |      0      bird\n",
      " |      1      bird\n",
      " |      2    mammal\n",
      " |      3    mammal\n",
      " |      Name: class, dtype: object\n",
      " |      \n",
      " |      >>> df\n",
      " |           name  max_speed\n",
      " |      0  falcon      389.0\n",
      " |      1  parrot       24.0\n",
      " |      2    lion       80.5\n",
      " |      3  monkey        NaN\n",
      " |  \n",
      " |  pow(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None)\n",
      " |      Get Exponential power of dataframe and other, element-wise (binary operator `pow`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe ** other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rpow`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  prod(self, axis: 'Axis | None' = None, skipna: 'bool_t' = True, numeric_only: 'bool_t' = False, min_count: 'int' = 0, **kwargs)\n",
      " |      Return the product of the values over the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |      \n",
      " |          .. versionadded:: 2.0.0\n",
      " |      \n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |      \n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or scalar\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the product of an empty or all-NA Series is ``1``\n",
      " |      \n",
      " |      >>> pd.Series([], dtype=\"float64\").prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter\n",
      " |      \n",
      " |      >>> pd.Series([], dtype=\"float64\").prod(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  product = prod(self, axis: 'Axis | None' = None, skipna: 'bool_t' = True, numeric_only: 'bool_t' = False, min_count: 'int' = 0, **kwargs)\n",
      " |  \n",
      " |  quantile(self, q: 'float | AnyArrayLike | Sequence[float]' = 0.5, axis: 'Axis' = 0, numeric_only: 'bool' = False, interpolation: 'QuantileInterpolation' = 'linear', method: \"Literal[('single', 'table')]\" = 'single') -> 'Series | DataFrame'\n",
      " |      Return values at the given quantile over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          Value between 0 <= q <= 1, the quantile(s) to compute.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Equals 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |              The default value of ``numeric_only`` is now ``False``.\n",
      " |      \n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |      \n",
      " |          * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |            fractional part of the index surrounded by `i` and `j`.\n",
      " |          * lower: `i`.\n",
      " |          * higher: `j`.\n",
      " |          * nearest: `i` or `j` whichever is nearest.\n",
      " |          * midpoint: (`i` + `j`) / 2.\n",
      " |      method : {'single', 'table'}, default 'single'\n",
      " |          Whether to compute quantiles per-column ('single') or over all columns\n",
      " |          ('table'). When 'table', the only allowed interpolation methods are\n",
      " |          'nearest', 'lower', and 'higher'.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |          If ``q`` is an array, a DataFrame will be returned where the\n",
      " |            index is ``q``, the columns are the columns of self, and the\n",
      " |            values are the quantiles.\n",
      " |          If ``q`` is a float, a Series will be returned where the\n",
      " |            index is the columns of self and the values are the quantiles.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.rolling.Rolling.quantile: Rolling quantile.\n",
      " |      numpy.percentile: Numpy function to compute the percentile.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n",
      " |      ...                   columns=['a', 'b'])\n",
      " |      >>> df.quantile(.1)\n",
      " |      a    1.3\n",
      " |      b    3.7\n",
      " |      Name: 0.1, dtype: float64\n",
      " |      >>> df.quantile([.1, .5])\n",
      " |             a     b\n",
      " |      0.1  1.3   3.7\n",
      " |      0.5  2.5  55.0\n",
      " |      \n",
      " |      Specifying `method='table'` will compute the quantile over all columns.\n",
      " |      \n",
      " |      >>> df.quantile(.1, method=\"table\", interpolation=\"nearest\")\n",
      " |      a    1\n",
      " |      b    1\n",
      " |      Name: 0.1, dtype: int64\n",
      " |      >>> df.quantile([.1, .5], method=\"table\", interpolation=\"nearest\")\n",
      " |           a    b\n",
      " |      0.1  1    1\n",
      " |      0.5  3  100\n",
      " |      \n",
      " |      Specifying `numeric_only=False` will also compute the quantile of\n",
      " |      datetime and timedelta data.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2],\n",
      " |      ...                    'B': [pd.Timestamp('2010'),\n",
      " |      ...                          pd.Timestamp('2011')],\n",
      " |      ...                    'C': [pd.Timedelta('1 days'),\n",
      " |      ...                          pd.Timedelta('2 days')]})\n",
      " |      >>> df.quantile(0.5, numeric_only=False)\n",
      " |      A                    1.5\n",
      " |      B    2010-07-02 12:00:00\n",
      " |      C        1 days 12:00:00\n",
      " |      Name: 0.5, dtype: object\n",
      " |  \n",
      " |  query(self, expr: 'str', *, inplace: 'bool' = False, **kwargs) -> 'DataFrame | None'\n",
      " |      Query the columns of a DataFrame with a boolean expression.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      expr : str\n",
      " |          The query string to evaluate.\n",
      " |      \n",
      " |          You can refer to variables\n",
      " |          in the environment by prefixing them with an '@' character like\n",
      " |          ``@a + b``.\n",
      " |      \n",
      " |          You can refer to column names that are not valid Python variable names\n",
      " |          by surrounding them in backticks. Thus, column names containing spaces\n",
      " |          or punctuations (besides underscores) or starting with digits must be\n",
      " |          surrounded by backticks. (For example, a column named \"Area (cm^2)\" would\n",
      " |          be referenced as ```Area (cm^2)```). Column names which are Python keywords\n",
      " |          (like \"list\", \"for\", \"import\", etc) cannot be used.\n",
      " |      \n",
      " |          For example, if one of your columns is called ``a a`` and you want\n",
      " |          to sum it with ``b``, your query should be ```a a` + b``.\n",
      " |      \n",
      " |      inplace : bool\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |      **kwargs\n",
      " |          See the documentation for :func:`eval` for complete details\n",
      " |          on the keyword arguments accepted by :meth:`DataFrame.query`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame resulting from the provided query expression or\n",
      " |          None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      eval : Evaluate a string describing operations on\n",
      " |          DataFrame columns.\n",
      " |      DataFrame.eval : Evaluate a string describing operations on\n",
      " |          DataFrame columns.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The result of the evaluation of this expression is first passed to\n",
      " |      :attr:`DataFrame.loc` and if that fails because of a\n",
      " |      multidimensional key (e.g., a DataFrame) then the result will be passed\n",
      " |      to :meth:`DataFrame.__getitem__`.\n",
      " |      \n",
      " |      This method uses the top-level :func:`eval` function to\n",
      " |      evaluate the passed query.\n",
      " |      \n",
      " |      The :meth:`~pandas.DataFrame.query` method uses a slightly\n",
      " |      modified Python syntax by default. For example, the ``&`` and ``|``\n",
      " |      (bitwise) operators have the precedence of their boolean cousins,\n",
      " |      :keyword:`and` and :keyword:`or`. This *is* syntactically valid Python,\n",
      " |      however the semantics are different.\n",
      " |      \n",
      " |      You can change the semantics of the expression by passing the keyword\n",
      " |      argument ``parser='python'``. This enforces the same semantics as\n",
      " |      evaluation in Python space. Likewise, you can pass ``engine='python'``\n",
      " |      to evaluate an expression using Python itself as a backend. This is not\n",
      " |      recommended as it is inefficient compared to using ``numexpr`` as the\n",
      " |      engine.\n",
      " |      \n",
      " |      The :attr:`DataFrame.index` and\n",
      " |      :attr:`DataFrame.columns` attributes of the\n",
      " |      :class:`~pandas.DataFrame` instance are placed in the query namespace\n",
      " |      by default, which allows you to treat both the index and columns of the\n",
      " |      frame as a column in the frame.\n",
      " |      The identifier ``index`` is used for the frame index; you can also\n",
      " |      use the name of the index to identify it in a query. Please note that\n",
      " |      Python keywords may not be used as identifiers.\n",
      " |      \n",
      " |      For further details and examples see the ``query`` documentation in\n",
      " |      :ref:`indexing <indexing.query>`.\n",
      " |      \n",
      " |      *Backtick quoted variables*\n",
      " |      \n",
      " |      Backtick quoted variables are parsed as literal Python code and\n",
      " |      are converted internally to a Python valid identifier.\n",
      " |      This can lead to the following problems.\n",
      " |      \n",
      " |      During parsing a number of disallowed characters inside the backtick\n",
      " |      quoted string are replaced by strings that are allowed as a Python identifier.\n",
      " |      These characters include all operators in Python, the space character, the\n",
      " |      question mark, the exclamation mark, the dollar sign, and the euro sign.\n",
      " |      For other characters that fall outside the ASCII range (U+0001..U+007F)\n",
      " |      and those that are not further specified in PEP 3131,\n",
      " |      the query parser will raise an error.\n",
      " |      This excludes whitespace different than the space character,\n",
      " |      but also the hashtag (as it is used for comments) and the backtick\n",
      " |      itself (backtick can also not be escaped).\n",
      " |      \n",
      " |      In a special case, quotes that make a pair around a backtick can\n",
      " |      confuse the parser.\n",
      " |      For example, ```it's` > `that's``` will raise an error,\n",
      " |      as it forms a quoted string (``'s > `that'``) with a backtick inside.\n",
      " |      \n",
      " |      See also the Python documentation about lexical analysis\n",
      " |      (https://docs.python.org/3/reference/lexical_analysis.html)\n",
      " |      in combination with the source code in :mod:`pandas.core.computation.parsing`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(1, 6),\n",
      " |      ...                    'B': range(10, 0, -2),\n",
      " |      ...                    'C C': range(10, 5, -1)})\n",
      " |      >>> df\n",
      " |         A   B  C C\n",
      " |      0  1  10   10\n",
      " |      1  2   8    9\n",
      " |      2  3   6    8\n",
      " |      3  4   4    7\n",
      " |      4  5   2    6\n",
      " |      >>> df.query('A > B')\n",
      " |         A  B  C C\n",
      " |      4  5  2    6\n",
      " |      \n",
      " |      The previous expression is equivalent to\n",
      " |      \n",
      " |      >>> df[df.A > df.B]\n",
      " |         A  B  C C\n",
      " |      4  5  2    6\n",
      " |      \n",
      " |      For columns with spaces in their name, you can use backtick quoting.\n",
      " |      \n",
      " |      >>> df.query('B == `C C`')\n",
      " |         A   B  C C\n",
      " |      0  1  10   10\n",
      " |      \n",
      " |      The previous expression is equivalent to\n",
      " |      \n",
      " |      >>> df[df.B == df['C C']]\n",
      " |         A   B  C C\n",
      " |      0  1  10   10\n",
      " |  \n",
      " |  radd(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None)\n",
      " |      Get Addition of dataframe and other, element-wise (binary operator `radd`).\n",
      " |      \n",
      " |      Equivalent to ``other + dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `add`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rdiv = rtruediv(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  reindex(self, labels=None, *, index=None, columns=None, axis: 'Axis | None' = None, method: 'str | None' = None, copy: 'bool | None' = None, level: 'Level | None' = None, fill_value: 'Scalar | None' = nan, limit: 'int | None' = None, tolerance=None) -> 'DataFrame'\n",
      " |      Conform DataFrame to new index with optional filling logic.\n",
      " |      \n",
      " |      Places NA/NaN in locations having no value in the previous index. A new object\n",
      " |      is produced unless the new index is equivalent to the current one and\n",
      " |      ``copy=False``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      labels : array-like, optional\n",
      " |          New labels / index to conform the axis specified by 'axis' to.\n",
      " |      index : array-like, optional\n",
      " |          New labels for the index. Preferably an Index object to avoid\n",
      " |          duplicating data.\n",
      " |      columns : array-like, optional\n",
      " |          New labels for the columns. Preferably an Index object to avoid\n",
      " |          duplicating data.\n",
      " |      axis : int or str, optional\n",
      " |          Axis to target. Can be either the axis name ('index', 'columns')\n",
      " |          or number (0, 1).\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      " |          Method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: Propagate last valid observation forward to next\n",
      " |            valid.\n",
      " |          * backfill / bfill: Use next valid observation to fill gap.\n",
      " |          * nearest: Use nearest valid observations to fill gap.\n",
      " |      \n",
      " |      copy : bool, default True\n",
      " |          Return a new object, even if the passed indexes are the same.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value.\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive elements to forward or backward fill.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame with changed index.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Set row labels.\n",
      " |      DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      ``DataFrame.reindex`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_labels, columns=column_labels, ...)``\n",
      " |      * ``(labels, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Create a dataframe with some fictional data.\n",
      " |      \n",
      " |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      " |      >>> df = pd.DataFrame({'http_status': [200, 200, 404, 404, 301],\n",
      " |      ...                   'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      " |      ...                   index=index)\n",
      " |      >>> df\n",
      " |                 http_status  response_time\n",
      " |      Firefox            200           0.04\n",
      " |      Chrome             200           0.02\n",
      " |      Safari             404           0.07\n",
      " |      IE10               404           0.08\n",
      " |      Konqueror          301           1.00\n",
      " |      \n",
      " |      Create a new index and reindex the dataframe. By default\n",
      " |      values in the new index that do not have corresponding\n",
      " |      records in the dataframe are assigned ``NaN``.\n",
      " |      \n",
      " |      >>> new_index = ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      " |      ...              'Chrome']\n",
      " |      >>> df.reindex(new_index)\n",
      " |                     http_status  response_time\n",
      " |      Safari               404.0           0.07\n",
      " |      Iceweasel              NaN            NaN\n",
      " |      Comodo Dragon          NaN            NaN\n",
      " |      IE10                 404.0           0.08\n",
      " |      Chrome               200.0           0.02\n",
      " |      \n",
      " |      We can fill in the missing values by passing a value to\n",
      " |      the keyword ``fill_value``. Because the index is not monotonically\n",
      " |      increasing or decreasing, we cannot use arguments to the keyword\n",
      " |      ``method`` to fill the ``NaN`` values.\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value=0)\n",
      " |                     http_status  response_time\n",
      " |      Safari                 404           0.07\n",
      " |      Iceweasel                0           0.00\n",
      " |      Comodo Dragon            0           0.00\n",
      " |      IE10                   404           0.08\n",
      " |      Chrome                 200           0.02\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value='missing')\n",
      " |                    http_status response_time\n",
      " |      Safari                404          0.07\n",
      " |      Iceweasel         missing       missing\n",
      " |      Comodo Dragon     missing       missing\n",
      " |      IE10                  404          0.08\n",
      " |      Chrome                200          0.02\n",
      " |      \n",
      " |      We can also reindex the columns.\n",
      " |      \n",
      " |      >>> df.reindex(columns=['http_status', 'user_agent'])\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      Or we can use \"axis-style\" keyword arguments\n",
      " |      \n",
      " |      >>> df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      To further illustrate the filling functionality in\n",
      " |      ``reindex``, we will create a dataframe with a\n",
      " |      monotonically increasing index (for example, a sequence\n",
      " |      of dates).\n",
      " |      \n",
      " |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      " |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      " |      ...                    index=date_index)\n",
      " |      >>> df2\n",
      " |                  prices\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      \n",
      " |      Suppose we decide to expand the dataframe to cover a wider\n",
      " |      date range.\n",
      " |      \n",
      " |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      " |      >>> df2.reindex(date_index2)\n",
      " |                  prices\n",
      " |      2009-12-29     NaN\n",
      " |      2009-12-30     NaN\n",
      " |      2009-12-31     NaN\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      The index entries that did not have a value in the original data frame\n",
      " |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      " |      If desired, we can fill in the missing values using one of several\n",
      " |      options.\n",
      " |      \n",
      " |      For example, to back-propagate the last valid value to fill the ``NaN``\n",
      " |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      " |      \n",
      " |      >>> df2.reindex(date_index2, method='bfill')\n",
      " |                  prices\n",
      " |      2009-12-29   100.0\n",
      " |      2009-12-30   100.0\n",
      " |      2009-12-31   100.0\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      Please note that the ``NaN`` value present in the original dataframe\n",
      " |      (at index value 2010-01-03) will not be filled by any of the\n",
      " |      value propagation schemes. This is because filling while reindexing\n",
      " |      does not look at dataframe values, but only compares the original and\n",
      " |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      " |      in the original dataframe, use the ``fillna()`` method.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.reindexing>` for more.\n",
      " |  \n",
      " |  rename(self, mapper: 'Renamer | None' = None, *, index: 'Renamer | None' = None, columns: 'Renamer | None' = None, axis: 'Axis | None' = None, copy: 'bool | None' = None, inplace: 'bool' = False, level: 'Level' = None, errors: 'IgnoreRaise' = 'ignore') -> 'DataFrame | None'\n",
      " |      Rename columns or index labels.\n",
      " |      \n",
      " |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      " |      a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      " |      error.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.rename>` for more.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : dict-like or function\n",
      " |          Dict-like or function transformations to apply to\n",
      " |          that axis' values. Use either ``mapper`` and ``axis`` to\n",
      " |          specify the axis to target with ``mapper``, or ``index`` and\n",
      " |          ``columns``.\n",
      " |      index : dict-like or function\n",
      " |          Alternative to specifying axis (``mapper, axis=0``\n",
      " |          is equivalent to ``index=mapper``).\n",
      " |      columns : dict-like or function\n",
      " |          Alternative to specifying axis (``mapper, axis=1``\n",
      " |          is equivalent to ``columns=mapper``).\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis to target with ``mapper``. Can be either the axis name\n",
      " |          ('index', 'columns') or number (0, 1). The default is 'index'.\n",
      " |      copy : bool, default True\n",
      " |          Also copy underlying data.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |          If True then value of copy is ignored.\n",
      " |      level : int or level name, default None\n",
      " |          In case of a MultiIndex, only rename labels in the specified\n",
      " |          level.\n",
      " |      errors : {'ignore', 'raise'}, default 'ignore'\n",
      " |          If 'raise', raise a `KeyError` when a dict-like `mapper`, `index`,\n",
      " |          or `columns` contains labels that are not present in the Index\n",
      " |          being transformed.\n",
      " |          If 'ignore', existing keys will be renamed and extra keys will be\n",
      " |          ignored.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with the renamed axis labels or None if ``inplace=True``.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any of the labels is not found in the selected axis and\n",
      " |          \"errors='raise'\".\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.rename_axis : Set the name of the axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      ``DataFrame.rename`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      " |      * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Rename columns using a mapping:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      >>> df.rename(columns={\"A\": \"a\", \"B\": \"c\"})\n",
      " |         a  c\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      Rename index using a mapping:\n",
      " |      \n",
      " |      >>> df.rename(index={0: \"x\", 1: \"y\", 2: \"z\"})\n",
      " |         A  B\n",
      " |      x  1  4\n",
      " |      y  2  5\n",
      " |      z  3  6\n",
      " |      \n",
      " |      Cast index labels to a different type:\n",
      " |      \n",
      " |      >>> df.index\n",
      " |      RangeIndex(start=0, stop=3, step=1)\n",
      " |      >>> df.rename(index=str).index\n",
      " |      Index(['0', '1', '2'], dtype='object')\n",
      " |      \n",
      " |      >>> df.rename(columns={\"A\": \"a\", \"B\": \"b\", \"C\": \"c\"}, errors=\"raise\")\n",
      " |      Traceback (most recent call last):\n",
      " |      KeyError: ['C'] not found in axis\n",
      " |      \n",
      " |      Using axis-style parameters:\n",
      " |      \n",
      " |      >>> df.rename(str.lower, axis='columns')\n",
      " |         a  b\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      >>> df.rename({1: 2, 2: 4}, axis='index')\n",
      " |         A  B\n",
      " |      0  1  4\n",
      " |      2  2  5\n",
      " |      4  3  6\n",
      " |  \n",
      " |  reorder_levels(self, order: 'Sequence[int | str]', axis: 'Axis' = 0) -> 'DataFrame'\n",
      " |      Rearrange index levels using input order. May not drop or duplicate levels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : list of int or list of str\n",
      " |          List representing new level order. Reference level by number\n",
      " |          (position) or by key (label).\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Where to reorder levels.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = {\n",
      " |      ...     \"class\": [\"Mammals\", \"Mammals\", \"Reptiles\"],\n",
      " |      ...     \"diet\": [\"Omnivore\", \"Carnivore\", \"Carnivore\"],\n",
      " |      ...     \"species\": [\"Humans\", \"Dogs\", \"Snakes\"],\n",
      " |      ... }\n",
      " |      >>> df = pd.DataFrame(data, columns=[\"class\", \"diet\", \"species\"])\n",
      " |      >>> df = df.set_index([\"class\", \"diet\"])\n",
      " |      >>> df\n",
      " |                                        species\n",
      " |      class      diet\n",
      " |      Mammals    Omnivore                Humans\n",
      " |                 Carnivore                 Dogs\n",
      " |      Reptiles   Carnivore               Snakes\n",
      " |      \n",
      " |      Let's reorder the levels of the index:\n",
      " |      \n",
      " |      >>> df.reorder_levels([\"diet\", \"class\"])\n",
      " |                                        species\n",
      " |      diet      class\n",
      " |      Omnivore  Mammals                  Humans\n",
      " |      Carnivore Mammals                    Dogs\n",
      " |                Reptiles                 Snakes\n",
      " |  \n",
      " |  replace(self, to_replace=None, value=<no_default>, *, inplace: 'bool' = False, limit: 'int | None' = None, regex: 'bool' = False, method: \"Literal[('pad', 'ffill', 'bfill')] | lib.NoDefault\" = <no_default>) -> 'DataFrame | None'\n",
      " |      Replace values given in `to_replace` with `value`.\n",
      " |      \n",
      " |      Values of the DataFrame are replaced with other values dynamically.\n",
      " |      \n",
      " |      This differs from updating with ``.loc`` or ``.iloc``, which require\n",
      " |      you to specify a location to update with some value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_replace : str, regex, list, dict, Series, int, float, or None\n",
      " |          How to find the values that will be replaced.\n",
      " |      \n",
      " |          * numeric, str or regex:\n",
      " |      \n",
      " |              - numeric: numeric values equal to `to_replace` will be\n",
      " |                replaced with `value`\n",
      " |              - str: string exactly matching `to_replace` will be replaced\n",
      " |                with `value`\n",
      " |              - regex: regexs matching `to_replace` will be replaced with\n",
      " |                `value`\n",
      " |      \n",
      " |          * list of str, regex, or numeric:\n",
      " |      \n",
      " |              - First, if `to_replace` and `value` are both lists, they\n",
      " |                **must** be the same length.\n",
      " |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      " |                lists will be interpreted as regexs otherwise they will match\n",
      " |                directly. This doesn't matter much for `value` since there\n",
      " |                are only a few possible substitution regexes you can use.\n",
      " |              - str, regex and numeric rules apply as above.\n",
      " |      \n",
      " |          * dict:\n",
      " |      \n",
      " |              - Dicts can be used to specify different replacement values\n",
      " |                for different existing values. For example,\n",
      " |                ``{'a': 'b', 'y': 'z'}`` replaces the value 'a' with 'b' and\n",
      " |                'y' with 'z'. To use a dict in this way, the optional `value`\n",
      " |                parameter should not be given.\n",
      " |              - For a DataFrame a dict can specify that different values\n",
      " |                should be replaced in different columns. For example,\n",
      " |                ``{'a': 1, 'b': 'z'}`` looks for the value 1 in column 'a'\n",
      " |                and the value 'z' in column 'b' and replaces these values\n",
      " |                with whatever is specified in `value`. The `value` parameter\n",
      " |                should not be ``None`` in this case. You can treat this as a\n",
      " |                special case of passing two lists except that you are\n",
      " |                specifying the column to search in.\n",
      " |              - For a DataFrame nested dictionaries, e.g.,\n",
      " |                ``{'a': {'b': np.nan}}``, are read as follows: look in column\n",
      " |                'a' for the value 'b' and replace it with NaN. The optional `value`\n",
      " |                parameter should not be specified to use a nested dict in this\n",
      " |                way. You can nest regular expressions as well. Note that\n",
      " |                column names (the top-level dictionary keys in a nested\n",
      " |                dictionary) **cannot** be regular expressions.\n",
      " |      \n",
      " |          * None:\n",
      " |      \n",
      " |              - This means that the `regex` argument must be a string,\n",
      " |                compiled regular expression, or list, dict, ndarray or\n",
      " |                Series of such elements. If `value` is also ``None`` then\n",
      " |                this **must** be a nested dictionary or Series.\n",
      " |      \n",
      " |          See the examples section for examples of each of these.\n",
      " |      value : scalar, dict, list, str, regex, default None\n",
      " |          Value to replace any values matching `to_replace` with.\n",
      " |          For a DataFrame a dict of values can be used to specify which\n",
      " |          value to use for each column (columns not in the dict will not be\n",
      " |          filled). Regular expressions, strings and lists or dicts of such\n",
      " |          objects are also allowed.\n",
      " |      \n",
      " |      inplace : bool, default False\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill.\n",
      " |      regex : bool or same types as `to_replace`, default False\n",
      " |          Whether to interpret `to_replace` and/or `value` as regular\n",
      " |          expressions. If this is ``True`` then `to_replace` *must* be a\n",
      " |          string. Alternatively, this could be a regular expression or a\n",
      " |          list, dict, or array of regular expressions in which case\n",
      " |          `to_replace` must be ``None``.\n",
      " |      method : {'pad', 'ffill', 'bfill'}\n",
      " |          The method to use when for replacement, when `to_replace` is a\n",
      " |          scalar, list or tuple and `value` is ``None``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Object after replacement.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AssertionError\n",
      " |          * If `regex` is not a ``bool`` and `to_replace` is not\n",
      " |            ``None``.\n",
      " |      \n",
      " |      TypeError\n",
      " |          * If `to_replace` is not a scalar, array-like, ``dict``, or ``None``\n",
      " |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      " |            ``dict``, ``ndarray``, or ``Series``\n",
      " |          * If `to_replace` is ``None`` and `regex` is not compilable\n",
      " |            into a regular expression or is a list, dict, ndarray, or\n",
      " |            Series.\n",
      " |          * When replacing multiple ``bool`` or ``datetime64`` objects and\n",
      " |            the arguments to `to_replace` does not match the type of the\n",
      " |            value being replaced\n",
      " |      \n",
      " |      ValueError\n",
      " |          * If a ``list`` or an ``ndarray`` is passed to `to_replace` and\n",
      " |            `value` but they are not the same length.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.fillna : Fill NA values.\n",
      " |      DataFrame.where : Replace values based on boolean condition.\n",
      " |      Series.str.replace : Simple string replacement.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      " |        rules for substitution for ``re.sub`` are the same.\n",
      " |      * Regular expressions will only substitute on strings, meaning you\n",
      " |        cannot provide, for example, a regular expression matching floating\n",
      " |        point numbers and expect the columns in your frame that have a\n",
      " |        numeric dtype to be matched. However, if those floating point\n",
      " |        numbers *are* strings, then you can do this.\n",
      " |      * This method has *a lot* of options. You are encouraged to experiment\n",
      " |        and play with this method to gain intuition about how it works.\n",
      " |      * When dict is used as the `to_replace` value, it is like\n",
      " |        key(s) in the dict are the to_replace part and\n",
      " |        value(s) in the dict are the value parameter.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      **Scalar `to_replace` and `value`**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4, 5])\n",
      " |      >>> s.replace(1, 5)\n",
      " |      0    5\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],\n",
      " |      ...                    'B': [5, 6, 7, 8, 9],\n",
      " |      ...                    'C': ['a', 'b', 'c', 'd', 'e']})\n",
      " |      >>> df.replace(0, 5)\n",
      " |          A  B  C\n",
      " |      0  5  5  a\n",
      " |      1  1  6  b\n",
      " |      2  2  7  c\n",
      " |      3  3  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      **List-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], 4)\n",
      " |          A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  4  6  b\n",
      " |      2  4  7  c\n",
      " |      3  4  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], [4, 3, 2, 1])\n",
      " |          A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  3  6  b\n",
      " |      2  2  7  c\n",
      " |      3  1  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> s.replace([1, 2], method='bfill')\n",
      " |      0    3\n",
      " |      1    3\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **dict-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace({0: 10, 1: 100})\n",
      " |              A  B  C\n",
      " |      0   10  5  a\n",
      " |      1  100  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4    4  9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': 0, 'B': 5}, 100)\n",
      " |              A    B  C\n",
      " |      0  100  100  a\n",
      " |      1    1    6  b\n",
      " |      2    2    7  c\n",
      " |      3    3    8  d\n",
      " |      4    4    9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': {0: 100, 4: 400}})\n",
      " |              A  B  C\n",
      " |      0  100  5  a\n",
      " |      1    1  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4  400  9  e\n",
      " |      \n",
      " |      **Regular expression `to_replace`**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['bat', 'foo', 'bait'],\n",
      " |      ...                    'B': ['abc', 'bar', 'xyz']})\n",
      " |      >>> df.replace(to_replace=r'^ba.$', value='new', regex=True)\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace({'A': r'^ba.$'}, {'A': 'new'}, regex=True)\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  bar\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=r'^ba.$', value='new')\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex={r'^ba.$': 'new', 'foo': 'xyz'})\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   xyz  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=[r'^ba.$', 'foo'], value='new')\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   new  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      Compare the behavior of ``s.replace({'a': None})`` and\n",
      " |      ``s.replace('a', None)`` to understand the peculiarities\n",
      " |      of the `to_replace` parameter:\n",
      " |      \n",
      " |      >>> s = pd.Series([10, 'a', 'a', 'b', 'a'])\n",
      " |      \n",
      " |      When one uses a dict as the `to_replace` value, it is like the\n",
      " |      value(s) in the dict are equal to the `value` parameter.\n",
      " |      ``s.replace({'a': None})`` is equivalent to\n",
      " |      ``s.replace(to_replace={'a': None}, value=None, method=None)``:\n",
      " |      \n",
      " |      >>> s.replace({'a': None})\n",
      " |      0      10\n",
      " |      1    None\n",
      " |      2    None\n",
      " |      3       b\n",
      " |      4    None\n",
      " |      dtype: object\n",
      " |      \n",
      " |      When ``value`` is not explicitly passed and `to_replace` is a scalar, list\n",
      " |      or tuple, `replace` uses the method parameter (default 'pad') to do the\n",
      " |      replacement. So this is why the 'a' values are being replaced by 10\n",
      " |      in rows 1 and 2 and 'b' in row 4 in this case.\n",
      " |      \n",
      " |      >>> s.replace('a')\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    10\n",
      " |      3     b\n",
      " |      4     b\n",
      " |      dtype: object\n",
      " |      \n",
      " |      On the other hand, if ``None`` is explicitly passed for ``value``, it will\n",
      " |      be respected:\n",
      " |      \n",
      " |      >>> s.replace('a', None)\n",
      " |      0      10\n",
      " |      1    None\n",
      " |      2    None\n",
      " |      3       b\n",
      " |      4    None\n",
      " |      dtype: object\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0\n",
      " |              Previously the explicit ``None`` was silently ignored.\n",
      " |  \n",
      " |  resample(self, rule, axis: 'Axis' = 0, closed: 'str | None' = None, label: 'str | None' = None, convention: 'str' = 'start', kind: 'str | None' = None, on: 'Level' = None, level: 'Level' = None, origin: 'str | TimestampConvertibleTypes' = 'start_day', offset: 'TimedeltaConvertibleTypes | None' = None, group_keys: 'bool' = False) -> 'Resampler'\n",
      " |      Resample time-series data.\n",
      " |      \n",
      " |      Convenience method for frequency conversion and resampling of time series.\n",
      " |      The object must have a datetime-like index (`DatetimeIndex`, `PeriodIndex`,\n",
      " |      or `TimedeltaIndex`), or the caller must pass the label of a datetime-like\n",
      " |      series/index to the ``on``/``level`` keyword parameter.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : DateOffset, Timedelta or str\n",
      " |          The offset string or object representing target conversion.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Which axis to use for up- or down-sampling. For `Series` this parameter\n",
      " |          is unused and defaults to 0. Must be\n",
      " |          `DatetimeIndex`, `TimedeltaIndex` or `PeriodIndex`.\n",
      " |      closed : {'right', 'left'}, default None\n",
      " |          Which side of bin interval is closed. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      label : {'right', 'left'}, default None\n",
      " |          Which bin edge label to label bucket with. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      convention : {'start', 'end', 's', 'e'}, default 'start'\n",
      " |          For `PeriodIndex` only, controls whether to use the start or\n",
      " |          end of `rule`.\n",
      " |      kind : {'timestamp', 'period'}, optional, default None\n",
      " |          Pass 'timestamp' to convert the resulting index to a\n",
      " |          `DateTimeIndex` or 'period' to convert it to a `PeriodIndex`.\n",
      " |          By default the input representation is retained.\n",
      " |      \n",
      " |      on : str, optional\n",
      " |          For a DataFrame, column to use instead of index for resampling.\n",
      " |          Column must be datetime-like.\n",
      " |      level : str or int, optional\n",
      " |          For a MultiIndex, level (name or number) to use for\n",
      " |          resampling. `level` must be datetime-like.\n",
      " |      origin : Timestamp or str, default 'start_day'\n",
      " |          The timestamp on which to adjust the grouping. The timezone of origin\n",
      " |          must match the timezone of the index.\n",
      " |          If string, must be one of the following:\n",
      " |      \n",
      " |          - 'epoch': `origin` is 1970-01-01\n",
      " |          - 'start': `origin` is the first value of the timeseries\n",
      " |          - 'start_day': `origin` is the first day at midnight of the timeseries\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          - 'end': `origin` is the last value of the timeseries\n",
      " |          - 'end_day': `origin` is the ceiling midnight of the last day\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      offset : Timedelta or str, default is None\n",
      " |          An offset timedelta added to the origin.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      group_keys : bool, default False\n",
      " |          Whether to include the group keys in the result index when using\n",
      " |          ``.apply()`` on the resampled object.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |              Not specifying ``group_keys`` will retain values-dependent behavior\n",
      " |              from pandas 1.4 and earlier (see :ref:`pandas 1.5.0 Release notes\n",
      " |              <whatsnew_150.enhancements.resample_group_keys>` for examples).\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              ``group_keys`` now defaults to ``False``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.core.Resampler\n",
      " |          :class:`~pandas.core.Resampler` object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.resample : Resample a Series.\n",
      " |      DataFrame.resample : Resample a DataFrame.\n",
      " |      groupby : Group DataFrame by mapping, function, label, or list of labels.\n",
      " |      asfreq : Reindex a DataFrame with the given frequency without grouping.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling>`__\n",
      " |      for more.\n",
      " |      \n",
      " |      To learn more about the offset strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Start by creating a series with 9 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> series = pd.Series(range(9), index=index)\n",
      " |      >>> series\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      2000-01-01 00:03:00    3\n",
      " |      2000-01-01 00:04:00    4\n",
      " |      2000-01-01 00:05:00    5\n",
      " |      2000-01-01 00:06:00    6\n",
      " |      2000-01-01 00:07:00    7\n",
      " |      2000-01-01 00:08:00    8\n",
      " |      Freq: T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and sum the values\n",
      " |      of the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> series.resample('3T').sum()\n",
      " |      2000-01-01 00:00:00     3\n",
      " |      2000-01-01 00:03:00    12\n",
      " |      2000-01-01 00:06:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but label each\n",
      " |      bin using the right edge instead of the left. Please note that the\n",
      " |      value in the bucket used as the label is not included in the bucket,\n",
      " |      which it labels. For example, in the original series the\n",
      " |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      " |      value in the resampled bucket with the label ``2000-01-01 00:03:00``\n",
      " |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      " |      To include this value close the right side of the bin interval as\n",
      " |      illustrated in the example below this one.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right').sum()\n",
      " |      2000-01-01 00:03:00     3\n",
      " |      2000-01-01 00:06:00    12\n",
      " |      2000-01-01 00:09:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right', closed='right').sum()\n",
      " |      2000-01-01 00:00:00     0\n",
      " |      2000-01-01 00:03:00     6\n",
      " |      2000-01-01 00:06:00    15\n",
      " |      2000-01-01 00:09:00    15\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> series.resample('30S').asfreq()[0:5]   # Select first 5 rows\n",
      " |      2000-01-01 00:00:00   0.0\n",
      " |      2000-01-01 00:00:30   NaN\n",
      " |      2000-01-01 00:01:00   1.0\n",
      " |      2000-01-01 00:01:30   NaN\n",
      " |      2000-01-01 00:02:00   2.0\n",
      " |      Freq: 30S, dtype: float64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      " |      values using the ``ffill`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').ffill()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the\n",
      " |      ``NaN`` values using the ``bfill`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').bfill()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    1\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    2\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Pass a custom function via ``apply``\n",
      " |      \n",
      " |      >>> def custom_resampler(arraylike):\n",
      " |      ...     return np.sum(arraylike) + 5\n",
      " |      ...\n",
      " |      >>> series.resample('3T').apply(custom_resampler)\n",
      " |      2000-01-01 00:00:00     8\n",
      " |      2000-01-01 00:03:00    17\n",
      " |      2000-01-01 00:06:00    26\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      For a Series with a PeriodIndex, the keyword `convention` can be\n",
      " |      used to control whether to use the start or end of `rule`.\n",
      " |      \n",
      " |      Resample a year by quarter using 'start' `convention`. Values are\n",
      " |      assigned to the first quarter of the period.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=pd.period_range('2012-01-01',\n",
      " |      ...                                             freq='A',\n",
      " |      ...                                             periods=2))\n",
      " |      >>> s\n",
      " |      2012    1\n",
      " |      2013    2\n",
      " |      Freq: A-DEC, dtype: int64\n",
      " |      >>> s.resample('Q', convention='start').asfreq()\n",
      " |      2012Q1    1.0\n",
      " |      2012Q2    NaN\n",
      " |      2012Q3    NaN\n",
      " |      2012Q4    NaN\n",
      " |      2013Q1    2.0\n",
      " |      2013Q2    NaN\n",
      " |      2013Q3    NaN\n",
      " |      2013Q4    NaN\n",
      " |      Freq: Q-DEC, dtype: float64\n",
      " |      \n",
      " |      Resample quarters by month using 'end' `convention`. Values are\n",
      " |      assigned to the last month of the period.\n",
      " |      \n",
      " |      >>> q = pd.Series([1, 2, 3, 4], index=pd.period_range('2018-01-01',\n",
      " |      ...                                                   freq='Q',\n",
      " |      ...                                                   periods=4))\n",
      " |      >>> q\n",
      " |      2018Q1    1\n",
      " |      2018Q2    2\n",
      " |      2018Q3    3\n",
      " |      2018Q4    4\n",
      " |      Freq: Q-DEC, dtype: int64\n",
      " |      >>> q.resample('M', convention='end').asfreq()\n",
      " |      2018-03    1.0\n",
      " |      2018-04    NaN\n",
      " |      2018-05    NaN\n",
      " |      2018-06    2.0\n",
      " |      2018-07    NaN\n",
      " |      2018-08    NaN\n",
      " |      2018-09    3.0\n",
      " |      2018-10    NaN\n",
      " |      2018-11    NaN\n",
      " |      2018-12    4.0\n",
      " |      Freq: M, dtype: float64\n",
      " |      \n",
      " |      For DataFrame objects, the keyword `on` can be used to specify the\n",
      " |      column instead of the index for resampling.\n",
      " |      \n",
      " |      >>> d = {'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      " |      ...      'volume': [50, 60, 40, 100, 50, 100, 40, 50]}\n",
      " |      >>> df = pd.DataFrame(d)\n",
      " |      >>> df['week_starting'] = pd.date_range('01/01/2018',\n",
      " |      ...                                     periods=8,\n",
      " |      ...                                     freq='W')\n",
      " |      >>> df\n",
      " |         price  volume week_starting\n",
      " |      0     10      50    2018-01-07\n",
      " |      1     11      60    2018-01-14\n",
      " |      2      9      40    2018-01-21\n",
      " |      3     13     100    2018-01-28\n",
      " |      4     14      50    2018-02-04\n",
      " |      5     18     100    2018-02-11\n",
      " |      6     17      40    2018-02-18\n",
      " |      7     19      50    2018-02-25\n",
      " |      >>> df.resample('M', on='week_starting').mean()\n",
      " |                     price  volume\n",
      " |      week_starting\n",
      " |      2018-01-31     10.75    62.5\n",
      " |      2018-02-28     17.00    60.0\n",
      " |      \n",
      " |      For a DataFrame with MultiIndex, the keyword `level` can be used to\n",
      " |      specify on which level the resampling needs to take place.\n",
      " |      \n",
      " |      >>> days = pd.date_range('1/1/2000', periods=4, freq='D')\n",
      " |      >>> d2 = {'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      " |      ...       'volume': [50, 60, 40, 100, 50, 100, 40, 50]}\n",
      " |      >>> df2 = pd.DataFrame(\n",
      " |      ...     d2,\n",
      " |      ...     index=pd.MultiIndex.from_product(\n",
      " |      ...         [days, ['morning', 'afternoon']]\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |      >>> df2\n",
      " |                            price  volume\n",
      " |      2000-01-01 morning       10      50\n",
      " |                 afternoon     11      60\n",
      " |      2000-01-02 morning        9      40\n",
      " |                 afternoon     13     100\n",
      " |      2000-01-03 morning       14      50\n",
      " |                 afternoon     18     100\n",
      " |      2000-01-04 morning       17      40\n",
      " |                 afternoon     19      50\n",
      " |      >>> df2.resample('D', level=0).sum()\n",
      " |                  price  volume\n",
      " |      2000-01-01     21     110\n",
      " |      2000-01-02     22     140\n",
      " |      2000-01-03     32     150\n",
      " |      2000-01-04     36      90\n",
      " |      \n",
      " |      If you want to adjust the start of the bins based on a fixed timestamp:\n",
      " |      \n",
      " |      >>> start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'\n",
      " |      >>> rng = pd.date_range(start, end, freq='7min')\n",
      " |      >>> ts = pd.Series(np.arange(len(rng)) * 3, index=rng)\n",
      " |      >>> ts\n",
      " |      2000-10-01 23:30:00     0\n",
      " |      2000-10-01 23:37:00     3\n",
      " |      2000-10-01 23:44:00     6\n",
      " |      2000-10-01 23:51:00     9\n",
      " |      2000-10-01 23:58:00    12\n",
      " |      2000-10-02 00:05:00    15\n",
      " |      2000-10-02 00:12:00    18\n",
      " |      2000-10-02 00:19:00    21\n",
      " |      2000-10-02 00:26:00    24\n",
      " |      Freq: 7T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min').sum()\n",
      " |      2000-10-01 23:14:00     0\n",
      " |      2000-10-01 23:31:00     9\n",
      " |      2000-10-01 23:48:00    21\n",
      " |      2000-10-02 00:05:00    54\n",
      " |      2000-10-02 00:22:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='epoch').sum()\n",
      " |      2000-10-01 23:18:00     0\n",
      " |      2000-10-01 23:35:00    18\n",
      " |      2000-10-01 23:52:00    27\n",
      " |      2000-10-02 00:09:00    39\n",
      " |      2000-10-02 00:26:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='2000-01-01').sum()\n",
      " |      2000-10-01 23:24:00     3\n",
      " |      2000-10-01 23:41:00    15\n",
      " |      2000-10-01 23:58:00    45\n",
      " |      2000-10-02 00:15:00    45\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      If you want to adjust the start of the bins with an `offset` Timedelta, the two\n",
      " |      following lines are equivalent:\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='start').sum()\n",
      " |      2000-10-01 23:30:00     9\n",
      " |      2000-10-01 23:47:00    21\n",
      " |      2000-10-02 00:04:00    54\n",
      " |      2000-10-02 00:21:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min', offset='23h30min').sum()\n",
      " |      2000-10-01 23:30:00     9\n",
      " |      2000-10-01 23:47:00    21\n",
      " |      2000-10-02 00:04:00    54\n",
      " |      2000-10-02 00:21:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      If you want to take the largest Timestamp as the end of the bins:\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='end').sum()\n",
      " |      2000-10-01 23:35:00     0\n",
      " |      2000-10-01 23:52:00    18\n",
      " |      2000-10-02 00:09:00    27\n",
      " |      2000-10-02 00:26:00    63\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      In contrast with the `start_day`, you can use `end_day` to take the ceiling\n",
      " |      midnight of the largest Timestamp as the end of the bins and drop the bins\n",
      " |      not containing data:\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='end_day').sum()\n",
      " |      2000-10-01 23:38:00     3\n",
      " |      2000-10-01 23:55:00    15\n",
      " |      2000-10-02 00:12:00    45\n",
      " |      2000-10-02 00:29:00    45\n",
      " |      Freq: 17T, dtype: int64\n",
      " |  \n",
      " |  reset_index(self, level: 'IndexLabel' = None, *, drop: 'bool' = False, inplace: 'bool' = False, col_level: 'Hashable' = 0, col_fill: 'Hashable' = '', allow_duplicates: 'bool | lib.NoDefault' = <no_default>, names: 'Hashable | Sequence[Hashable]' = None) -> 'DataFrame | None'\n",
      " |      Reset the index, or a level of it.\n",
      " |      \n",
      " |      Reset the index of the DataFrame, and use the default one instead.\n",
      " |      If the DataFrame has a MultiIndex, this method can remove one or more\n",
      " |      levels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, tuple, or list, default None\n",
      " |          Only remove the given levels from the index. Removes all levels by\n",
      " |          default.\n",
      " |      drop : bool, default False\n",
      " |          Do not try to insert index into dataframe columns. This resets\n",
      " |          the index to the default integer index.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |      col_level : int or str, default 0\n",
      " |          If the columns have multiple levels, determines which level the\n",
      " |          labels are inserted into. By default it is inserted into the first\n",
      " |          level.\n",
      " |      col_fill : object, default ''\n",
      " |          If the columns have multiple levels, determines how the other\n",
      " |          levels are named. If None then the index name is repeated.\n",
      " |      allow_duplicates : bool, optional, default lib.no_default\n",
      " |          Allow duplicate column labels to be created.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      names : int, str or 1-dimensional list, default None\n",
      " |          Using the given string, rename the DataFrame column which contains the\n",
      " |          index data. If the DataFrame has a MultiIndex, this has to be a list or\n",
      " |          tuple with length equal to the number of levels.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with the new index or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Opposite of reset_index.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('bird', 389.0),\n",
      " |      ...                    ('bird', 24.0),\n",
      " |      ...                    ('mammal', 80.5),\n",
      " |      ...                    ('mammal', np.nan)],\n",
      " |      ...                   index=['falcon', 'parrot', 'lion', 'monkey'],\n",
      " |      ...                   columns=('class', 'max_speed'))\n",
      " |      >>> df\n",
      " |               class  max_speed\n",
      " |      falcon    bird      389.0\n",
      " |      parrot    bird       24.0\n",
      " |      lion    mammal       80.5\n",
      " |      monkey  mammal        NaN\n",
      " |      \n",
      " |      When we reset the index, the old index is added as a column, and a\n",
      " |      new sequential index is used:\n",
      " |      \n",
      " |      >>> df.reset_index()\n",
      " |          index   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      3  monkey  mammal        NaN\n",
      " |      \n",
      " |      We can use the `drop` parameter to avoid the old index being added as\n",
      " |      a column:\n",
      " |      \n",
      " |      >>> df.reset_index(drop=True)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      1    bird       24.0\n",
      " |      2  mammal       80.5\n",
      " |      3  mammal        NaN\n",
      " |      \n",
      " |      You can also use `reset_index` with `MultiIndex`.\n",
      " |      \n",
      " |      >>> index = pd.MultiIndex.from_tuples([('bird', 'falcon'),\n",
      " |      ...                                    ('bird', 'parrot'),\n",
      " |      ...                                    ('mammal', 'lion'),\n",
      " |      ...                                    ('mammal', 'monkey')],\n",
      " |      ...                                   names=['class', 'name'])\n",
      " |      >>> columns = pd.MultiIndex.from_tuples([('speed', 'max'),\n",
      " |      ...                                      ('species', 'type')])\n",
      " |      >>> df = pd.DataFrame([(389.0, 'fly'),\n",
      " |      ...                    (24.0, 'fly'),\n",
      " |      ...                    (80.5, 'run'),\n",
      " |      ...                    (np.nan, 'jump')],\n",
      " |      ...                   index=index,\n",
      " |      ...                   columns=columns)\n",
      " |      >>> df\n",
      " |                     speed species\n",
      " |                       max    type\n",
      " |      class  name\n",
      " |      bird   falcon  389.0     fly\n",
      " |             parrot   24.0     fly\n",
      " |      mammal lion     80.5     run\n",
      " |             monkey    NaN    jump\n",
      " |      \n",
      " |      Using the `names` parameter, choose a name for the index column:\n",
      " |      \n",
      " |      >>> df.reset_index(names=['classes', 'names'])\n",
      " |        classes   names  speed species\n",
      " |                           max    type\n",
      " |      0    bird  falcon  389.0     fly\n",
      " |      1    bird  parrot   24.0     fly\n",
      " |      2  mammal    lion   80.5     run\n",
      " |      3  mammal  monkey    NaN    jump\n",
      " |      \n",
      " |      If the index has multiple levels, we can reset a subset of them:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class')\n",
      " |               class  speed species\n",
      " |                        max    type\n",
      " |      name\n",
      " |      falcon    bird  389.0     fly\n",
      " |      parrot    bird   24.0     fly\n",
      " |      lion    mammal   80.5     run\n",
      " |      monkey  mammal    NaN    jump\n",
      " |      \n",
      " |      If we are not dropping the index, by default, it is placed in the top\n",
      " |      level. We can place it in another level:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1)\n",
      " |                      speed species\n",
      " |               class    max    type\n",
      " |      name\n",
      " |      falcon    bird  389.0     fly\n",
      " |      parrot    bird   24.0     fly\n",
      " |      lion    mammal   80.5     run\n",
      " |      monkey  mammal    NaN    jump\n",
      " |      \n",
      " |      When the index is inserted under another level, we can specify under\n",
      " |      which one with the parameter `col_fill`:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1, col_fill='species')\n",
      " |                    species  speed species\n",
      " |                      class    max    type\n",
      " |      name\n",
      " |      falcon           bird  389.0     fly\n",
      " |      parrot           bird   24.0     fly\n",
      " |      lion           mammal   80.5     run\n",
      " |      monkey         mammal    NaN    jump\n",
      " |      \n",
      " |      If we specify a nonexistent level for `col_fill`, it is created:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1, col_fill='genus')\n",
      " |                      genus  speed species\n",
      " |                      class    max    type\n",
      " |      name\n",
      " |      falcon           bird  389.0     fly\n",
      " |      parrot           bird   24.0     fly\n",
      " |      lion           mammal   80.5     run\n",
      " |      monkey         mammal    NaN    jump\n",
      " |  \n",
      " |  rfloordiv(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None)\n",
      " |      Get Integer division of dataframe and other, element-wise (binary operator `rfloordiv`).\n",
      " |      \n",
      " |      Equivalent to ``other // dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `floordiv`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rmod(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None)\n",
      " |      Get Modulo of dataframe and other, element-wise (binary operator `rmod`).\n",
      " |      \n",
      " |      Equivalent to ``other % dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `mod`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rmul(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None)\n",
      " |      Get Multiplication of dataframe and other, element-wise (binary operator `rmul`).\n",
      " |      \n",
      " |      Equivalent to ``other * dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `mul`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  round(self, decimals: 'int | dict[IndexLabel, int] | Series' = 0, *args, **kwargs) -> 'DataFrame'\n",
      " |      Round a DataFrame to a variable number of decimal places.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      decimals : int, dict, Series\n",
      " |          Number of decimal places to round each column to. If an int is\n",
      " |          given, round each column to the same number of places.\n",
      " |          Otherwise dict and Series round to variable numbers of places.\n",
      " |          Column names should be in the keys if `decimals` is a\n",
      " |          dict-like, or in the index if `decimals` is a Series. Any\n",
      " |          columns not included in `decimals` will be left as is. Elements\n",
      " |          of `decimals` which are not columns of the input will be\n",
      " |          ignored.\n",
      " |      *args\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with numpy.\n",
      " |      **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with numpy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A DataFrame with the affected columns rounded to the specified\n",
      " |          number of decimal places.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.around : Round a numpy array to the given number of decimals.\n",
      " |      Series.round : Round a Series to the given number of decimals.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([(.21, .32), (.01, .67), (.66, .03), (.21, .18)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df\n",
      " |          dogs  cats\n",
      " |      0  0.21  0.32\n",
      " |      1  0.01  0.67\n",
      " |      2  0.66  0.03\n",
      " |      3  0.21  0.18\n",
      " |      \n",
      " |      By providing an integer each column is rounded to the same number\n",
      " |      of decimal places\n",
      " |      \n",
      " |      >>> df.round(1)\n",
      " |          dogs  cats\n",
      " |      0   0.2   0.3\n",
      " |      1   0.0   0.7\n",
      " |      2   0.7   0.0\n",
      " |      3   0.2   0.2\n",
      " |      \n",
      " |      With a dict, the number of places for specific columns can be\n",
      " |      specified with the column names as key and the number of decimal\n",
      " |      places as value\n",
      " |      \n",
      " |      >>> df.round({'dogs': 1, 'cats': 0})\n",
      " |          dogs  cats\n",
      " |      0   0.2   0.0\n",
      " |      1   0.0   1.0\n",
      " |      2   0.7   0.0\n",
      " |      3   0.2   0.0\n",
      " |      \n",
      " |      Using a Series, the number of places for specific columns can be\n",
      " |      specified with the column names as index and the number of\n",
      " |      decimal places as value\n",
      " |      \n",
      " |      >>> decimals = pd.Series([0, 1], index=['cats', 'dogs'])\n",
      " |      >>> df.round(decimals)\n",
      " |          dogs  cats\n",
      " |      0   0.2   0.0\n",
      " |      1   0.0   1.0\n",
      " |      2   0.7   0.0\n",
      " |      3   0.2   0.0\n",
      " |  \n",
      " |  rpow(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None)\n",
      " |      Get Exponential power of dataframe and other, element-wise (binary operator `rpow`).\n",
      " |      \n",
      " |      Equivalent to ``other ** dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `pow`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rsub(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None)\n",
      " |      Get Subtraction of dataframe and other, element-wise (binary operator `rsub`).\n",
      " |      \n",
      " |      Equivalent to ``other - dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `sub`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rtruediv(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None)\n",
      " |      Get Floating division of dataframe and other, element-wise (binary operator `rtruediv`).\n",
      " |      \n",
      " |      Equivalent to ``other / dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `truediv`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  select_dtypes(self, include=None, exclude=None) -> 'DataFrame'\n",
      " |      Return a subset of the DataFrame's columns based on the column dtypes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      include, exclude : scalar or list-like\n",
      " |          A selection of dtypes or strings to be included/excluded. At least\n",
      " |          one of these parameters must be supplied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The subset of the frame including the dtypes in ``include`` and\n",
      " |          excluding the dtypes in ``exclude``.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If both of ``include`` and ``exclude`` are empty\n",
      " |          * If ``include`` and ``exclude`` have overlapping elements\n",
      " |          * If any kind of string dtype is passed in.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.dtypes: Return Series with the data type of each column.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * To select all *numeric* types, use ``np.number`` or ``'number'``\n",
      " |      * To select strings you must use the ``object`` dtype, but note that\n",
      " |        this will return *all* object dtype columns\n",
      " |      * See the `numpy dtype hierarchy\n",
      " |        <https://numpy.org/doc/stable/reference/arrays.scalars.html>`__\n",
      " |      * To select datetimes, use ``np.datetime64``, ``'datetime'`` or\n",
      " |        ``'datetime64'``\n",
      " |      * To select timedeltas, use ``np.timedelta64``, ``'timedelta'`` or\n",
      " |        ``'timedelta64'``\n",
      " |      * To select Pandas categorical dtypes, use ``'category'``\n",
      " |      * To select Pandas datetimetz dtypes, use ``'datetimetz'`` (new in\n",
      " |        0.20.0) or ``'datetime64[ns, tz]'``\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'a': [1, 2] * 3,\n",
      " |      ...                    'b': [True, False] * 3,\n",
      " |      ...                    'c': [1.0, 2.0] * 3})\n",
      " |      >>> df\n",
      " |              a      b  c\n",
      " |      0       1   True  1.0\n",
      " |      1       2  False  2.0\n",
      " |      2       1   True  1.0\n",
      " |      3       2  False  2.0\n",
      " |      4       1   True  1.0\n",
      " |      5       2  False  2.0\n",
      " |      \n",
      " |      >>> df.select_dtypes(include='bool')\n",
      " |         b\n",
      " |      0  True\n",
      " |      1  False\n",
      " |      2  True\n",
      " |      3  False\n",
      " |      4  True\n",
      " |      5  False\n",
      " |      \n",
      " |      >>> df.select_dtypes(include=['float64'])\n",
      " |         c\n",
      " |      0  1.0\n",
      " |      1  2.0\n",
      " |      2  1.0\n",
      " |      3  2.0\n",
      " |      4  1.0\n",
      " |      5  2.0\n",
      " |      \n",
      " |      >>> df.select_dtypes(exclude=['int64'])\n",
      " |             b    c\n",
      " |      0   True  1.0\n",
      " |      1  False  2.0\n",
      " |      2   True  1.0\n",
      " |      3  False  2.0\n",
      " |      4   True  1.0\n",
      " |      5  False  2.0\n",
      " |  \n",
      " |  sem(self, axis: 'Axis | None' = None, skipna: 'bool_t' = True, ddof: 'int' = 1, numeric_only: 'bool_t' = False, **kwargs)\n",
      " |      Return unbiased standard error of the mean over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  set_axis(self, labels, *, axis: 'Axis' = 0, copy: 'bool | None' = None) -> 'DataFrame'\n",
      " |      Assign desired index to given axis.\n",
      " |      \n",
      " |      Indexes for column or row labels can be changed by assigning\n",
      " |      a list-like or Index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : list-like, Index\n",
      " |          The values for the new index.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to update. The value 0 identifies the rows. For `Series`\n",
      " |          this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |      copy : bool, default True\n",
      " |          Whether to make a copy of the underlying data.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          An object of type DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.rename_axis : Alter the name of the index or columns.\n",
      " |      \n",
      " |              Examples\n",
      " |              --------\n",
      " |              >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      \n",
      " |              Change the row labels.\n",
      " |      \n",
      " |              >>> df.set_axis(['a', 'b', 'c'], axis='index')\n",
      " |                 A  B\n",
      " |              a  1  4\n",
      " |              b  2  5\n",
      " |              c  3  6\n",
      " |      \n",
      " |              Change the column labels.\n",
      " |      \n",
      " |              >>> df.set_axis(['I', 'II'], axis='columns')\n",
      " |                 I  II\n",
      " |              0  1   4\n",
      " |              1  2   5\n",
      " |              2  3   6\n",
      " |  \n",
      " |  set_index(self, keys, *, drop: 'bool' = True, append: 'bool' = False, inplace: 'bool' = False, verify_integrity: 'bool' = False) -> 'DataFrame | None'\n",
      " |      Set the DataFrame index using existing columns.\n",
      " |      \n",
      " |      Set the DataFrame index (row labels) using one or more existing\n",
      " |      columns or arrays (of the correct length). The index can replace the\n",
      " |      existing index or expand on it.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keys : label or array-like or list of labels/arrays\n",
      " |          This parameter can be either a single column key, a single array of\n",
      " |          the same length as the calling DataFrame, or a list containing an\n",
      " |          arbitrary combination of column keys and arrays. Here, \"array\"\n",
      " |          encompasses :class:`Series`, :class:`Index`, ``np.ndarray``, and\n",
      " |          instances of :class:`~collections.abc.Iterator`.\n",
      " |      drop : bool, default True\n",
      " |          Delete columns to be used as the new index.\n",
      " |      append : bool, default False\n",
      " |          Whether to append columns to existing index.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |      verify_integrity : bool, default False\n",
      " |          Check the new index for duplicates. Otherwise defer the check until\n",
      " |          necessary. Setting to False will improve the performance of this\n",
      " |          method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          Changed row labels or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.reset_index : Opposite of set_index.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'month': [1, 4, 7, 10],\n",
      " |      ...                    'year': [2012, 2014, 2013, 2014],\n",
      " |      ...                    'sale': [55, 40, 84, 31]})\n",
      " |      >>> df\n",
      " |         month  year  sale\n",
      " |      0      1  2012    55\n",
      " |      1      4  2014    40\n",
      " |      2      7  2013    84\n",
      " |      3     10  2014    31\n",
      " |      \n",
      " |      Set the index to become the 'month' column:\n",
      " |      \n",
      " |      >>> df.set_index('month')\n",
      " |             year  sale\n",
      " |      month\n",
      " |      1      2012    55\n",
      " |      4      2014    40\n",
      " |      7      2013    84\n",
      " |      10     2014    31\n",
      " |      \n",
      " |      Create a MultiIndex using columns 'year' and 'month':\n",
      " |      \n",
      " |      >>> df.set_index(['year', 'month'])\n",
      " |                  sale\n",
      " |      year  month\n",
      " |      2012  1     55\n",
      " |      2014  4     40\n",
      " |      2013  7     84\n",
      " |      2014  10    31\n",
      " |      \n",
      " |      Create a MultiIndex using an Index and a column:\n",
      " |      \n",
      " |      >>> df.set_index([pd.Index([1, 2, 3, 4]), 'year'])\n",
      " |               month  sale\n",
      " |         year\n",
      " |      1  2012  1      55\n",
      " |      2  2014  4      40\n",
      " |      3  2013  7      84\n",
      " |      4  2014  10     31\n",
      " |      \n",
      " |      Create a MultiIndex using two Series:\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> df.set_index([s, s**2])\n",
      " |            month  year  sale\n",
      " |      1 1       1  2012    55\n",
      " |      2 4       4  2014    40\n",
      " |      3 9       7  2013    84\n",
      " |      4 16     10  2014    31\n",
      " |  \n",
      " |  shift(self, periods: 'int' = 1, freq: 'Frequency | None' = None, axis: 'Axis' = 0, fill_value: 'Hashable' = <no_default>) -> 'DataFrame'\n",
      " |      Shift index by desired number of periods with an optional time `freq`.\n",
      " |      \n",
      " |      When `freq` is not passed, shift the index without realigning the data.\n",
      " |      If `freq` is passed (in this case, the index must be date or datetime,\n",
      " |      or it will raise a `NotImplementedError`), the index will be\n",
      " |      increased using the periods and the `freq`. `freq` can be inferred\n",
      " |      when specified as \"infer\" as long as either freq or inferred_freq\n",
      " |      attribute is set in the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to shift. Can be positive or negative.\n",
      " |      freq : DateOffset, tseries.offsets, timedelta, or str, optional\n",
      " |          Offset to use from the tseries module or time rule (e.g. 'EOM').\n",
      " |          If `freq` is specified then the index values are shifted but the\n",
      " |          data is not realigned. That is, use `freq` if you would like to\n",
      " |          extend the index when shifting and preserve the original data.\n",
      " |          If `freq` is specified as \"infer\" then it will be inferred from\n",
      " |          the freq or inferred_freq attributes of the index. If neither of\n",
      " |          those attributes exist, a ValueError is thrown.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          Shift direction. For `Series` this parameter is unused and defaults to 0.\n",
      " |      fill_value : object, optional\n",
      " |          The scalar value to use for newly introduced missing values.\n",
      " |          the default depends on the dtype of `self`.\n",
      " |          For numeric data, ``np.nan`` is used.\n",
      " |          For datetime, timedelta, or period data, etc. :attr:`NaT` is used.\n",
      " |          For extension dtypes, ``self.dtype.na_value`` is used.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Copy of input object, shifted.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.shift : Shift values of Index.\n",
      " |      DatetimeIndex.shift : Shift values of DatetimeIndex.\n",
      " |      PeriodIndex.shift : Shift values of PeriodIndex.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"Col1\": [10, 20, 15, 30, 45],\n",
      " |      ...                    \"Col2\": [13, 23, 18, 33, 48],\n",
      " |      ...                    \"Col3\": [17, 27, 22, 37, 52]},\n",
      " |      ...                   index=pd.date_range(\"2020-01-01\", \"2020-01-05\"))\n",
      " |      >>> df\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01    10    13    17\n",
      " |      2020-01-02    20    23    27\n",
      " |      2020-01-03    15    18    22\n",
      " |      2020-01-04    30    33    37\n",
      " |      2020-01-05    45    48    52\n",
      " |      \n",
      " |      >>> df.shift(periods=3)\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01   NaN   NaN   NaN\n",
      " |      2020-01-02   NaN   NaN   NaN\n",
      " |      2020-01-03   NaN   NaN   NaN\n",
      " |      2020-01-04  10.0  13.0  17.0\n",
      " |      2020-01-05  20.0  23.0  27.0\n",
      " |      \n",
      " |      >>> df.shift(periods=1, axis=\"columns\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01   NaN    10    13\n",
      " |      2020-01-02   NaN    20    23\n",
      " |      2020-01-03   NaN    15    18\n",
      " |      2020-01-04   NaN    30    33\n",
      " |      2020-01-05   NaN    45    48\n",
      " |      \n",
      " |      >>> df.shift(periods=3, fill_value=0)\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01     0     0     0\n",
      " |      2020-01-02     0     0     0\n",
      " |      2020-01-03     0     0     0\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      \n",
      " |      >>> df.shift(periods=3, freq=\"D\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      2020-01-06    15    18    22\n",
      " |      2020-01-07    30    33    37\n",
      " |      2020-01-08    45    48    52\n",
      " |      \n",
      " |      >>> df.shift(periods=3, freq=\"infer\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      2020-01-06    15    18    22\n",
      " |      2020-01-07    30    33    37\n",
      " |      2020-01-08    45    48    52\n",
      " |  \n",
      " |  skew(self, axis: 'AxisInt | None' = 0, skipna: 'bool_t' = True, numeric_only: 'bool_t' = False, **kwargs)\n",
      " |      Return unbiased skew over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |      \n",
      " |          .. versionadded:: 2.0.0\n",
      " |      \n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or scalar\n",
      " |  \n",
      " |  sort_index(self, *, axis: 'Axis' = 0, level: 'IndexLabel' = None, ascending: 'bool | Sequence[bool]' = True, inplace: 'bool' = False, kind: 'SortKind' = 'quicksort', na_position: 'NaPosition' = 'last', sort_remaining: 'bool' = True, ignore_index: 'bool' = False, key: 'IndexKeyFunc' = None) -> 'DataFrame | None'\n",
      " |      Sort object by labels (along an axis).\n",
      " |      \n",
      " |      Returns a new DataFrame sorted by label if `inplace` argument is\n",
      " |      ``False``, otherwise updates the original DataFrame and returns None.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis along which to sort.  The value 0 identifies the rows,\n",
      " |          and 1 identifies the columns.\n",
      " |      level : int or level name or list of ints or list of level names\n",
      " |          If not None, sort on values in specified index level(s).\n",
      " |      ascending : bool or list-like of bools, default True\n",
      " |          Sort ascending vs. descending. When the index is a MultiIndex the\n",
      " |          sort direction can be controlled for each level individually.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to modify the DataFrame rather than creating a new one.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |          information. `mergesort` and `stable` are the only stable algorithms. For\n",
      " |          DataFrames, this option is only applied when sorting on a single\n",
      " |          column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |          Puts NaNs at the beginning if `first`; `last` puts NaNs at the end.\n",
      " |          Not implemented for MultiIndex.\n",
      " |      sort_remaining : bool, default True\n",
      " |          If True and sorting by level and index is multilevel, sort by other\n",
      " |          levels too (in order) after sorting by specified level.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      key : callable, optional\n",
      " |          If not None, apply the key function to the index values\n",
      " |          before sorting. This is similar to the `key` argument in the\n",
      " |          builtin :meth:`sorted` function, with the notable difference that\n",
      " |          this `key` function should be *vectorized*. It should expect an\n",
      " |          ``Index`` and return an ``Index`` of the same shape. For MultiIndex\n",
      " |          inputs, the key is applied *per level*.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          The original DataFrame sorted by the labels or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_index : Sort Series by the index.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the value.\n",
      " |      Series.sort_values : Sort Series by the value.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([1, 2, 3, 4, 5], index=[100, 29, 234, 1, 150],\n",
      " |      ...                   columns=['A'])\n",
      " |      >>> df.sort_index()\n",
      " |           A\n",
      " |      1    4\n",
      " |      29   2\n",
      " |      100  1\n",
      " |      150  5\n",
      " |      234  3\n",
      " |      \n",
      " |      By default, it sorts in ascending order, to sort in descending order,\n",
      " |      use ``ascending=False``\n",
      " |      \n",
      " |      >>> df.sort_index(ascending=False)\n",
      " |           A\n",
      " |      234  3\n",
      " |      150  5\n",
      " |      100  1\n",
      " |      29   2\n",
      " |      1    4\n",
      " |      \n",
      " |      A key function can be specified which is applied to the index before\n",
      " |      sorting. For a ``MultiIndex`` this is applied to each level separately.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"a\": [1, 2, 3, 4]}, index=['A', 'b', 'C', 'd'])\n",
      " |      >>> df.sort_index(key=lambda x: x.str.lower())\n",
      " |         a\n",
      " |      A  1\n",
      " |      b  2\n",
      " |      C  3\n",
      " |      d  4\n",
      " |  \n",
      " |  sort_values(self, by: 'IndexLabel', *, axis: 'Axis' = 0, ascending: 'bool | list[bool] | tuple[bool, ...]' = True, inplace: 'bool' = False, kind: 'str' = 'quicksort', na_position: 'str' = 'last', ignore_index: 'bool' = False, key: 'ValueKeyFunc' = None) -> 'DataFrame | None'\n",
      " |      Sort by the values along either axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : str or list of str\n",
      " |          Name or list of names to sort by.\n",
      " |      \n",
      " |          - if `axis` is 0 or `'index'` then `by` may contain index\n",
      " |            levels and/or column labels.\n",
      " |          - if `axis` is 1 or `'columns'` then `by` may contain column\n",
      " |            levels and/or index labels.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |           Axis to be sorted.\n",
      " |      ascending : bool or list of bool, default True\n",
      " |           Sort ascending vs. descending. Specify list for multiple sort\n",
      " |           orders.  If this is a list of bools, must match the length of\n",
      " |           the by.\n",
      " |      inplace : bool, default False\n",
      " |           If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'\n",
      " |           Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |           information. `mergesort` and `stable` are the only stable algorithms. For\n",
      " |           DataFrames, this option is only applied when sorting on a single\n",
      " |           column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |           Puts NaNs at the beginning if `first`; `last` puts NaNs at the\n",
      " |           end.\n",
      " |      ignore_index : bool, default False\n",
      " |           If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      key : callable, optional\n",
      " |          Apply the key function to the values\n",
      " |          before sorting. This is similar to the `key` argument in the\n",
      " |          builtin :meth:`sorted` function, with the notable difference that\n",
      " |          this `key` function should be *vectorized*. It should expect a\n",
      " |          ``Series`` and return a Series with the same shape as the input.\n",
      " |          It will be applied to each column in `by` independently.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with sorted values or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.sort_index : Sort a DataFrame by the index.\n",
      " |      Series.sort_values : Similar method for a Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'col1': ['A', 'A', 'B', np.nan, 'D', 'C'],\n",
      " |      ...     'col2': [2, 1, 9, 8, 7, 4],\n",
      " |      ...     'col3': [0, 1, 9, 4, 2, 3],\n",
      " |      ...     'col4': ['a', 'B', 'c', 'D', 'e', 'F']\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |        col1  col2  col3 col4\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      2    B     9     9    c\n",
      " |      3  NaN     8     4    D\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      \n",
      " |      Sort by col1\n",
      " |      \n",
      " |      >>> df.sort_values(by=['col1'])\n",
      " |        col1  col2  col3 col4\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      2    B     9     9    c\n",
      " |      5    C     4     3    F\n",
      " |      4    D     7     2    e\n",
      " |      3  NaN     8     4    D\n",
      " |      \n",
      " |      Sort by multiple columns\n",
      " |      \n",
      " |      >>> df.sort_values(by=['col1', 'col2'])\n",
      " |        col1  col2  col3 col4\n",
      " |      1    A     1     1    B\n",
      " |      0    A     2     0    a\n",
      " |      2    B     9     9    c\n",
      " |      5    C     4     3    F\n",
      " |      4    D     7     2    e\n",
      " |      3  NaN     8     4    D\n",
      " |      \n",
      " |      Sort Descending\n",
      " |      \n",
      " |      >>> df.sort_values(by='col1', ascending=False)\n",
      " |        col1  col2  col3 col4\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      2    B     9     9    c\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      3  NaN     8     4    D\n",
      " |      \n",
      " |      Putting NAs first\n",
      " |      \n",
      " |      >>> df.sort_values(by='col1', ascending=False, na_position='first')\n",
      " |        col1  col2  col3 col4\n",
      " |      3  NaN     8     4    D\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      2    B     9     9    c\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      \n",
      " |      Sorting with a key function\n",
      " |      \n",
      " |      >>> df.sort_values(by='col4', key=lambda col: col.str.lower())\n",
      " |         col1  col2  col3 col4\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      2    B     9     9    c\n",
      " |      3  NaN     8     4    D\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      \n",
      " |      Natural sort with the key argument,\n",
      " |      using the `natsort <https://github.com/SethMMorton/natsort>` package.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...    \"time\": ['0hr', '128hr', '72hr', '48hr', '96hr'],\n",
      " |      ...    \"value\": [10, 20, 30, 40, 50]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |          time  value\n",
      " |      0    0hr     10\n",
      " |      1  128hr     20\n",
      " |      2   72hr     30\n",
      " |      3   48hr     40\n",
      " |      4   96hr     50\n",
      " |      >>> from natsort import index_natsorted\n",
      " |      >>> df.sort_values(\n",
      " |      ...     by=\"time\",\n",
      " |      ...     key=lambda x: np.argsort(index_natsorted(df[\"time\"]))\n",
      " |      ... )\n",
      " |          time  value\n",
      " |      0    0hr     10\n",
      " |      3   48hr     40\n",
      " |      2   72hr     30\n",
      " |      4   96hr     50\n",
      " |      1  128hr     20\n",
      " |  \n",
      " |  stack(self, level: 'Level' = -1, dropna: 'bool' = True)\n",
      " |      Stack the prescribed level(s) from columns to index.\n",
      " |      \n",
      " |      Return a reshaped DataFrame or Series having a multi-level\n",
      " |      index with one or more new inner-most levels compared to the current\n",
      " |      DataFrame. The new inner-most levels are created by pivoting the\n",
      " |      columns of the current dataframe:\n",
      " |      \n",
      " |        - if the columns have a single level, the output is a Series;\n",
      " |        - if the columns have multiple levels, the new index\n",
      " |          level(s) is (are) taken from the prescribed level(s) and\n",
      " |          the output is a DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, list, default -1\n",
      " |          Level(s) to stack from the column axis onto the index\n",
      " |          axis, defined as one index or label, or a list of indices\n",
      " |          or labels.\n",
      " |      dropna : bool, default True\n",
      " |          Whether to drop rows in the resulting Frame/Series with\n",
      " |          missing values. Stacking a column level onto the index\n",
      " |          axis can create combinations of index and column values\n",
      " |          that are missing from the original dataframe. See Examples\n",
      " |          section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or Series\n",
      " |          Stacked dataframe or series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.unstack : Unstack prescribed level(s) from index axis\n",
      " |           onto column axis.\n",
      " |      DataFrame.pivot : Reshape dataframe from long format to wide\n",
      " |           format.\n",
      " |      DataFrame.pivot_table : Create a spreadsheet-style pivot table\n",
      " |           as a DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The function is named by analogy with a collection of books\n",
      " |      being reorganized from being side by side on a horizontal\n",
      " |      position (the columns of the dataframe) to being stacked\n",
      " |      vertically on top of each other (in the index of the\n",
      " |      dataframe).\n",
      " |      \n",
      " |      Reference :ref:`the user guide <reshaping.stacking>` for more examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Single level columns**\n",
      " |      \n",
      " |      >>> df_single_level_cols = pd.DataFrame([[0, 1], [2, 3]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=['weight', 'height'])\n",
      " |      \n",
      " |      Stacking a dataframe with a single level column axis returns a Series:\n",
      " |      \n",
      " |      >>> df_single_level_cols\n",
      " |           weight height\n",
      " |      cat       0      1\n",
      " |      dog       2      3\n",
      " |      >>> df_single_level_cols.stack()\n",
      " |      cat  weight    0\n",
      " |           height    1\n",
      " |      dog  weight    2\n",
      " |           height    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **Multi level columns: simple case**\n",
      " |      \n",
      " |      >>> multicol1 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n",
      " |      ...                                        ('weight', 'pounds')])\n",
      " |      >>> df_multi_level_cols1 = pd.DataFrame([[1, 2], [2, 4]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol1)\n",
      " |      \n",
      " |      Stacking a dataframe with a multi-level column axis:\n",
      " |      \n",
      " |      >>> df_multi_level_cols1\n",
      " |           weight\n",
      " |               kg    pounds\n",
      " |      cat       1        2\n",
      " |      dog       2        4\n",
      " |      >>> df_multi_level_cols1.stack()\n",
      " |                  weight\n",
      " |      cat kg           1\n",
      " |          pounds       2\n",
      " |      dog kg           2\n",
      " |          pounds       4\n",
      " |      \n",
      " |      **Missing values**\n",
      " |      \n",
      " |      >>> multicol2 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n",
      " |      ...                                        ('height', 'm')])\n",
      " |      >>> df_multi_level_cols2 = pd.DataFrame([[1.0, 2.0], [3.0, 4.0]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol2)\n",
      " |      \n",
      " |      It is common to have missing values when stacking a dataframe\n",
      " |      with multi-level columns, as the stacked dataframe typically\n",
      " |      has more values than the original dataframe. Missing values\n",
      " |      are filled with NaNs:\n",
      " |      \n",
      " |      >>> df_multi_level_cols2\n",
      " |          weight height\n",
      " |              kg      m\n",
      " |      cat    1.0    2.0\n",
      " |      dog    3.0    4.0\n",
      " |      >>> df_multi_level_cols2.stack()\n",
      " |              height  weight\n",
      " |      cat kg     NaN     1.0\n",
      " |          m      2.0     NaN\n",
      " |      dog kg     NaN     3.0\n",
      " |          m      4.0     NaN\n",
      " |      \n",
      " |      **Prescribing the level(s) to be stacked**\n",
      " |      \n",
      " |      The first parameter controls which level or levels are stacked:\n",
      " |      \n",
      " |      >>> df_multi_level_cols2.stack(0)\n",
      " |                   kg    m\n",
      " |      cat height  NaN  2.0\n",
      " |          weight  1.0  NaN\n",
      " |      dog height  NaN  4.0\n",
      " |          weight  3.0  NaN\n",
      " |      >>> df_multi_level_cols2.stack([0, 1])\n",
      " |      cat  height  m     2.0\n",
      " |           weight  kg    1.0\n",
      " |      dog  height  m     4.0\n",
      " |           weight  kg    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **Dropping missing values**\n",
      " |      \n",
      " |      >>> df_multi_level_cols3 = pd.DataFrame([[None, 1.0], [2.0, 3.0]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol2)\n",
      " |      \n",
      " |      Note that rows where all values are missing are dropped by\n",
      " |      default but this behaviour can be controlled via the dropna\n",
      " |      keyword parameter:\n",
      " |      \n",
      " |      >>> df_multi_level_cols3\n",
      " |          weight height\n",
      " |              kg      m\n",
      " |      cat    NaN    1.0\n",
      " |      dog    2.0    3.0\n",
      " |      >>> df_multi_level_cols3.stack(dropna=False)\n",
      " |              height  weight\n",
      " |      cat kg     NaN     NaN\n",
      " |          m      1.0     NaN\n",
      " |      dog kg     NaN     2.0\n",
      " |          m      3.0     NaN\n",
      " |      >>> df_multi_level_cols3.stack(dropna=True)\n",
      " |              height  weight\n",
      " |      cat m      1.0     NaN\n",
      " |      dog kg     NaN     2.0\n",
      " |          m      3.0     NaN\n",
      " |  \n",
      " |  std(self, axis: 'Axis | None' = None, skipna: 'bool_t' = True, ddof: 'int' = 1, numeric_only: 'bool_t' = False, **kwargs)\n",
      " |      Return sample standard deviation over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified) \n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To have the same behaviour as `numpy.std`, use `ddof=0` (instead of the\n",
      " |      default `ddof=1`)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],\n",
      " |      ...                    'age': [21, 25, 62, 43],\n",
      " |      ...                    'height': [1.61, 1.87, 1.49, 2.01]}\n",
      " |      ...                   ).set_index('person_id')\n",
      " |      >>> df\n",
      " |                 age  height\n",
      " |      person_id\n",
      " |      0           21    1.61\n",
      " |      1           25    1.87\n",
      " |      2           62    1.49\n",
      " |      3           43    2.01\n",
      " |      \n",
      " |      The standard deviation of the columns can be found as follows:\n",
      " |      \n",
      " |      >>> df.std()\n",
      " |      age       18.786076\n",
      " |      height     0.237417\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Alternatively, `ddof=0` can be set to normalize by N instead of N-1:\n",
      " |      \n",
      " |      >>> df.std(ddof=0)\n",
      " |      age       16.269219\n",
      " |      height     0.205609\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  sub(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None)\n",
      " |      Get Subtraction of dataframe and other, element-wise (binary operator `sub`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe - other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rsub`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  subtract = sub(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  sum(self, axis: 'Axis | None' = None, skipna: 'bool_t' = True, numeric_only: 'bool_t' = False, min_count: 'int' = 0, **kwargs)\n",
      " |      Return the sum of the values over the requested axis.\n",
      " |      \n",
      " |      This is equivalent to the method ``numpy.sum``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |      \n",
      " |          .. versionadded:: 2.0.0\n",
      " |      \n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |      \n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or scalar\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.sum()\n",
      " |      14\n",
      " |      \n",
      " |      By default, the sum of an empty or all-NA Series is ``0``.\n",
      " |      \n",
      " |      >>> pd.Series([], dtype=\"float64\").sum()  # min_count=0 is the default\n",
      " |      0.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter. For example, if\n",
      " |      you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
      " |      \n",
      " |      >>> pd.Series([], dtype=\"float64\").sum(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum()\n",
      " |      0.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  swaplevel(self, i: 'Axis' = -2, j: 'Axis' = -1, axis: 'Axis' = 0) -> 'DataFrame'\n",
      " |      Swap levels i and j in a :class:`MultiIndex`.\n",
      " |      \n",
      " |      Default is to swap the two innermost levels of the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i, j : int or str\n",
      " |          Levels of the indices to be swapped. Can pass level name as string.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |                  The axis to swap levels on. 0 or 'index' for row-wise, 1 or\n",
      " |                  'columns' for column-wise.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame with levels swapped in MultiIndex.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\"Grade\": [\"A\", \"B\", \"A\", \"C\"]},\n",
      " |      ...     index=[\n",
      " |      ...         [\"Final exam\", \"Final exam\", \"Coursework\", \"Coursework\"],\n",
      " |      ...         [\"History\", \"Geography\", \"History\", \"Geography\"],\n",
      " |      ...         [\"January\", \"February\", \"March\", \"April\"],\n",
      " |      ...     ],\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |                                          Grade\n",
      " |      Final exam  History     January      A\n",
      " |                  Geography   February     B\n",
      " |      Coursework  History     March        A\n",
      " |                  Geography   April        C\n",
      " |      \n",
      " |      In the following example, we will swap the levels of the indices.\n",
      " |      Here, we will swap the levels column-wise, but levels can be swapped row-wise\n",
      " |      in a similar manner. Note that column-wise is the default behaviour.\n",
      " |      By not supplying any arguments for i and j, we swap the last and second to\n",
      " |      last indices.\n",
      " |      \n",
      " |      >>> df.swaplevel()\n",
      " |                                          Grade\n",
      " |      Final exam  January     History         A\n",
      " |                  February    Geography       B\n",
      " |      Coursework  March       History         A\n",
      " |                  April       Geography       C\n",
      " |      \n",
      " |      By supplying one argument, we can choose which index to swap the last\n",
      " |      index with. We can for example swap the first index with the last one as\n",
      " |      follows.\n",
      " |      \n",
      " |      >>> df.swaplevel(0)\n",
      " |                                          Grade\n",
      " |      January     History     Final exam      A\n",
      " |      February    Geography   Final exam      B\n",
      " |      March       History     Coursework      A\n",
      " |      April       Geography   Coursework      C\n",
      " |      \n",
      " |      We can also define explicitly which indices we want to swap by supplying values\n",
      " |      for both i and j. Here, we for example swap the first and second indices.\n",
      " |      \n",
      " |      >>> df.swaplevel(0, 1)\n",
      " |                                          Grade\n",
      " |      History     Final exam  January         A\n",
      " |      Geography   Final exam  February        B\n",
      " |      History     Coursework  March           A\n",
      " |      Geography   Coursework  April           C\n",
      " |  \n",
      " |  to_dict(self, orient: \"Literal[('dict', 'list', 'series', 'split', 'tight', 'records', 'index')]\" = 'dict', into: 'type[dict]' = <class 'dict'>, index: 'bool' = True) -> 'dict | list[dict]'\n",
      " |      Convert the DataFrame to a dictionary.\n",
      " |      \n",
      " |      The type of the key-value pairs can be customized with the parameters\n",
      " |      (see below).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      orient : str {'dict', 'list', 'series', 'split', 'tight', 'records', 'index'}\n",
      " |          Determines the type of the values of the dictionary.\n",
      " |      \n",
      " |          - 'dict' (default) : dict like {column -> {index -> value}}\n",
      " |          - 'list' : dict like {column -> [values]}\n",
      " |          - 'series' : dict like {column -> Series(values)}\n",
      " |          - 'split' : dict like\n",
      " |            {'index' -> [index], 'columns' -> [columns], 'data' -> [values]}\n",
      " |          - 'tight' : dict like\n",
      " |            {'index' -> [index], 'columns' -> [columns], 'data' -> [values],\n",
      " |            'index_names' -> [index.names], 'column_names' -> [column.names]}\n",
      " |          - 'records' : list like\n",
      " |            [{column -> value}, ... , {column -> value}]\n",
      " |          - 'index' : dict like {index -> {column -> value}}\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |              'tight' as an allowed value for the ``orient`` argument\n",
      " |      \n",
      " |      into : class, default dict\n",
      " |          The collections.abc.Mapping subclass used for all Mappings\n",
      " |          in the return value.  Can be the actual class or an empty\n",
      " |          instance of the mapping type you want.  If you want a\n",
      " |          collections.defaultdict, you must pass it initialized.\n",
      " |      \n",
      " |      index : bool, default True\n",
      " |          Whether to include the index item (and index_names item if `orient`\n",
      " |          is 'tight') in the returned dictionary. Can only be ``False``\n",
      " |          when `orient` is 'split' or 'tight'.\n",
      " |      \n",
      " |          .. versionadded:: 2.0.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict, list or collections.abc.Mapping\n",
      " |          Return a collections.abc.Mapping object representing the DataFrame.\n",
      " |          The resulting transformation depends on the `orient` parameter.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_dict: Create a DataFrame from a dictionary.\n",
      " |      DataFrame.to_json: Convert a DataFrame to JSON format.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2],\n",
      " |      ...                    'col2': [0.5, 0.75]},\n",
      " |      ...                   index=['row1', 'row2'])\n",
      " |      >>> df\n",
      " |            col1  col2\n",
      " |      row1     1  0.50\n",
      " |      row2     2  0.75\n",
      " |      >>> df.to_dict()\n",
      " |      {'col1': {'row1': 1, 'row2': 2}, 'col2': {'row1': 0.5, 'row2': 0.75}}\n",
      " |      \n",
      " |      You can specify the return orientation.\n",
      " |      \n",
      " |      >>> df.to_dict('series')\n",
      " |      {'col1': row1    1\n",
      " |               row2    2\n",
      " |      Name: col1, dtype: int64,\n",
      " |      'col2': row1    0.50\n",
      " |              row2    0.75\n",
      " |      Name: col2, dtype: float64}\n",
      " |      \n",
      " |      >>> df.to_dict('split')\n",
      " |      {'index': ['row1', 'row2'], 'columns': ['col1', 'col2'],\n",
      " |       'data': [[1, 0.5], [2, 0.75]]}\n",
      " |      \n",
      " |      >>> df.to_dict('records')\n",
      " |      [{'col1': 1, 'col2': 0.5}, {'col1': 2, 'col2': 0.75}]\n",
      " |      \n",
      " |      >>> df.to_dict('index')\n",
      " |      {'row1': {'col1': 1, 'col2': 0.5}, 'row2': {'col1': 2, 'col2': 0.75}}\n",
      " |      \n",
      " |      >>> df.to_dict('tight')\n",
      " |      {'index': ['row1', 'row2'], 'columns': ['col1', 'col2'],\n",
      " |       'data': [[1, 0.5], [2, 0.75]], 'index_names': [None], 'column_names': [None]}\n",
      " |      \n",
      " |      You can also specify the mapping type.\n",
      " |      \n",
      " |      >>> from collections import OrderedDict, defaultdict\n",
      " |      >>> df.to_dict(into=OrderedDict)\n",
      " |      OrderedDict([('col1', OrderedDict([('row1', 1), ('row2', 2)])),\n",
      " |                   ('col2', OrderedDict([('row1', 0.5), ('row2', 0.75)]))])\n",
      " |      \n",
      " |      If you want a `defaultdict`, you need to initialize it:\n",
      " |      \n",
      " |      >>> dd = defaultdict(list)\n",
      " |      >>> df.to_dict('records', into=dd)\n",
      " |      [defaultdict(<class 'list'>, {'col1': 1, 'col2': 0.5}),\n",
      " |       defaultdict(<class 'list'>, {'col1': 2, 'col2': 0.75})]\n",
      " |  \n",
      " |  to_feather(self, path: 'FilePath | WriteBuffer[bytes]', **kwargs) -> 'None'\n",
      " |      Write a DataFrame to the binary Feather format.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, path object, file-like object\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a binary ``write()`` function. If a string or a path,\n",
      " |          it will be used as Root Directory path when writing a partitioned dataset.\n",
      " |      **kwargs :\n",
      " |          Additional keywords passed to :func:`pyarrow.feather.write_feather`.\n",
      " |          Starting with pyarrow 0.17, this includes the `compression`,\n",
      " |          `compression_level`, `chunksize` and `version` keywords.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function writes the dataframe as a `feather file\n",
      " |      <https://arrow.apache.org/docs/python/feather.html>`_. Requires a default\n",
      " |      index. For saving the DataFrame with your custom index use a method that\n",
      " |      supports custom indices e.g. `to_parquet`.\n",
      " |  \n",
      " |  to_gbq(self, destination_table: 'str', project_id: 'str | None' = None, chunksize: 'int | None' = None, reauth: 'bool' = False, if_exists: 'str' = 'fail', auth_local_webserver: 'bool' = True, table_schema: 'list[dict[str, str]] | None' = None, location: 'str | None' = None, progress_bar: 'bool' = True, credentials=None) -> 'None'\n",
      " |      Write a DataFrame to a Google BigQuery table.\n",
      " |      \n",
      " |      This function requires the `pandas-gbq package\n",
      " |      <https://pandas-gbq.readthedocs.io>`__.\n",
      " |      \n",
      " |      See the `How to authenticate with Google BigQuery\n",
      " |      <https://pandas-gbq.readthedocs.io/en/latest/howto/authentication.html>`__\n",
      " |      guide for authentication instructions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      destination_table : str\n",
      " |          Name of table to be written, in the form ``dataset.tablename``.\n",
      " |      project_id : str, optional\n",
      " |          Google BigQuery Account project ID. Optional when available from\n",
      " |          the environment.\n",
      " |      chunksize : int, optional\n",
      " |          Number of rows to be inserted in each chunk from the dataframe.\n",
      " |          Set to ``None`` to load the whole dataframe at once.\n",
      " |      reauth : bool, default False\n",
      " |          Force Google BigQuery to re-authenticate the user. This is useful\n",
      " |          if multiple accounts are used.\n",
      " |      if_exists : str, default 'fail'\n",
      " |          Behavior when the destination table exists. Value can be one of:\n",
      " |      \n",
      " |          ``'fail'``\n",
      " |              If table exists raise pandas_gbq.gbq.TableCreationError.\n",
      " |          ``'replace'``\n",
      " |              If table exists, drop it, recreate it, and insert data.\n",
      " |          ``'append'``\n",
      " |              If table exists, insert data. Create if does not exist.\n",
      " |      auth_local_webserver : bool, default True\n",
      " |          Use the `local webserver flow`_ instead of the `console flow`_\n",
      " |          when getting user credentials.\n",
      " |      \n",
      " |          .. _local webserver flow:\n",
      " |              https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_local_server\n",
      " |          .. _console flow:\n",
      " |              https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_console\n",
      " |      \n",
      " |          *New in version 0.2.0 of pandas-gbq*.\n",
      " |      \n",
      " |          .. versionchanged:: 1.5.0\n",
      " |             Default value is changed to ``True``. Google has deprecated the\n",
      " |             ``auth_local_webserver = False`` `\"out of band\" (copy-paste)\n",
      " |             flow\n",
      " |             <https://developers.googleblog.com/2022/02/making-oauth-flows-safer.html?m=1#disallowed-oob>`_.\n",
      " |      table_schema : list of dicts, optional\n",
      " |          List of BigQuery table fields to which according DataFrame\n",
      " |          columns conform to, e.g. ``[{'name': 'col1', 'type':\n",
      " |          'STRING'},...]``. If schema is not provided, it will be\n",
      " |          generated according to dtypes of DataFrame columns. See\n",
      " |          BigQuery API documentation on available names of a field.\n",
      " |      \n",
      " |          *New in version 0.3.1 of pandas-gbq*.\n",
      " |      location : str, optional\n",
      " |          Location where the load job should run. See the `BigQuery locations\n",
      " |          documentation\n",
      " |          <https://cloud.google.com/bigquery/docs/dataset-locations>`__ for a\n",
      " |          list of available locations. The location must match that of the\n",
      " |          target dataset.\n",
      " |      \n",
      " |          *New in version 0.5.0 of pandas-gbq*.\n",
      " |      progress_bar : bool, default True\n",
      " |          Use the library `tqdm` to show the progress bar for the upload,\n",
      " |          chunk by chunk.\n",
      " |      \n",
      " |          *New in version 0.5.0 of pandas-gbq*.\n",
      " |      credentials : google.auth.credentials.Credentials, optional\n",
      " |          Credentials for accessing Google APIs. Use this parameter to\n",
      " |          override default credentials, such as to use Compute Engine\n",
      " |          :class:`google.auth.compute_engine.Credentials` or Service\n",
      " |          Account :class:`google.oauth2.service_account.Credentials`\n",
      " |          directly.\n",
      " |      \n",
      " |          *New in version 0.8.0 of pandas-gbq*.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas_gbq.to_gbq : This function in the pandas-gbq library.\n",
      " |      read_gbq : Read a DataFrame from Google BigQuery.\n",
      " |  \n",
      " |  to_html(self, buf: 'FilePath | WriteBuffer[str] | None' = None, columns: 'Sequence[Level] | None' = None, col_space: 'ColspaceArgType | None' = None, header: 'bool | Sequence[str]' = True, index: 'bool' = True, na_rep: 'str' = 'NaN', formatters: 'FormattersType | None' = None, float_format: 'FloatFormatType | None' = None, sparsify: 'bool | None' = None, index_names: 'bool' = True, justify: 'str | None' = None, max_rows: 'int | None' = None, max_cols: 'int | None' = None, show_dimensions: 'bool | str' = False, decimal: 'str' = '.', bold_rows: 'bool' = True, classes: 'str | list | tuple | None' = None, escape: 'bool' = True, notebook: 'bool' = False, border: 'int | bool | None' = None, table_id: 'str | None' = None, render_links: 'bool' = False, encoding: 'str | None' = None) -> 'str | None'\n",
      " |      Render a DataFrame as an HTML table.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : sequence, optional, default None\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      col_space : str or int, list or dict of int or str, optional\n",
      " |          The minimum width of each column in CSS length units.  An int is assumed to be px units..\n",
      " |      header : bool, optional\n",
      " |          Whether to print column labels, default True.\n",
      " |      index : bool, optional, default True\n",
      " |          Whether to print index (row) labels.\n",
      " |      na_rep : str, optional, default 'NaN'\n",
      " |          String representation of ``NaN`` to use.\n",
      " |      formatters : list, tuple or dict of one-param. functions, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name.\n",
      " |          The result of each function must be a unicode string.\n",
      " |          List/tuple must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function, optional, default None\n",
      " |          Formatter function to apply to columns' elements if they are\n",
      " |          floats. This function must return a unicode string and will be\n",
      " |          applied only to the non-``NaN`` elements, with ``NaN`` being\n",
      " |          handled by ``na_rep``.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |      sparsify : bool, optional, default True\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row.\n",
      " |      index_names : bool, optional, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      justify : str, default None\n",
      " |          How to justify the column labels. If None uses the option from\n",
      " |          the print configuration (controlled by set_option), 'right' out\n",
      " |          of the box. Valid values are\n",
      " |      \n",
      " |          * left\n",
      " |          * right\n",
      " |          * center\n",
      " |          * justify\n",
      " |          * justify-all\n",
      " |          * start\n",
      " |          * end\n",
      " |          * inherit\n",
      " |          * match-parent\n",
      " |          * initial\n",
      " |          * unset.\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to display in the console.\n",
      " |      max_cols : int, optional\n",
      " |          Maximum number of columns to display in the console.\n",
      " |      show_dimensions : bool, default False\n",
      " |          Display DataFrame dimensions (number of rows by number of columns).\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      \n",
      " |      bold_rows : bool, default True\n",
      " |          Make the row labels bold in the output.\n",
      " |      classes : str or list or tuple, default None\n",
      " |          CSS class(es) to apply to the resulting html table.\n",
      " |      escape : bool, default True\n",
      " |          Convert the characters <, >, and & to HTML-safe sequences.\n",
      " |      notebook : {True, False}, default False\n",
      " |          Whether the generated HTML is for IPython Notebook.\n",
      " |      border : int\n",
      " |          A ``border=border`` attribute is included in the opening\n",
      " |          `<table>` tag. Default ``pd.options.display.html.border``.\n",
      " |      table_id : str, optional\n",
      " |          A css id is included in the opening `<table>` tag if specified.\n",
      " |      render_links : bool, default False\n",
      " |          Convert URLs to HTML links.\n",
      " |      encoding : str, default \"utf-8\"\n",
      " |          Set character encoding.\n",
      " |      \n",
      " |          .. versionadded:: 1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or None\n",
      " |          If buf is None, returns the result as a string. Otherwise returns\n",
      " |          None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_string : Convert DataFrame to a string.\n",
      " |  \n",
      " |  to_markdown(self, buf: 'FilePath | WriteBuffer[str] | None' = None, mode: 'str' = 'wt', index: 'bool' = True, storage_options: 'StorageOptions' = None, **kwargs) -> 'str | None'\n",
      " |      Print DataFrame in Markdown-friendly format.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      mode : str, optional\n",
      " |          Mode in which file is opened, \"wt\" by default.\n",
      " |      index : bool, optional, default True\n",
      " |          Add index (row) labels.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          These parameters will be passed to `tabulate                 <https://pypi.org/project/tabulate>`_.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          DataFrame in Markdown-friendly format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requires the `tabulate <https://pypi.org/project/tabulate>`_ package.\n",
      " |      \n",
      " |      Examples\n",
      " |              --------\n",
      " |              >>> df = pd.DataFrame(\n",
      " |              ...     data={\"animal_1\": [\"elk\", \"pig\"], \"animal_2\": [\"dog\", \"quetzal\"]}\n",
      " |              ... )\n",
      " |              >>> print(df.to_markdown())\n",
      " |              |    | animal_1   | animal_2   |\n",
      " |              |---:|:-----------|:-----------|\n",
      " |              |  0 | elk        | dog        |\n",
      " |              |  1 | pig        | quetzal    |\n",
      " |      \n",
      " |              Output markdown with a tabulate option.\n",
      " |      \n",
      " |              >>> print(df.to_markdown(tablefmt=\"grid\"))\n",
      " |              +----+------------+------------+\n",
      " |              |    | animal_1   | animal_2   |\n",
      " |              +====+============+============+\n",
      " |              |  0 | elk        | dog        |\n",
      " |              +----+------------+------------+\n",
      " |              |  1 | pig        | quetzal    |\n",
      " |              +----+------------+------------+\n",
      " |  \n",
      " |  to_numpy(self, dtype: 'npt.DTypeLike | None' = None, copy: 'bool' = False, na_value: 'object' = <no_default>) -> 'np.ndarray'\n",
      " |      Convert the DataFrame to a NumPy array.\n",
      " |      \n",
      " |      By default, the dtype of the returned array will be the common NumPy\n",
      " |      dtype of all types in the DataFrame. For example, if the dtypes are\n",
      " |      ``float16`` and ``float32``, the results dtype will be ``float32``.\n",
      " |      This may require copying data and coercing values, which may be\n",
      " |      expensive.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str or numpy.dtype, optional\n",
      " |          The dtype to pass to :meth:`numpy.asarray`.\n",
      " |      copy : bool, default False\n",
      " |          Whether to ensure that the returned value is not a view on\n",
      " |          another array. Note that ``copy=False`` does not *ensure* that\n",
      " |          ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\n",
      " |          a copy is made, even if not strictly necessary.\n",
      " |      na_value : Any, optional\n",
      " |          The value to use for missing values. The default value depends\n",
      " |          on `dtype` and the dtypes of the DataFrame columns.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.to_numpy : Similar method for Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]}).to_numpy()\n",
      " |      array([[1, 3],\n",
      " |             [2, 4]])\n",
      " |      \n",
      " |      With heterogeneous data, the lowest common type will have to\n",
      " |      be used.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3.0, 4.5]})\n",
      " |      >>> df.to_numpy()\n",
      " |      array([[1. , 3. ],\n",
      " |             [2. , 4.5]])\n",
      " |      \n",
      " |      For a mix of numeric and non-numeric types, the output array will\n",
      " |      have object dtype.\n",
      " |      \n",
      " |      >>> df['C'] = pd.date_range('2000', periods=2)\n",
      " |      >>> df.to_numpy()\n",
      " |      array([[1, 3.0, Timestamp('2000-01-01 00:00:00')],\n",
      " |             [2, 4.5, Timestamp('2000-01-02 00:00:00')]], dtype=object)\n",
      " |  \n",
      " |  to_orc(self, path: 'FilePath | WriteBuffer[bytes] | None' = None, *, engine: \"Literal['pyarrow']\" = 'pyarrow', index: 'bool | None' = None, engine_kwargs: 'dict[str, Any] | None' = None) -> 'bytes | None'\n",
      " |      Write a DataFrame to the ORC format.\n",
      " |      \n",
      " |      .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, file-like object or None, default None\n",
      " |          If a string, it will be used as Root Directory path\n",
      " |          when writing a partitioned dataset. By file-like object,\n",
      " |          we refer to objects with a write() method, such as a file handle\n",
      " |          (e.g. via builtin open function). If path is None,\n",
      " |          a bytes object is returned.\n",
      " |      engine : str, default 'pyarrow'\n",
      " |          ORC library to use. Pyarrow must be >= 7.0.0.\n",
      " |      index : bool, optional\n",
      " |          If ``True``, include the dataframe's index(es) in the file output.\n",
      " |          If ``False``, they will not be written to the file.\n",
      " |          If ``None``, similar to ``infer`` the dataframe's index(es)\n",
      " |          will be saved. However, instead of being saved as values,\n",
      " |          the RangeIndex will be stored as a range in the metadata so it\n",
      " |          doesn't require much space and is faster. Other indexes will\n",
      " |          be included as columns in the file output.\n",
      " |      engine_kwargs : dict[str, Any] or None, default None\n",
      " |          Additional keyword arguments passed to :func:`pyarrow.orc.write_table`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bytes if no path argument is provided else None\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      NotImplementedError\n",
      " |          Dtype of one or more columns is category, unsigned integers, interval,\n",
      " |          period or sparse.\n",
      " |      ValueError\n",
      " |          engine is not pyarrow.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_orc : Read a ORC file.\n",
      " |      DataFrame.to_parquet : Write a parquet file.\n",
      " |      DataFrame.to_csv : Write a csv file.\n",
      " |      DataFrame.to_sql : Write to a sql table.\n",
      " |      DataFrame.to_hdf : Write to hdf.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Before using this function you should read the :ref:`user guide about\n",
      " |        ORC <io.orc>` and :ref:`install optional dependencies <install.warn_orc>`.\n",
      " |      * This function requires `pyarrow <https://arrow.apache.org/docs/python/>`_\n",
      " |        library.\n",
      " |      * For supported dtypes please refer to `supported ORC features in Arrow\n",
      " |        <https://arrow.apache.org/docs/cpp/orc.html#data-types>`__.\n",
      " |      * Currently timezones in datetime columns are not preserved when a\n",
      " |        dataframe is converted into ORC files.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [4, 3]})\n",
      " |      >>> df.to_orc('df.orc')  # doctest: +SKIP\n",
      " |      >>> pd.read_orc('df.orc')  # doctest: +SKIP\n",
      " |         col1  col2\n",
      " |      0     1     4\n",
      " |      1     2     3\n",
      " |      \n",
      " |      If you want to get a buffer to the orc content you can write it to io.BytesIO\n",
      " |      >>> import io\n",
      " |      >>> b = io.BytesIO(df.to_orc())  # doctest: +SKIP\n",
      " |      >>> b.seek(0)  # doctest: +SKIP\n",
      " |      0\n",
      " |      >>> content = b.read()  # doctest: +SKIP\n",
      " |  \n",
      " |  to_parquet(self, path: 'FilePath | WriteBuffer[bytes] | None' = None, engine: 'str' = 'auto', compression: 'str | None' = 'snappy', index: 'bool | None' = None, partition_cols: 'list[str] | None' = None, storage_options: 'StorageOptions' = None, **kwargs) -> 'bytes | None'\n",
      " |      Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      This function writes the dataframe as a `parquet file\n",
      " |      <https://parquet.apache.org/>`_. You can choose different parquet\n",
      " |      backends, and have the option of compression. See\n",
      " |      :ref:`the user guide <io.parquet>` for more details.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a binary ``write()`` function. If None, the result is\n",
      " |          returned as bytes. If a string or path, it will be used as Root Directory\n",
      " |          path when writing a partitioned dataset.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |          Previously this was \"fname\"\n",
      " |      \n",
      " |      engine : {'auto', 'pyarrow', 'fastparquet'}, default 'auto'\n",
      " |          Parquet library to use. If 'auto', then the option\n",
      " |          ``io.parquet.engine`` is used. The default ``io.parquet.engine``\n",
      " |          behavior is to try 'pyarrow', falling back to 'fastparquet' if\n",
      " |          'pyarrow' is unavailable.\n",
      " |      compression : {'snappy', 'gzip', 'brotli', None}, default 'snappy'\n",
      " |          Name of the compression to use. Use ``None`` for no compression.\n",
      " |      index : bool, default None\n",
      " |          If ``True``, include the dataframe's index(es) in the file output.\n",
      " |          If ``False``, they will not be written to the file.\n",
      " |          If ``None``, similar to ``True`` the dataframe's index(es)\n",
      " |          will be saved. However, instead of being saved as values,\n",
      " |          the RangeIndex will be stored as a range in the metadata so it\n",
      " |          doesn't require much space and is faster. Other indexes will\n",
      " |          be included as columns in the file output.\n",
      " |      partition_cols : list, optional, default None\n",
      " |          Column names by which to partition the dataset.\n",
      " |          Columns are partitioned in the order they are given.\n",
      " |          Must be None if path is not a string.\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional arguments passed to the parquet library. See\n",
      " |          :ref:`pandas io <io.parquet>` for more details.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bytes if no path argument is provided else None\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_parquet : Read a parquet file.\n",
      " |      DataFrame.to_orc : Write an orc file.\n",
      " |      DataFrame.to_csv : Write a csv file.\n",
      " |      DataFrame.to_sql : Write to a sql table.\n",
      " |      DataFrame.to_hdf : Write to hdf.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function requires either the `fastparquet\n",
      " |      <https://pypi.org/project/fastparquet>`_ or `pyarrow\n",
      " |      <https://arrow.apache.org/docs/python/>`_ library.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.to_parquet('df.parquet.gzip',\n",
      " |      ...               compression='gzip')  # doctest: +SKIP\n",
      " |      >>> pd.read_parquet('df.parquet.gzip')  # doctest: +SKIP\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |      \n",
      " |      If you want to get a buffer to the parquet content you can use a io.BytesIO\n",
      " |      object, as long as you don't use partition_cols, which creates multiple files.\n",
      " |      \n",
      " |      >>> import io\n",
      " |      >>> f = io.BytesIO()\n",
      " |      >>> df.to_parquet(f)\n",
      " |      >>> f.seek(0)\n",
      " |      0\n",
      " |      >>> content = f.read()\n",
      " |  \n",
      " |  to_period(self, freq: 'Frequency | None' = None, axis: 'Axis' = 0, copy: 'bool | None' = None) -> 'DataFrame'\n",
      " |      Convert DataFrame from DatetimeIndex to PeriodIndex.\n",
      " |      \n",
      " |      Convert DataFrame from DatetimeIndex to PeriodIndex with desired\n",
      " |      frequency (inferred from index if not passed).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str, default\n",
      " |          Frequency of the PeriodIndex.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to convert (the index by default).\n",
      " |      copy : bool, default True\n",
      " |          If False then underlying input data is not copied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The DataFrame has a PeriodIndex.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.to_datetime(\n",
      " |      ...     [\n",
      " |      ...         \"2001-03-31 00:00:00\",\n",
      " |      ...         \"2002-05-31 00:00:00\",\n",
      " |      ...         \"2003-08-31 00:00:00\",\n",
      " |      ...     ]\n",
      " |      ... )\n",
      " |      \n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['2001-03-31', '2002-05-31', '2003-08-31'],\n",
      " |      dtype='datetime64[ns]', freq=None)\n",
      " |      \n",
      " |      >>> idx.to_period(\"M\")\n",
      " |      PeriodIndex(['2001-03', '2002-05', '2003-08'], dtype='period[M]')\n",
      " |      \n",
      " |      For the yearly frequency\n",
      " |      \n",
      " |      >>> idx.to_period(\"Y\")\n",
      " |      PeriodIndex(['2001', '2002', '2003'], dtype='period[A-DEC]')\n",
      " |  \n",
      " |  to_records(self, index: 'bool' = True, column_dtypes=None, index_dtypes=None) -> 'np.recarray'\n",
      " |      Convert DataFrame to a NumPy record array.\n",
      " |      \n",
      " |      Index will be included as the first field of the record array if\n",
      " |      requested.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Include index in resulting record array, stored in 'index'\n",
      " |          field or using the index label, if set.\n",
      " |      column_dtypes : str, type, dict, default None\n",
      " |          If a string or type, the data type to store all columns. If\n",
      " |          a dictionary, a mapping of column names and indices (zero-indexed)\n",
      " |          to specific data types.\n",
      " |      index_dtypes : str, type, dict, default None\n",
      " |          If a string or type, the data type to store all index levels. If\n",
      " |          a dictionary, a mapping of index level names and indices\n",
      " |          (zero-indexed) to specific data types.\n",
      " |      \n",
      " |          This mapping is applied only if `index=True`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.recarray\n",
      " |          NumPy ndarray with the DataFrame labels as fields and each row\n",
      " |          of the DataFrame as entries.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_records: Convert structured or record ndarray\n",
      " |          to DataFrame.\n",
      " |      numpy.recarray: An ndarray that allows field access using\n",
      " |          attributes, analogous to typed columns in a\n",
      " |          spreadsheet.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2], 'B': [0.5, 0.75]},\n",
      " |      ...                   index=['a', 'b'])\n",
      " |      >>> df\n",
      " |         A     B\n",
      " |      a  1  0.50\n",
      " |      b  2  0.75\n",
      " |      >>> df.to_records()\n",
      " |      rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
      " |                dtype=[('index', 'O'), ('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      If the DataFrame index has no label then the recarray field name\n",
      " |      is set to 'index'. If the index has a label then this is used as the\n",
      " |      field name:\n",
      " |      \n",
      " |      >>> df.index = df.index.rename(\"I\")\n",
      " |      >>> df.to_records()\n",
      " |      rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
      " |                dtype=[('I', 'O'), ('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      The index can be excluded from the record array:\n",
      " |      \n",
      " |      >>> df.to_records(index=False)\n",
      " |      rec.array([(1, 0.5 ), (2, 0.75)],\n",
      " |                dtype=[('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      Data types can be specified for the columns:\n",
      " |      \n",
      " |      >>> df.to_records(column_dtypes={\"A\": \"int32\"})\n",
      " |      rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
      " |                dtype=[('I', 'O'), ('A', '<i4'), ('B', '<f8')])\n",
      " |      \n",
      " |      As well as for the index:\n",
      " |      \n",
      " |      >>> df.to_records(index_dtypes=\"<S2\")\n",
      " |      rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],\n",
      " |                dtype=[('I', 'S2'), ('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      >>> index_dtypes = f\"<S{df.index.str.len().max()}\"\n",
      " |      >>> df.to_records(index_dtypes=index_dtypes)\n",
      " |      rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],\n",
      " |                dtype=[('I', 'S1'), ('A', '<i8'), ('B', '<f8')])\n",
      " |  \n",
      " |  to_stata(self, path: 'FilePath | WriteBuffer[bytes]', *, convert_dates: 'dict[Hashable, str] | None' = None, write_index: 'bool' = True, byteorder: 'str | None' = None, time_stamp: 'datetime.datetime | None' = None, data_label: 'str | None' = None, variable_labels: 'dict[Hashable, str] | None' = None, version: 'int | None' = 114, convert_strl: 'Sequence[Hashable] | None' = None, compression: 'CompressionOptions' = 'infer', storage_options: 'StorageOptions' = None, value_labels: 'dict[Hashable, dict[float, str]] | None' = None) -> 'None'\n",
      " |      Export DataFrame object to Stata dta format.\n",
      " |      \n",
      " |      Writes the DataFrame to a Stata dataset file.\n",
      " |      \"dta\" files contain a Stata dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, path object, or buffer\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a binary ``write()`` function.\n",
      " |      \n",
      " |      convert_dates : dict\n",
      " |          Dictionary mapping columns containing datetime types to stata\n",
      " |          internal format to use when writing the dates. Options are 'tc',\n",
      " |          'td', 'tm', 'tw', 'th', 'tq', 'ty'. Column can be either an integer\n",
      " |          or a name. Datetime columns that do not have a conversion type\n",
      " |          specified will be converted to 'tc'. Raises NotImplementedError if\n",
      " |          a datetime column has timezone information.\n",
      " |      write_index : bool\n",
      " |          Write the index to Stata dataset.\n",
      " |      byteorder : str\n",
      " |          Can be \">\", \"<\", \"little\", or \"big\". default is `sys.byteorder`.\n",
      " |      time_stamp : datetime\n",
      " |          A datetime to use as file creation date.  Default is the current\n",
      " |          time.\n",
      " |      data_label : str, optional\n",
      " |          A label for the data set.  Must be 80 characters or smaller.\n",
      " |      variable_labels : dict\n",
      " |          Dictionary containing columns as keys and variable labels as\n",
      " |          values. Each label must be 80 characters or smaller.\n",
      " |      version : {114, 117, 118, 119, None}, default 114\n",
      " |          Version to use in the output dta file. Set to None to let pandas\n",
      " |          decide between 118 or 119 formats depending on the number of\n",
      " |          columns in the frame. Version 114 can be read by Stata 10 and\n",
      " |          later. Version 117 can be read by Stata 13 or later. Version 118\n",
      " |          is supported in Stata 14 and later. Version 119 is supported in\n",
      " |          Stata 15 and later. Version 114 limits string variables to 244\n",
      " |          characters or fewer while versions 117 and later allow strings\n",
      " |          with lengths up to 2,000,000 characters. Versions 118 and 119\n",
      " |          support Unicode characters, and version 119 supports more than\n",
      " |          32,767 variables.\n",
      " |      \n",
      " |          Version 119 should usually only be used when the number of\n",
      " |          variables exceeds the capacity of dta format 118. Exporting\n",
      " |          smaller datasets in format 119 may have unintended consequences,\n",
      " |          and, as of November 2020, Stata SE cannot read version 119 files.\n",
      " |      \n",
      " |      convert_strl : list, optional\n",
      " |          List of column names to convert to string columns to Stata StrL\n",
      " |          format. Only available if version is 117.  Storing strings in the\n",
      " |          StrL format can produce smaller dta files if strings have more than\n",
      " |          8 characters and values are repeated.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'tar'``} and other\n",
      " |          key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |              Added support for `.tar` files.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0 Zstandard support.\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      value_labels : dict of dicts\n",
      " |          Dictionary containing columns as keys and dictionaries of column value\n",
      " |          to labels as values. Labels for a single variable must be 32,000\n",
      " |          characters or smaller.\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      NotImplementedError\n",
      " |          * If datetimes contain timezone information\n",
      " |          * Column dtype is not representable in Stata\n",
      " |      ValueError\n",
      " |          * Columns listed in convert_dates are neither datetime64[ns]\n",
      " |            or datetime.datetime\n",
      " |          * Column listed in convert_dates is not in DataFrame\n",
      " |          * Categorical label contains more than 32,000 characters\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_stata : Import Stata data files.\n",
      " |      io.stata.StataWriter : Low-level writer for Stata data files.\n",
      " |      io.stata.StataWriter117 : Low-level writer for version 117 files.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['falcon', 'parrot', 'falcon',\n",
      " |      ...                               'parrot'],\n",
      " |      ...                    'speed': [350, 18, 361, 15]})\n",
      " |      >>> df.to_stata('animals.dta')  # doctest: +SKIP\n",
      " |  \n",
      " |  to_string(self, buf: 'FilePath | WriteBuffer[str] | None' = None, columns: 'Sequence[str] | None' = None, col_space: 'int | list[int] | dict[Hashable, int] | None' = None, header: 'bool | Sequence[str]' = True, index: 'bool' = True, na_rep: 'str' = 'NaN', formatters: 'fmt.FormattersType | None' = None, float_format: 'fmt.FloatFormatType | None' = None, sparsify: 'bool | None' = None, index_names: 'bool' = True, justify: 'str | None' = None, max_rows: 'int | None' = None, max_cols: 'int | None' = None, show_dimensions: 'bool' = False, decimal: 'str' = '.', line_width: 'int | None' = None, min_rows: 'int | None' = None, max_colwidth: 'int | None' = None, encoding: 'str | None' = None) -> 'str | None'\n",
      " |      Render a DataFrame to a console-friendly tabular output.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : sequence, optional, default None\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      col_space : int, list or dict of int, optional\n",
      " |          The minimum width of each column. If a list of ints is given every integers corresponds with one column. If a dict is given, the key references the column, while the value defines the space to use..\n",
      " |      header : bool or sequence of str, optional\n",
      " |          Write out the column names. If a list of strings is given, it is assumed to be aliases for the column names.\n",
      " |      index : bool, optional, default True\n",
      " |          Whether to print index (row) labels.\n",
      " |      na_rep : str, optional, default 'NaN'\n",
      " |          String representation of ``NaN`` to use.\n",
      " |      formatters : list, tuple or dict of one-param. functions, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name.\n",
      " |          The result of each function must be a unicode string.\n",
      " |          List/tuple must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function, optional, default None\n",
      " |          Formatter function to apply to columns' elements if they are\n",
      " |          floats. This function must return a unicode string and will be\n",
      " |          applied only to the non-``NaN`` elements, with ``NaN`` being\n",
      " |          handled by ``na_rep``.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |      sparsify : bool, optional, default True\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row.\n",
      " |      index_names : bool, optional, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      justify : str, default None\n",
      " |          How to justify the column labels. If None uses the option from\n",
      " |          the print configuration (controlled by set_option), 'right' out\n",
      " |          of the box. Valid values are\n",
      " |      \n",
      " |          * left\n",
      " |          * right\n",
      " |          * center\n",
      " |          * justify\n",
      " |          * justify-all\n",
      " |          * start\n",
      " |          * end\n",
      " |          * inherit\n",
      " |          * match-parent\n",
      " |          * initial\n",
      " |          * unset.\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to display in the console.\n",
      " |      max_cols : int, optional\n",
      " |          Maximum number of columns to display in the console.\n",
      " |      show_dimensions : bool, default False\n",
      " |          Display DataFrame dimensions (number of rows by number of columns).\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      \n",
      " |      line_width : int, optional\n",
      " |          Width to wrap a line in characters.\n",
      " |      min_rows : int, optional\n",
      " |          The number of rows to display in the console in a truncated repr\n",
      " |          (when number of rows is above `max_rows`).\n",
      " |      max_colwidth : int, optional\n",
      " |          Max width to truncate each column in characters. By default, no limit.\n",
      " |      encoding : str, default \"utf-8\"\n",
      " |          Set character encoding.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or None\n",
      " |          If buf is None, returns the result as a string. Otherwise returns\n",
      " |          None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_html : Convert DataFrame to HTML.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> d = {'col1': [1, 2, 3], 'col2': [4, 5, 6]}\n",
      " |      >>> df = pd.DataFrame(d)\n",
      " |      >>> print(df.to_string())\n",
      " |         col1  col2\n",
      " |      0     1     4\n",
      " |      1     2     5\n",
      " |      2     3     6\n",
      " |  \n",
      " |  to_timestamp(self, freq: 'Frequency | None' = None, how: 'str' = 'start', axis: 'Axis' = 0, copy: 'bool | None' = None) -> 'DataFrame'\n",
      " |      Cast to DatetimeIndex of timestamps, at *beginning* of period.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str, default frequency of PeriodIndex\n",
      " |          Desired frequency.\n",
      " |      how : {'s', 'e', 'start', 'end'}\n",
      " |          Convention for converting period to timestamp; start of period\n",
      " |          vs. end.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to convert (the index by default).\n",
      " |      copy : bool, default True\n",
      " |          If False then underlying input data is not copied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The DataFrame has a DatetimeIndex.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.PeriodIndex(['2023', '2024'], freq='Y')\n",
      " |      >>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df1 = pd.DataFrame(data=d, index=idx)\n",
      " |      >>> df1\n",
      " |            col1   col2\n",
      " |      2023     1      3\n",
      " |      2024     2      4\n",
      " |      \n",
      " |      The resulting timestamps will be at the beginning of the year in this case\n",
      " |      \n",
      " |      >>> df1 = df1.to_timestamp()\n",
      " |      >>> df1\n",
      " |                  col1   col2\n",
      " |      2023-01-01     1      3\n",
      " |      2024-01-01     2      4\n",
      " |      >>> df1.index\n",
      " |      DatetimeIndex(['2023-01-01', '2024-01-01'], dtype='datetime64[ns]', freq=None)\n",
      " |      \n",
      " |      Using `freq` which is the offset that the Timestamps will have\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame(data=d, index=idx)\n",
      " |      >>> df2 = df2.to_timestamp(freq='M')\n",
      " |      >>> df2\n",
      " |                  col1   col2\n",
      " |      2023-01-31     1      3\n",
      " |      2024-01-31     2      4\n",
      " |      >>> df2.index\n",
      " |      DatetimeIndex(['2023-01-31', '2024-01-31'], dtype='datetime64[ns]', freq=None)\n",
      " |  \n",
      " |  to_xml(self, path_or_buffer: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, index: 'bool' = True, root_name: 'str | None' = 'data', row_name: 'str | None' = 'row', na_rep: 'str | None' = None, attr_cols: 'list[str] | None' = None, elem_cols: 'list[str] | None' = None, namespaces: 'dict[str | None, str] | None' = None, prefix: 'str | None' = None, encoding: 'str' = 'utf-8', xml_declaration: 'bool | None' = True, pretty_print: 'bool | None' = True, parser: 'str | None' = 'lxml', stylesheet: 'FilePath | ReadBuffer[str] | ReadBuffer[bytes] | None' = None, compression: 'CompressionOptions' = 'infer', storage_options: 'StorageOptions' = None) -> 'str | None'\n",
      " |      Render a DataFrame to an XML document.\n",
      " |      \n",
      " |      .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buffer : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a ``write()`` function. If None, the result is returned\n",
      " |          as a string.\n",
      " |      index : bool, default True\n",
      " |          Whether to include index in XML document.\n",
      " |      root_name : str, default 'data'\n",
      " |          The name of root element in XML document.\n",
      " |      row_name : str, default 'row'\n",
      " |          The name of row element in XML document.\n",
      " |      na_rep : str, optional\n",
      " |          Missing data representation.\n",
      " |      attr_cols : list-like, optional\n",
      " |          List of columns to write as attributes in row element.\n",
      " |          Hierarchical columns will be flattened with underscore\n",
      " |          delimiting the different levels.\n",
      " |      elem_cols : list-like, optional\n",
      " |          List of columns to write as children in row element. By default,\n",
      " |          all columns output as children of row element. Hierarchical\n",
      " |          columns will be flattened with underscore delimiting the\n",
      " |          different levels.\n",
      " |      namespaces : dict, optional\n",
      " |          All namespaces to be defined in root element. Keys of dict\n",
      " |          should be prefix names and values of dict corresponding URIs.\n",
      " |          Default namespaces should be given empty string key. For\n",
      " |          example, ::\n",
      " |      \n",
      " |              namespaces = {\"\": \"https://example.com\"}\n",
      " |      \n",
      " |      prefix : str, optional\n",
      " |          Namespace prefix to be used for every element and/or attribute\n",
      " |          in document. This should be one of the keys in ``namespaces``\n",
      " |          dict.\n",
      " |      encoding : str, default 'utf-8'\n",
      " |          Encoding of the resulting document.\n",
      " |      xml_declaration : bool, default True\n",
      " |          Whether to include the XML declaration at start of document.\n",
      " |      pretty_print : bool, default True\n",
      " |          Whether output should be pretty printed with indentation and\n",
      " |          line breaks.\n",
      " |      parser : {'lxml','etree'}, default 'lxml'\n",
      " |          Parser module to use for building of tree. Only 'lxml' and\n",
      " |          'etree' are supported. With 'lxml', the ability to use XSLT\n",
      " |          stylesheet is supported.\n",
      " |      stylesheet : str, path object or file-like object, optional\n",
      " |          A URL, file-like object, or a raw string containing an XSLT\n",
      " |          script used to transform the raw XML output. Script should use\n",
      " |          layout of elements and attributes from original output. This\n",
      " |          argument requires ``lxml`` to be installed. Only XSLT 1.0\n",
      " |          scripts and not later versions is currently supported.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path_or_buffer' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'tar'``} and other\n",
      " |          key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |              Added support for `.tar` files.\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0 Zstandard support.\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If ``io`` is None, returns the resulting XML format as a\n",
      " |          string. Otherwise returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_json : Convert the pandas object to a JSON string.\n",
      " |      to_html : Convert DataFrame to a html.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'shape': ['square', 'circle', 'triangle'],\n",
      " |      ...                    'degrees': [360, 360, 180],\n",
      " |      ...                    'sides': [4, np.nan, 3]})\n",
      " |      \n",
      " |      >>> df.to_xml()  # doctest: +SKIP\n",
      " |      <?xml version='1.0' encoding='utf-8'?>\n",
      " |      <data>\n",
      " |        <row>\n",
      " |          <index>0</index>\n",
      " |          <shape>square</shape>\n",
      " |          <degrees>360</degrees>\n",
      " |          <sides>4.0</sides>\n",
      " |        </row>\n",
      " |        <row>\n",
      " |          <index>1</index>\n",
      " |          <shape>circle</shape>\n",
      " |          <degrees>360</degrees>\n",
      " |          <sides/>\n",
      " |        </row>\n",
      " |        <row>\n",
      " |          <index>2</index>\n",
      " |          <shape>triangle</shape>\n",
      " |          <degrees>180</degrees>\n",
      " |          <sides>3.0</sides>\n",
      " |        </row>\n",
      " |      </data>\n",
      " |      \n",
      " |      >>> df.to_xml(attr_cols=[\n",
      " |      ...           'index', 'shape', 'degrees', 'sides'\n",
      " |      ...           ])  # doctest: +SKIP\n",
      " |      <?xml version='1.0' encoding='utf-8'?>\n",
      " |      <data>\n",
      " |        <row index=\"0\" shape=\"square\" degrees=\"360\" sides=\"4.0\"/>\n",
      " |        <row index=\"1\" shape=\"circle\" degrees=\"360\"/>\n",
      " |        <row index=\"2\" shape=\"triangle\" degrees=\"180\" sides=\"3.0\"/>\n",
      " |      </data>\n",
      " |      \n",
      " |      >>> df.to_xml(namespaces={\"doc\": \"https://example.com\"},\n",
      " |      ...           prefix=\"doc\")  # doctest: +SKIP\n",
      " |      <?xml version='1.0' encoding='utf-8'?>\n",
      " |      <doc:data xmlns:doc=\"https://example.com\">\n",
      " |        <doc:row>\n",
      " |          <doc:index>0</doc:index>\n",
      " |          <doc:shape>square</doc:shape>\n",
      " |          <doc:degrees>360</doc:degrees>\n",
      " |          <doc:sides>4.0</doc:sides>\n",
      " |        </doc:row>\n",
      " |        <doc:row>\n",
      " |          <doc:index>1</doc:index>\n",
      " |          <doc:shape>circle</doc:shape>\n",
      " |          <doc:degrees>360</doc:degrees>\n",
      " |          <doc:sides/>\n",
      " |        </doc:row>\n",
      " |        <doc:row>\n",
      " |          <doc:index>2</doc:index>\n",
      " |          <doc:shape>triangle</doc:shape>\n",
      " |          <doc:degrees>180</doc:degrees>\n",
      " |          <doc:sides>3.0</doc:sides>\n",
      " |        </doc:row>\n",
      " |      </doc:data>\n",
      " |  \n",
      " |  transform(self, func: 'AggFuncType', axis: 'Axis' = 0, *args, **kwargs) -> 'DataFrame'\n",
      " |      Call ``func`` on self producing a DataFrame with the same axis shape as self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list-like or dict-like\n",
      " |          Function to use for transforming the data. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply. If func\n",
      " |          is both list-like and dict-like, dict-like behavior takes precedence.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list-like of functions and/or function names, e.g. ``[np.exp, 'sqrt']``\n",
      " |          - dict-like of axis labels -> functions, function names or list-like of such.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |              If 0 or 'index': apply function to each column.\n",
      " |              If 1 or 'columns': apply function to each row.\n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A DataFrame that must have the same length as self.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError : If the returned DataFrame has a different length than self.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.agg : Only perform aggregating type operations.\n",
      " |      DataFrame.apply : Invoke function on a DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(3), 'B': range(1, 4)})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  1  2\n",
      " |      2  2  3\n",
      " |      >>> df.transform(lambda x: x + 1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  2  3\n",
      " |      2  3  4\n",
      " |      \n",
      " |      Even though the resulting DataFrame must have the same length as the\n",
      " |      input DataFrame, it is possible to provide several input functions:\n",
      " |      \n",
      " |      >>> s = pd.Series(range(3))\n",
      " |      >>> s\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      dtype: int64\n",
      " |      >>> s.transform([np.sqrt, np.exp])\n",
      " |             sqrt        exp\n",
      " |      0  0.000000   1.000000\n",
      " |      1  1.000000   2.718282\n",
      " |      2  1.414214   7.389056\n",
      " |      \n",
      " |      You can call transform on a GroupBy object:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     \"Date\": [\n",
      " |      ...         \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\",\n",
      " |      ...         \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\"],\n",
      " |      ...     \"Data\": [5, 8, 6, 1, 50, 100, 60, 120],\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |               Date  Data\n",
      " |      0  2015-05-08     5\n",
      " |      1  2015-05-07     8\n",
      " |      2  2015-05-06     6\n",
      " |      3  2015-05-05     1\n",
      " |      4  2015-05-08    50\n",
      " |      5  2015-05-07   100\n",
      " |      6  2015-05-06    60\n",
      " |      7  2015-05-05   120\n",
      " |      >>> df.groupby('Date')['Data'].transform('sum')\n",
      " |      0     55\n",
      " |      1    108\n",
      " |      2     66\n",
      " |      3    121\n",
      " |      4     55\n",
      " |      5    108\n",
      " |      6     66\n",
      " |      7    121\n",
      " |      Name: Data, dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     \"c\": [1, 1, 1, 2, 2, 2, 2],\n",
      " |      ...     \"type\": [\"m\", \"n\", \"o\", \"m\", \"m\", \"n\", \"n\"]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |         c type\n",
      " |      0  1    m\n",
      " |      1  1    n\n",
      " |      2  1    o\n",
      " |      3  2    m\n",
      " |      4  2    m\n",
      " |      5  2    n\n",
      " |      6  2    n\n",
      " |      >>> df['size'] = df.groupby('c')['type'].transform(len)\n",
      " |      >>> df\n",
      " |         c type size\n",
      " |      0  1    m    3\n",
      " |      1  1    n    3\n",
      " |      2  1    o    3\n",
      " |      3  2    m    4\n",
      " |      4  2    m    4\n",
      " |      5  2    n    4\n",
      " |      6  2    n    4\n",
      " |  \n",
      " |  transpose(self, *args, copy: 'bool' = False) -> 'DataFrame'\n",
      " |      Transpose index and columns.\n",
      " |      \n",
      " |      Reflect the DataFrame over its main diagonal by writing rows as columns\n",
      " |      and vice-versa. The property :attr:`.T` is an accessor to the method\n",
      " |      :meth:`transpose`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      *args : tuple, optional\n",
      " |          Accepted for compatibility with NumPy.\n",
      " |      copy : bool, default False\n",
      " |          Whether to copy the data after transposing, even for DataFrames\n",
      " |          with a single dtype.\n",
      " |      \n",
      " |          Note that a copy is always required for mixed dtype DataFrames,\n",
      " |          or for DataFrames with any extension types.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The transposed DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.transpose : Permute the dimensions of a given array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Transposing a DataFrame with mixed dtypes will result in a homogeneous\n",
      " |      DataFrame with the `object` dtype. In such a case, a copy of the data\n",
      " |      is always made.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Square DataFrame with homogeneous dtype**\n",
      " |      \n",
      " |      >>> d1 = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df1 = pd.DataFrame(data=d1)\n",
      " |      >>> df1\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |      \n",
      " |      >>> df1_transposed = df1.T  # or df1.transpose()\n",
      " |      >>> df1_transposed\n",
      " |            0  1\n",
      " |      col1  1  2\n",
      " |      col2  3  4\n",
      " |      \n",
      " |      When the dtype is homogeneous in the original DataFrame, we get a\n",
      " |      transposed DataFrame with the same dtype:\n",
      " |      \n",
      " |      >>> df1.dtypes\n",
      " |      col1    int64\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      >>> df1_transposed.dtypes\n",
      " |      0    int64\n",
      " |      1    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      **Non-square DataFrame with mixed dtypes**\n",
      " |      \n",
      " |      >>> d2 = {'name': ['Alice', 'Bob'],\n",
      " |      ...       'score': [9.5, 8],\n",
      " |      ...       'employed': [False, True],\n",
      " |      ...       'kids': [0, 0]}\n",
      " |      >>> df2 = pd.DataFrame(data=d2)\n",
      " |      >>> df2\n",
      " |          name  score  employed  kids\n",
      " |      0  Alice    9.5     False     0\n",
      " |      1    Bob    8.0      True     0\n",
      " |      \n",
      " |      >>> df2_transposed = df2.T  # or df2.transpose()\n",
      " |      >>> df2_transposed\n",
      " |                    0     1\n",
      " |      name      Alice   Bob\n",
      " |      score       9.5   8.0\n",
      " |      employed  False  True\n",
      " |      kids          0     0\n",
      " |      \n",
      " |      When the DataFrame has mixed dtypes, we get a transposed DataFrame with\n",
      " |      the `object` dtype:\n",
      " |      \n",
      " |      >>> df2.dtypes\n",
      " |      name         object\n",
      " |      score       float64\n",
      " |      employed       bool\n",
      " |      kids          int64\n",
      " |      dtype: object\n",
      " |      >>> df2_transposed.dtypes\n",
      " |      0    object\n",
      " |      1    object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  truediv(self, other, axis: 'Axis' = 'columns', level=None, fill_value=None)\n",
      " |      Get Floating division of dataframe and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe / other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rtruediv`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns.\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a dictionary by axis.\n",
      " |      \n",
      " |      >>> df.mul({'angles': 0, 'degrees': 2})\n",
      " |                  angles  degrees\n",
      " |      circle           0      720\n",
      " |      triangle         0      360\n",
      " |      rectangle        0      720\n",
      " |      \n",
      " |      >>> df.mul({'circle': 0, 'triangle': 2, 'rectangle': 3}, axis='index')\n",
      " |                  angles  degrees\n",
      " |      circle           0        0\n",
      " |      triangle         6      360\n",
      " |      rectangle       12     1080\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  unstack(self, level: 'Level' = -1, fill_value=None)\n",
      " |      Pivot a level of the (necessarily hierarchical) index labels.\n",
      " |      \n",
      " |      Returns a DataFrame having a new level of column labels whose inner-most level\n",
      " |      consists of the pivoted index labels.\n",
      " |      \n",
      " |      If the index is not a MultiIndex, the output will be a Series\n",
      " |      (the analogue of stack when the columns are not a MultiIndex).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, or list of these, default -1 (last level)\n",
      " |          Level(s) of index to unstack, can pass level name.\n",
      " |      fill_value : int, str or dict\n",
      " |          Replace NaN with this value if the unstack produces missing values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pivot : Pivot a table based on column values.\n",
      " |      DataFrame.stack : Pivot a level of the column labels (inverse operation\n",
      " |          from `unstack`).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Reference :ref:`the user guide <reshaping.stacking>` for more examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),\n",
      " |      ...                                    ('two', 'a'), ('two', 'b')])\n",
      " |      >>> s = pd.Series(np.arange(1.0, 5.0), index=index)\n",
      " |      >>> s\n",
      " |      one  a   1.0\n",
      " |           b   2.0\n",
      " |      two  a   3.0\n",
      " |           b   4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.unstack(level=-1)\n",
      " |           a   b\n",
      " |      one  1.0  2.0\n",
      " |      two  3.0  4.0\n",
      " |      \n",
      " |      >>> s.unstack(level=0)\n",
      " |         one  two\n",
      " |      a  1.0   3.0\n",
      " |      b  2.0   4.0\n",
      " |      \n",
      " |      >>> df = s.unstack(level=0)\n",
      " |      >>> df.unstack()\n",
      " |      one  a  1.0\n",
      " |           b  2.0\n",
      " |      two  a  3.0\n",
      " |           b  4.0\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  update(self, other, join: 'str' = 'left', overwrite: 'bool' = True, filter_func=None, errors: 'str' = 'ignore') -> 'None'\n",
      " |      Modify in place using non-NA values from another DataFrame.\n",
      " |      \n",
      " |      Aligns on indices. There is no return value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, or object coercible into a DataFrame\n",
      " |          Should have at least one matching index/column label\n",
      " |          with the original DataFrame. If a Series is passed,\n",
      " |          its name attribute must be set, and that will be\n",
      " |          used as the column name to align with the original DataFrame.\n",
      " |      join : {'left'}, default 'left'\n",
      " |          Only left join is implemented, keeping the index and columns of the\n",
      " |          original object.\n",
      " |      overwrite : bool, default True\n",
      " |          How to handle non-NA values for overlapping keys:\n",
      " |      \n",
      " |          * True: overwrite original DataFrame's values\n",
      " |            with values from `other`.\n",
      " |          * False: only update values that are NA in\n",
      " |            the original DataFrame.\n",
      " |      \n",
      " |      filter_func : callable(1d-array) -> bool 1d-array, optional\n",
      " |          Can choose to replace values other than NA. Return True for values\n",
      " |          that should be updated.\n",
      " |      errors : {'raise', 'ignore'}, default 'ignore'\n",
      " |          If 'raise', will raise a ValueError if the DataFrame and `other`\n",
      " |          both contain non-NA data in the same place.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None\n",
      " |          This method directly changes calling object.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * When `errors='raise'` and there's overlapping non-NA data.\n",
      " |          * When `errors` is not either `'ignore'` or `'raise'`\n",
      " |      NotImplementedError\n",
      " |          * If `join != 'left'`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      dict.update : Similar method for dictionaries.\n",
      " |      DataFrame.merge : For column(s)-on-column(s) operations.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3],\n",
      " |      ...                    'B': [400, 500, 600]})\n",
      " |      >>> new_df = pd.DataFrame({'B': [4, 5, 6],\n",
      " |      ...                        'C': [7, 8, 9]})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      The DataFrame's length does not increase as a result of the update,\n",
      " |      only values at matching index/column labels are updated.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_df = pd.DataFrame({'B': ['d', 'e', 'f', 'g', 'h', 'i']})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  d\n",
      " |      1  b  e\n",
      " |      2  c  f\n",
      " |      \n",
      " |      For Series, its name attribute must be set.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_column = pd.Series(['d', 'e'], name='B', index=[0, 2])\n",
      " |      >>> df.update(new_column)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  d\n",
      " |      1  b  y\n",
      " |      2  c  e\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_df = pd.DataFrame({'B': ['d', 'e']}, index=[1, 2])\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  x\n",
      " |      1  b  d\n",
      " |      2  c  e\n",
      " |      \n",
      " |      If `other` contains NaNs the corresponding values are not updated\n",
      " |      in the original dataframe.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3],\n",
      " |      ...                    'B': [400, 500, 600]})\n",
      " |      >>> new_df = pd.DataFrame({'B': [4, np.nan, 6]})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A    B\n",
      " |      0  1    4\n",
      " |      1  2  500\n",
      " |      2  3    6\n",
      " |  \n",
      " |  value_counts(self, subset: 'Sequence[Hashable] | None' = None, normalize: 'bool' = False, sort: 'bool' = True, ascending: 'bool' = False, dropna: 'bool' = True) -> 'Series'\n",
      " |      Return a Series containing counts of unique rows in the DataFrame.\n",
      " |      \n",
      " |      .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : label or list of labels, optional\n",
      " |          Columns to use when counting unique combinations.\n",
      " |      normalize : bool, default False\n",
      " |          Return proportions rather than frequencies.\n",
      " |      sort : bool, default True\n",
      " |          Sort by frequencies.\n",
      " |      ascending : bool, default False\n",
      " |          Sort in ascending order.\n",
      " |      dropna : bool, default True\n",
      " |          Don’t include counts of rows that contain NA values.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.value_counts: Equivalent method on Series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The returned Series will have a MultiIndex with one level per input\n",
      " |      column but an Index (non-multi) for a single label. By default, rows\n",
      " |      that contain any NA values are omitted from the result. By default,\n",
      " |      the resulting Series will be in descending order so that the first\n",
      " |      element is the most frequently-occurring row.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4, 4, 6],\n",
      " |      ...                    'num_wings': [2, 0, 0, 0]},\n",
      " |      ...                   index=['falcon', 'dog', 'cat', 'ant'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings\n",
      " |      falcon         2          2\n",
      " |      dog            4          0\n",
      " |      cat            4          0\n",
      " |      ant            6          0\n",
      " |      \n",
      " |      >>> df.value_counts()\n",
      " |      num_legs  num_wings\n",
      " |      4         0            2\n",
      " |      2         2            1\n",
      " |      6         0            1\n",
      " |      Name: count, dtype: int64\n",
      " |      \n",
      " |      >>> df.value_counts(sort=False)\n",
      " |      num_legs  num_wings\n",
      " |      2         2            1\n",
      " |      4         0            2\n",
      " |      6         0            1\n",
      " |      Name: count, dtype: int64\n",
      " |      \n",
      " |      >>> df.value_counts(ascending=True)\n",
      " |      num_legs  num_wings\n",
      " |      2         2            1\n",
      " |      6         0            1\n",
      " |      4         0            2\n",
      " |      Name: count, dtype: int64\n",
      " |      \n",
      " |      >>> df.value_counts(normalize=True)\n",
      " |      num_legs  num_wings\n",
      " |      4         0            0.50\n",
      " |      2         2            0.25\n",
      " |      6         0            0.25\n",
      " |      Name: proportion, dtype: float64\n",
      " |      \n",
      " |      With `dropna` set to `False` we can also count rows with NA values.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'first_name': ['John', 'Anne', 'John', 'Beth'],\n",
      " |      ...                    'middle_name': ['Smith', pd.NA, pd.NA, 'Louise']})\n",
      " |      >>> df\n",
      " |        first_name middle_name\n",
      " |      0       John       Smith\n",
      " |      1       Anne        <NA>\n",
      " |      2       John        <NA>\n",
      " |      3       Beth      Louise\n",
      " |      \n",
      " |      >>> df.value_counts()\n",
      " |      first_name  middle_name\n",
      " |      Beth        Louise         1\n",
      " |      John        Smith          1\n",
      " |      Name: count, dtype: int64\n",
      " |      \n",
      " |      >>> df.value_counts(dropna=False)\n",
      " |      first_name  middle_name\n",
      " |      Anne        NaN            1\n",
      " |      Beth        Louise         1\n",
      " |      John        Smith          1\n",
      " |                  NaN            1\n",
      " |      Name: count, dtype: int64\n",
      " |      \n",
      " |      >>> df.value_counts(\"first_name\")\n",
      " |      first_name\n",
      " |      John    2\n",
      " |      Anne    1\n",
      " |      Beth    1\n",
      " |      Name: count, dtype: int64\n",
      " |  \n",
      " |  var(self, axis: 'Axis | None' = None, skipna: 'bool_t' = True, ddof: 'int' = 1, numeric_only: 'bool_t' = False, **kwargs)\n",
      " |      Return unbiased variance over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified) \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'person_id': [0, 1, 2, 3],\n",
      " |      ...                   'age': [21, 25, 62, 43],\n",
      " |      ...                   'height': [1.61, 1.87, 1.49, 2.01]}\n",
      " |      ...                  ).set_index('person_id')\n",
      " |      >>> df\n",
      " |                 age  height\n",
      " |      person_id\n",
      " |      0           21    1.61\n",
      " |      1           25    1.87\n",
      " |      2           62    1.49\n",
      " |      3           43    2.01\n",
      " |      \n",
      " |      >>> df.var()\n",
      " |      age       352.916667\n",
      " |      height      0.056367\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Alternatively, ``ddof=0`` can be set to normalize by N instead of N-1:\n",
      " |      \n",
      " |      >>> df.var(ddof=0)\n",
      " |      age       264.687500\n",
      " |      height      0.042275\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  where(self, cond, other=<no_default>, *, inplace: 'bool' = False, axis: 'Axis | None' = None, level: 'Level' = None) -> 'DataFrame | None'\n",
      " |      Replace values where the condition is False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : bool Series/DataFrame, array-like, or callable\n",
      " |          Where `cond` is True, keep the original value. Where\n",
      " |          False, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the Series/DataFrame and\n",
      " |          should return boolean Series/DataFrame or array. The callable must\n",
      " |          not change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      other : scalar, Series/DataFrame, or callable\n",
      " |          Entries where `cond` is False are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the Series/DataFrame and\n",
      " |          should return scalar or Series/DataFrame. The callable must not\n",
      " |          change input Series/DataFrame (though pandas doesn't check it).\n",
      " |          If not specified, entries will be filled with the corresponding\n",
      " |          NULL value (``np.nan`` for numpy dtypes, ``pd.NA`` for extension\n",
      " |          dtypes).\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      axis : int, default None\n",
      " |          Alignment axis if needed. For `Series` this parameter is\n",
      " |          unused and defaults to 0.\n",
      " |      level : int, default None\n",
      " |          Alignment level if needed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as caller or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.mask` : Return an object of same shape as\n",
      " |          self.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The where method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``True`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used. If the axis of ``other`` does not align with axis of\n",
      " |      ``cond`` Series/DataFrame, the misaligned index positions will be filled with\n",
      " |      False.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``where`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      The dtype of the object takes precedence. The fill value is casted to\n",
      " |      the object's dtype, if this can be done losslessly.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      dtype: float64\n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> t = pd.Series([True, False])\n",
      " |      >>> s.where(t, 99)\n",
      " |      0     0\n",
      " |      1    99\n",
      " |      2    99\n",
      " |      3    99\n",
      " |      4    99\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(t, 99)\n",
      " |      0    99\n",
      " |      1     1\n",
      " |      2    99\n",
      " |      3    99\n",
      " |      4    99\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(s > 1, 10)\n",
      " |      0     0\n",
      " |      1     1\n",
      " |      2    10\n",
      " |      3    10\n",
      " |      4    10\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  2  3\n",
      " |      2  4  5\n",
      " |      3  6  7\n",
      " |      4  8  9\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_dict(data: 'dict', orient: 'str' = 'columns', dtype: 'Dtype | None' = None, columns: 'Axes | None' = None) -> 'DataFrame' from builtins.type\n",
      " |      Construct DataFrame from dict of array-like or dicts.\n",
      " |      \n",
      " |      Creates DataFrame object from dictionary by columns or by index\n",
      " |      allowing dtype specification.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : dict\n",
      " |          Of the form {field : array-like} or {field : dict}.\n",
      " |      orient : {'columns', 'index', 'tight'}, default 'columns'\n",
      " |          The \"orientation\" of the data. If the keys of the passed dict\n",
      " |          should be the columns of the resulting DataFrame, pass 'columns'\n",
      " |          (default). Otherwise if the keys should be rows, pass 'index'.\n",
      " |          If 'tight', assume a dict with keys ['index', 'columns', 'data',\n",
      " |          'index_names', 'column_names'].\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |             'tight' as an allowed value for the ``orient`` argument\n",
      " |      \n",
      " |      dtype : dtype, default None\n",
      " |          Data type to force after DataFrame construction, otherwise infer.\n",
      " |      columns : list, default None\n",
      " |          Column labels to use when ``orient='index'``. Raises a ValueError\n",
      " |          if used with ``orient='columns'`` or ``orient='tight'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_records : DataFrame from structured ndarray, sequence\n",
      " |          of tuples or dicts, or DataFrame.\n",
      " |      DataFrame : DataFrame object creation using constructor.\n",
      " |      DataFrame.to_dict : Convert the DataFrame to a dictionary.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default the keys of the dict become the DataFrame columns:\n",
      " |      \n",
      " |      >>> data = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}\n",
      " |      >>> pd.DataFrame.from_dict(data)\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |      \n",
      " |      Specify ``orient='index'`` to create the DataFrame using dictionary\n",
      " |      keys as rows:\n",
      " |      \n",
      " |      >>> data = {'row_1': [3, 2, 1, 0], 'row_2': ['a', 'b', 'c', 'd']}\n",
      " |      >>> pd.DataFrame.from_dict(data, orient='index')\n",
      " |             0  1  2  3\n",
      " |      row_1  3  2  1  0\n",
      " |      row_2  a  b  c  d\n",
      " |      \n",
      " |      When using the 'index' orientation, the column names can be\n",
      " |      specified manually:\n",
      " |      \n",
      " |      >>> pd.DataFrame.from_dict(data, orient='index',\n",
      " |      ...                        columns=['A', 'B', 'C', 'D'])\n",
      " |             A  B  C  D\n",
      " |      row_1  3  2  1  0\n",
      " |      row_2  a  b  c  d\n",
      " |      \n",
      " |      Specify ``orient='tight'`` to create the DataFrame using a 'tight'\n",
      " |      format:\n",
      " |      \n",
      " |      >>> data = {'index': [('a', 'b'), ('a', 'c')],\n",
      " |      ...         'columns': [('x', 1), ('y', 2)],\n",
      " |      ...         'data': [[1, 3], [2, 4]],\n",
      " |      ...         'index_names': ['n1', 'n2'],\n",
      " |      ...         'column_names': ['z1', 'z2']}\n",
      " |      >>> pd.DataFrame.from_dict(data, orient='tight')\n",
      " |      z1     x  y\n",
      " |      z2     1  2\n",
      " |      n1 n2\n",
      " |      a  b   1  3\n",
      " |         c   2  4\n",
      " |  \n",
      " |  from_records(data, index=None, exclude=None, columns=None, coerce_float: 'bool' = False, nrows: 'int | None' = None) -> 'DataFrame' from builtins.type\n",
      " |      Convert structured or record ndarray to DataFrame.\n",
      " |      \n",
      " |      Creates a DataFrame object from a structured ndarray, sequence of\n",
      " |      tuples or dicts, or DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : structured ndarray, sequence of tuples or dicts, or DataFrame\n",
      " |          Structured input data.\n",
      " |      index : str, list of fields, array-like\n",
      " |          Field of array to use as the index, alternately a specific set of\n",
      " |          input labels to use.\n",
      " |      exclude : sequence, default None\n",
      " |          Columns or fields to exclude.\n",
      " |      columns : sequence, default None\n",
      " |          Column names to use. If the passed data do not have names\n",
      " |          associated with them, this argument provides names for the\n",
      " |          columns. Otherwise this argument indicates the order of the columns\n",
      " |          in the result (any names not found in the data will become all-NA\n",
      " |          columns).\n",
      " |      coerce_float : bool, default False\n",
      " |          Attempt to convert values of non-string, non-numeric objects (like\n",
      " |          decimal.Decimal) to floating point, useful for SQL result sets.\n",
      " |      nrows : int, default None\n",
      " |          Number of rows to read if data is an iterator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_dict : DataFrame from dict of array-like or dicts.\n",
      " |      DataFrame : DataFrame object creation using constructor.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Data can be provided as a structured ndarray:\n",
      " |      \n",
      " |      >>> data = np.array([(3, 'a'), (2, 'b'), (1, 'c'), (0, 'd')],\n",
      " |      ...                 dtype=[('col_1', 'i4'), ('col_2', 'U1')])\n",
      " |      >>> pd.DataFrame.from_records(data)\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |      \n",
      " |      Data can be provided as a list of dicts:\n",
      " |      \n",
      " |      >>> data = [{'col_1': 3, 'col_2': 'a'},\n",
      " |      ...         {'col_1': 2, 'col_2': 'b'},\n",
      " |      ...         {'col_1': 1, 'col_2': 'c'},\n",
      " |      ...         {'col_1': 0, 'col_2': 'd'}]\n",
      " |      >>> pd.DataFrame.from_records(data)\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |      \n",
      " |      Data can be provided as a list of tuples with corresponding columns:\n",
      " |      \n",
      " |      >>> data = [(3, 'a'), (2, 'b'), (1, 'c'), (0, 'd')]\n",
      " |      >>> pd.DataFrame.from_records(data, columns=['col_1', 'col_2'])\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  T\n",
      " |      The transpose of the DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The transposed DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.transpose : Transpose index and columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |      \n",
      " |      >>> df.T\n",
      " |            0  1\n",
      " |      col1  1  2\n",
      " |      col2  3  4\n",
      " |  \n",
      " |  axes\n",
      " |      Return a list representing the axes of the DataFrame.\n",
      " |      \n",
      " |      It has the row axis labels and column axis labels as the only members.\n",
      " |      They are returned in that order.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.axes\n",
      " |      [RangeIndex(start=0, stop=2, step=1), Index(['col1', 'col2'],\n",
      " |      dtype='object')]\n",
      " |  \n",
      " |  shape\n",
      " |      Return a tuple representing the dimensionality of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.shape : Tuple of array dimensions.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.shape\n",
      " |      (2, 2)\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4],\n",
      " |      ...                    'col3': [5, 6]})\n",
      " |      >>> df.shape\n",
      " |      (2, 3)\n",
      " |  \n",
      " |  style\n",
      " |      Returns a Styler object.\n",
      " |      \n",
      " |      Contains methods for building a styled HTML representation of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      io.formats.style.Styler : Helps style a DataFrame or Series according to the\n",
      " |          data with HTML and CSS.\n",
      " |  \n",
      " |  values\n",
      " |      Return a Numpy representation of the DataFrame.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         We recommend using :meth:`DataFrame.to_numpy` instead.\n",
      " |      \n",
      " |      Only the values in the DataFrame will be returned, the axes labels\n",
      " |      will be removed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The values of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_numpy : Recommended alternative to this method.\n",
      " |      DataFrame.index : Retrieve the index labels.\n",
      " |      DataFrame.columns : Retrieving the column names.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The dtype will be a lower-common-denominator dtype (implicit\n",
      " |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      " |      are mixed, the one that accommodates all will be chosen. Use this\n",
      " |      with care if you are not dealing with the blocks.\n",
      " |      \n",
      " |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      " |      float32.  If dtypes are int32 and uint8, dtype will be upcast to\n",
      " |      int32. By :func:`numpy.find_common_type` convention, mixing int64\n",
      " |      and uint64 will result in a float64 dtype.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      A DataFrame where all columns are the same type (e.g., int64) results\n",
      " |      in an array of the same type.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age':    [ 3,  29],\n",
      " |      ...                    'height': [94, 170],\n",
      " |      ...                    'weight': [31, 115]})\n",
      " |      >>> df\n",
      " |         age  height  weight\n",
      " |      0    3      94      31\n",
      " |      1   29     170     115\n",
      " |      >>> df.dtypes\n",
      " |      age       int64\n",
      " |      height    int64\n",
      " |      weight    int64\n",
      " |      dtype: object\n",
      " |      >>> df.values\n",
      " |      array([[  3,  94,  31],\n",
      " |             [ 29, 170, 115]])\n",
      " |      \n",
      " |      A DataFrame with mixed type columns(e.g., str/object, int64, float32)\n",
      " |      results in an ndarray of the broadest type that accommodates these\n",
      " |      mixed types (e.g., object).\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame([('parrot',   24.0, 'second'),\n",
      " |      ...                     ('lion',     80.5, 1),\n",
      " |      ...                     ('monkey', np.nan, None)],\n",
      " |      ...                   columns=('name', 'max_speed', 'rank'))\n",
      " |      >>> df2.dtypes\n",
      " |      name          object\n",
      " |      max_speed    float64\n",
      " |      rank          object\n",
      " |      dtype: object\n",
      " |      >>> df2.values\n",
      " |      array([['parrot', 24.0, 'second'],\n",
      " |             ['lion', 80.5, 1],\n",
      " |             ['monkey', nan, None]], dtype=object)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  columns\n",
      " |      The column labels of the DataFrame.\n",
      " |  \n",
      " |  index\n",
      " |      The index (row labels) of the DataFrame.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_AXIS_ORDERS': \"list[Literal[('index', 'columns')]...\n",
      " |  \n",
      " |  plot = <class 'pandas.plotting._core.PlotAccessor'>\n",
      " |      Make plots of Series or DataFrame.\n",
      " |      \n",
      " |      Uses the backend specified by the\n",
      " |      option ``plotting.backend``. By default, matplotlib is used.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : Series or DataFrame\n",
      " |          The object for which the method is called.\n",
      " |      x : label or position, default None\n",
      " |          Only used if data is a DataFrame.\n",
      " |      y : label, position or list of label, positions, default None\n",
      " |          Allows plotting of one column versus another. Only used if data is a\n",
      " |          DataFrame.\n",
      " |      kind : str\n",
      " |          The kind of plot to produce:\n",
      " |      \n",
      " |          - 'line' : line plot (default)\n",
      " |          - 'bar' : vertical bar plot\n",
      " |          - 'barh' : horizontal bar plot\n",
      " |          - 'hist' : histogram\n",
      " |          - 'box' : boxplot\n",
      " |          - 'kde' : Kernel Density Estimation plot\n",
      " |          - 'density' : same as 'kde'\n",
      " |          - 'area' : area plot\n",
      " |          - 'pie' : pie plot\n",
      " |          - 'scatter' : scatter plot (DataFrame only)\n",
      " |          - 'hexbin' : hexbin plot (DataFrame only)\n",
      " |      ax : matplotlib axes object, default None\n",
      " |          An axes of the current figure.\n",
      " |      subplots : bool or sequence of iterables, default False\n",
      " |          Whether to group columns into subplots:\n",
      " |      \n",
      " |          - ``False`` : No subplots will be used\n",
      " |          - ``True`` : Make separate subplots for each column.\n",
      " |          - sequence of iterables of column labels: Create a subplot for each\n",
      " |            group of columns. For example `[('a', 'c'), ('b', 'd')]` will\n",
      " |            create 2 subplots: one with columns 'a' and 'c', and one\n",
      " |            with columns 'b' and 'd'. Remaining columns that aren't specified\n",
      " |            will be plotted in additional subplots (one per column).\n",
      " |      \n",
      " |            .. versionadded:: 1.5.0\n",
      " |      \n",
      " |      sharex : bool, default True if ax is None else False\n",
      " |          In case ``subplots=True``, share x axis and set some x axis labels\n",
      " |          to invisible; defaults to True if ax is None otherwise False if\n",
      " |          an ax is passed in; Be aware, that passing in both an ax and\n",
      " |          ``sharex=True`` will alter all x axis labels for all axis in a figure.\n",
      " |      sharey : bool, default False\n",
      " |          In case ``subplots=True``, share y axis and set some y axis labels to invisible.\n",
      " |      layout : tuple, optional\n",
      " |          (rows, columns) for the layout of subplots.\n",
      " |      figsize : a tuple (width, height) in inches\n",
      " |          Size of a figure object.\n",
      " |      use_index : bool, default True\n",
      " |          Use index as ticks for x axis.\n",
      " |      title : str or list\n",
      " |          Title to use for the plot. If a string is passed, print the string\n",
      " |          at the top of the figure. If a list is passed and `subplots` is\n",
      " |          True, print each item in the list above the corresponding subplot.\n",
      " |      grid : bool, default None (matlab style default)\n",
      " |          Axis grid lines.\n",
      " |      legend : bool or {'reverse'}\n",
      " |          Place legend on axis subplots.\n",
      " |      style : list or dict\n",
      " |          The matplotlib line style per column.\n",
      " |      logx : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on x axis.\n",
      " |      \n",
      " |      logy : bool or 'sym' default False\n",
      " |          Use log scaling or symlog scaling on y axis.\n",
      " |      \n",
      " |      loglog : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on both x and y axes.\n",
      " |      \n",
      " |      xticks : sequence\n",
      " |          Values to use for the xticks.\n",
      " |      yticks : sequence\n",
      " |          Values to use for the yticks.\n",
      " |      xlim : 2-tuple/list\n",
      " |          Set the x limits of the current axes.\n",
      " |      ylim : 2-tuple/list\n",
      " |          Set the y limits of the current axes.\n",
      " |      xlabel : label, optional\n",
      " |          Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\n",
      " |          x-column name for planar plots.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |             Now applicable to planar plots (`scatter`, `hexbin`).\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              Now applicable to histograms.\n",
      " |      \n",
      " |      ylabel : label, optional\n",
      " |          Name to use for the ylabel on y-axis. Default will show no ylabel, or the\n",
      " |          y-column name for planar plots.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |             Now applicable to planar plots (`scatter`, `hexbin`).\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |              Now applicable to histograms.\n",
      " |      \n",
      " |      rot : float, default None\n",
      " |          Rotation for ticks (xticks for vertical, yticks for horizontal\n",
      " |          plots).\n",
      " |      fontsize : float, default None\n",
      " |          Font size for xticks and yticks.\n",
      " |      colormap : str or matplotlib colormap object, default None\n",
      " |          Colormap to select colors from. If string, load colormap with that\n",
      " |          name from matplotlib.\n",
      " |      colorbar : bool, optional\n",
      " |          If True, plot colorbar (only relevant for 'scatter' and 'hexbin'\n",
      " |          plots).\n",
      " |      position : float\n",
      " |          Specify relative alignments for bar plot layout.\n",
      " |          From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |          (center).\n",
      " |      table : bool, Series or DataFrame, default False\n",
      " |          If True, draw a table using the data in the DataFrame and the data\n",
      " |          will be transposed to meet matplotlib's default layout.\n",
      " |          If a Series or DataFrame is passed, use passed data to draw a\n",
      " |          table.\n",
      " |      yerr : DataFrame, Series, array-like, dict and str\n",
      " |          See :ref:`Plotting with Error Bars <visualization.errorbars>` for\n",
      " |          detail.\n",
      " |      xerr : DataFrame, Series, array-like, dict and str\n",
      " |          Equivalent to yerr.\n",
      " |      stacked : bool, default False in line and bar plots, and True in area plot\n",
      " |          If True, create stacked plot.\n",
      " |      secondary_y : bool or sequence, default False\n",
      " |          Whether to plot on the secondary y-axis if a list/tuple, which\n",
      " |          columns to plot on secondary y-axis.\n",
      " |      mark_right : bool, default True\n",
      " |          When using a secondary_y axis, automatically mark the column\n",
      " |          labels with \"(right)\" in the legend.\n",
      " |      include_bool : bool, default is False\n",
      " |          If True, boolean values can be plotted.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      **kwargs\n",
      " |          Options to pass to matplotlib plotting method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`matplotlib.axes.Axes` or numpy.ndarray of them\n",
      " |          If the backend is not the default matplotlib one, the return value\n",
      " |          will be the object returned by the backend.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      - See matplotlib documentation online for more on this subject\n",
      " |      - If `kind` = 'bar' or 'barh', you can specify relative alignments\n",
      " |        for bar plot layout by `position` keyword.\n",
      " |        From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |        (center)\n",
      " |  \n",
      " |  sparse = <class 'pandas.core.arrays.sparse.accessor.SparseFrameAccesso...\n",
      " |      DataFrame accessor for sparse data.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __abs__(self: 'NDFrameT') -> 'NDFrameT'\n",
      " |  \n",
      " |  __array__(self, dtype: 'npt.DTypeLike | None' = None) -> 'np.ndarray'\n",
      " |  \n",
      " |  __array_ufunc__(self, ufunc: 'np.ufunc', method: 'str', *inputs: 'Any', **kwargs: 'Any')\n",
      " |  \n",
      " |  __bool__ = __nonzero__(self) -> 'NoReturn'\n",
      " |  \n",
      " |  __contains__(self, key) -> 'bool_t'\n",
      " |      True if the key is in the info axis\n",
      " |  \n",
      " |  __copy__(self: 'NDFrameT', deep: 'bool_t' = True) -> 'NDFrameT'\n",
      " |  \n",
      " |  __deepcopy__(self: 'NDFrameT', memo=None) -> 'NDFrameT'\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      memo, default None\n",
      " |          Standard signature. Unused\n",
      " |  \n",
      " |  __delitem__(self, key) -> 'None'\n",
      " |      Delete item\n",
      " |  \n",
      " |  __finalize__(self: 'NDFrameT', other, method: 'str | None' = None, **kwargs) -> 'NDFrameT'\n",
      " |      Propagate metadata from other to self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : the object from which to get the attributes that we are going\n",
      " |          to propagate\n",
      " |      method : str, optional\n",
      " |          A passed method name providing context on where ``__finalize__``\n",
      " |          was called.\n",
      " |      \n",
      " |          .. warning::\n",
      " |      \n",
      " |             The value passed as `method` are not currently considered\n",
      " |             stable across pandas releases.\n",
      " |  \n",
      " |  __getattr__(self, name: 'str')\n",
      " |      After regular attribute access, try looking up the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __getstate__(self) -> 'dict[str, Any]'\n",
      " |  \n",
      " |  __iadd__(self: 'NDFrameT', other) -> 'NDFrameT'\n",
      " |  \n",
      " |  __iand__(self: 'NDFrameT', other) -> 'NDFrameT'\n",
      " |  \n",
      " |  __ifloordiv__(self: 'NDFrameT', other) -> 'NDFrameT'\n",
      " |  \n",
      " |  __imod__(self: 'NDFrameT', other) -> 'NDFrameT'\n",
      " |  \n",
      " |  __imul__(self: 'NDFrameT', other) -> 'NDFrameT'\n",
      " |  \n",
      " |  __invert__(self: 'NDFrameT') -> 'NDFrameT'\n",
      " |  \n",
      " |  __ior__(self: 'NDFrameT', other) -> 'NDFrameT'\n",
      " |  \n",
      " |  __ipow__(self: 'NDFrameT', other) -> 'NDFrameT'\n",
      " |  \n",
      " |  __isub__(self: 'NDFrameT', other) -> 'NDFrameT'\n",
      " |  \n",
      " |  __iter__(self) -> 'Iterator'\n",
      " |      Iterate over info axis.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterator\n",
      " |          Info axis as iterator.\n",
      " |  \n",
      " |  __itruediv__(self: 'NDFrameT', other) -> 'NDFrameT'\n",
      " |  \n",
      " |  __ixor__(self: 'NDFrameT', other) -> 'NDFrameT'\n",
      " |  \n",
      " |  __neg__(self: 'NDFrameT') -> 'NDFrameT'\n",
      " |  \n",
      " |  __nonzero__(self) -> 'NoReturn'\n",
      " |  \n",
      " |  __pos__(self: 'NDFrameT') -> 'NDFrameT'\n",
      " |  \n",
      " |  __round__(self: 'NDFrameT', decimals: 'int' = 0) -> 'NDFrameT'\n",
      " |  \n",
      " |  __setattr__(self, name: 'str', value) -> 'None'\n",
      " |      After regular attribute access, try setting the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __setstate__(self, state) -> 'None'\n",
      " |  \n",
      " |  abs(self: 'NDFrameT') -> 'NDFrameT'\n",
      " |      Return a Series/DataFrame with absolute numeric value of each element.\n",
      " |      \n",
      " |      This function only applies to elements that are all numeric.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      abs\n",
      " |          Series/DataFrame containing the absolute value of each element.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.absolute : Calculate the absolute value element-wise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For ``complex`` inputs, ``1.2 + 1j``, the absolute value is\n",
      " |      :math:`\\sqrt{ a^2 + b^2 }`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Absolute numeric values in a Series.\n",
      " |      \n",
      " |      >>> s = pd.Series([-1.10, 2, -3.33, 4])\n",
      " |      >>> s.abs()\n",
      " |      0    1.10\n",
      " |      1    2.00\n",
      " |      2    3.33\n",
      " |      3    4.00\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with complex numbers.\n",
      " |      \n",
      " |      >>> s = pd.Series([1.2 + 1j])\n",
      " |      >>> s.abs()\n",
      " |      0    1.56205\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with a Timedelta element.\n",
      " |      \n",
      " |      >>> s = pd.Series([pd.Timedelta('1 days')])\n",
      " |      >>> s.abs()\n",
      " |      0   1 days\n",
      " |      dtype: timedelta64[ns]\n",
      " |      \n",
      " |      Select rows with data closest to certain value using argsort (from\n",
      " |      `StackOverflow <https://stackoverflow.com/a/17758115>`__).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'a': [4, 5, 6, 7],\n",
      " |      ...     'b': [10, 20, 30, 40],\n",
      " |      ...     'c': [100, 50, -30, -50]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |           a    b    c\n",
      " |      0    4   10  100\n",
      " |      1    5   20   50\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |      >>> df.loc[(df.c - 43).abs().argsort()]\n",
      " |           a    b    c\n",
      " |      1    5   20   50\n",
      " |      0    4   10  100\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |  \n",
      " |  add_prefix(self: 'NDFrameT', prefix: 'str', axis: 'Axis | None' = None) -> 'NDFrameT'\n",
      " |      Prefix labels with string `prefix`.\n",
      " |      \n",
      " |      For Series, the row labels are prefixed.\n",
      " |      For DataFrame, the column labels are prefixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      prefix : str\n",
      " |          The string to add before each label.\n",
      " |      axis : {{0 or 'index', 1 or 'columns', None}}, default None\n",
      " |          Axis to add prefix on\n",
      " |      \n",
      " |          .. versionadded:: 2.0.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_suffix: Suffix row labels with string `suffix`.\n",
      " |      DataFrame.add_suffix: Suffix column labels with string `suffix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_prefix('item_')\n",
      " |      item_0    1\n",
      " |      item_1    2\n",
      " |      item_2    3\n",
      " |      item_3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_prefix('col_')\n",
      " |           col_A  col_B\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  add_suffix(self: 'NDFrameT', suffix: 'str', axis: 'Axis | None' = None) -> 'NDFrameT'\n",
      " |      Suffix labels with string `suffix`.\n",
      " |      \n",
      " |      For Series, the row labels are suffixed.\n",
      " |      For DataFrame, the column labels are suffixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      suffix : str\n",
      " |          The string to add after each label.\n",
      " |      axis : {{0 or 'index', 1 or 'columns', None}}, default None\n",
      " |          Axis to add suffix on\n",
      " |      \n",
      " |          .. versionadded:: 2.0.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_prefix: Prefix row labels with string `prefix`.\n",
      " |      DataFrame.add_prefix: Prefix column labels with string `prefix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_suffix('_item')\n",
      " |      0_item    1\n",
      " |      1_item    2\n",
      " |      2_item    3\n",
      " |      3_item    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_suffix('_col')\n",
      " |           A_col  B_col\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  asof(self, where, subset=None)\n",
      " |      Return the last row(s) without any NaNs before `where`.\n",
      " |      \n",
      " |      The last row (for each element in `where`, if list) without any\n",
      " |      NaN is taken.\n",
      " |      In case of a :class:`~pandas.DataFrame`, the last row without NaN\n",
      " |      considering only the subset of columns (if not `None`)\n",
      " |      \n",
      " |      If there is no good value, NaN is returned for a Series or\n",
      " |      a Series of NaN values for a DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      where : date or array-like of dates\n",
      " |          Date(s) before which the last row(s) are returned.\n",
      " |      subset : str or array-like of str, default `None`\n",
      " |          For DataFrame, if not `None`, only use these columns to\n",
      " |          check for NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series, or DataFrame\n",
      " |      \n",
      " |          The return can be:\n",
      " |      \n",
      " |          * scalar : when `self` is a Series and `where` is a scalar\n",
      " |          * Series: when `self` is a Series and `where` is an array-like,\n",
      " |            or when `self` is a DataFrame and `where` is a scalar\n",
      " |          * DataFrame : when `self` is a DataFrame and `where` is an\n",
      " |            array-like\n",
      " |      \n",
      " |          Return scalar, Series, or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_asof : Perform an asof merge. Similar to left join.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Dates are assumed to be sorted. Raises if this is not the case.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      A Series and a scalar `where`.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, np.nan, 4], index=[10, 20, 30, 40])\n",
      " |      >>> s\n",
      " |      10    1.0\n",
      " |      20    2.0\n",
      " |      30    NaN\n",
      " |      40    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.asof(20)\n",
      " |      2.0\n",
      " |      \n",
      " |      For a sequence `where`, a Series is returned. The first value is\n",
      " |      NaN, because the first element of `where` is before the first\n",
      " |      index value.\n",
      " |      \n",
      " |      >>> s.asof([5, 20])\n",
      " |      5     NaN\n",
      " |      20    2.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Missing values are not considered. The following is ``2.0``, not\n",
      " |      NaN, even though NaN is at the index location for ``30``.\n",
      " |      \n",
      " |      >>> s.asof(30)\n",
      " |      2.0\n",
      " |      \n",
      " |      Take all columns into consideration\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [10, 20, 30, 40, 50],\n",
      " |      ...                    'b': [None, None, None, None, 500]},\n",
      " |      ...                   index=pd.DatetimeIndex(['2018-02-27 09:01:00',\n",
      " |      ...                                           '2018-02-27 09:02:00',\n",
      " |      ...                                           '2018-02-27 09:03:00',\n",
      " |      ...                                           '2018-02-27 09:04:00',\n",
      " |      ...                                           '2018-02-27 09:05:00']))\n",
      " |      >>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',\n",
      " |      ...                           '2018-02-27 09:04:30']))\n",
      " |                            a   b\n",
      " |      2018-02-27 09:03:30 NaN NaN\n",
      " |      2018-02-27 09:04:30 NaN NaN\n",
      " |      \n",
      " |      Take a single column into consideration\n",
      " |      \n",
      " |      >>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',\n",
      " |      ...                           '2018-02-27 09:04:30']),\n",
      " |      ...         subset=['a'])\n",
      " |                            a   b\n",
      " |      2018-02-27 09:03:30  30 NaN\n",
      " |      2018-02-27 09:04:30  40 NaN\n",
      " |  \n",
      " |  astype(self: 'NDFrameT', dtype, copy: 'bool_t | None' = None, errors: 'IgnoreRaise' = 'raise') -> 'NDFrameT'\n",
      " |      Cast a pandas object to a specified dtype ``dtype``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str, data type, Series or Mapping of column name -> data type\n",
      " |          Use a str, numpy.dtype, pandas.ExtensionDtype or Python type to\n",
      " |          cast entire pandas object to the same type. Alternatively, use a\n",
      " |          mapping, e.g. {col: dtype, ...}, where col is a column label and dtype is\n",
      " |          a numpy.dtype or Python type to cast one or more of the DataFrame's\n",
      " |          columns to column-specific types.\n",
      " |      copy : bool, default True\n",
      " |          Return a copy when ``copy=True`` (be very careful setting\n",
      " |          ``copy=False`` as changes to values then may propagate to other\n",
      " |          pandas objects).\n",
      " |      errors : {'raise', 'ignore'}, default 'raise'\n",
      " |          Control raising of exceptions on invalid data for provided dtype.\n",
      " |      \n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to a numeric type.\n",
      " |      numpy.ndarray.astype : Cast a numpy array to a specified type.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      .. versionchanged:: 2.0.0\n",
      " |      \n",
      " |          Using ``astype`` to convert from timezone-naive dtype to\n",
      " |          timezone-aware dtype will raise an exception.\n",
      " |          Use :meth:`Series.dt.tz_localize` instead.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create a DataFrame:\n",
      " |      \n",
      " |      >>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df = pd.DataFrame(data=d)\n",
      " |      >>> df.dtypes\n",
      " |      col1    int64\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Cast all columns to int32:\n",
      " |      \n",
      " |      >>> df.astype('int32').dtypes\n",
      " |      col1    int32\n",
      " |      col2    int32\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Cast col1 to int32 using a dictionary:\n",
      " |      \n",
      " |      >>> df.astype({'col1': 'int32'}).dtypes\n",
      " |      col1    int32\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Create a series:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2], dtype='int32')\n",
      " |      >>> ser\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int32\n",
      " |      >>> ser.astype('int64')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Convert to categorical type:\n",
      " |      \n",
      " |      >>> ser.astype('category')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int32): [1, 2]\n",
      " |      \n",
      " |      Convert to ordered categorical type with custom ordering:\n",
      " |      \n",
      " |      >>> from pandas.api.types import CategoricalDtype\n",
      " |      >>> cat_dtype = CategoricalDtype(\n",
      " |      ...     categories=[2, 1], ordered=True)\n",
      " |      >>> ser.astype(cat_dtype)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [2 < 1]\n",
      " |      \n",
      " |      Create a series of dates:\n",
      " |      \n",
      " |      >>> ser_date = pd.Series(pd.date_range('20200101', periods=3))\n",
      " |      >>> ser_date\n",
      " |      0   2020-01-01\n",
      " |      1   2020-01-02\n",
      " |      2   2020-01-03\n",
      " |      dtype: datetime64[ns]\n",
      " |  \n",
      " |  at_time(self: 'NDFrameT', time, asof: 'bool_t' = False, axis: 'Axis | None' = None) -> 'NDFrameT'\n",
      " |      Select values at particular time of day (e.g., 9:30AM).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      time : datetime.time or str\n",
      " |          The values to select.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      DatetimeIndex.indexer_at_time : Get just the index locations for\n",
      " |          values at particular time of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='12H')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 00:00:00  3\n",
      " |      2018-04-10 12:00:00  4\n",
      " |      \n",
      " |      >>> ts.at_time('12:00')\n",
      " |                           A\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 12:00:00  4\n",
      " |  \n",
      " |  backfill(self: 'NDFrameT', *, axis: 'None | Axis' = None, inplace: 'bool_t' = False, limit: 'None | int' = None, downcast: 'dict | None' = None) -> 'NDFrameT | None'\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='bfill'``.\n",
      " |      \n",
      " |      .. deprecated:: 2.0\n",
      " |      \n",
      " |          Series/DataFrame.backfill is deprecated. Use Series/DataFrame.bfill instead.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  between_time(self: 'NDFrameT', start_time, end_time, inclusive: 'IntervalClosedType' = 'both', axis: 'Axis | None' = None) -> 'NDFrameT'\n",
      " |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      " |      \n",
      " |      By setting ``start_time`` to be later than ``end_time``,\n",
      " |      you can get the times that are *not* between the two times.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_time : datetime.time or str\n",
      " |          Initial time as a time filter limit.\n",
      " |      end_time : datetime.time or str\n",
      " |          End time as a time filter limit.\n",
      " |      inclusive : {\"both\", \"neither\", \"left\", \"right\"}, default \"both\"\n",
      " |          Include boundaries; whether to set each bound as closed or open.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Determine range time on index or columns value.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Data from the original object filtered to the specified dates range.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      DatetimeIndex.indexer_between_time : Get just the index locations for\n",
      " |          values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      2018-04-12 01:00:00  4\n",
      " |      \n",
      " |      >>> ts.between_time('0:15', '0:45')\n",
      " |                           A\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      \n",
      " |      You get the times that are *not* between two times by setting\n",
      " |      ``start_time`` later than ``end_time``:\n",
      " |      \n",
      " |      >>> ts.between_time('0:45', '0:15')\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-12 01:00:00  4\n",
      " |  \n",
      " |  bool(self) -> 'bool_t'\n",
      " |      Return the bool of a single element Series or DataFrame.\n",
      " |      \n",
      " |      This must be a boolean scalar value, either True or False. It will raise a\n",
      " |      ValueError if the Series or DataFrame does not have exactly 1 element, or that\n",
      " |      element is not boolean (integer values 0 and 1 will also raise an exception).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          The value in the Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.astype : Change the data type of a Series, including to boolean.\n",
      " |      DataFrame.astype : Change the data type of a DataFrame, including to boolean.\n",
      " |      numpy.bool_ : NumPy boolean data type, used by pandas for boolean values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The method will only work for single element objects with a boolean value:\n",
      " |      \n",
      " |      >>> pd.Series([True]).bool()\n",
      " |      True\n",
      " |      >>> pd.Series([False]).bool()\n",
      " |      False\n",
      " |      \n",
      " |      >>> pd.DataFrame({'col': [True]}).bool()\n",
      " |      True\n",
      " |      >>> pd.DataFrame({'col': [False]}).bool()\n",
      " |      False\n",
      " |  \n",
      " |  convert_dtypes(self: 'NDFrameT', infer_objects: 'bool_t' = True, convert_string: 'bool_t' = True, convert_integer: 'bool_t' = True, convert_boolean: 'bool_t' = True, convert_floating: 'bool_t' = True, dtype_backend: 'DtypeBackend' = 'numpy_nullable') -> 'NDFrameT'\n",
      " |      Convert columns to the best possible dtypes using dtypes supporting ``pd.NA``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      infer_objects : bool, default True\n",
      " |          Whether object dtypes should be converted to the best possible types.\n",
      " |      convert_string : bool, default True\n",
      " |          Whether object dtypes should be converted to ``StringDtype()``.\n",
      " |      convert_integer : bool, default True\n",
      " |          Whether, if possible, conversion can be done to integer extension types.\n",
      " |      convert_boolean : bool, defaults True\n",
      " |          Whether object dtypes should be converted to ``BooleanDtypes()``.\n",
      " |      convert_floating : bool, defaults True\n",
      " |          Whether, if possible, conversion can be done to floating extension types.\n",
      " |          If `convert_integer` is also True, preference will be give to integer\n",
      " |          dtypes if the floats can be faithfully casted to integers.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      dtype_backend : {\"numpy_nullable\", \"pyarrow\"}, default \"numpy_nullable\"\n",
      " |          Which dtype_backend to use, e.g. whether a DataFrame should use nullable\n",
      " |          dtypes for all dtypes that have a nullable\n",
      " |          implementation when \"numpy_nullable\" is set, pyarrow is used for all\n",
      " |          dtypes if \"pyarrow\" is set.\n",
      " |      \n",
      " |          The dtype_backends are still experimential.\n",
      " |      \n",
      " |          .. versionadded:: 2.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Copy of input object with new dtype.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      infer_objects : Infer dtypes of objects.\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to a numeric type.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, ``convert_dtypes`` will attempt to convert a Series (or each\n",
      " |      Series in a DataFrame) to dtypes that support ``pd.NA``. By using the options\n",
      " |      ``convert_string``, ``convert_integer``, ``convert_boolean`` and\n",
      " |      ``convert_floating``, it is possible to turn off individual conversions\n",
      " |      to ``StringDtype``, the integer extension types, ``BooleanDtype``\n",
      " |      or floating extension types, respectively.\n",
      " |      \n",
      " |      For object-dtyped columns, if ``infer_objects`` is ``True``, use the inference\n",
      " |      rules as during normal Series/DataFrame construction.  Then, if possible,\n",
      " |      convert to ``StringDtype``, ``BooleanDtype`` or an appropriate integer\n",
      " |      or floating extension type, otherwise leave as ``object``.\n",
      " |      \n",
      " |      If the dtype is integer, convert to an appropriate integer extension type.\n",
      " |      \n",
      " |      If the dtype is numeric, and consists of all integers, convert to an\n",
      " |      appropriate integer extension type. Otherwise, convert to an\n",
      " |      appropriate floating extension type.\n",
      " |      \n",
      " |      .. versionchanged:: 1.2\n",
      " |          Starting with pandas 1.2, this method also converts float columns\n",
      " |          to the nullable floating extension type.\n",
      " |      \n",
      " |      In the future, as new dtypes are added that support ``pd.NA``, the results\n",
      " |      of this method will change to support those new dtypes.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": pd.Series([1, 2, 3], dtype=np.dtype(\"int32\")),\n",
      " |      ...         \"b\": pd.Series([\"x\", \"y\", \"z\"], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"c\": pd.Series([True, False, np.nan], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"d\": pd.Series([\"h\", \"i\", np.nan], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"e\": pd.Series([10, np.nan, 20], dtype=np.dtype(\"float\")),\n",
      " |      ...         \"f\": pd.Series([np.nan, 100.5, 200], dtype=np.dtype(\"float\")),\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      \n",
      " |      Start with a DataFrame with default dtypes.\n",
      " |      \n",
      " |      >>> df\n",
      " |         a  b      c    d     e      f\n",
      " |      0  1  x   True    h  10.0    NaN\n",
      " |      1  2  y  False    i   NaN  100.5\n",
      " |      2  3  z    NaN  NaN  20.0  200.0\n",
      " |      \n",
      " |      >>> df.dtypes\n",
      " |      a      int32\n",
      " |      b     object\n",
      " |      c     object\n",
      " |      d     object\n",
      " |      e    float64\n",
      " |      f    float64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Convert the DataFrame to use best possible dtypes.\n",
      " |      \n",
      " |      >>> dfn = df.convert_dtypes()\n",
      " |      >>> dfn\n",
      " |         a  b      c     d     e      f\n",
      " |      0  1  x   True     h    10   <NA>\n",
      " |      1  2  y  False     i  <NA>  100.5\n",
      " |      2  3  z   <NA>  <NA>    20  200.0\n",
      " |      \n",
      " |      >>> dfn.dtypes\n",
      " |      a             Int32\n",
      " |      b    string[python]\n",
      " |      c           boolean\n",
      " |      d    string[python]\n",
      " |      e             Int64\n",
      " |      f           Float64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Start with a Series of strings and missing data represented by ``np.nan``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\"a\", \"b\", np.nan])\n",
      " |      >>> s\n",
      " |      0      a\n",
      " |      1      b\n",
      " |      2    NaN\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Obtain a Series with dtype ``StringDtype``.\n",
      " |      \n",
      " |      >>> s.convert_dtypes()\n",
      " |      0       a\n",
      " |      1       b\n",
      " |      2    <NA>\n",
      " |      dtype: string\n",
      " |  \n",
      " |  copy(self: 'NDFrameT', deep: 'bool_t | None' = True) -> 'NDFrameT'\n",
      " |      Make a copy of this object's indices and data.\n",
      " |      \n",
      " |      When ``deep=True`` (default), a new object will be created with a\n",
      " |      copy of the calling object's data and indices. Modifications to\n",
      " |      the data or indices of the copy will not be reflected in the\n",
      " |      original object (see notes below).\n",
      " |      \n",
      " |      When ``deep=False``, a new object will be created without copying\n",
      " |      the calling object's data or index (only references to the data\n",
      " |      and index are copied). Any changes to the data of the original\n",
      " |      will be reflected in the shallow copy (and vice versa).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default True\n",
      " |          Make a deep copy, including a copy of the data and the indices.\n",
      " |          With ``deep=False`` neither the indices nor the data are copied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Object type matches caller.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When ``deep=True``, data is copied but actual Python objects\n",
      " |      will not be copied recursively, only the reference to the object.\n",
      " |      This is in contrast to `copy.deepcopy` in the Standard Library,\n",
      " |      which recursively copies object data (see examples below).\n",
      " |      \n",
      " |      While ``Index`` objects are copied when ``deep=True``, the underlying\n",
      " |      numpy array is not copied for performance reasons. Since ``Index`` is\n",
      " |      immutable, the underlying data can be safely shared and a copy\n",
      " |      is not needed.\n",
      " |      \n",
      " |      Since pandas is not thread safe, see the\n",
      " |      :ref:`gotchas <gotchas.thread-safety>` when copying in a threading\n",
      " |      environment.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> s\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s_copy = s.copy()\n",
      " |      >>> s_copy\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **Shallow copy versus default (deep) copy:**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> shallow = s.copy(deep=False)\n",
      " |      \n",
      " |      Shallow copy shares data and index with original.\n",
      " |      \n",
      " |      >>> s is shallow\n",
      " |      False\n",
      " |      >>> s.values is shallow.values and s.index is shallow.index\n",
      " |      True\n",
      " |      \n",
      " |      Deep copy has own copy of data and index.\n",
      " |      \n",
      " |      >>> s is deep\n",
      " |      False\n",
      " |      >>> s.values is deep.values or s.index is deep.index\n",
      " |      False\n",
      " |      \n",
      " |      Updates to the data shared by shallow copy and original is reflected\n",
      " |      in both; deep copy remains unchanged.\n",
      " |      \n",
      " |      >>> s[0] = 3\n",
      " |      >>> shallow[1] = 4\n",
      " |      >>> s\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> shallow\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> deep\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Note that when copying an object containing Python objects, a deep copy\n",
      " |      will copy the data, but will not do so recursively. Updating a nested\n",
      " |      data object will be reflected in the deep copy.\n",
      " |      \n",
      " |      >>> s = pd.Series([[1, 2], [3, 4]])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> s[0][0] = 10\n",
      " |      >>> s\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |      >>> deep\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |  \n",
      " |  describe(self: 'NDFrameT', percentiles=None, include=None, exclude=None) -> 'NDFrameT'\n",
      " |      Generate descriptive statistics.\n",
      " |      \n",
      " |      Descriptive statistics include those that summarize the central\n",
      " |      tendency, dispersion and shape of a\n",
      " |      dataset's distribution, excluding ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(exclude=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Summary statistics of the Series or Dataframe provided.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count: Count number of non-NA/null observations.\n",
      " |      DataFrame.max: Maximum of the values in the object.\n",
      " |      DataFrame.min: Minimum of the values in the object.\n",
      " |      DataFrame.mean: Mean of the values.\n",
      " |      DataFrame.std: Standard deviation of the observations.\n",
      " |      DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
      " |          columns based on their dtype.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...     np.datetime64(\"2000-01-01\"),\n",
      " |      ...     np.datetime64(\"2010-01-01\"),\n",
      " |      ...     np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe()\n",
      " |      count                      3\n",
      " |      mean     2006-09-01 08:00:00\n",
      " |      min      2000-01-01 00:00:00\n",
      " |      25%      2004-12-31 12:00:00\n",
      " |      50%      2010-01-01 00:00:00\n",
      " |      75%      2010-01-01 00:00:00\n",
      " |      max      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),\n",
      " |      ...                    'numeric': [1, 2, 3],\n",
      " |      ...                    'object': ['a', 'b', 'c']\n",
      " |      ...                   })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')  # doctest: +SKIP\n",
      " |             categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      a\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[object])  # doctest: +SKIP\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         a\n",
      " |      freq        1\n",
      " |      \n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              d\n",
      " |      freq             1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])  # doctest: +SKIP\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      a\n",
      " |      freq             1      1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[object])  # doctest: +SKIP\n",
      " |             categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |  \n",
      " |  droplevel(self: 'NDFrameT', level: 'IndexLabel', axis: 'Axis' = 0) -> 'NDFrameT'\n",
      " |      Return Series/DataFrame with requested index / column level(s) removed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, or list-like\n",
      " |          If a string is given, must be the name of a level\n",
      " |          If list-like, elements must be names or positional indexes\n",
      " |          of levels.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis along which the level(s) is removed:\n",
      " |      \n",
      " |          * 0 or 'index': remove level(s) in column.\n",
      " |          * 1 or 'columns': remove level(s) in row.\n",
      " |      \n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame\n",
      " |          Series/DataFrame with requested index / column level(s) removed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([\n",
      " |      ...     [1, 2, 3, 4],\n",
      " |      ...     [5, 6, 7, 8],\n",
      " |      ...     [9, 10, 11, 12]\n",
      " |      ... ]).set_index([0, 1]).rename_axis(['a', 'b'])\n",
      " |      \n",
      " |      >>> df.columns = pd.MultiIndex.from_tuples([\n",
      " |      ...     ('c', 'e'), ('d', 'f')\n",
      " |      ... ], names=['level_1', 'level_2'])\n",
      " |      \n",
      " |      >>> df\n",
      " |      level_1   c   d\n",
      " |      level_2   e   f\n",
      " |      a b\n",
      " |      1 2      3   4\n",
      " |      5 6      7   8\n",
      " |      9 10    11  12\n",
      " |      \n",
      " |      >>> df.droplevel('a')\n",
      " |      level_1   c   d\n",
      " |      level_2   e   f\n",
      " |      b\n",
      " |      2        3   4\n",
      " |      6        7   8\n",
      " |      10      11  12\n",
      " |      \n",
      " |      >>> df.droplevel('level_2', axis=1)\n",
      " |      level_1   c   d\n",
      " |      a b\n",
      " |      1 2      3   4\n",
      " |      5 6      7   8\n",
      " |      9 10    11  12\n",
      " |  \n",
      " |  equals(self, other: 'object') -> 'bool_t'\n",
      " |      Test whether two objects contain the same elements.\n",
      " |      \n",
      " |      This function allows two Series or DataFrames to be compared against\n",
      " |      each other to see if they have the same shape and elements. NaNs in\n",
      " |      the same location are considered equal.\n",
      " |      \n",
      " |      The row/column index do not need to have the same type, as long\n",
      " |      as the values are considered equal. Corresponding columns must be of\n",
      " |      the same dtype.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or DataFrame\n",
      " |          The other Series or DataFrame to be compared with the first.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          True if all elements are the same in both objects, False\n",
      " |          otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.eq : Compare two Series objects of the same length\n",
      " |          and return a Series where each element is True if the element\n",
      " |          in each Series is equal, False otherwise.\n",
      " |      DataFrame.eq : Compare two DataFrame objects of the same shape and\n",
      " |          return a DataFrame where each element is True if the respective\n",
      " |          element in each DataFrame is equal, False otherwise.\n",
      " |      testing.assert_series_equal : Raises an AssertionError if left and\n",
      " |          right are not equal. Provides an easy interface to ignore\n",
      " |          inequality in dtypes, indexes and precision among others.\n",
      " |      testing.assert_frame_equal : Like assert_series_equal, but targets\n",
      " |          DataFrames.\n",
      " |      numpy.array_equal : Return True if two arrays have the same shape\n",
      " |          and elements, False otherwise.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({1: [10], 2: [20]})\n",
      " |      >>> df\n",
      " |          1   2\n",
      " |      0  10  20\n",
      " |      \n",
      " |      DataFrames df and exactly_equal have the same types and values for\n",
      " |      their elements and column labels, which will return True.\n",
      " |      \n",
      " |      >>> exactly_equal = pd.DataFrame({1: [10], 2: [20]})\n",
      " |      >>> exactly_equal\n",
      " |          1   2\n",
      " |      0  10  20\n",
      " |      >>> df.equals(exactly_equal)\n",
      " |      True\n",
      " |      \n",
      " |      DataFrames df and different_column_type have the same element\n",
      " |      types and values, but have different types for the column labels,\n",
      " |      which will still return True.\n",
      " |      \n",
      " |      >>> different_column_type = pd.DataFrame({1.0: [10], 2.0: [20]})\n",
      " |      >>> different_column_type\n",
      " |         1.0  2.0\n",
      " |      0   10   20\n",
      " |      >>> df.equals(different_column_type)\n",
      " |      True\n",
      " |      \n",
      " |      DataFrames df and different_data_type have different types for the\n",
      " |      same values for their elements, and will return False even though\n",
      " |      their column labels are the same values and types.\n",
      " |      \n",
      " |      >>> different_data_type = pd.DataFrame({1: [10.0], 2: [20.0]})\n",
      " |      >>> different_data_type\n",
      " |            1     2\n",
      " |      0  10.0  20.0\n",
      " |      >>> df.equals(different_data_type)\n",
      " |      False\n",
      " |  \n",
      " |  ewm(self, com: 'float | None' = None, span: 'float | None' = None, halflife: 'float | TimedeltaConvertibleTypes | None' = None, alpha: 'float | None' = None, min_periods: 'int | None' = 0, adjust: 'bool_t' = True, ignore_na: 'bool_t' = False, axis: 'Axis' = 0, times: 'np.ndarray | DataFrame | Series | None' = None, method: 'str' = 'single') -> 'ExponentialMovingWindow'\n",
      " |      Provide exponentially weighted (EW) calculations.\n",
      " |      \n",
      " |      Exactly one of ``com``, ``span``, ``halflife``, or ``alpha`` must be\n",
      " |      provided if ``times`` is not provided. If ``times`` is provided,\n",
      " |      ``halflife`` and one of ``com``, ``span`` or ``alpha`` may be provided.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      com : float, optional\n",
      " |          Specify decay in terms of center of mass\n",
      " |      \n",
      " |          :math:`\\alpha = 1 / (1 + com)`, for :math:`com \\geq 0`.\n",
      " |      \n",
      " |      span : float, optional\n",
      " |          Specify decay in terms of span\n",
      " |      \n",
      " |          :math:`\\alpha = 2 / (span + 1)`, for :math:`span \\geq 1`.\n",
      " |      \n",
      " |      halflife : float, str, timedelta, optional\n",
      " |          Specify decay in terms of half-life\n",
      " |      \n",
      " |          :math:`\\alpha = 1 - \\exp\\left(-\\ln(2) / halflife\\right)`, for\n",
      " |          :math:`halflife > 0`.\n",
      " |      \n",
      " |          If ``times`` is specified, a timedelta convertible unit over which an\n",
      " |          observation decays to half its value. Only applicable to ``mean()``,\n",
      " |          and halflife value will not apply to the other functions.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      alpha : float, optional\n",
      " |          Specify smoothing factor :math:`\\alpha` directly\n",
      " |      \n",
      " |          :math:`0 < \\alpha \\leq 1`.\n",
      " |      \n",
      " |      min_periods : int, default 0\n",
      " |          Minimum number of observations in window required to have a value;\n",
      " |          otherwise, result is ``np.nan``.\n",
      " |      \n",
      " |      adjust : bool, default True\n",
      " |          Divide by decaying adjustment factor in beginning periods to account\n",
      " |          for imbalance in relative weightings (viewing EWMA as a moving average).\n",
      " |      \n",
      " |          - When ``adjust=True`` (default), the EW function is calculated using weights\n",
      " |            :math:`w_i = (1 - \\alpha)^i`. For example, the EW moving average of the series\n",
      " |            [:math:`x_0, x_1, ..., x_t`] would be:\n",
      " |      \n",
      " |          .. math::\n",
      " |              y_t = \\frac{x_t + (1 - \\alpha)x_{t-1} + (1 - \\alpha)^2 x_{t-2} + ... + (1 -\n",
      " |              \\alpha)^t x_0}{1 + (1 - \\alpha) + (1 - \\alpha)^2 + ... + (1 - \\alpha)^t}\n",
      " |      \n",
      " |          - When ``adjust=False``, the exponentially weighted function is calculated\n",
      " |            recursively:\n",
      " |      \n",
      " |          .. math::\n",
      " |              \\begin{split}\n",
      " |                  y_0 &= x_0\\\\\n",
      " |                  y_t &= (1 - \\alpha) y_{t-1} + \\alpha x_t,\n",
      " |              \\end{split}\n",
      " |      ignore_na : bool, default False\n",
      " |          Ignore missing values when calculating weights.\n",
      " |      \n",
      " |          - When ``ignore_na=False`` (default), weights are based on absolute positions.\n",
      " |            For example, the weights of :math:`x_0` and :math:`x_2` used in calculating\n",
      " |            the final weighted average of [:math:`x_0`, None, :math:`x_2`] are\n",
      " |            :math:`(1-\\alpha)^2` and :math:`1` if ``adjust=True``, and\n",
      " |            :math:`(1-\\alpha)^2` and :math:`\\alpha` if ``adjust=False``.\n",
      " |      \n",
      " |          - When ``ignore_na=True``, weights are based\n",
      " |            on relative positions. For example, the weights of :math:`x_0` and :math:`x_2`\n",
      " |            used in calculating the final weighted average of\n",
      " |            [:math:`x_0`, None, :math:`x_2`] are :math:`1-\\alpha` and :math:`1` if\n",
      " |            ``adjust=True``, and :math:`1-\\alpha` and :math:`\\alpha` if ``adjust=False``.\n",
      " |      \n",
      " |      axis : {0, 1}, default 0\n",
      " |          If ``0`` or ``'index'``, calculate across the rows.\n",
      " |      \n",
      " |          If ``1`` or ``'columns'``, calculate across the columns.\n",
      " |      \n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |      times : np.ndarray, Series, default None\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          Only applicable to ``mean()``.\n",
      " |      \n",
      " |          Times corresponding to the observations. Must be monotonically increasing and\n",
      " |          ``datetime64[ns]`` dtype.\n",
      " |      \n",
      " |          If 1-D array like, a sequence with the same shape as the observations.\n",
      " |      \n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |      \n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |      \n",
      " |          Only applicable to ``mean()``\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ``ExponentialMovingWindow`` subclass\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations.\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See :ref:`Windowing Operations <window.exponentially_weighted>`\n",
      " |      for further usage details and examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.ewm(com=0.5).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      >>> df.ewm(alpha=2 / 3).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      \n",
      " |      **adjust**\n",
      " |      \n",
      " |      >>> df.ewm(com=0.5, adjust=True).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      >>> df.ewm(com=0.5, adjust=False).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.666667\n",
      " |      2  1.555556\n",
      " |      3  1.555556\n",
      " |      4  3.650794\n",
      " |      \n",
      " |      **ignore_na**\n",
      " |      \n",
      " |      >>> df.ewm(com=0.5, ignore_na=True).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.225000\n",
      " |      >>> df.ewm(com=0.5, ignore_na=False).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      \n",
      " |      **times**\n",
      " |      \n",
      " |      Exponentially weighted mean with weights calculated with a timedelta ``halflife``\n",
      " |      relative to ``times``.\n",
      " |      \n",
      " |      >>> times = ['2020-01-01', '2020-01-03', '2020-01-10', '2020-01-15', '2020-01-17']\n",
      " |      >>> df.ewm(halflife='4 days', times=pd.DatetimeIndex(times)).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.585786\n",
      " |      2  1.523889\n",
      " |      3  1.523889\n",
      " |      4  3.233686\n",
      " |  \n",
      " |  expanding(self, min_periods: 'int' = 1, axis: 'Axis' = 0, method: 'str' = 'single') -> 'Expanding'\n",
      " |      Provide expanding window calculations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, default 1\n",
      " |          Minimum number of observations in window required to have a value;\n",
      " |          otherwise, result is ``np.nan``.\n",
      " |      \n",
      " |      axis : int or str, default 0\n",
      " |          If ``0`` or ``'index'``, roll across the rows.\n",
      " |      \n",
      " |          If ``1`` or ``'columns'``, roll across the columns.\n",
      " |      \n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |      \n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ``Expanding`` subclass\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations.\n",
      " |      ewm : Provides exponential weighted functions.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See :ref:`Windowing Operations <window.expanding>` for further usage details\n",
      " |      and examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"B\": [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      **min_periods**\n",
      " |      \n",
      " |      Expanding sum with 1 vs 3 observations needed to calculate a value.\n",
      " |      \n",
      " |      >>> df.expanding(1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |      >>> df.expanding(3).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  NaN\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |  \n",
      " |  filter(self: 'NDFrameT', items=None, like: 'str | None' = None, regex: 'str | None' = None, axis: 'Axis | None' = None) -> 'NDFrameT'\n",
      " |      Subset the dataframe rows or columns according to the specified index labels.\n",
      " |      \n",
      " |      Note that this routine does not filter a dataframe on its\n",
      " |      contents. The filter is applied to the labels of the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : list-like\n",
      " |          Keep labels from axis which are in items.\n",
      " |      like : str\n",
      " |          Keep labels from axis for which \"like in label == True\".\n",
      " |      regex : str (regular expression)\n",
      " |          Keep labels from axis for which re.search(regex, label) == True.\n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default None\n",
      " |          The axis to filter on, expressed either as an index (int)\n",
      " |          or axis name (str). By default this is the info axis, 'columns' for\n",
      " |          DataFrame. For `Series` this parameter is unused and defaults to `None`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Access a group of rows and columns\n",
      " |          by label(s) or a boolean array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The ``items``, ``like``, and ``regex`` parameters are\n",
      " |      enforced to be mutually exclusive.\n",
      " |      \n",
      " |      ``axis`` defaults to the info axis that is used when indexing\n",
      " |      with ``[]``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])),\n",
      " |      ...                   index=['mouse', 'rabbit'],\n",
      " |      ...                   columns=['one', 'two', 'three'])\n",
      " |      >>> df\n",
      " |              one  two  three\n",
      " |      mouse     1    2      3\n",
      " |      rabbit    4    5      6\n",
      " |      \n",
      " |      >>> # select columns by name\n",
      " |      >>> df.filter(items=['one', 'three'])\n",
      " |               one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select columns by regular expression\n",
      " |      >>> df.filter(regex='e$', axis=1)\n",
      " |               one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select rows containing 'bbi'\n",
      " |      >>> df.filter(like='bbi', axis=0)\n",
      " |               one  two  three\n",
      " |      rabbit    4    5      6\n",
      " |  \n",
      " |  first(self: 'NDFrameT', offset) -> 'NDFrameT'\n",
      " |      Select initial periods of time series data based on a date offset.\n",
      " |      \n",
      " |      For a DataFrame with a sorted DatetimeIndex, this function can\n",
      " |      select the first few rows based on a date offset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : str, DateOffset or dateutil.relativedelta\n",
      " |          The offset length of the data that will be selected. For instance,\n",
      " |          '1M' will display all the rows having their index within the first month.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A subset of the caller.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the first 3 days:\n",
      " |      \n",
      " |      >>> ts.first('3D')\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      \n",
      " |      Notice the data for 3 first calendar days were returned, not the first\n",
      " |      3 days observed in the dataset, and therefore data for 2018-04-13 was\n",
      " |      not returned.\n",
      " |  \n",
      " |  first_valid_index(self) -> 'Hashable | None'\n",
      " |      Return index for first non-NA value or None, if no non-NA value is found.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty Series/DataFrame.\n",
      " |  \n",
      " |  get(self, key, default=None)\n",
      " |      Get item from object for given key (ex: DataFrame column).\n",
      " |      \n",
      " |      Returns default value if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as items contained in object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     [\n",
      " |      ...         [24.3, 75.7, \"high\"],\n",
      " |      ...         [31, 87.8, \"high\"],\n",
      " |      ...         [22, 71.6, \"medium\"],\n",
      " |      ...         [35, 95, \"medium\"],\n",
      " |      ...     ],\n",
      " |      ...     columns=[\"temp_celsius\", \"temp_fahrenheit\", \"windspeed\"],\n",
      " |      ...     index=pd.date_range(start=\"2014-02-12\", end=\"2014-02-15\", freq=\"D\"),\n",
      " |      ... )\n",
      " |      \n",
      " |      >>> df\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          24.3             75.7      high\n",
      " |      2014-02-13          31.0             87.8      high\n",
      " |      2014-02-14          22.0             71.6    medium\n",
      " |      2014-02-15          35.0             95.0    medium\n",
      " |      \n",
      " |      >>> df.get([\"temp_celsius\", \"windspeed\"])\n",
      " |                  temp_celsius windspeed\n",
      " |      2014-02-12          24.3      high\n",
      " |      2014-02-13          31.0      high\n",
      " |      2014-02-14          22.0    medium\n",
      " |      2014-02-15          35.0    medium\n",
      " |      \n",
      " |      >>> ser = df['windspeed']\n",
      " |      >>> ser.get('2014-02-13')\n",
      " |      'high'\n",
      " |      \n",
      " |      If the key isn't found, the default value will be used.\n",
      " |      \n",
      " |      >>> df.get([\"temp_celsius\", \"temp_kelvin\"], default=\"default_value\")\n",
      " |      'default_value'\n",
      " |      \n",
      " |      >>> ser.get('2014-02-10', '[unknown]')\n",
      " |      '[unknown]'\n",
      " |  \n",
      " |  head(self: 'NDFrameT', n: 'int' = 5) -> 'NDFrameT'\n",
      " |      Return the first `n` rows.\n",
      " |      \n",
      " |      This function returns the first `n` rows for the object based\n",
      " |      on position. It is useful for quickly testing if your object\n",
      " |      has the right type of data in it.\n",
      " |      \n",
      " |      For negative values of `n`, this function returns all rows except\n",
      " |      the last `|n|` rows, equivalent to ``df[:n]``.\n",
      " |      \n",
      " |      If n is larger than the number of rows, this function returns all rows.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          The first `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.tail: Returns the last `n` rows.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the first 5 lines\n",
      " |      \n",
      " |      >>> df.head()\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      \n",
      " |      Viewing the first `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.head(3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      \n",
      " |      For negative values of `n`\n",
      " |      \n",
      " |      >>> df.head(-3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |  \n",
      " |  infer_objects(self: 'NDFrameT', copy: 'bool_t | None' = None) -> 'NDFrameT'\n",
      " |      Attempt to infer better dtypes for object columns.\n",
      " |      \n",
      " |      Attempts soft conversion of object-dtyped\n",
      " |      columns, leaving non-object and unconvertible\n",
      " |      columns unchanged. The inference rules are the\n",
      " |      same as during normal Series/DataFrame construction.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : bool, default True\n",
      " |          Whether to make a copy for non-object or non-inferrable columns\n",
      " |          or Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to numeric type.\n",
      " |      convert_dtypes : Convert argument to best possible dtype.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n",
      " |      >>> df = df.iloc[1:]\n",
      " |      >>> df\n",
      " |         A\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      \n",
      " |      >>> df.dtypes\n",
      " |      A    object\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> df.infer_objects().dtypes\n",
      " |      A    int64\n",
      " |      dtype: object\n",
      " |  \n",
      " |  keys(self) -> 'Index'\n",
      " |      Get the 'info axis' (see Indexing for more).\n",
      " |      \n",
      " |      This is index for Series, columns for DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Info axis.\n",
      " |  \n",
      " |  last(self: 'NDFrameT', offset) -> 'NDFrameT'\n",
      " |      Select final periods of time series data based on a date offset.\n",
      " |      \n",
      " |      For a DataFrame with a sorted DatetimeIndex, this function\n",
      " |      selects the last few rows based on a date offset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : str, DateOffset, dateutil.relativedelta\n",
      " |          The offset length of the data that will be selected. For instance,\n",
      " |          '3D' will display all the rows having their index within the last 3 days.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A subset of the caller.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the last 3 days:\n",
      " |      \n",
      " |      >>> ts.last('3D')\n",
      " |                  A\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Notice the data for 3 last calendar days were returned, not the last\n",
      " |      3 observed days in the dataset, and therefore data for 2018-04-11 was\n",
      " |      not returned.\n",
      " |  \n",
      " |  last_valid_index(self) -> 'Hashable | None'\n",
      " |      Return index for last non-NA value or None, if no non-NA value is found.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty Series/DataFrame.\n",
      " |  \n",
      " |  pad(self: 'NDFrameT', *, axis: 'None | Axis' = None, inplace: 'bool_t' = False, limit: 'None | int' = None, downcast: 'dict | None' = None) -> 'NDFrameT | None'\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='ffill'``.\n",
      " |      \n",
      " |      .. deprecated:: 2.0\n",
      " |      \n",
      " |          Series/DataFrame.pad is deprecated. Use Series/DataFrame.ffill instead.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  pct_change(self: 'NDFrameT', periods: 'int' = 1, fill_method: \"Literal[('backfill', 'bfill', 'pad', 'ffill')] | None\" = 'pad', limit=None, freq=None, **kwargs) -> 'NDFrameT'\n",
      " |      Percentage change between the current and a prior element.\n",
      " |      \n",
      " |      Computes the percentage change from the immediately previous row by\n",
      " |      default. This is useful in comparing the percentage of change in a time\n",
      " |      series of elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming percent change.\n",
      " |      fill_method : {'backfill', 'bfill', 'pad', 'ffill', None}, default 'pad'\n",
      " |          How to handle NAs **before** computing percent changes.\n",
      " |      limit : int, default None\n",
      " |          The number of consecutive NAs to fill before stopping.\n",
      " |      freq : DateOffset, timedelta, or str, optional\n",
      " |          Increment to use from time series API (e.g. 'M' or BDay()).\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments are passed into\n",
      " |          `DataFrame.shift` or `Series.shift`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          The same type as the calling object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.diff : Compute the difference of two elements in a Series.\n",
      " |      DataFrame.diff : Compute the difference of two elements in a DataFrame.\n",
      " |      Series.shift : Shift the index by some number of periods.\n",
      " |      DataFrame.shift : Shift the index by some number of periods.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, 85])\n",
      " |      >>> s\n",
      " |      0    90\n",
      " |      1    91\n",
      " |      2    85\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.pct_change()\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(periods=2)\n",
      " |      0         NaN\n",
      " |      1         NaN\n",
      " |      2   -0.055556\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See the percentage change in a Series where filling NAs with last\n",
      " |      valid observation forward to next valid.\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, None, 85])\n",
      " |      >>> s\n",
      " |      0    90.0\n",
      " |      1    91.0\n",
      " |      2     NaN\n",
      " |      3    85.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(fill_method='ffill')\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2    0.000000\n",
      " |      3   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Percentage change in French franc, Deutsche Mark, and Italian lira from\n",
      " |      1980-01-01 to 1980-03-01.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'FR': [4.0405, 4.0963, 4.3149],\n",
      " |      ...     'GR': [1.7246, 1.7482, 1.8519],\n",
      " |      ...     'IT': [804.74, 810.01, 860.13]},\n",
      " |      ...     index=['1980-01-01', '1980-02-01', '1980-03-01'])\n",
      " |      >>> df\n",
      " |                      FR      GR      IT\n",
      " |      1980-01-01  4.0405  1.7246  804.74\n",
      " |      1980-02-01  4.0963  1.7482  810.01\n",
      " |      1980-03-01  4.3149  1.8519  860.13\n",
      " |      \n",
      " |      >>> df.pct_change()\n",
      " |                        FR        GR        IT\n",
      " |      1980-01-01       NaN       NaN       NaN\n",
      " |      1980-02-01  0.013810  0.013684  0.006549\n",
      " |      1980-03-01  0.053365  0.059318  0.061876\n",
      " |      \n",
      " |      Percentage of change in GOOG and APPL stock volume. Shows computing\n",
      " |      the percentage change between columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     '2016': [1769950, 30586265],\n",
      " |      ...     '2015': [1500923, 40912316],\n",
      " |      ...     '2014': [1371819, 41403351]},\n",
      " |      ...     index=['GOOG', 'APPL'])\n",
      " |      >>> df\n",
      " |                2016      2015      2014\n",
      " |      GOOG   1769950   1500923   1371819\n",
      " |      APPL  30586265  40912316  41403351\n",
      " |      \n",
      " |      >>> df.pct_change(axis='columns', periods=-1)\n",
      " |                2016      2015  2014\n",
      " |      GOOG  0.179241  0.094112   NaN\n",
      " |      APPL -0.252395 -0.011860   NaN\n",
      " |  \n",
      " |  pipe(self, func: 'Callable[..., T] | tuple[Callable[..., T], str]', *args, **kwargs) -> 'T'\n",
      " |      Apply chainable functions that expect Series or DataFrames.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Function to apply to the Series/DataFrame.\n",
      " |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      " |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      " |          ``data_keyword`` is a string indicating the keyword of\n",
      " |          ``callable`` that expects the Series/DataFrame.\n",
      " |      args : iterable, optional\n",
      " |          Positional arguments passed into ``func``.\n",
      " |      kwargs : mapping, optional\n",
      " |          A dictionary of keyword arguments passed into ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      the return type of ``func``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Apply a function along input axis of DataFrame.\n",
      " |      DataFrame.applymap : Apply a function elementwise on a whole DataFrame.\n",
      " |      Series.map : Apply a mapping correspondence on a\n",
      " |          :class:`~pandas.Series`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Use ``.pipe`` when chaining together functions that expect\n",
      " |      Series, DataFrames or GroupBy objects. Instead of writing\n",
      " |      \n",
      " |      >>> func(g(h(df), arg1=a), arg2=b, arg3=c)  # doctest: +SKIP\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(func, arg2=b, arg3=c)\n",
      " |      ... )  # doctest: +SKIP\n",
      " |      \n",
      " |      If you have a function that takes the data as (say) the second\n",
      " |      argument, pass a tuple indicating which keyword expects the\n",
      " |      data. For example, suppose ``func`` takes its data as ``arg2``:\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe((func, 'arg2'), arg1=a, arg3=c)\n",
      " |      ...  )  # doctest: +SKIP\n",
      " |  \n",
      " |  rank(self: 'NDFrameT', axis: 'Axis' = 0, method: 'str' = 'average', numeric_only: 'bool_t' = False, na_option: 'str' = 'keep', ascending: 'bool_t' = True, pct: 'bool_t' = False) -> 'NDFrameT'\n",
      " |      Compute numerical data ranks (1 through n) along axis.\n",
      " |      \n",
      " |      By default, equal values are assigned a rank that is the average of the\n",
      " |      ranks of those values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Index to direct ranking.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n",
      " |          How to rank the group of records that have the same value (i.e. ties):\n",
      " |      \n",
      " |          * average: average rank of the group\n",
      " |          * min: lowest rank in the group\n",
      " |          * max: highest rank in the group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups.\n",
      " |      \n",
      " |      numeric_only : bool, default False\n",
      " |          For DataFrame objects, rank only numeric columns if set to True.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |              The default value of ``numeric_only`` is now ``False``.\n",
      " |      \n",
      " |      na_option : {'keep', 'top', 'bottom'}, default 'keep'\n",
      " |          How to rank NaN values:\n",
      " |      \n",
      " |          * keep: assign NaN rank to NaN values\n",
      " |          * top: assign lowest rank to NaN values\n",
      " |          * bottom: assign highest rank to NaN values\n",
      " |      \n",
      " |      ascending : bool, default True\n",
      " |          Whether or not the elements should be ranked in ascending order.\n",
      " |      pct : bool, default False\n",
      " |          Whether or not to display the returned rankings in percentile\n",
      " |          form.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          Return a Series or DataFrame with data ranks as values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.groupby.DataFrameGroupBy.rank : Rank of values within each group.\n",
      " |      core.groupby.SeriesGroupBy.rank : Rank of values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'Animal': ['cat', 'penguin', 'dog',\n",
      " |      ...                                    'spider', 'snake'],\n",
      " |      ...                         'Number_legs': [4, 2, 4, 8, np.nan]})\n",
      " |      >>> df\n",
      " |          Animal  Number_legs\n",
      " |      0      cat          4.0\n",
      " |      1  penguin          2.0\n",
      " |      2      dog          4.0\n",
      " |      3   spider          8.0\n",
      " |      4    snake          NaN\n",
      " |      \n",
      " |      Ties are assigned the mean of the ranks (by default) for the group.\n",
      " |      \n",
      " |      >>> s = pd.Series(range(5), index=list(\"abcde\"))\n",
      " |      >>> s[\"d\"] = s[\"b\"]\n",
      " |      >>> s.rank()\n",
      " |      a    1.0\n",
      " |      b    2.5\n",
      " |      c    4.0\n",
      " |      d    2.5\n",
      " |      e    5.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      The following example shows how the method behaves with the above\n",
      " |      parameters:\n",
      " |      \n",
      " |      * default_rank: this is the default behaviour obtained without using\n",
      " |        any parameter.\n",
      " |      * max_rank: setting ``method = 'max'`` the records that have the\n",
      " |        same values are ranked using the highest rank (e.g.: since 'cat'\n",
      " |        and 'dog' are both in the 2nd and 3rd position, rank 3 is assigned.)\n",
      " |      * NA_bottom: choosing ``na_option = 'bottom'``, if there are records\n",
      " |        with NaN values they are placed at the bottom of the ranking.\n",
      " |      * pct_rank: when setting ``pct = True``, the ranking is expressed as\n",
      " |        percentile rank.\n",
      " |      \n",
      " |      >>> df['default_rank'] = df['Number_legs'].rank()\n",
      " |      >>> df['max_rank'] = df['Number_legs'].rank(method='max')\n",
      " |      >>> df['NA_bottom'] = df['Number_legs'].rank(na_option='bottom')\n",
      " |      >>> df['pct_rank'] = df['Number_legs'].rank(pct=True)\n",
      " |      >>> df\n",
      " |          Animal  Number_legs  default_rank  max_rank  NA_bottom  pct_rank\n",
      " |      0      cat          4.0           2.5       3.0        2.5     0.625\n",
      " |      1  penguin          2.0           1.0       1.0        1.0     0.250\n",
      " |      2      dog          4.0           2.5       3.0        2.5     0.625\n",
      " |      3   spider          8.0           4.0       4.0        4.0     1.000\n",
      " |      4    snake          NaN           NaN       NaN        5.0       NaN\n",
      " |  \n",
      " |  reindex_like(self: 'NDFrameT', other, method: \"Literal[('backfill', 'bfill', 'pad', 'ffill', 'nearest')] | None\" = None, copy: 'bool_t | None' = None, limit=None, tolerance=None) -> 'NDFrameT'\n",
      " |      Return an object with matching indices as other object.\n",
      " |      \n",
      " |      Conform the object to the same index on all axes. Optional\n",
      " |      filling logic, placing NaN in locations having no value\n",
      " |      in the previous index. A new object is produced unless the\n",
      " |      new index is equivalent to the current one and copy=False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Object of the same data type\n",
      " |          Its row and column indices are used to define the new indices\n",
      " |          of this object.\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      " |          Method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * backfill / bfill: use next valid observation to fill gap\n",
      " |          * nearest: use nearest valid observations to fill gap.\n",
      " |      \n",
      " |      copy : bool, default True\n",
      " |          Return a new object, even if the passed indexes are the same.\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive labels to fill for inexact matches.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations must\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as caller, but with changed indices on each axis.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Set row labels.\n",
      " |      DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Same as calling\n",
      " |      ``.reindex(index=other.index, columns=other.columns,...)``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame([[24.3, 75.7, 'high'],\n",
      " |      ...                     [31, 87.8, 'high'],\n",
      " |      ...                     [22, 71.6, 'medium'],\n",
      " |      ...                     [35, 95, 'medium']],\n",
      " |      ...                    columns=['temp_celsius', 'temp_fahrenheit',\n",
      " |      ...                             'windspeed'],\n",
      " |      ...                    index=pd.date_range(start='2014-02-12',\n",
      " |      ...                                        end='2014-02-15', freq='D'))\n",
      " |      \n",
      " |      >>> df1\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          24.3             75.7      high\n",
      " |      2014-02-13          31.0             87.8      high\n",
      " |      2014-02-14          22.0             71.6    medium\n",
      " |      2014-02-15          35.0             95.0    medium\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame([[28, 'low'],\n",
      " |      ...                     [30, 'low'],\n",
      " |      ...                     [35.1, 'medium']],\n",
      " |      ...                    columns=['temp_celsius', 'windspeed'],\n",
      " |      ...                    index=pd.DatetimeIndex(['2014-02-12', '2014-02-13',\n",
      " |      ...                                            '2014-02-15']))\n",
      " |      \n",
      " |      >>> df2\n",
      " |                  temp_celsius windspeed\n",
      " |      2014-02-12          28.0       low\n",
      " |      2014-02-13          30.0       low\n",
      " |      2014-02-15          35.1    medium\n",
      " |      \n",
      " |      >>> df2.reindex_like(df1)\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          28.0              NaN       low\n",
      " |      2014-02-13          30.0              NaN       low\n",
      " |      2014-02-14           NaN              NaN       NaN\n",
      " |      2014-02-15          35.1              NaN    medium\n",
      " |  \n",
      " |  rename_axis(self: 'NDFrameT', mapper: 'IndexLabel | lib.NoDefault' = <no_default>, *, index=<no_default>, columns=<no_default>, axis: 'Axis' = 0, copy: 'bool_t | None' = None, inplace: 'bool_t' = False) -> 'NDFrameT | None'\n",
      " |      Set the name of the axis for the index or columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : scalar, list-like, optional\n",
      " |          Value to set the axis name attribute.\n",
      " |      index, columns : scalar, list-like, dict-like or function, optional\n",
      " |          A scalar, list-like, dict-like or functions transformations to\n",
      " |          apply to that axis' values.\n",
      " |          Note that the ``columns`` parameter is not allowed if the\n",
      " |          object is a Series. This parameter only apply for DataFrame\n",
      " |          type objects.\n",
      " |      \n",
      " |          Use either ``mapper`` and ``axis`` to\n",
      " |          specify the axis to target with ``mapper``, or ``index``\n",
      " |          and/or ``columns``.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to rename. For `Series` this parameter is unused and defaults to 0.\n",
      " |      copy : bool, default None\n",
      " |          Also copy underlying data.\n",
      " |      inplace : bool, default False\n",
      " |          Modifies the object directly, instead of creating a new Series\n",
      " |          or DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series, DataFrame, or None\n",
      " |          The same type as the caller or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rename : Alter Series index labels or name.\n",
      " |      DataFrame.rename : Alter DataFrame index labels or name.\n",
      " |      Index.rename : Set new names on index.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      ``DataFrame.rename_axis`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      " |      * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      The first calling convention will only modify the names of\n",
      " |      the index and/or the names of the Index object that is the columns.\n",
      " |      In this case, the parameter ``copy`` is ignored.\n",
      " |      \n",
      " |      The second calling convention will modify the names of the\n",
      " |      corresponding index if mapper is a list or a scalar.\n",
      " |      However, if mapper is dict-like or a function, it will use the\n",
      " |      deprecated behavior of modifying the axis *labels*.\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([\"dog\", \"cat\", \"monkey\"])\n",
      " |      >>> s\n",
      " |      0       dog\n",
      " |      1       cat\n",
      " |      2    monkey\n",
      " |      dtype: object\n",
      " |      >>> s.rename_axis(\"animal\")\n",
      " |      animal\n",
      " |      0    dog\n",
      " |      1    cat\n",
      " |      2    monkey\n",
      " |      dtype: object\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"num_legs\": [4, 4, 2],\n",
      " |      ...                    \"num_arms\": [0, 0, 2]},\n",
      " |      ...                   [\"dog\", \"cat\", \"monkey\"])\n",
      " |      >>> df\n",
      " |              num_legs  num_arms\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      >>> df = df.rename_axis(\"animal\")\n",
      " |      >>> df\n",
      " |              num_legs  num_arms\n",
      " |      animal\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      >>> df = df.rename_axis(\"limbs\", axis=\"columns\")\n",
      " |      >>> df\n",
      " |      limbs   num_legs  num_arms\n",
      " |      animal\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      \n",
      " |      **MultiIndex**\n",
      " |      \n",
      " |      >>> df.index = pd.MultiIndex.from_product([['mammal'],\n",
      " |      ...                                        ['dog', 'cat', 'monkey']],\n",
      " |      ...                                       names=['type', 'name'])\n",
      " |      >>> df\n",
      " |      limbs          num_legs  num_arms\n",
      " |      type   name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |      \n",
      " |      >>> df.rename_axis(index={'type': 'class'})\n",
      " |      limbs          num_legs  num_arms\n",
      " |      class  name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |      \n",
      " |      >>> df.rename_axis(columns=str.upper)\n",
      " |      LIMBS          num_legs  num_arms\n",
      " |      type   name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |  \n",
      " |  rolling(self, window: 'int | dt.timedelta | str | BaseOffset | BaseIndexer', min_periods: 'int | None' = None, center: 'bool_t' = False, win_type: 'str | None' = None, on: 'str | None' = None, axis: 'Axis' = 0, closed: 'str | None' = None, step: 'int | None' = None, method: 'str' = 'single') -> 'Window | Rolling'\n",
      " |      Provide rolling window calculations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      window : int, timedelta, str, offset, or BaseIndexer subclass\n",
      " |          Size of the moving window.\n",
      " |      \n",
      " |          If an integer, the fixed number of observations used for\n",
      " |          each window.\n",
      " |      \n",
      " |          If a timedelta, str, or offset, the time period of each window. Each\n",
      " |          window will be a variable sized based on the observations included in\n",
      " |          the time-period. This is only valid for datetimelike indexes.\n",
      " |          To learn more about the offsets & frequency strings, please see `this link\n",
      " |          <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |          If a BaseIndexer subclass, the window boundaries\n",
      " |          based on the defined ``get_window_bounds`` method. Additional rolling\n",
      " |          keyword arguments, namely ``min_periods``, ``center``, ``closed`` and\n",
      " |          ``step`` will be passed to ``get_window_bounds``.\n",
      " |      \n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value;\n",
      " |          otherwise, result is ``np.nan``.\n",
      " |      \n",
      " |          For a window that is specified by an offset, ``min_periods`` will default to 1.\n",
      " |      \n",
      " |          For a window that is specified by an integer, ``min_periods`` will default\n",
      " |          to the size of the window.\n",
      " |      \n",
      " |      center : bool, default False\n",
      " |          If False, set the window labels as the right edge of the window index.\n",
      " |      \n",
      " |          If True, set the window labels as the center of the window index.\n",
      " |      \n",
      " |      win_type : str, default None\n",
      " |          If ``None``, all points are evenly weighted.\n",
      " |      \n",
      " |          If a string, it must be a valid `scipy.signal window function\n",
      " |          <https://docs.scipy.org/doc/scipy/reference/signal.windows.html#module-scipy.signal.windows>`__.\n",
      " |      \n",
      " |          Certain Scipy window types require additional parameters to be passed\n",
      " |          in the aggregation function. The additional parameters must match\n",
      " |          the keywords specified in the Scipy window type method signature.\n",
      " |      \n",
      " |      on : str, optional\n",
      " |          For a DataFrame, a column label or Index level on which\n",
      " |          to calculate the rolling window, rather than the DataFrame's index.\n",
      " |      \n",
      " |          Provided integer column is ignored and excluded from result since\n",
      " |          an integer index is not used to calculate the rolling window.\n",
      " |      \n",
      " |      axis : int or str, default 0\n",
      " |          If ``0`` or ``'index'``, roll across the rows.\n",
      " |      \n",
      " |          If ``1`` or ``'columns'``, roll across the columns.\n",
      " |      \n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      \n",
      " |      closed : str, default None\n",
      " |          If ``'right'``, the first point in the window is excluded from calculations.\n",
      " |      \n",
      " |          If ``'left'``, the last point in the window is excluded from calculations.\n",
      " |      \n",
      " |          If ``'both'``, the no points in the window are excluded from calculations.\n",
      " |      \n",
      " |          If ``'neither'``, the first and last points in the window are excluded\n",
      " |          from calculations.\n",
      " |      \n",
      " |          Default ``None`` (``'right'``).\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |              The closed parameter with fixed windows is now supported.\n",
      " |      \n",
      " |      step : int, default None\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |      \n",
      " |          Evaluate the window at every ``step`` result, equivalent to slicing as\n",
      " |          ``[::step]``. ``window`` must be an integer. Using a step argument other\n",
      " |          than None or 1 will produce a result with a different shape than the input.\n",
      " |      \n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |      \n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ``Window`` subclass if a ``win_type`` is passed\n",
      " |      \n",
      " |      ``Rolling`` subclass if ``win_type`` is not passed\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      ewm : Provides exponential weighted functions.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See :ref:`Windowing Operations <window.generic>` for further usage details\n",
      " |      and examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      **window**\n",
      " |      \n",
      " |      Rolling sum with a window length of 2 observations.\n",
      " |      \n",
      " |      >>> df.rolling(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Rolling sum with a window span of 2 seconds.\n",
      " |      \n",
      " |      >>> df_time = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
      " |      ...                        index = [pd.Timestamp('20130101 09:00:00'),\n",
      " |      ...                                 pd.Timestamp('20130101 09:00:02'),\n",
      " |      ...                                 pd.Timestamp('20130101 09:00:03'),\n",
      " |      ...                                 pd.Timestamp('20130101 09:00:05'),\n",
      " |      ...                                 pd.Timestamp('20130101 09:00:06')])\n",
      " |      \n",
      " |      >>> df_time\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  2.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      >>> df_time.rolling('2s').sum()\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  3.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      Rolling sum with forward looking windows with 2 observations.\n",
      " |      \n",
      " |      >>> indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=2)\n",
      " |      >>> df.rolling(window=indexer, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  1.0\n",
      " |      1  3.0\n",
      " |      2  2.0\n",
      " |      3  4.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      **min_periods**\n",
      " |      \n",
      " |      Rolling sum with a window length of 2 observations, but only needs a minimum of 1\n",
      " |      observation to calculate a value.\n",
      " |      \n",
      " |      >>> df.rolling(2, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  2.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      **center**\n",
      " |      \n",
      " |      Rolling sum with the result assigned to the center of the window index.\n",
      " |      \n",
      " |      >>> df.rolling(3, min_periods=1, center=True).sum()\n",
      " |           B\n",
      " |      0  1.0\n",
      " |      1  3.0\n",
      " |      2  3.0\n",
      " |      3  6.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.rolling(3, min_periods=1, center=False).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  6.0\n",
      " |      \n",
      " |      **step**\n",
      " |      \n",
      " |      Rolling sum with a window length of 2 observations, minimum of 1 observation to\n",
      " |      calculate a value, and a step of 2.\n",
      " |      \n",
      " |      >>> df.rolling(2, min_periods=1, step=2).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      2  3.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      **win_type**\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, using the Scipy ``'gaussian'``\n",
      " |      window type. ``std`` is required in the aggregation function.\n",
      " |      \n",
      " |      >>> df.rolling(2, win_type='gaussian').sum(std=3)\n",
      " |                B\n",
      " |      0       NaN\n",
      " |      1  0.986207\n",
      " |      2  2.958621\n",
      " |      3       NaN\n",
      " |      4       NaN\n",
      " |      \n",
      " |      **on**\n",
      " |      \n",
      " |      Rolling sum with a window length of 2 days.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'A': [pd.to_datetime('2020-01-01'),\n",
      " |      ...           pd.to_datetime('2020-01-01'),\n",
      " |      ...           pd.to_datetime('2020-01-02'),],\n",
      " |      ...     'B': [1, 2, 3], },\n",
      " |      ...     index=pd.date_range('2020', periods=3))\n",
      " |      \n",
      " |      >>> df\n",
      " |                          A  B\n",
      " |      2020-01-01 2020-01-01  1\n",
      " |      2020-01-02 2020-01-01  2\n",
      " |      2020-01-03 2020-01-02  3\n",
      " |      \n",
      " |      >>> df.rolling('2D', on='A').sum()\n",
      " |                          A    B\n",
      " |      2020-01-01 2020-01-01  1.0\n",
      " |      2020-01-02 2020-01-01  3.0\n",
      " |      2020-01-03 2020-01-02  6.0\n",
      " |  \n",
      " |  sample(self: 'NDFrameT', n: 'int | None' = None, frac: 'float | None' = None, replace: 'bool_t' = False, weights=None, random_state: 'RandomState | None' = None, axis: 'Axis | None' = None, ignore_index: 'bool_t' = False) -> 'NDFrameT'\n",
      " |      Return a random sample of items from an axis of object.\n",
      " |      \n",
      " |      You can use `random_state` for reproducibility.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          Number of items from axis to return. Cannot be used with `frac`.\n",
      " |          Default = 1 if `frac` = None.\n",
      " |      frac : float, optional\n",
      " |          Fraction of axis items to return. Cannot be used with `n`.\n",
      " |      replace : bool, default False\n",
      " |          Allow or disallow sampling of the same row more than once.\n",
      " |      weights : str or ndarray-like, optional\n",
      " |          Default 'None' results in equal probability weighting.\n",
      " |          If passed a Series, will align with target object on index. Index\n",
      " |          values in weights not found in sampled object will be ignored and\n",
      " |          index values in sampled object not in weights will be assigned\n",
      " |          weights of zero.\n",
      " |          If called on a DataFrame, will accept the name of a column\n",
      " |          when axis = 0.\n",
      " |          Unless weights are a Series, weights must be same length as axis\n",
      " |          being sampled.\n",
      " |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      " |          Missing values in the weights column will be treated as zero.\n",
      " |          Infinite values not allowed.\n",
      " |      random_state : int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional\n",
      " |          If int, array-like, or BitGenerator, seed for random number generator.\n",
      " |          If np.random.RandomState or np.random.Generator, use as given.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |      \n",
      " |              array-like and BitGenerator object now passed to np.random.RandomState()\n",
      " |              as seed\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0\n",
      " |      \n",
      " |              np.random.Generator objects now accepted\n",
      " |      \n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default None\n",
      " |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      " |          for given data type. For `Series` this parameter is unused and defaults to `None`.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting index will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A new object of same type as caller containing `n` items randomly\n",
      " |          sampled from the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrameGroupBy.sample: Generates random samples from each group of a\n",
      " |          DataFrame object.\n",
      " |      SeriesGroupBy.sample: Generates random samples from each group of a\n",
      " |          Series object.\n",
      " |      numpy.random.choice: Generates a random sample from a given 1-D numpy\n",
      " |          array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If `frac` > 1, `replacement` should be set to `True`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4, 8, 0],\n",
      " |      ...                    'num_wings': [2, 0, 0, 0],\n",
      " |      ...                    'num_specimen_seen': [10, 2, 1, 8]},\n",
      " |      ...                   index=['falcon', 'dog', 'spider', 'fish'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      falcon         2          2                 10\n",
      " |      dog            4          0                  2\n",
      " |      spider         8          0                  1\n",
      " |      fish           0          0                  8\n",
      " |      \n",
      " |      Extract 3 random elements from the ``Series`` ``df['num_legs']``:\n",
      " |      Note that we use `random_state` to ensure the reproducibility of\n",
      " |      the examples.\n",
      " |      \n",
      " |      >>> df['num_legs'].sample(n=3, random_state=1)\n",
      " |      fish      0\n",
      " |      spider    8\n",
      " |      falcon    2\n",
      " |      Name: num_legs, dtype: int64\n",
      " |      \n",
      " |      A random 50% sample of the ``DataFrame`` with replacement:\n",
      " |      \n",
      " |      >>> df.sample(frac=0.5, replace=True, random_state=1)\n",
      " |            num_legs  num_wings  num_specimen_seen\n",
      " |      dog          4          0                  2\n",
      " |      fish         0          0                  8\n",
      " |      \n",
      " |      An upsample sample of the ``DataFrame`` with replacement:\n",
      " |      Note that `replace` parameter has to be `True` for `frac` parameter > 1.\n",
      " |      \n",
      " |      >>> df.sample(frac=2, replace=True, random_state=1)\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      dog            4          0                  2\n",
      " |      fish           0          0                  8\n",
      " |      falcon         2          2                 10\n",
      " |      falcon         2          2                 10\n",
      " |      fish           0          0                  8\n",
      " |      dog            4          0                  2\n",
      " |      fish           0          0                  8\n",
      " |      dog            4          0                  2\n",
      " |      \n",
      " |      Using a DataFrame column as weights. Rows with larger value in the\n",
      " |      `num_specimen_seen` column are more likely to be sampled.\n",
      " |      \n",
      " |      >>> df.sample(n=2, weights='num_specimen_seen', random_state=1)\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      falcon         2          2                 10\n",
      " |      fish           0          0                  8\n",
      " |  \n",
      " |  set_flags(self: 'NDFrameT', *, copy: 'bool_t' = False, allows_duplicate_labels: 'bool_t | None' = None) -> 'NDFrameT'\n",
      " |      Return a new object with updated flags.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : bool, default False\n",
      " |          Specify if a copy of the object should be made.\n",
      " |      allows_duplicate_labels : bool, optional\n",
      " |          Whether the returned object allows duplicate labels.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          The same type as the caller.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.attrs : Global metadata applying to this dataset.\n",
      " |      DataFrame.flags : Global flags applying to this object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method returns a new object that's a view on the same data\n",
      " |      as the input. Mutating the input or the output values will be reflected\n",
      " |      in the other.\n",
      " |      \n",
      " |      This method is intended to be used in method chains.\n",
      " |      \n",
      " |      \"Flags\" differ from \"metadata\". Flags reflect properties of the\n",
      " |      pandas object (the Series or DataFrame). Metadata refer to properties\n",
      " |      of the dataset, and should be stored in :attr:`DataFrame.attrs`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2]})\n",
      " |      >>> df.flags.allows_duplicate_labels\n",
      " |      True\n",
      " |      >>> df2 = df.set_flags(allows_duplicate_labels=False)\n",
      " |      >>> df2.flags.allows_duplicate_labels\n",
      " |      False\n",
      " |  \n",
      " |  squeeze(self, axis: 'Axis | None' = None)\n",
      " |      Squeeze 1 dimensional axis objects into scalars.\n",
      " |      \n",
      " |      Series or DataFrames with a single element are squeezed to a scalar.\n",
      " |      DataFrames with a single column or a single row are squeezed to a\n",
      " |      Series. Otherwise the object is unchanged.\n",
      " |      \n",
      " |      This method is most useful when you don't know if your\n",
      " |      object is a Series or DataFrame, but you do know it has just a single\n",
      " |      column. In that case you can safely call `squeeze` to ensure you have a\n",
      " |      Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          A specific axis to squeeze. By default, all length-1 axes are\n",
      " |          squeezed. For `Series` this parameter is unused and defaults to `None`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame, Series, or scalar\n",
      " |          The projection after squeezing `axis` or all the axes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.iloc : Integer-location based indexing for selecting scalars.\n",
      " |      DataFrame.iloc : Integer-location based indexing for selecting Series.\n",
      " |      Series.to_frame : Inverse of DataFrame.squeeze for a\n",
      " |          single-column DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> primes = pd.Series([2, 3, 5, 7])\n",
      " |      \n",
      " |      Slicing might produce a Series with a single value:\n",
      " |      \n",
      " |      >>> even_primes = primes[primes % 2 == 0]\n",
      " |      >>> even_primes\n",
      " |      0    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> even_primes.squeeze()\n",
      " |      2\n",
      " |      \n",
      " |      Squeezing objects with more than one value in every axis does nothing:\n",
      " |      \n",
      " |      >>> odd_primes = primes[primes % 2 == 1]\n",
      " |      >>> odd_primes\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> odd_primes.squeeze()\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Squeezing is even more effective when used with DataFrames.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=['a', 'b'])\n",
      " |      >>> df\n",
      " |         a  b\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      \n",
      " |      Slicing a single column will produce a DataFrame with the columns\n",
      " |      having only one value:\n",
      " |      \n",
      " |      >>> df_a = df[['a']]\n",
      " |      >>> df_a\n",
      " |         a\n",
      " |      0  1\n",
      " |      1  3\n",
      " |      \n",
      " |      So the columns can be squeezed down, resulting in a Series:\n",
      " |      \n",
      " |      >>> df_a.squeeze('columns')\n",
      " |      0    1\n",
      " |      1    3\n",
      " |      Name: a, dtype: int64\n",
      " |      \n",
      " |      Slicing a single row from a single column will produce a single\n",
      " |      scalar DataFrame:\n",
      " |      \n",
      " |      >>> df_0a = df.loc[df.index < 1, ['a']]\n",
      " |      >>> df_0a\n",
      " |         a\n",
      " |      0  1\n",
      " |      \n",
      " |      Squeezing the rows produces a single scalar Series:\n",
      " |      \n",
      " |      >>> df_0a.squeeze('rows')\n",
      " |      a    1\n",
      " |      Name: 0, dtype: int64\n",
      " |      \n",
      " |      Squeezing all axes will project directly into a scalar:\n",
      " |      \n",
      " |      >>> df_0a.squeeze()\n",
      " |      1\n",
      " |  \n",
      " |  swapaxes(self: 'NDFrameT', axis1: 'Axis', axis2: 'Axis', copy: 'bool_t | None' = None) -> 'NDFrameT'\n",
      " |      Interchange axes and swap values axes appropriately.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same as input\n",
      " |  \n",
      " |  tail(self: 'NDFrameT', n: 'int' = 5) -> 'NDFrameT'\n",
      " |      Return the last `n` rows.\n",
      " |      \n",
      " |      This function returns last `n` rows from the object based on\n",
      " |      position. It is useful for quickly verifying data, for example,\n",
      " |      after sorting or appending rows.\n",
      " |      \n",
      " |      For negative values of `n`, this function returns all rows except\n",
      " |      the first `|n|` rows, equivalent to ``df[|n|:]``.\n",
      " |      \n",
      " |      If n is larger than the number of rows, this function returns all rows.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The last `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.head : The first `n` rows of the caller object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the last 5 lines\n",
      " |      \n",
      " |      >>> df.tail()\n",
      " |         animal\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |      \n",
      " |      Viewing the last `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.tail(3)\n",
      " |        animal\n",
      " |      6  shark\n",
      " |      7  whale\n",
      " |      8  zebra\n",
      " |      \n",
      " |      For negative values of `n`\n",
      " |      \n",
      " |      >>> df.tail(-3)\n",
      " |         animal\n",
      " |      3    lion\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |  \n",
      " |  take(self: 'NDFrameT', indices, axis: 'Axis' = 0, **kwargs) -> 'NDFrameT'\n",
      " |      Return the elements in the given *positional* indices along an axis.\n",
      " |      \n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          An array-like containing the elements taken from the object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      " |      ...                    ('parrot', 'bird', 24.0),\n",
      " |      ...                    ('lion', 'mammal', 80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed'],\n",
      " |      ...                   index=[0, 2, 3, 1])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      2  parrot    bird       24.0\n",
      " |      3    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      " |      \n",
      " |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      " |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      " |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      " |      \n",
      " |      >>> df.take([0, 3])\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |      \n",
      " |      >>> df.take([1, 2], axis=1)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      2    bird       24.0\n",
      " |      3  mammal       80.5\n",
      " |      1  mammal        NaN\n",
      " |      \n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |      \n",
      " |      >>> df.take([-1, -2])\n",
      " |           name   class  max_speed\n",
      " |      1  monkey  mammal        NaN\n",
      " |      3    lion  mammal       80.5\n",
      " |  \n",
      " |  to_clipboard(self, excel: 'bool_t' = True, sep: 'str | None' = None, **kwargs) -> 'None'\n",
      " |      Copy object to the system clipboard.\n",
      " |      \n",
      " |      Write a text representation of object to the system clipboard.\n",
      " |      This can be pasted into Excel, for example.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel : bool, default True\n",
      " |          Produce output in a csv format for easy pasting into excel.\n",
      " |      \n",
      " |          - True, use the provided separator for csv pasting.\n",
      " |          - False, write a string representation of the object to the clipboard.\n",
      " |      \n",
      " |      sep : str, default ``'\\t'``\n",
      " |          Field delimiter.\n",
      " |      **kwargs\n",
      " |          These parameters will be passed to DataFrame.to_csv.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_csv : Write a DataFrame to a comma-separated values\n",
      " |          (csv) file.\n",
      " |      read_clipboard : Read text from clipboard and pass to read_csv.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requirements for your platform.\n",
      " |      \n",
      " |        - Linux : `xclip`, or `xsel` (with `PyQt4` modules)\n",
      " |        - Windows : none\n",
      " |        - macOS : none\n",
      " |      \n",
      " |      This method uses the processes developed for the package `pyperclip`. A\n",
      " |      solution to render any output string format is given in the examples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Copy the contents of a DataFrame to the clipboard.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])\n",
      " |      \n",
      " |      >>> df.to_clipboard(sep=',')  # doctest: +SKIP\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # ,A,B,C\n",
      " |      ... # 0,1,2,3\n",
      " |      ... # 1,4,5,6\n",
      " |      \n",
      " |      We can omit the index by passing the keyword `index` and setting\n",
      " |      it to false.\n",
      " |      \n",
      " |      >>> df.to_clipboard(sep=',', index=False)  # doctest: +SKIP\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # A,B,C\n",
      " |      ... # 1,2,3\n",
      " |      ... # 4,5,6\n",
      " |      \n",
      " |      Using the original `pyperclip` package for any string output format.\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |         import pyperclip\n",
      " |         html = df.style.to_html()\n",
      " |         pyperclip.copy(html)\n",
      " |  \n",
      " |  to_csv(self, path_or_buf: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, sep: 'str' = ',', na_rep: 'str' = '', float_format: 'str | Callable | None' = None, columns: 'Sequence[Hashable] | None' = None, header: 'bool_t | list[str]' = True, index: 'bool_t' = True, index_label: 'IndexLabel | None' = None, mode: 'str' = 'w', encoding: 'str | None' = None, compression: 'CompressionOptions' = 'infer', quoting: 'int | None' = None, quotechar: 'str' = '\"', lineterminator: 'str | None' = None, chunksize: 'int | None' = None, date_format: 'str | None' = None, doublequote: 'bool_t' = True, escapechar: 'str | None' = None, decimal: 'str' = '.', errors: 'str' = 'strict', storage_options: 'StorageOptions' = None) -> 'str | None'\n",
      " |      Write object to a comma-separated values (csv) file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing os.PathLike[str]), or file-like\n",
      " |          object implementing a write() function. If None, the result is\n",
      " |          returned as a string. If a non-binary file object is passed, it should\n",
      " |          be opened with `newline=''`, disabling universal newlines. If a binary\n",
      " |          file object is passed, `mode` might need to contain a `'b'`.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |             Support for binary file objects was introduced.\n",
      " |      \n",
      " |      sep : str, default ','\n",
      " |          String of length 1. Field delimiter for the output file.\n",
      " |      na_rep : str, default ''\n",
      " |          Missing data representation.\n",
      " |      float_format : str, Callable, default None\n",
      " |          Format string for floating point numbers. If a Callable is given, it takes\n",
      " |          precedence over other numeric formatting parameters, like decimal.\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of strings is given it is\n",
      " |          assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      index_label : str or sequence, or False, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the object uses MultiIndex. If\n",
      " |          False do not print fields for index names. Use index_label=False\n",
      " |          for easier importing in R.\n",
      " |      mode : str, default 'w'\n",
      " |          Python write mode. The available write modes are the same as\n",
      " |          :py:func:`open`.\n",
      " |      encoding : str, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'utf-8'. `encoding` is not supported if `path_or_buf`\n",
      " |          is a non-binary file object.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path_or_buf' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'tar'``} and other\n",
      " |          key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |              Added support for `.tar` files.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |             May now be a dict with key 'method' as compression mode\n",
      " |             and other entries as additional compression options if\n",
      " |             compression mode is 'zip'.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |      \n",
      " |             Passing compression options as keys in dict is\n",
      " |             supported for compression modes 'gzip', 'bz2', 'zstd', and 'zip'.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |              Compression is supported for binary file objects.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |              Previous versions forwarded dict entries for 'gzip' to\n",
      " |              `gzip.open` instead of `gzip.GzipFile` which prevented\n",
      " |              setting `mtime`.\n",
      " |      \n",
      " |      quoting : optional constant from csv module\n",
      " |          Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      " |          then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      " |          will treat them as non-numeric.\n",
      " |      quotechar : str, default '\\\"'\n",
      " |          String of length 1. Character used to quote fields.\n",
      " |      lineterminator : str, optional\n",
      " |          The newline character or character sequence to use in the output\n",
      " |          file. Defaults to `os.linesep`, which depends on the OS in which\n",
      " |          this method is called ('\\\\n' for linux, '\\\\r\\\\n' for Windows, i.e.).\n",
      " |      \n",
      " |          .. versionchanged:: 1.5.0\n",
      " |      \n",
      " |              Previously was line_terminator, changed for consistency with\n",
      " |              read_csv and the standard library 'csv' module.\n",
      " |      \n",
      " |      chunksize : int or None\n",
      " |          Rows to write at a time.\n",
      " |      date_format : str, default None\n",
      " |          Format string for datetime objects.\n",
      " |      doublequote : bool, default True\n",
      " |          Control quoting of `quotechar` inside a field.\n",
      " |      escapechar : str, default None\n",
      " |          String of length 1. Character used to escape `sep` and `quotechar`\n",
      " |          when appropriate.\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator. E.g. use ',' for\n",
      " |          European data.\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If path_or_buf is None, returns the resulting csv format as a\n",
      " |          string. Otherwise returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_csv : Load a CSV file into a DataFrame.\n",
      " |      to_excel : Write DataFrame to an Excel file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      " |      ...                    'mask': ['red', 'purple'],\n",
      " |      ...                    'weapon': ['sai', 'bo staff']})\n",
      " |      >>> df.to_csv(index=False)\n",
      " |      'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
      " |      \n",
      " |      Create 'out.zip' containing 'out.csv'\n",
      " |      \n",
      " |      >>> compression_opts = dict(method='zip',\n",
      " |      ...                         archive_name='out.csv')  # doctest: +SKIP\n",
      " |      >>> df.to_csv('out.zip', index=False,\n",
      " |      ...           compression=compression_opts)  # doctest: +SKIP\n",
      " |      \n",
      " |      To write a csv file to a new folder or nested folder you will first\n",
      " |      need to create it using either Pathlib or os:\n",
      " |      \n",
      " |      >>> from pathlib import Path  # doctest: +SKIP\n",
      " |      >>> filepath = Path('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      " |      >>> filepath.parent.mkdir(parents=True, exist_ok=True)  # doctest: +SKIP\n",
      " |      >>> df.to_csv(filepath)  # doctest: +SKIP\n",
      " |      \n",
      " |      >>> import os  # doctest: +SKIP\n",
      " |      >>> os.makedirs('folder/subfolder', exist_ok=True)  # doctest: +SKIP\n",
      " |      >>> df.to_csv('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      " |  \n",
      " |  to_excel(self, excel_writer, sheet_name: 'str' = 'Sheet1', na_rep: 'str' = '', float_format: 'str | None' = None, columns: 'Sequence[Hashable] | None' = None, header: 'Sequence[Hashable] | bool_t' = True, index: 'bool_t' = True, index_label: 'IndexLabel' = None, startrow: 'int' = 0, startcol: 'int' = 0, engine: 'str | None' = None, merge_cells: 'bool_t' = True, inf_rep: 'str' = 'inf', freeze_panes: 'tuple[int, int] | None' = None, storage_options: 'StorageOptions' = None) -> 'None'\n",
      " |      Write object to an Excel sheet.\n",
      " |      \n",
      " |      To write a single object to an Excel .xlsx file it is only necessary to\n",
      " |      specify a target file name. To write to multiple sheets it is necessary to\n",
      " |      create an `ExcelWriter` object with a target file name, and specify a sheet\n",
      " |      in the file to write to.\n",
      " |      \n",
      " |      Multiple sheets may be written to by specifying unique `sheet_name`.\n",
      " |      With all data written to the file it is necessary to save the changes.\n",
      " |      Note that creating an `ExcelWriter` object with a file name that already\n",
      " |      exists will result in the contents of the existing file being erased.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel_writer : path-like, file-like, or ExcelWriter object\n",
      " |          File path or existing ExcelWriter.\n",
      " |      sheet_name : str, default 'Sheet1'\n",
      " |          Name of sheet which will contain DataFrame.\n",
      " |      na_rep : str, default ''\n",
      " |          Missing data representation.\n",
      " |      float_format : str, optional\n",
      " |          Format string for floating point numbers. For example\n",
      " |          ``float_format=\"%.2f\"`` will format 0.1234 to 0.12.\n",
      " |      columns : sequence or list of str, optional\n",
      " |          Columns to write.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of string is given it is\n",
      " |          assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      index_label : str or sequence, optional\n",
      " |          Column label for index column(s) if desired. If not specified, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      startrow : int, default 0\n",
      " |          Upper left cell row to dump data frame.\n",
      " |      startcol : int, default 0\n",
      " |          Upper left cell column to dump data frame.\n",
      " |      engine : str, optional\n",
      " |          Write engine to use, 'openpyxl' or 'xlsxwriter'. You can also set this\n",
      " |          via the options ``io.excel.xlsx.writer`` or\n",
      " |          ``io.excel.xlsm.writer``.\n",
      " |      \n",
      " |      merge_cells : bool, default True\n",
      " |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      " |      inf_rep : str, default 'inf'\n",
      " |          Representation for infinity (there is no native representation for\n",
      " |          infinity in Excel).\n",
      " |      freeze_panes : tuple of int (length 2), optional\n",
      " |          Specifies the one-based bottommost row and rightmost column that\n",
      " |          is to be frozen.\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      " |      ExcelWriter : Class for writing DataFrame objects into excel sheets.\n",
      " |      read_excel : Read an Excel file into a pandas DataFrame.\n",
      " |      read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      " |      io.formats.style.Styler.to_excel : Add styles to Excel sheet.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For compatibility with :meth:`~DataFrame.to_csv`,\n",
      " |      to_excel serializes lists and dicts to strings before writing.\n",
      " |      \n",
      " |      Once a workbook has been saved it is not possible to write further\n",
      " |      data without rewriting the whole workbook.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create, write to and save a workbook:\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      " |      ...                    index=['row 1', 'row 2'],\n",
      " |      ...                    columns=['col 1', 'col 2'])\n",
      " |      >>> df1.to_excel(\"output.xlsx\")  # doctest: +SKIP\n",
      " |      \n",
      " |      To specify the sheet name:\n",
      " |      \n",
      " |      >>> df1.to_excel(\"output.xlsx\",\n",
      " |      ...              sheet_name='Sheet_name_1')  # doctest: +SKIP\n",
      " |      \n",
      " |      If you wish to write to more than one sheet in the workbook, it is\n",
      " |      necessary to specify an ExcelWriter object:\n",
      " |      \n",
      " |      >>> df2 = df1.copy()\n",
      " |      >>> with pd.ExcelWriter('output.xlsx') as writer:  # doctest: +SKIP\n",
      " |      ...     df1.to_excel(writer, sheet_name='Sheet_name_1')\n",
      " |      ...     df2.to_excel(writer, sheet_name='Sheet_name_2')\n",
      " |      \n",
      " |      ExcelWriter can also be used to append to an existing Excel file:\n",
      " |      \n",
      " |      >>> with pd.ExcelWriter('output.xlsx',\n",
      " |      ...                     mode='a') as writer:  # doctest: +SKIP\n",
      " |      ...     df.to_excel(writer, sheet_name='Sheet_name_3')\n",
      " |      \n",
      " |      To set the library that is used to write the Excel file,\n",
      " |      you can pass the `engine` keyword (the default engine is\n",
      " |      automatically chosen depending on the file extension):\n",
      " |      \n",
      " |      >>> df1.to_excel('output1.xlsx', engine='xlsxwriter')  # doctest: +SKIP\n",
      " |  \n",
      " |  to_hdf(self, path_or_buf: 'FilePath | HDFStore', key: 'str', mode: 'str' = 'a', complevel: 'int | None' = None, complib: 'str | None' = None, append: 'bool_t' = False, format: 'str | None' = None, index: 'bool_t' = True, min_itemsize: 'int | dict[str, int] | None' = None, nan_rep=None, dropna: 'bool_t | None' = None, data_columns: 'Literal[True] | list[str] | None' = None, errors: 'str' = 'strict', encoding: 'str' = 'UTF-8') -> 'None'\n",
      " |      Write the contained data to an HDF5 file using HDFStore.\n",
      " |      \n",
      " |      Hierarchical Data Format (HDF) is self-describing, allowing an\n",
      " |      application to interpret the structure and contents of a file with\n",
      " |      no outside information. One HDF file can hold a mix of related objects\n",
      " |      which can be accessed as a group or as individual objects.\n",
      " |      \n",
      " |      In order to add another DataFrame or Series to an existing HDF file\n",
      " |      please use append mode and a different a key.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         One can store a subclass of ``DataFrame`` or ``Series`` to HDF5,\n",
      " |         but the type of the subclass is lost upon storing.\n",
      " |      \n",
      " |      For more information see the :ref:`user guide <io.hdf5>`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or pandas.HDFStore\n",
      " |          File path or HDFStore object.\n",
      " |      key : str\n",
      " |          Identifier for the group in the store.\n",
      " |      mode : {'a', 'w', 'r+'}, default 'a'\n",
      " |          Mode to open file:\n",
      " |      \n",
      " |          - 'w': write, a new file is created (an existing file with\n",
      " |            the same name would be deleted).\n",
      " |          - 'a': append, an existing file is opened for reading and\n",
      " |            writing, and if the file does not exist it is created.\n",
      " |          - 'r+': similar to 'a', but the file must already exist.\n",
      " |      complevel : {0-9}, default None\n",
      " |          Specifies a compression level for data.\n",
      " |          A value of 0 or None disables compression.\n",
      " |      complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'\n",
      " |          Specifies the compression library to be used.\n",
      " |          As of v0.20.2 these additional compressors for Blosc are supported\n",
      " |          (default if no compressor specified: 'blosc:blosclz'):\n",
      " |          {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      " |          'blosc:zlib', 'blosc:zstd'}.\n",
      " |          Specifying a compression library which is not available issues\n",
      " |          a ValueError.\n",
      " |      append : bool, default False\n",
      " |          For Table formats, append the input data to the existing.\n",
      " |      format : {'fixed', 'table', None}, default 'fixed'\n",
      " |          Possible values:\n",
      " |      \n",
      " |          - 'fixed': Fixed format. Fast writing/reading. Not-appendable,\n",
      " |            nor searchable.\n",
      " |          - 'table': Table format. Write as a PyTables Table structure\n",
      " |            which may perform worse but allow more flexible operations\n",
      " |            like searching / selecting subsets of the data.\n",
      " |          - If None, pd.get_option('io.hdf.default_format') is checked,\n",
      " |            followed by fallback to \"fixed\".\n",
      " |      index : bool, default True\n",
      " |          Write DataFrame index as a column.\n",
      " |      min_itemsize : dict or int, optional\n",
      " |          Map column names to minimum string sizes for columns.\n",
      " |      nan_rep : Any, optional\n",
      " |          How to represent null values as str.\n",
      " |          Not allowed with append=True.\n",
      " |      dropna : bool, default False, optional\n",
      " |          Remove missing values.\n",
      " |      data_columns : list of columns or True, optional\n",
      " |          List of columns to create as indexed data columns for on-disk\n",
      " |          queries, or True to use all columns. By default only the axes\n",
      " |          of the object are indexed. See\n",
      " |          :ref:`Query via data columns<io.hdf5-query-data-columns>`. for\n",
      " |          more information.\n",
      " |          Applicable only to format='table'.\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |      encoding : str, default \"UTF-8\"\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_hdf : Read from HDF file.\n",
      " |      DataFrame.to_orc : Write a DataFrame to the binary orc format.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      DataFrame.to_sql : Write to a SQL table.\n",
      " |      DataFrame.to_feather : Write out feather-format for DataFrames.\n",
      " |      DataFrame.to_csv : Write out to a csv file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},\n",
      " |      ...                   index=['a', 'b', 'c'])  # doctest: +SKIP\n",
      " |      >>> df.to_hdf('data.h5', key='df', mode='w')  # doctest: +SKIP\n",
      " |      \n",
      " |      We can add another object to the same file:\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4])  # doctest: +SKIP\n",
      " |      >>> s.to_hdf('data.h5', key='s')  # doctest: +SKIP\n",
      " |      \n",
      " |      Reading from HDF file:\n",
      " |      \n",
      " |      >>> pd.read_hdf('data.h5', 'df')  # doctest: +SKIP\n",
      " |      A  B\n",
      " |      a  1  4\n",
      " |      b  2  5\n",
      " |      c  3  6\n",
      " |      >>> pd.read_hdf('data.h5', 's')  # doctest: +SKIP\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  to_json(self, path_or_buf: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, orient: 'str | None' = None, date_format: 'str | None' = None, double_precision: 'int' = 10, force_ascii: 'bool_t' = True, date_unit: 'str' = 'ms', default_handler: 'Callable[[Any], JSONSerializable] | None' = None, lines: 'bool_t' = False, compression: 'CompressionOptions' = 'infer', index: 'bool_t' = True, indent: 'int | None' = None, storage_options: 'StorageOptions' = None, mode: \"Literal[('a', 'w')]\" = 'w') -> 'str | None'\n",
      " |      Convert the object to a JSON string.\n",
      " |      \n",
      " |      Note NaN's and None will be converted to null and datetime objects\n",
      " |      will be converted to UNIX timestamps.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing os.PathLike[str]), or file-like\n",
      " |          object implementing a write() function. If None, the result is\n",
      " |          returned as a string.\n",
      " |      orient : str\n",
      " |          Indication of expected JSON string format.\n",
      " |      \n",
      " |          * Series:\n",
      " |      \n",
      " |              - default is 'index'\n",
      " |              - allowed values are: {'split', 'records', 'index', 'table'}.\n",
      " |      \n",
      " |          * DataFrame:\n",
      " |      \n",
      " |              - default is 'columns'\n",
      " |              - allowed values are: {'split', 'records', 'index', 'columns',\n",
      " |                'values', 'table'}.\n",
      " |      \n",
      " |          * The format of the JSON string:\n",
      " |      \n",
      " |              - 'split' : dict like {'index' -> [index], 'columns' -> [columns],\n",
      " |                'data' -> [values]}\n",
      " |              - 'records' : list like [{column -> value}, ... , {column -> value}]\n",
      " |              - 'index' : dict like {index -> {column -> value}}\n",
      " |              - 'columns' : dict like {column -> {index -> value}}\n",
      " |              - 'values' : just the values array\n",
      " |              - 'table' : dict like {'schema': {schema}, 'data': {data}}\n",
      " |      \n",
      " |              Describing the data, where data component is like ``orient='records'``.\n",
      " |      \n",
      " |      date_format : {None, 'epoch', 'iso'}\n",
      " |          Type of date conversion. 'epoch' = epoch milliseconds,\n",
      " |          'iso' = ISO8601. The default depends on the `orient`. For\n",
      " |          ``orient='table'``, the default is 'iso'. For all other orients,\n",
      " |          the default is 'epoch'.\n",
      " |      double_precision : int, default 10\n",
      " |          The number of decimal places to use when encoding\n",
      " |          floating point values.\n",
      " |      force_ascii : bool, default True\n",
      " |          Force encoded string to be ASCII.\n",
      " |      date_unit : str, default 'ms' (milliseconds)\n",
      " |          The time unit to encode to, governs timestamp and ISO8601\n",
      " |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      " |          microsecond, and nanosecond respectively.\n",
      " |      default_handler : callable, default None\n",
      " |          Handler to call if object cannot otherwise be converted to a\n",
      " |          suitable format for JSON. Should receive a single argument which is\n",
      " |          the object to convert and return a serialisable object.\n",
      " |      lines : bool, default False\n",
      " |          If 'orient' is 'records' write out line-delimited json format. Will\n",
      " |          throw ValueError if incorrect 'orient' since others are not\n",
      " |          list-like.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path_or_buf' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'tar'``} and other\n",
      " |          key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |              Added support for `.tar` files.\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0 Zstandard support.\n",
      " |      \n",
      " |      index : bool, default True\n",
      " |          Whether to include the index values in the JSON string. Not\n",
      " |          including the index (``index=False``) is only supported when\n",
      " |          orient is 'split' or 'table'.\n",
      " |      indent : int, optional\n",
      " |         Length of whitespace used to indent each record.\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      mode : str, default 'w' (writing)\n",
      " |          Specify the IO mode for output when supplying a path_or_buf.\n",
      " |          Accepted args are 'w' (writing) and 'a' (append) only.\n",
      " |          mode='a' is only supported when lines is True and orient is 'records'.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If path_or_buf is None, returns the resulting json format as a\n",
      " |          string. Otherwise returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_json : Convert a JSON string to pandas object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The behavior of ``indent=0`` varies from the stdlib, which does not\n",
      " |      indent the output but does insert newlines. Currently, ``indent=0``\n",
      " |      and the default ``indent=None`` are equivalent in pandas, though this\n",
      " |      may change in a future release.\n",
      " |      \n",
      " |      ``orient='table'`` contains a 'pandas_version' field under 'schema'.\n",
      " |      This stores the version of `pandas` used in the latest revision of the\n",
      " |      schema.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from json import loads, dumps\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     [[\"a\", \"b\"], [\"c\", \"d\"]],\n",
      " |      ...     index=[\"row 1\", \"row 2\"],\n",
      " |      ...     columns=[\"col 1\", \"col 2\"],\n",
      " |      ... )\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"split\")\n",
      " |      >>> parsed = loads(result)\n",
      " |      >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"columns\": [\n",
      " |              \"col 1\",\n",
      " |              \"col 2\"\n",
      " |          ],\n",
      " |          \"index\": [\n",
      " |              \"row 1\",\n",
      " |              \"row 2\"\n",
      " |          ],\n",
      " |          \"data\": [\n",
      " |              [\n",
      " |                  \"a\",\n",
      " |                  \"b\"\n",
      " |              ],\n",
      " |              [\n",
      " |                  \"c\",\n",
      " |                  \"d\"\n",
      " |              ]\n",
      " |          ]\n",
      " |      }\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      " |      Note that index labels are not preserved with this encoding.\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"records\")\n",
      " |      >>> parsed = loads(result)\n",
      " |      >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      [\n",
      " |          {\n",
      " |              \"col 1\": \"a\",\n",
      " |              \"col 2\": \"b\"\n",
      " |          },\n",
      " |          {\n",
      " |              \"col 1\": \"c\",\n",
      " |              \"col 2\": \"d\"\n",
      " |          }\n",
      " |      ]\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"index\")\n",
      " |      >>> parsed = loads(result)\n",
      " |      >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"row 1\": {\n",
      " |              \"col 1\": \"a\",\n",
      " |              \"col 2\": \"b\"\n",
      " |          },\n",
      " |          \"row 2\": {\n",
      " |              \"col 1\": \"c\",\n",
      " |              \"col 2\": \"d\"\n",
      " |          }\n",
      " |      }\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'columns'`` formatted JSON:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"columns\")\n",
      " |      >>> parsed = loads(result)\n",
      " |      >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"col 1\": {\n",
      " |              \"row 1\": \"a\",\n",
      " |              \"row 2\": \"c\"\n",
      " |          },\n",
      " |          \"col 2\": {\n",
      " |              \"row 1\": \"b\",\n",
      " |              \"row 2\": \"d\"\n",
      " |          }\n",
      " |      }\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'values'`` formatted JSON:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"values\")\n",
      " |      >>> parsed = loads(result)\n",
      " |      >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      [\n",
      " |          [\n",
      " |              \"a\",\n",
      " |              \"b\"\n",
      " |          ],\n",
      " |          [\n",
      " |              \"c\",\n",
      " |              \"d\"\n",
      " |          ]\n",
      " |      ]\n",
      " |      \n",
      " |      Encoding with Table Schema:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"table\")\n",
      " |      >>> parsed = loads(result)\n",
      " |      >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"schema\": {\n",
      " |              \"fields\": [\n",
      " |                  {\n",
      " |                      \"name\": \"index\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  },\n",
      " |                  {\n",
      " |                      \"name\": \"col 1\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  },\n",
      " |                  {\n",
      " |                      \"name\": \"col 2\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  }\n",
      " |              ],\n",
      " |              \"primaryKey\": [\n",
      " |                  \"index\"\n",
      " |              ],\n",
      " |              \"pandas_version\": \"1.4.0\"\n",
      " |          },\n",
      " |          \"data\": [\n",
      " |              {\n",
      " |                  \"index\": \"row 1\",\n",
      " |                  \"col 1\": \"a\",\n",
      " |                  \"col 2\": \"b\"\n",
      " |              },\n",
      " |              {\n",
      " |                  \"index\": \"row 2\",\n",
      " |                  \"col 1\": \"c\",\n",
      " |                  \"col 2\": \"d\"\n",
      " |              }\n",
      " |          ]\n",
      " |      }\n",
      " |  \n",
      " |  to_latex(self, buf: 'FilePath | WriteBuffer[str] | None' = None, columns: 'Sequence[Hashable] | None' = None, header: 'bool_t | Sequence[str]' = True, index: 'bool_t' = True, na_rep: 'str' = 'NaN', formatters: 'FormattersType | None' = None, float_format: 'FloatFormatType | None' = None, sparsify: 'bool_t | None' = None, index_names: 'bool_t' = True, bold_rows: 'bool_t' = False, column_format: 'str | None' = None, longtable: 'bool_t | None' = None, escape: 'bool_t | None' = None, encoding: 'str | None' = None, decimal: 'str' = '.', multicolumn: 'bool_t | None' = None, multicolumn_format: 'str | None' = None, multirow: 'bool_t | None' = None, caption: 'str | tuple[str, str] | None' = None, label: 'str | None' = None, position: 'str | None' = None) -> 'str | None'\n",
      " |      Render object to a LaTeX tabular, longtable, or nested table.\n",
      " |      \n",
      " |      Requires ``\\usepackage{{booktabs}}``.  The output can be copy/pasted\n",
      " |      into a main LaTeX document or read from an external file\n",
      " |      with ``\\input{{table.tex}}``.\n",
      " |      \n",
      " |      .. versionchanged:: 1.2.0\n",
      " |         Added position argument, changed meaning of caption argument.\n",
      " |      \n",
      " |      .. versionchanged:: 2.0.0\n",
      " |         Refactored to use the Styler implementation via jinja2 templating.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : list of label, optional\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of strings is given,\n",
      " |          it is assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      na_rep : str, default 'NaN'\n",
      " |          Missing data representation.\n",
      " |      formatters : list of functions or dict of {{str: function}}, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name. The result of each function must be a unicode string.\n",
      " |          List must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function or str, optional, default None\n",
      " |          Formatter for floating point numbers. For example\n",
      " |          ``float_format=\"%.2f\"`` and ``float_format=\"{{:0.2f}}\".format`` will\n",
      " |          both result in 0.1234 being formatted as 0.12.\n",
      " |      sparsify : bool, optional\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row. By default, the value will be\n",
      " |          read from the config module.\n",
      " |      index_names : bool, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      bold_rows : bool, default False\n",
      " |          Make the row labels bold in the output.\n",
      " |      column_format : str, optional\n",
      " |          The columns format as specified in `LaTeX table format\n",
      " |          <https://en.wikibooks.org/wiki/LaTeX/Tables>`__ e.g. 'rcl' for 3\n",
      " |          columns. By default, 'l' will be used for all columns except\n",
      " |          columns of numbers, which default to 'r'.\n",
      " |      longtable : bool, optional\n",
      " |          Use a longtable environment instead of tabular. Requires\n",
      " |          adding a \\usepackage{{longtable}} to your LaTeX preamble.\n",
      " |          By default, the value will be read from the pandas config\n",
      " |          module, and set to `True` if the option ``styler.latex.environment`` is\n",
      " |          `\"longtable\"`.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |             The pandas option affecting this argument has changed.\n",
      " |      escape : bool, optional\n",
      " |          By default, the value will be read from the pandas config\n",
      " |          module and set to `True` if the option ``styler.format.escape`` is\n",
      " |          `\"latex\"`. When set to False prevents from escaping latex special\n",
      " |          characters in column names.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |             The pandas option affecting this argument has changed, as has the\n",
      " |             default value to `False`.\n",
      " |      encoding : str, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'utf-8'.\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      multicolumn : bool, default True\n",
      " |          Use \\multicolumn to enhance MultiIndex columns.\n",
      " |          The default will be read from the config module, and is set\n",
      " |          as the option ``styler.sparse.columns``.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |             The pandas option affecting this argument has changed.\n",
      " |      multicolumn_format : str, default 'r'\n",
      " |          The alignment for multicolumns, similar to `column_format`\n",
      " |          The default will be read from the config module, and is set as the option\n",
      " |          ``styler.latex.multicol_align``.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |             The pandas option affecting this argument has changed, as has the\n",
      " |             default value to \"r\".\n",
      " |      multirow : bool, default True\n",
      " |          Use \\multirow to enhance MultiIndex rows. Requires adding a\n",
      " |          \\usepackage{{multirow}} to your LaTeX preamble. Will print\n",
      " |          centered labels (instead of top-aligned) across the contained\n",
      " |          rows, separating groups via clines. The default will be read\n",
      " |          from the pandas config module, and is set as the option\n",
      " |          ``styler.sparse.index``.\n",
      " |      \n",
      " |          .. versionchanged:: 2.0.0\n",
      " |             The pandas option affecting this argument has changed, as has the\n",
      " |             default value to `True`.\n",
      " |      caption : str or tuple, optional\n",
      " |          Tuple (full_caption, short_caption),\n",
      " |          which results in ``\\caption[short_caption]{{full_caption}}``;\n",
      " |          if a single string is passed, no short caption will be set.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |             Optionally allow caption to be a tuple ``(full_caption, short_caption)``.\n",
      " |      \n",
      " |      label : str, optional\n",
      " |          The LaTeX label to be placed inside ``\\label{{}}`` in the output.\n",
      " |          This is used with ``\\ref{{}}`` in the main ``.tex`` file.\n",
      " |      \n",
      " |      position : str, optional\n",
      " |          The LaTeX positional argument for tables, to be placed after\n",
      " |          ``\\begin{{}}`` in the output.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or None\n",
      " |          If buf is None, returns the result as a string. Otherwise returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      io.formats.style.Styler.to_latex : Render a DataFrame to LaTeX\n",
      " |          with conditional formatting.\n",
      " |      DataFrame.to_string : Render a DataFrame to a console-friendly\n",
      " |          tabular output.\n",
      " |      DataFrame.to_html : Render a DataFrame as an HTML table.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      As of v2.0.0 this method has changed to use the Styler implementation as\n",
      " |      part of :meth:`.Styler.to_latex` via ``jinja2`` templating. This means\n",
      " |      that ``jinja2`` is a requirement, and needs to be installed, for this method\n",
      " |      to function. It is advised that users switch to using Styler, since that\n",
      " |      implementation is more frequently updated and contains much more\n",
      " |      flexibility with the output.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Convert a general DataFrame to LaTeX with formatting:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(name=['Raphael', 'Donatello'],\n",
      " |      ...                        age=[26, 45],\n",
      " |      ...                        height=[181.23, 177.65]))\n",
      " |      >>> print(df.to_latex(index=False,\n",
      " |      ...                   formatters={\"name\": str.upper},\n",
      " |      ...                   float_format=\"{:.1f}\".format,\n",
      " |      ... ))  # doctest: +SKIP\n",
      " |      \\begin{tabular}{lrr}\n",
      " |      \\toprule\n",
      " |      name & age & height \\\\\n",
      " |      \\midrule\n",
      " |      RAPHAEL & 26 & 181.2 \\\\\n",
      " |      DONATELLO & 45 & 177.7 \\\\\n",
      " |      \\bottomrule\n",
      " |      \\end{tabular}\n",
      " |  \n",
      " |  to_pickle(self, path: 'FilePath | WriteBuffer[bytes]', compression: 'CompressionOptions' = 'infer', protocol: 'int' = 5, storage_options: 'StorageOptions' = None) -> 'None'\n",
      " |      Pickle (serialize) object to file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, path object, or file-like object\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a binary ``write()`` function. File path where\n",
      " |          the pickled object will be stored.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'tar'``} and other\n",
      " |          key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |      \n",
      " |          .. versionadded:: 1.5.0\n",
      " |              Added support for `.tar` files.\n",
      " |      protocol : int\n",
      " |          Int which indicates which protocol should be used by the pickler,\n",
      " |          default HIGHEST_PROTOCOL (see [1]_ paragraph 12.1.2). The possible\n",
      " |          values are 0, 1, 2, 3, 4, 5. A negative value for the protocol\n",
      " |          parameter is equivalent to setting its value to HIGHEST_PROTOCOL.\n",
      " |      \n",
      " |          .. [1] https://docs.python.org/3/library/pickle.html.\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_pickle : Load pickled pandas object (or any object) from file.\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_sql : Write DataFrame to a SQL database.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> original_df = pd.DataFrame({\"foo\": range(5), \"bar\": range(5, 10)})  # doctest: +SKIP\n",
      " |      >>> original_df  # doctest: +SKIP\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      >>> original_df.to_pickle(\"./dummy.pkl\")  # doctest: +SKIP\n",
      " |      \n",
      " |      >>> unpickled_df = pd.read_pickle(\"./dummy.pkl\")  # doctest: +SKIP\n",
      " |      >>> unpickled_df  # doctest: +SKIP\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |  \n",
      " |  to_sql(self, name: 'str', con, schema: 'str | None' = None, if_exists: \"Literal[('fail', 'replace', 'append')]\" = 'fail', index: 'bool_t' = True, index_label: 'IndexLabel' = None, chunksize: 'int | None' = None, dtype: 'DtypeArg | None' = None, method: 'str | None' = None) -> 'int | None'\n",
      " |      Write records stored in a DataFrame to a SQL database.\n",
      " |      \n",
      " |      Databases supported by SQLAlchemy [1]_ are supported. Tables can be\n",
      " |      newly created, appended to, or overwritten.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : str\n",
      " |          Name of SQL table.\n",
      " |      con : sqlalchemy.engine.(Engine or Connection) or sqlite3.Connection\n",
      " |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      " |          library. Legacy support is provided for sqlite3.Connection objects. The user\n",
      " |          is responsible for engine disposal and connection closure for the SQLAlchemy\n",
      " |          connectable. See `here                 <https://docs.sqlalchemy.org/en/20/core/connections.html>`_.\n",
      " |          If passing a sqlalchemy.engine.Connection which is already in a transaction,\n",
      " |          the transaction will not be committed.  If passing a sqlite3.Connection,\n",
      " |          it will not be possible to roll back the record insertion.\n",
      " |      \n",
      " |      schema : str, optional\n",
      " |          Specify the schema (if database flavor supports this). If None, use\n",
      " |          default schema.\n",
      " |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      " |          How to behave if the table already exists.\n",
      " |      \n",
      " |          * fail: Raise a ValueError.\n",
      " |          * replace: Drop the table before inserting new values.\n",
      " |          * append: Insert new values to the existing table.\n",
      " |      \n",
      " |      index : bool, default True\n",
      " |          Write DataFrame index as a column. Uses `index_label` as the column\n",
      " |          name in the table.\n",
      " |      index_label : str or sequence, default None\n",
      " |          Column label for index column(s). If None is given (default) and\n",
      " |          `index` is True, then the index names are used.\n",
      " |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      chunksize : int, optional\n",
      " |          Specify the number of rows in each batch to be written at a time.\n",
      " |          By default, all rows will be written at once.\n",
      " |      dtype : dict or scalar, optional\n",
      " |          Specifying the datatype for columns. If a dictionary is used, the\n",
      " |          keys should be the column names and the values should be the\n",
      " |          SQLAlchemy types or strings for the sqlite3 legacy mode. If a\n",
      " |          scalar is provided, it will be applied to all columns.\n",
      " |      method : {None, 'multi', callable}, optional\n",
      " |          Controls the SQL insertion clause used:\n",
      " |      \n",
      " |          * None : Uses standard SQL ``INSERT`` clause (one per row).\n",
      " |          * 'multi': Pass multiple values in a single ``INSERT`` clause.\n",
      " |          * callable with signature ``(pd_table, conn, keys, data_iter)``.\n",
      " |      \n",
      " |          Details and a sample callable implementation can be found in the\n",
      " |          section :ref:`insert method <io.sql.method>`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or int\n",
      " |          Number of rows affected by to_sql. None is returned if the callable\n",
      " |          passed into ``method`` does not return an integer number of rows.\n",
      " |      \n",
      " |          The number of returned rows affected is the sum of the ``rowcount``\n",
      " |          attribute of ``sqlite3.Cursor`` or SQLAlchemy connectable which may not\n",
      " |          reflect the exact number of written rows as stipulated in the\n",
      " |          `sqlite3 <https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.rowcount>`__ or\n",
      " |          `SQLAlchemy <https://docs.sqlalchemy.org/en/20/core/connections.html#sqlalchemy.engine.CursorResult.rowcount>`__.\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When the table already exists and `if_exists` is 'fail' (the\n",
      " |          default).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_sql : Read a DataFrame from a table.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Timezone aware datetime columns will be written as\n",
      " |      ``Timestamp with timezone`` type with SQLAlchemy if supported by the\n",
      " |      database. Otherwise, the datetimes will be stored as timezone unaware\n",
      " |      timestamps local to the original timezone.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://docs.sqlalchemy.org\n",
      " |      .. [2] https://www.python.org/dev/peps/pep-0249/\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create an in-memory SQLite database.\n",
      " |      \n",
      " |      >>> from sqlalchemy import create_engine\n",
      " |      >>> engine = create_engine('sqlite://', echo=False)\n",
      " |      \n",
      " |      Create a table from scratch with 3 rows.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
      " |      >>> df\n",
      " |           name\n",
      " |      0  User 1\n",
      " |      1  User 2\n",
      " |      2  User 3\n",
      " |      \n",
      " |      >>> df.to_sql('users', con=engine)\n",
      " |      3\n",
      " |      >>> from sqlalchemy import text\n",
      " |      >>> with engine.connect() as conn:\n",
      " |      ...    conn.execute(text(\"SELECT * FROM users\")).fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]\n",
      " |      \n",
      " |      An `sqlalchemy.engine.Connection` can also be passed to `con`:\n",
      " |      \n",
      " |      >>> with engine.begin() as connection:\n",
      " |      ...     df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})\n",
      " |      ...     df1.to_sql('users', con=connection, if_exists='append')\n",
      " |      2\n",
      " |      \n",
      " |      This is allowed to support operations that require that the same\n",
      " |      DBAPI connection is used for the entire operation.\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame({'name' : ['User 6', 'User 7']})\n",
      " |      >>> df2.to_sql('users', con=engine, if_exists='append')\n",
      " |      2\n",
      " |      >>> with engine.connect() as conn:\n",
      " |      ...    conn.execute(text(\"SELECT * FROM users\")).fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),\n",
      " |       (0, 'User 4'), (1, 'User 5'), (0, 'User 6'),\n",
      " |       (1, 'User 7')]\n",
      " |      \n",
      " |      Overwrite the table with just ``df2``.\n",
      " |      \n",
      " |      >>> df2.to_sql('users', con=engine, if_exists='replace',\n",
      " |      ...            index_label='id')\n",
      " |      2\n",
      " |      >>> with engine.connect() as conn:\n",
      " |      ...    conn.execute(text(\"SELECT * FROM users\")).fetchall()\n",
      " |      [(0, 'User 6'), (1, 'User 7')]\n",
      " |      \n",
      " |      Specify the dtype (especially useful for integers with missing values).\n",
      " |      Notice that while pandas is forced to store the data as floating point,\n",
      " |      the database supports nullable integers. When fetching the data with\n",
      " |      Python, we get back integer scalars.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, None, 2]})\n",
      " |      >>> df\n",
      " |           A\n",
      " |      0  1.0\n",
      " |      1  NaN\n",
      " |      2  2.0\n",
      " |      \n",
      " |      >>> from sqlalchemy.types import Integer\n",
      " |      >>> df.to_sql('integers', con=engine, index=False,\n",
      " |      ...           dtype={\"A\": Integer()})\n",
      " |      3\n",
      " |      \n",
      " |      >>> with engine.connect() as conn:\n",
      " |      ...   conn.execute(text(\"SELECT * FROM integers\")).fetchall()\n",
      " |      [(1,), (None,), (2,)]\n",
      " |  \n",
      " |  to_xarray(self)\n",
      " |      Return an xarray object from the pandas object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      xarray.DataArray or xarray.Dataset\n",
      " |          Data in the pandas structure converted to Dataset if the object is\n",
      " |          a DataFrame, or a DataArray if the object is a Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `xarray docs <https://xarray.pydata.org/en/stable/>`__\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0, 2),\n",
      " |      ...                    ('parrot', 'bird', 24.0, 2),\n",
      " |      ...                    ('lion', 'mammal', 80.5, 4),\n",
      " |      ...                    ('monkey', 'mammal', np.nan, 4)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed',\n",
      " |      ...                            'num_legs'])\n",
      " |      >>> df\n",
      " |           name   class  max_speed  num_legs\n",
      " |      0  falcon    bird      389.0         2\n",
      " |      1  parrot    bird       24.0         2\n",
      " |      2    lion  mammal       80.5         4\n",
      " |      3  monkey  mammal        NaN         4\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:    (index: 4)\n",
      " |      Coordinates:\n",
      " |        * index      (index) int64 0 1 2 3\n",
      " |      Data variables:\n",
      " |          name       (index) object 'falcon' 'parrot' 'lion' 'monkey'\n",
      " |          class      (index) object 'bird' 'bird' 'mammal' 'mammal'\n",
      " |          max_speed  (index) float64 389.0 24.0 80.5 nan\n",
      " |          num_legs   (index) int64 2 2 4 4\n",
      " |      \n",
      " |      >>> df['max_speed'].to_xarray()\n",
      " |      <xarray.DataArray 'max_speed' (index: 4)>\n",
      " |      array([389. ,  24. ,  80.5,   nan])\n",
      " |      Coordinates:\n",
      " |        * index    (index) int64 0 1 2 3\n",
      " |      \n",
      " |      >>> dates = pd.to_datetime(['2018-01-01', '2018-01-01',\n",
      " |      ...                         '2018-01-02', '2018-01-02'])\n",
      " |      >>> df_multiindex = pd.DataFrame({'date': dates,\n",
      " |      ...                               'animal': ['falcon', 'parrot',\n",
      " |      ...                                          'falcon', 'parrot'],\n",
      " |      ...                               'speed': [350, 18, 361, 15]})\n",
      " |      >>> df_multiindex = df_multiindex.set_index(['date', 'animal'])\n",
      " |      \n",
      " |      >>> df_multiindex\n",
      " |                         speed\n",
      " |      date       animal\n",
      " |      2018-01-01 falcon    350\n",
      " |                 parrot     18\n",
      " |      2018-01-02 falcon    361\n",
      " |                 parrot     15\n",
      " |      \n",
      " |      >>> df_multiindex.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (date: 2, animal: 2)\n",
      " |      Coordinates:\n",
      " |        * date     (date) datetime64[ns] 2018-01-01 2018-01-02\n",
      " |        * animal   (animal) object 'falcon' 'parrot'\n",
      " |      Data variables:\n",
      " |          speed    (date, animal) int64 350 18 361 15\n",
      " |  \n",
      " |  truncate(self: 'NDFrameT', before=None, after=None, axis: 'Axis | None' = None, copy: 'bool_t | None' = None) -> 'NDFrameT'\n",
      " |      Truncate a Series or DataFrame before and after some index value.\n",
      " |      \n",
      " |      This is a useful shorthand for boolean indexing based on index\n",
      " |      values above or below certain thresholds.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      before : date, str, int\n",
      " |          Truncate all rows before this index value.\n",
      " |      after : date, str, int\n",
      " |          Truncate all rows after this index value.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, optional\n",
      " |          Axis to truncate. Truncates the index (rows) by default.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      copy : bool, default is True,\n",
      " |          Return a copy of the truncated section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The truncated Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by label.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by position.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the index being truncated contains only datetime values,\n",
      " |      `before` and `after` may be specified as strings instead of\n",
      " |      Timestamps.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],\n",
      " |      ...                    'B': ['f', 'g', 'h', 'i', 'j'],\n",
      " |      ...                    'C': ['k', 'l', 'm', 'n', 'o']},\n",
      " |      ...                   index=[1, 2, 3, 4, 5])\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      1  a  f  k\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      5  e  j  o\n",
      " |      \n",
      " |      >>> df.truncate(before=2, after=4)\n",
      " |         A  B  C\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      \n",
      " |      The columns of a DataFrame can be truncated.\n",
      " |      \n",
      " |      >>> df.truncate(before=\"A\", after=\"B\", axis=\"columns\")\n",
      " |         A  B\n",
      " |      1  a  f\n",
      " |      2  b  g\n",
      " |      3  c  h\n",
      " |      4  d  i\n",
      " |      5  e  j\n",
      " |      \n",
      " |      For Series, only rows can be truncated.\n",
      " |      \n",
      " |      >>> df['A'].truncate(before=2, after=4)\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    d\n",
      " |      Name: A, dtype: object\n",
      " |      \n",
      " |      The index values in ``truncate`` can be datetimes or string\n",
      " |      dates.\n",
      " |      \n",
      " |      >>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')\n",
      " |      >>> df = pd.DataFrame(index=dates, data={'A': 1})\n",
      " |      >>> df.tail()\n",
      " |                           A\n",
      " |      2016-01-31 23:59:56  1\n",
      " |      2016-01-31 23:59:57  1\n",
      " |      2016-01-31 23:59:58  1\n",
      " |      2016-01-31 23:59:59  1\n",
      " |      2016-02-01 00:00:00  1\n",
      " |      \n",
      " |      >>> df.truncate(before=pd.Timestamp('2016-01-05'),\n",
      " |      ...             after=pd.Timestamp('2016-01-10')).tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Because the index is a DatetimeIndex containing only dates, we can\n",
      " |      specify `before` and `after` as strings. They will be coerced to\n",
      " |      Timestamps before truncation.\n",
      " |      \n",
      " |      >>> df.truncate('2016-01-05', '2016-01-10').tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Note that ``truncate`` assumes a 0 value for any unspecified time\n",
      " |      component (midnight). This differs from partial string slicing, which\n",
      " |      returns any partially matching dates.\n",
      " |      \n",
      " |      >>> df.loc['2016-01-05':'2016-01-10', :].tail()\n",
      " |                           A\n",
      " |      2016-01-10 23:59:55  1\n",
      " |      2016-01-10 23:59:56  1\n",
      " |      2016-01-10 23:59:57  1\n",
      " |      2016-01-10 23:59:58  1\n",
      " |      2016-01-10 23:59:59  1\n",
      " |  \n",
      " |  tz_convert(self: 'NDFrameT', tz, axis: 'Axis' = 0, level=None, copy: 'bool_t | None' = None) -> 'NDFrameT'\n",
      " |      Convert tz-aware axis to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str or tzinfo object or None\n",
      " |          Target time zone. Passing ``None`` will convert to\n",
      " |          UTC and remove the timezone information.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to convert\n",
      " |      level : int, str, default None\n",
      " |          If axis is a MultiIndex, convert a specific level. Otherwise\n",
      " |          must be None.\n",
      " |      copy : bool, default True\n",
      " |          Also make a copy of the underlying data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame\n",
      " |          Object with time zone converted axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the axis is tz-naive.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Change to another time zone:\n",
      " |      \n",
      " |      >>> s = pd.Series(\n",
      " |      ...     [1],\n",
      " |      ...     index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']),\n",
      " |      ... )\n",
      " |      >>> s.tz_convert('Asia/Shanghai')\n",
      " |      2018-09-15 07:30:00+08:00    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Pass None to convert to UTC and get a tz-naive index:\n",
      " |      \n",
      " |      >>> s = pd.Series([1],\n",
      " |      ...     index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']))\n",
      " |      >>> s.tz_convert(None)\n",
      " |      2018-09-14 23:30:00    1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  tz_localize(self: 'NDFrameT', tz, axis: 'Axis' = 0, level=None, copy: 'bool_t | None' = None, ambiguous: 'TimeAmbiguous' = 'raise', nonexistent: 'TimeNonexistent' = 'raise') -> 'NDFrameT'\n",
      " |      Localize tz-naive index of a Series or DataFrame to target time zone.\n",
      " |      \n",
      " |      This operation localizes the Index. To localize the values in a\n",
      " |      timezone-naive Series, use :meth:`Series.dt.tz_localize`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str or tzinfo or None\n",
      " |          Time zone to localize. Passing ``None`` will remove the\n",
      " |          time zone information and preserve local time.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to localize\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      " |          must be None.\n",
      " |      copy : bool, default True\n",
      " |          Also make a copy of the underlying data.\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          When clocks moved backward due to DST, ambiguous times may arise.\n",
      " |          For example in Central European Time (UTC+01), when going from\n",
      " |          03:00 DST to 02:00 non-DST, 02:30:00 local time occurs both at\n",
      " |          00:30:00 UTC and at 01:30:00 UTC. In such a situation, the\n",
      " |          `ambiguous` parameter dictates how ambiguous times should be\n",
      " |          handled.\n",
      " |      \n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times.\n",
      " |      nonexistent : str, default 'raise'\n",
      " |          A nonexistent time does not exist in a particular timezone\n",
      " |          where clocks moved forward due to DST. Valid values are:\n",
      " |      \n",
      " |          - 'shift_forward' will shift the nonexistent time forward to the\n",
      " |            closest existing time\n",
      " |          - 'shift_backward' will shift the nonexistent time backward to the\n",
      " |            closest existing time\n",
      " |          - 'NaT' will return NaT where there are nonexistent times\n",
      " |          - timedelta objects will shift nonexistent times by the timedelta\n",
      " |          - 'raise' will raise an NonExistentTimeError if there are\n",
      " |            nonexistent times.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame\n",
      " |          Same type as the input.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the TimeSeries is tz-aware and tz is not None.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Localize local times:\n",
      " |      \n",
      " |      >>> s = pd.Series(\n",
      " |      ...     [1],\n",
      " |      ...     index=pd.DatetimeIndex(['2018-09-15 01:30:00']),\n",
      " |      ... )\n",
      " |      >>> s.tz_localize('CET')\n",
      " |      2018-09-15 01:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Pass None to convert to tz-naive index and preserve local time:\n",
      " |      \n",
      " |      >>> s = pd.Series([1],\n",
      " |      ...     index=pd.DatetimeIndex(['2018-09-15 01:30:00+02:00']))\n",
      " |      >>> s.tz_localize(None)\n",
      " |      2018-09-15 01:30:00    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Be careful with DST changes. When there is sequential data, pandas\n",
      " |      can infer the DST time:\n",
      " |      \n",
      " |      >>> s = pd.Series(range(7),\n",
      " |      ...               index=pd.DatetimeIndex(['2018-10-28 01:30:00',\n",
      " |      ...                                       '2018-10-28 02:00:00',\n",
      " |      ...                                       '2018-10-28 02:30:00',\n",
      " |      ...                                       '2018-10-28 02:00:00',\n",
      " |      ...                                       '2018-10-28 02:30:00',\n",
      " |      ...                                       '2018-10-28 03:00:00',\n",
      " |      ...                                       '2018-10-28 03:30:00']))\n",
      " |      >>> s.tz_localize('CET', ambiguous='infer')\n",
      " |      2018-10-28 01:30:00+02:00    0\n",
      " |      2018-10-28 02:00:00+02:00    1\n",
      " |      2018-10-28 02:30:00+02:00    2\n",
      " |      2018-10-28 02:00:00+01:00    3\n",
      " |      2018-10-28 02:30:00+01:00    4\n",
      " |      2018-10-28 03:00:00+01:00    5\n",
      " |      2018-10-28 03:30:00+01:00    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      In some cases, inferring the DST is impossible. In such cases, you can\n",
      " |      pass an ndarray to the ambiguous parameter to set the DST explicitly\n",
      " |      \n",
      " |      >>> s = pd.Series(range(3),\n",
      " |      ...               index=pd.DatetimeIndex(['2018-10-28 01:20:00',\n",
      " |      ...                                       '2018-10-28 02:36:00',\n",
      " |      ...                                       '2018-10-28 03:46:00']))\n",
      " |      >>> s.tz_localize('CET', ambiguous=np.array([True, True, False]))\n",
      " |      2018-10-28 01:20:00+02:00    0\n",
      " |      2018-10-28 02:36:00+02:00    1\n",
      " |      2018-10-28 03:46:00+01:00    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      If the DST transition causes nonexistent times, you can shift these\n",
      " |      dates forward or backward with a timedelta object or `'shift_forward'`\n",
      " |      or `'shift_backward'`.\n",
      " |      \n",
      " |      >>> s = pd.Series(range(2),\n",
      " |      ...               index=pd.DatetimeIndex(['2015-03-29 02:30:00',\n",
      " |      ...                                       '2015-03-29 03:30:00']))\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent='shift_forward')\n",
      " |      2015-03-29 03:00:00+02:00    0\n",
      " |      2015-03-29 03:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent='shift_backward')\n",
      " |      2015-03-29 01:59:59.999999999+01:00    0\n",
      " |      2015-03-29 03:30:00+02:00              1\n",
      " |      dtype: int64\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent=pd.Timedelta('1H'))\n",
      " |      2015-03-29 03:30:00+02:00    0\n",
      " |      2015-03-29 03:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  xs(self: 'NDFrameT', key: 'IndexLabel', axis: 'Axis' = 0, level: 'IndexLabel' = None, drop_level: 'bool_t' = True) -> 'NDFrameT'\n",
      " |      Return cross-section from the Series/DataFrame.\n",
      " |      \n",
      " |      This method takes a `key` argument to select data at a particular\n",
      " |      level of a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : label or tuple of label\n",
      " |          Label contained in the index, or partially in a MultiIndex.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis to retrieve cross-section on.\n",
      " |      level : object, defaults to first n levels (n=1 or len(key))\n",
      " |          In case of a key partially contained in a MultiIndex, indicate\n",
      " |          which levels are used. Levels can be referred by label or position.\n",
      " |      drop_level : bool, default True\n",
      " |          If False, returns object with same levels as self.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Cross-section from the original Series or DataFrame\n",
      " |          corresponding to the selected index levels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Access a group of rows and columns\n",
      " |          by label(s) or a boolean array.\n",
      " |      DataFrame.iloc : Purely integer-location based indexing\n",
      " |          for selection by position.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `xs` can not be used to set values.\n",
      " |      \n",
      " |      MultiIndex Slicers is a generic way to get/set values on\n",
      " |      any level or levels.\n",
      " |      It is a superset of `xs` functionality, see\n",
      " |      :ref:`MultiIndex Slicers <advanced.mi_slicers>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> d = {'num_legs': [4, 4, 2, 2],\n",
      " |      ...      'num_wings': [0, 0, 2, 2],\n",
      " |      ...      'class': ['mammal', 'mammal', 'mammal', 'bird'],\n",
      " |      ...      'animal': ['cat', 'dog', 'bat', 'penguin'],\n",
      " |      ...      'locomotion': ['walks', 'walks', 'flies', 'walks']}\n",
      " |      >>> df = pd.DataFrame(data=d)\n",
      " |      >>> df = df.set_index(['class', 'animal', 'locomotion'])\n",
      " |      >>> df\n",
      " |                                 num_legs  num_wings\n",
      " |      class  animal  locomotion\n",
      " |      mammal cat     walks              4          0\n",
      " |             dog     walks              4          0\n",
      " |             bat     flies              2          2\n",
      " |      bird   penguin walks              2          2\n",
      " |      \n",
      " |      Get values at specified index\n",
      " |      \n",
      " |      >>> df.xs('mammal')\n",
      " |                         num_legs  num_wings\n",
      " |      animal locomotion\n",
      " |      cat    walks              4          0\n",
      " |      dog    walks              4          0\n",
      " |      bat    flies              2          2\n",
      " |      \n",
      " |      Get values at several indexes\n",
      " |      \n",
      " |      >>> df.xs(('mammal', 'dog', 'walks'))\n",
      " |      num_legs     4\n",
      " |      num_wings    0\n",
      " |      Name: (mammal, dog, walks), dtype: int64\n",
      " |      \n",
      " |      Get values at specified index and level\n",
      " |      \n",
      " |      >>> df.xs('cat', level=1)\n",
      " |                         num_legs  num_wings\n",
      " |      class  locomotion\n",
      " |      mammal walks              4          0\n",
      " |      \n",
      " |      Get values at several indexes and levels\n",
      " |      \n",
      " |      >>> df.xs(('bird', 'walks'),\n",
      " |      ...       level=[0, 'locomotion'])\n",
      " |               num_legs  num_wings\n",
      " |      animal\n",
      " |      penguin         2          2\n",
      " |      \n",
      " |      Get values at specified column and axis\n",
      " |      \n",
      " |      >>> df.xs('num_wings', axis=1)\n",
      " |      class   animal   locomotion\n",
      " |      mammal  cat      walks         0\n",
      " |              dog      walks         0\n",
      " |              bat      flies         2\n",
      " |      bird    penguin  walks         2\n",
      " |      Name: num_wings, dtype: int64\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  dtypes\n",
      " |      Return the dtypes in the DataFrame.\n",
      " |      \n",
      " |      This returns a Series with the data type of each column.\n",
      " |      The result's index is the original DataFrame's columns. Columns\n",
      " |      with mixed types are stored with the ``object`` dtype. See\n",
      " |      :ref:`the User Guide <basics.dtypes>` for more.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series\n",
      " |          The data type of each column.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'float': [1.0],\n",
      " |      ...                    'int': [1],\n",
      " |      ...                    'datetime': [pd.Timestamp('20180310')],\n",
      " |      ...                    'string': ['foo']})\n",
      " |      >>> df.dtypes\n",
      " |      float              float64\n",
      " |      int                  int64\n",
      " |      datetime    datetime64[ns]\n",
      " |      string              object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  empty\n",
      " |      Indicator whether Series/DataFrame is empty.\n",
      " |      \n",
      " |      True if Series/DataFrame is entirely empty (no items), meaning any of the\n",
      " |      axes are of length 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          If Series/DataFrame is empty, return True, if not return False.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.dropna : Return series without null values.\n",
      " |      DataFrame.dropna : Return DataFrame with labels on given axis omitted\n",
      " |          where (all or any) data are missing.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If Series/DataFrame contains only NaNs, it is still not considered empty. See\n",
      " |      the example below.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      An example of an actual empty DataFrame. Notice the index is empty:\n",
      " |      \n",
      " |      >>> df_empty = pd.DataFrame({'A' : []})\n",
      " |      >>> df_empty\n",
      " |      Empty DataFrame\n",
      " |      Columns: [A]\n",
      " |      Index: []\n",
      " |      >>> df_empty.empty\n",
      " |      True\n",
      " |      \n",
      " |      If we only have NaNs in our DataFrame, it is not considered empty! We\n",
      " |      will need to drop the NaNs to make the DataFrame empty:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A' : [np.nan]})\n",
      " |      >>> df\n",
      " |          A\n",
      " |      0 NaN\n",
      " |      >>> df.empty\n",
      " |      False\n",
      " |      >>> df.dropna().empty\n",
      " |      True\n",
      " |      \n",
      " |      >>> ser_empty = pd.Series({'A' : []})\n",
      " |      >>> ser_empty\n",
      " |      A    []\n",
      " |      dtype: object\n",
      " |      >>> ser_empty.empty\n",
      " |      False\n",
      " |      >>> ser_empty = pd.Series()\n",
      " |      >>> ser_empty.empty\n",
      " |      True\n",
      " |  \n",
      " |  flags\n",
      " |      Get the properties associated with this pandas object.\n",
      " |      \n",
      " |      The available flags are\n",
      " |      \n",
      " |      * :attr:`Flags.allows_duplicate_labels`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Flags : Flags that apply to pandas objects.\n",
      " |      DataFrame.attrs : Global metadata applying to this dataset.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \"Flags\" differ from \"metadata\". Flags reflect properties of the\n",
      " |      pandas object (the Series or DataFrame). Metadata refer to properties\n",
      " |      of the dataset, and should be stored in :attr:`DataFrame.attrs`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2]})\n",
      " |      >>> df.flags\n",
      " |      <Flags(allows_duplicate_labels=True)>\n",
      " |      \n",
      " |      Flags can be get or set using ``.``\n",
      " |      \n",
      " |      >>> df.flags.allows_duplicate_labels\n",
      " |      True\n",
      " |      >>> df.flags.allows_duplicate_labels = False\n",
      " |      \n",
      " |      Or by slicing with a key\n",
      " |      \n",
      " |      >>> df.flags[\"allows_duplicate_labels\"]\n",
      " |      False\n",
      " |      >>> df.flags[\"allows_duplicate_labels\"] = True\n",
      " |  \n",
      " |  ndim\n",
      " |      Return an int representing the number of axes / array dimensions.\n",
      " |      \n",
      " |      Return 1 if Series. Otherwise return 2 if DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.ndim : Number of array dimensions.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
      " |      >>> s.ndim\n",
      " |      1\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.ndim\n",
      " |      2\n",
      " |  \n",
      " |  size\n",
      " |      Return an int representing the number of elements in this object.\n",
      " |      \n",
      " |      Return the number of rows if Series. Otherwise return the number of\n",
      " |      rows times number of columns if DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.size : Number of elements in the array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
      " |      >>> s.size\n",
      " |      3\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.size\n",
      " |      4\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  attrs\n",
      " |      Dictionary of global attributes of this dataset.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         attrs is experimental and may change without warning.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.flags : Global flags applying to this object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __array_priority__ = 1000\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __sizeof__(self) -> 'int'\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self) -> 'list[str]'\n",
      " |      Provide method name lookup and completion.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Only provide 'public' methods.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.indexing.IndexingMixin:\n",
      " |  \n",
      " |  at\n",
      " |      Access a single value for a row/column label pair.\n",
      " |      \n",
      " |      Similar to ``loc``, in that both provide label-based lookups. Use\n",
      " |      ``at`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          * If getting a value and 'label' does not exist in a DataFrame or\n",
      " |              Series.\n",
      " |      ValueError\n",
      " |          * If row/column label pair is not a tuple or if any label from\n",
      " |              the pair is not a scalar for DataFrame.\n",
      " |          * If label is list-like (*excluding* NamedTuple) for Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column pair by label.\n",
      " |      DataFrame.iat : Access a single value for a row/column pair by integer\n",
      " |          position.\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s).\n",
      " |      DataFrame.iloc : Access a group of rows and columns by integer\n",
      " |          position(s).\n",
      " |      Series.at : Access a single value by label.\n",
      " |      Series.iat : Access a single value by integer position.\n",
      " |      Series.loc : Access a group of rows by label(s).\n",
      " |      Series.iloc : Access a group of rows by integer position(s).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See :ref:`Fast scalar value getting and setting <indexing.basics.get_value>`\n",
      " |      for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   index=[4, 5, 6], columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      4   0   2   3\n",
      " |      5   0   4   1\n",
      " |      6  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B']\n",
      " |      2\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B'] = 10\n",
      " |      >>> df.at[4, 'B']\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a Series\n",
      " |      \n",
      " |      >>> df.loc[5].at['B']\n",
      " |      4\n",
      " |  \n",
      " |  iat\n",
      " |      Access a single value for a row/column pair by integer position.\n",
      " |      \n",
      " |      Similar to ``iloc``, in that both provide integer-based lookups. Use\n",
      " |      ``iat`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      IndexError\n",
      " |          When integer position is out of bounds.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair.\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s).\n",
      " |      DataFrame.iloc : Access a group of rows and columns by integer position(s).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      0   0   2   3\n",
      " |      1   0   4   1\n",
      " |      2  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2]\n",
      " |      1\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2] = 10\n",
      " |      >>> df.iat[1, 2]\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a series\n",
      " |      \n",
      " |      >>> df.loc[0].iat[1]\n",
      " |      2\n",
      " |  \n",
      " |  iloc\n",
      " |      Purely integer-location based indexing for selection by position.\n",
      " |      \n",
      " |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      " |      ``length-1`` of the axis), but may also be used with a boolean\n",
      " |      array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - An integer, e.g. ``5``.\n",
      " |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      " |      - A slice object with ints, e.g. ``1:7``.\n",
      " |      - A boolean array.\n",
      " |      - A ``callable`` function with one argument (the calling Series or\n",
      " |        DataFrame) and that returns valid output for indexing (one of the above).\n",
      " |        This is useful in method chains, when you don't have a reference to the\n",
      " |        calling object, but would like to base your selection on some value.\n",
      " |      - A tuple of row and column indexes. The tuple elements consist of one of the\n",
      " |        above inputs, e.g. ``(0, 1)``.\n",
      " |      \n",
      " |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      " |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      " |      indexing (this conforms with python/numpy *slice* semantics).\n",
      " |      \n",
      " |      See more at :ref:`Selection by Position <indexing.integer>`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iat : Fast integer location scalar accessor.\n",
      " |      DataFrame.loc : Purely label-location based indexer for selection by label.\n",
      " |      Series.iloc : Purely integer-location based indexing for\n",
      " |                     selection by position.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n",
      " |      ...           {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n",
      " |      ...           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]\n",
      " |      >>> df = pd.DataFrame(mydict)\n",
      " |      >>> df\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      1   100   200   300   400\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      **Indexing just the rows**\n",
      " |      \n",
      " |      With a scalar integer.\n",
      " |      \n",
      " |      >>> type(df.iloc[0])\n",
      " |      <class 'pandas.core.series.Series'>\n",
      " |      >>> df.iloc[0]\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      c    3\n",
      " |      d    4\n",
      " |      Name: 0, dtype: int64\n",
      " |      \n",
      " |      With a list of integers.\n",
      " |      \n",
      " |      >>> df.iloc[[0]]\n",
      " |         a  b  c  d\n",
      " |      0  1  2  3  4\n",
      " |      >>> type(df.iloc[[0]])\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      \n",
      " |      >>> df.iloc[[0, 1]]\n",
      " |           a    b    c    d\n",
      " |      0    1    2    3    4\n",
      " |      1  100  200  300  400\n",
      " |      \n",
      " |      With a `slice` object.\n",
      " |      \n",
      " |      >>> df.iloc[:3]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      1   100   200   300   400\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      With a boolean mask the same length as the index.\n",
      " |      \n",
      " |      >>> df.iloc[[True, False, True]]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      With a callable, useful in method chains. The `x` passed\n",
      " |      to the ``lambda`` is the DataFrame being sliced. This selects\n",
      " |      the rows whose index label even.\n",
      " |      \n",
      " |      >>> df.iloc[lambda x: x.index % 2 == 0]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      **Indexing both axes**\n",
      " |      \n",
      " |      You can mix the indexer types for the index and columns. Use ``:`` to\n",
      " |      select the entire axis.\n",
      " |      \n",
      " |      With scalar integers.\n",
      " |      \n",
      " |      >>> df.iloc[0, 1]\n",
      " |      2\n",
      " |      \n",
      " |      With lists of integers.\n",
      " |      \n",
      " |      >>> df.iloc[[0, 2], [1, 3]]\n",
      " |            b     d\n",
      " |      0     2     4\n",
      " |      2  2000  4000\n",
      " |      \n",
      " |      With `slice` objects.\n",
      " |      \n",
      " |      >>> df.iloc[1:3, 0:3]\n",
      " |            a     b     c\n",
      " |      1   100   200   300\n",
      " |      2  1000  2000  3000\n",
      " |      \n",
      " |      With a boolean array whose length matches the columns.\n",
      " |      \n",
      " |      >>> df.iloc[:, [True, False, True, False]]\n",
      " |            a     c\n",
      " |      0     1     3\n",
      " |      1   100   300\n",
      " |      2  1000  3000\n",
      " |      \n",
      " |      With a callable function that expects the Series or DataFrame.\n",
      " |      \n",
      " |      >>> df.iloc[:, lambda df: [0, 2]]\n",
      " |            a     c\n",
      " |      0     1     3\n",
      " |      1   100   300\n",
      " |      2  1000  3000\n",
      " |  \n",
      " |  loc\n",
      " |      Access a group of rows and columns by label(s) or a boolean array.\n",
      " |      \n",
      " |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |      boolean array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |        interpreted as a *label* of the index, and **never** as an\n",
      " |        integer position along the index).\n",
      " |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |      - A slice object with labels, e.g. ``'a':'f'``.\n",
      " |      \n",
      " |        .. warning:: Note that contrary to usual python slices, **both** the\n",
      " |            start and the stop are included\n",
      " |      \n",
      " |      - A boolean array of the same length as the axis being sliced,\n",
      " |        e.g. ``[True, False, True]``.\n",
      " |      - An alignable boolean Series. The index of the key will be aligned before\n",
      " |        masking.\n",
      " |      - An alignable Index. The Index of the returned selection will be the input.\n",
      " |      - A ``callable`` function with one argument (the calling Series or\n",
      " |        DataFrame) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      See more at :ref:`Selection by Label <indexing.label>`.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any items are not found.\n",
      " |      IndexingError\n",
      " |          If an indexed key is passed and its index is unalignable to the frame index.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair.\n",
      " |      DataFrame.iloc : Access group of rows and columns by integer position(s).\n",
      " |      DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the\n",
      " |          Series/DataFrame.\n",
      " |      Series.loc : Access group of values using labels.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Getting values**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=['cobra', 'viper', 'sidewinder'],\n",
      " |      ...      columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label. Note this returns the row as a Series.\n",
      " |      \n",
      " |      >>> df.loc['viper']\n",
      " |      max_speed    4\n",
      " |      shield       5\n",
      " |      Name: viper, dtype: int64\n",
      " |      \n",
      " |      List of labels. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder']]\n",
      " |                  max_speed  shield\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label for row and column\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice with labels for row and single label for column. As mentioned\n",
      " |      above, note that both the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc['cobra':'viper', 'max_speed']\n",
      " |      cobra    1\n",
      " |      viper    4\n",
      " |      Name: max_speed, dtype: int64\n",
      " |      \n",
      " |      Boolean list with the same length as the row axis\n",
      " |      \n",
      " |      >>> df.loc[[False, False, True]]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Alignable boolean Series:\n",
      " |      \n",
      " |      >>> df.loc[pd.Series([False, True, False],\n",
      " |      ...        index=['viper', 'sidewinder', 'cobra'])]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Index (same behavior as ``df.reindex``)\n",
      " |      \n",
      " |      >>> df.loc[pd.Index([\"cobra\", \"viper\"], name=\"foo\")]\n",
      " |             max_speed  shield\n",
      " |      foo\n",
      " |      cobra          1       2\n",
      " |      viper          4       5\n",
      " |      \n",
      " |      Conditional that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Conditional that returns a boolean Series with column labels specified\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6, ['max_speed']]\n",
      " |                  max_speed\n",
      " |      sidewinder          7\n",
      " |      \n",
      " |      Callable that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[lambda df: df['shield'] == 8]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      **Setting values**\n",
      " |      \n",
      " |      Set value for all items matching the list of labels\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder'], ['shield']] = 50\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire row\n",
      " |      \n",
      " |      >>> df.loc['cobra'] = 10\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              10      10\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire column\n",
      " |      \n",
      " |      >>> df.loc[:, 'max_speed'] = 30\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper              30      50\n",
      " |      sidewinder         30      50\n",
      " |      \n",
      " |      Set value for rows matching callable condition\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 35] = 0\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper               0       0\n",
      " |      sidewinder          0       0\n",
      " |      \n",
      " |      **Getting values on a DataFrame with an index that has integer labels**\n",
      " |      \n",
      " |      Another example using integers for the index\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=[7, 8, 9], columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      Slice with integer labels for rows. As mentioned above, note that both\n",
      " |      the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc[7:9]\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      **Getting values with a MultiIndex**\n",
      " |      \n",
      " |      A number of examples using a DataFrame with a MultiIndex\n",
      " |      \n",
      " |      >>> tuples = [\n",
      " |      ...    ('cobra', 'mark i'), ('cobra', 'mark ii'),\n",
      " |      ...    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n",
      " |      ...    ('viper', 'mark ii'), ('viper', 'mark iii')\n",
      " |      ... ]\n",
      " |      >>> index = pd.MultiIndex.from_tuples(tuples)\n",
      " |      >>> values = [[12, 2], [0, 4], [10, 20],\n",
      " |      ...         [1, 4], [7, 1], [16, 36]]\n",
      " |      >>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n",
      " |      >>> df\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Single label. Note this returns a DataFrame with a single index.\n",
      " |      \n",
      " |      >>> df.loc['cobra']\n",
      " |               max_speed  shield\n",
      " |      mark i          12       2\n",
      " |      mark ii          0       4\n",
      " |      \n",
      " |      Single index tuple. Note this returns a Series.\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark ii')]\n",
      " |      max_speed    0\n",
      " |      shield       4\n",
      " |      Name: (cobra, mark ii), dtype: int64\n",
      " |      \n",
      " |      Single label for row and column. Similar to passing in a tuple, this\n",
      " |      returns a Series.\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'mark i']\n",
      " |      max_speed    12\n",
      " |      shield        2\n",
      " |      Name: (cobra, mark i), dtype: int64\n",
      " |      \n",
      " |      Single tuple. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[[('cobra', 'mark ii')]]\n",
      " |                     max_speed  shield\n",
      " |      cobra mark ii          0       4\n",
      " |      \n",
      " |      Single tuple for the index with a single label for the column\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'), 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice from index tuple to single label\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):'viper']\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Slice from index tuple to index tuple\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):('viper', 'mark ii')]\n",
      " |                          max_speed  shield\n",
      " |      cobra      mark i          12       2\n",
      " |                 mark ii          0       4\n",
      " |      sidewinder mark i          10      20\n",
      " |                 mark ii          1       4\n",
      " |      viper      mark ii          7       1\n",
      " |      \n",
      " |      Please see the :ref:`user guide<advanced.advanced_hierarchical>`\n",
      " |      for more details and explanations of advanced indexing.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.arraylike.OpsMixin:\n",
      " |  \n",
      " |  __add__(self, other)\n",
      " |      Get Addition of DataFrame and other, column-wise.\n",
      " |      \n",
      " |      Equivalent to ``DataFrame.add(other)``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Object to be added to the DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The result of adding ``other`` to DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add a DataFrame and another object, with option for index-\n",
      " |          or column-oriented addition.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'height': [1.5, 2.6], 'weight': [500, 800]},\n",
      " |      ...                   index=['elk', 'moose'])\n",
      " |      >>> df\n",
      " |             height  weight\n",
      " |      elk       1.5     500\n",
      " |      moose     2.6     800\n",
      " |      \n",
      " |      Adding a scalar affects all rows and columns.\n",
      " |      \n",
      " |      >>> df[['height', 'weight']] + 1.5\n",
      " |             height  weight\n",
      " |      elk       3.0   501.5\n",
      " |      moose     4.1   801.5\n",
      " |      \n",
      " |      Each element of a list is added to a column of the DataFrame, in order.\n",
      " |      \n",
      " |      >>> df[['height', 'weight']] + [0.5, 1.5]\n",
      " |             height  weight\n",
      " |      elk       2.0   501.5\n",
      " |      moose     3.1   801.5\n",
      " |      \n",
      " |      Keys of a dictionary are aligned to the DataFrame, based on column names;\n",
      " |      each value in the dictionary is added to the corresponding column.\n",
      " |      \n",
      " |      >>> df[['height', 'weight']] + {'height': 0.5, 'weight': 1.5}\n",
      " |             height  weight\n",
      " |      elk       2.0   501.5\n",
      " |      moose     3.1   801.5\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the index of `other` is aligned with the\n",
      " |      columns of the DataFrame.\n",
      " |      \n",
      " |      >>> s1 = pd.Series([0.5, 1.5], index=['weight', 'height'])\n",
      " |      >>> df[['height', 'weight']] + s1\n",
      " |             height  weight\n",
      " |      elk       3.0   500.5\n",
      " |      moose     4.1   800.5\n",
      " |      \n",
      " |      Even when the index of `other` is the same as the index of the DataFrame,\n",
      " |      the :class:`Series` will not be reoriented. If index-wise alignment is desired,\n",
      " |      :meth:`DataFrame.add` should be used with `axis='index'`.\n",
      " |      \n",
      " |      >>> s2 = pd.Series([0.5, 1.5], index=['elk', 'moose'])\n",
      " |      >>> df[['height', 'weight']] + s2\n",
      " |             elk  height  moose  weight\n",
      " |      elk    NaN     NaN    NaN     NaN\n",
      " |      moose  NaN     NaN    NaN     NaN\n",
      " |      \n",
      " |      >>> df[['height', 'weight']].add(s2, axis='index')\n",
      " |             height  weight\n",
      " |      elk       2.0   500.5\n",
      " |      moose     4.1   801.5\n",
      " |      \n",
      " |      When `other` is a :class:`DataFrame`, both columns names and the\n",
      " |      index are aligned.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'height': [0.2, 0.4, 0.6]},\n",
      " |      ...                      index=['elk', 'moose', 'deer'])\n",
      " |      >>> df[['height', 'weight']] + other\n",
      " |             height  weight\n",
      " |      deer      NaN     NaN\n",
      " |      elk       1.7     NaN\n",
      " |      moose     3.0     NaN\n",
      " |  \n",
      " |  __and__(self, other)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __floordiv__(self, other)\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mod__(self, other)\n",
      " |  \n",
      " |  __mul__(self, other)\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __or__(self, other)\n",
      " |  \n",
      " |  __pow__(self, other)\n",
      " |  \n",
      " |  __radd__(self, other)\n",
      " |  \n",
      " |  __rand__(self, other)\n",
      " |  \n",
      " |  __rfloordiv__(self, other)\n",
      " |  \n",
      " |  __rmod__(self, other)\n",
      " |  \n",
      " |  __rmul__(self, other)\n",
      " |  \n",
      " |  __ror__(self, other)\n",
      " |  \n",
      " |  __rpow__(self, other)\n",
      " |  \n",
      " |  __rsub__(self, other)\n",
      " |  \n",
      " |  __rtruediv__(self, other)\n",
      " |  \n",
      " |  __rxor__(self, other)\n",
      " |  \n",
      " |  __sub__(self, other)\n",
      " |  \n",
      " |  __truediv__(self, other)\n",
      " |  \n",
      " |  __xor__(self, other)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.arraylike.OpsMixin:\n",
      " |  \n",
      " |  __hash__ = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "027c834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data,columns=['Data','Description','Requirements'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "aa1577a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_description.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c134bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "requi = (df['Requirements']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e279959b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"yêu cầu công việc\\n\\n- education level, certification: university degree in computer science, marketing analytics,\\nbusiness, statistics or other related studies; or equivalent work experience\\n- experience:\\n\\n3+ years' experience in similar or equivalent position\\nexperience and knowledge of consumer financing industry and collection as a preferred.\\nstrong analytical skills with ability to deliver insightful ideas, excited to draw findings from figures.\\n\\n- individual characteristics:\\n\\ngood interpersonal, communication and presentation skills.\\nproactive, responsible, attention to detail and a good team player.\\nfluency in written and spoken english\\n\\t\",\n",
       "       '',\n",
       "       'yêu cầu ứng viên\\n- tốt nghiệp đại học ngành kinh tế, phân tích dữ liệu, công nghệ thông tin, hệ thống thông tin.- ưu tiên ứng viên có kinh nghiệm làm việc thực tế.- ưu tiên ứng viên có kinh nghiệm đã sử dụng hoặc triển khai các giải pháp bi, excel nâng cao, phân tích tài chính, bsc/kpi- kỹ năng phân tích yêu cầu dữ liệu, tư duy, học hỏi nhanh- có kinh nghiệm xây dựng dashboard, làm việc với tableau bi, power bi.- sử dụng tốt microsoft office word, excel- tiếng anh đọc hiểu bắt buộc, có khả năng giao tiếp cơ bản là một lợi thế',\n",
       "       'yêu cầu ứng viên\\n1. trình độ:có kiến thức cơ bản về supply chain/ logistics và ngành bán lẻ;nắm được các phương pháp & công cụ thống kê phân tích;tốt nghiệp đại học các chuyên ngành toán thống kê/thống kê kinh tế/ thống kê kinh doanh/kinh tế lượng/ khoa học dữ liệu/ khoa học máy tính/logictics & chuỗi cung ứng/ quản trị kinh doanh2. kinh nghiệm: ưu tiên ứng viên có đam mê phân tích dữ liệu và kinh nghiệm làm việc từ dưới 06 tháng – 01 năm.3. kỹ năng:kỹ năng tư duy logic, có hệ thống, trực quan hóa dữ liệu;kỹ năng excel nâng cao (vba, sql, access);kỹ năng lập kế hoạch và quản lý công việc;kỹ năng giao tiếp tốt và khả năng thuyết trình;kỹ năng giải quyết vấn đề;kỹ năng tổ chức, tổng hợp và phân tích dữ liệu: dashboard (qlik hoặc powerbi hoặc tableau), xử lý & phân tích dữ liệu (alteryx, sql, r hoặc python là một lợi thế).4. thái độ/phẩm chất: nhạy bén, linh hoạt, khéo léo, có trách nhiệm, ham học hỏi, dấn thân.\\nquyền lợi\\nlương thỏa thuận và nhận đúng hạn;thưởng thâm niên, thưởng tháng 13;được hỗ trợ cơm trưa tại công ty;chỗ ở nội trú cho các nhân sự ở xaxem xét tăng lương 1 lần/năm;bhxh, bhyt, bhtn đầy đủ theo luật;tham gia bảo hiểm bảo việt (thời gian làm việc chính thức đủ 8 tháng);nghỉ phép thường niên, lễ, tết theo quy định;tham gia teambuilding, các hoạt động nội bộ và các hoạt động cộng đồng do công ty tổ chức;được đào tạo bài bản về các kiến thức, kỹ năng cho công việc & kỹ năng đời sống (sức khỏe, dinh dưỡng,...);cơ hội thăng tiến công bằng, không giới hạn phòng ban;làm việc với các nhân sự dày dặn kinh nghiệm trong ngành giày chỉ có ở thương hiệu quốc dân “biti\\'s - nâng niu bàn chân việt”;có cơ hội tham gia dự án hạnh phúc happy biti\\'s để hiểu hơn về chính mình, hiểu & kết nối với người khác, kết nối với thiên nhiên;môi trường làm việc được chia sẻ, được lắng nghe và được tôn trọng;được nhận học bổng \"nâng niu tài năng việt\" cho con em có thành tích học tập tốt.\\ncách thức ứng tuyển\\n\\nhết hạn nộp đơn\\n',\n",
       "       'experience.what you will do:design the architecture, implement and maintain the data pipelines that are scalable and reliable for kiotviet data platform.design and implement data warehouse, datamarts to meet the need of querying data and perform descriptive and predictive analytics.collect, process, store and analyze our ever-growing customer data.participate in design and implement new generation of our data platform to help push our stakeholders take advantage from data faster.build high-performance, mission critical apis to allow various customer-facing and internal services to query data, perform analytics.brainstorm, discuss with various experts from other departments to develop data products that serve various customer-facing problems and how data will help push our business further.skillsdata structuresdata warehousingbig datarequirementyou must be strong in data structures and algorithms and have a good knowledge in data analysis.deep understanding of data warehouse concepts and practices.you should be experienced building a data warehouse on cloud platform such a google bigquery.possess an in-depth understanding of the data management.you should be experienced in big data processing framework like apache spark.you should be proficient in one or more of the following programming languages: java / scala / python.eager to learn and willing trial and error several times.experienced in manipulating, processing and extracting data from various source systems; working familiarity with relational databases is a plus.experience with cloud platforms such as google cloud platform is a plus.',\n",
       "       'yêu cầu ứng viên\\ntốt nghiệp chuyên ngành liên quan: công nghệ thông tin, điện tử viễn thông, tự động hóa;có tối thiểu 4 năm kinh nghiệm trở lên về lập trình ai trên các thiết bị main board như jetson devices, raspberry pi;có kiến thức về lập trình ai trên các dòng chip arm, hisilicon, rockchip là 1 lợi thế;làm việc thành thạo với các giao thức tcp/ip, mqtt, http,…các mô trình giao tiếp với số lượng lớn client;có kinh nghiệm lập trình driver giao tiếp scanner, các giải pháp vision xử lý ảnh, làm việc với máy xray kiểm soát hàng hoá là một lợi thế;đọc, hiểu tài liệu kỹ thuật tốt;chủ động, sáng tạo, nhiệt tình và có trách nhiệm trong công việc;biết lắng nghe, kiên trì học hỏi, cẩn thận và tỉ mỉ và có khả năng làm việc với cường độ cao;sẵn sàng làm việc over-time khi có yêu cầu;có khả năng làm việc độc lập và làm việc theo nhóm.\\nquyền lợi\\nlương từ junior đến senior: 500$ – 2000$ net (đánh giá tăng lương theo năng lực định kỳ);bảo hiểm sức khỏe cao cấp generali;môi trường làm việc trẻ trung, năng động;làm việc cùng đội ngũ công nghệ giỏi chuyên môn, có cơ hội để phát huy tối đa năng lực của bản thân;liên tục được đào tạo về kiến thức, kỹ năng liên quan đến các lĩnh vực hoạt động của công ty;được cung cấp đầy đủ phương tiện làm việc theo yêu cầu của tính chất công việc;các hoạt động tập thể, giải trí đa dạng (clb bóng đá, game, bi lắc, …); sự kiện team-building hàng năm;được đảm bảo đầy đủ các chế độ phúc lợi theo quy định của pháp luật hiện hành và của công ty;thưởng tết nguyên đán, tết dương lịch, ngày lễ khác và thưởng thành tích nổi bật.\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 31/07/2023\\n\\n\\n',\n",
       "       'job requirements:university degree in computer science, engineering and/or a technically oriented field2 years of experience with flink/spark, databricks2 years of experience with azure (dp200 and/or dp201, dp203 certification acts as a plus)passionate about analytics machine learning technology & applications and eager to learnenglish communicationknowledge of big data technologies, such as spark, hadoop/mapreduceknowledge of azure services like storage account, azure databricks etc.good knowledge of sql and excellent coding skillsworking knowledge of various ml/dl applications such as keras, tensorflow, python scikit learn and rself-development, communication, problem-solving skills.open-minded, multi-tasking, teamwork, flexible and interest to learn new things\\n',\n",
       "       '', '', '',\n",
       "       'experience with linux os, bash scriptfamiliar with crawling data from the websiteexperienced in sql, and mysql databases.experienced in python/javascript/bash scriptingdata mining or have an interest in data scienceteamwork spirit, responsibility, and good english\\n\\n\\ngeneral information\\n\\n\\nlevel: junior-middletype of the position: full-time permanent',\n",
       "       'experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \\n\\nall locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nbusiness intelligence developer (bangkok based, relocation provided)\\napply now\\nbangkok, thailand\\n\\nabout agoda',\n",
       "       'job requirements\\n\\n1+ years experience with python asynchronous programming. ( fresher accepted. )\\n\\nadvanced experience with sql\\n\\n\\nupper-intermediate',\n",
       "       '', '',\n",
       "       'yêu cầu ứng viên- previous experience as a data engineer or in a similar role\\n- technical expertise with data models, data mining, and segmentation techniques\\n- knowledge of programming languages ',\n",
       "       'kinh nghiệm tại các vị trí tương đương- thành thạo excel, biết sql là một lợi thế- có kỹ năng tổng hợp và phân tích số liệu- nhanh nhẹn, trung thực, trách nhiệm, cầu tiến - ưu tiên đã từng làm giám sát bán hàng, vận đơn, cửa hàng trưởng, ngành hàng trong các chuỗi bán lẻ lớn\\nđịa điểm làm việc\\nbạn có thể lựa chọn làm tại 1 trong các văn phòng- trụ sở chính yody: đường an định, p. việt hòa, tp. hải dương (maps)- với ứng viên tại hà nội, bạn sẽ di chuyển về hải dương làm việc (yody hỗ trợ xe đưa đón hà nội - hải dương hoặc sắp xếp nơi ở miễn phí tại hải dương)\\nquyền lợi:\\n– thu nhập: 15 – 20 triệu (lương + thưởng doanh thu đơn hàng sản phẩm phụ trách)– thưởng cuối năm: 1-2 tháng thu nhập, thưởng theo doanh thu, thưởng các ngày lễ, tết+ cung cấp thiết bị làm việc+ phụ cấp ăn trưa miễn phí tại công ty.+ nghỉ chủ nhật, năm có 12 ngày nghỉ phép+ đóng bảo hiểm khi chính thức theo quy định+ được tổ chức sinh nhật, du lịch 1-2 lần/năm, hưởng các chính sách đãi ngộ đặc biệt từ công ty',\n",
       "       '', '',\n",
       "       'yêu cầu ứng viên\\nadvanced working sql knowledge and experience working with relational databases, query authoring (sql) as well as working familiarity with a variety of databases.experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.strong analytic skills related to working with unstructured datasets.build processes supporting data transformation, data structures,…a successful history of manipulating, processing and extracting value from large disconnected datasets.working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.strong project management and organizational skills.experience supporting and working with cross-functional teams in a dynamic environment.having 2+ years of experience in a data engineer role, who has attained a graduate degree in computer science, statistics, informatics, information systems or another quantitative field. they should also have experience using the following software/tools:experience with big data tools: hadoop, spark, kafka, etc.experience with relational sql and nosql databases, including postgres and mongodbexperience with data pipeline and workflow management tools: azkaban, luigi, airflow, etc.experience with aws cloud services: ec2, emr, rds, redshiftexperience with stream-processing systems: storm, spark-streaming, etc.experience with object-oriented/object function scripting languages: python, java, c++, scala, etc.\\nquyền lợi\\nprofessional work environment:',\n",
       "       '',\n",
       "       'yêu cầu công việc\\n– đang là sinh viên năm 3 hoặc năm cuối chuyên ngành cntt hoặc hiểu biết tương đương, muốn có môi trường học tập và phát triển thực tế.\\n– kỹ năng giao tiếp tốt, cởi mở, thân thiện, làm việc nhóm hiệu quả.\\n– có hiểu biết về các ngôn ngữ / nền tảng sau: spring, spring boot, spring mvc, .net, nodejs, react, vue, angular, go\\n– khả năng nắm bắt, yêu thích nghiên cứu công nghệ mới.\\n',\n",
       "       'experience in the e-commerce industry.\\nwe are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end-to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\\ni. job descriptions\\n\\nresponsible for industrialization, deployment and functional maintenance of data products/solutions, including digital products, business intelligence, and machine learning use cases.\\ncollaborate with other member and user to build data pipelines.\\nresponsible for quality checking and testing.\\ncollaboratively work to solve research problems.\\ndevelop new algorithms and computational tools to solve research problems.\\nreview research code created by other team members.\\nwrite technical documentation and reports.\\ncontinue learning new technologies, introducing existing products, improving product experience, and creating more value.\\n\\nii. skill and experience\\n\\nat least 1 year experiences in data engineer.\\ndemonstrable experience in web application development (building of api driven interfaces).\\nability to program with python is required.\\ngood knowledge in data warehouse, etl, data pipeline.\\nproficiency in sql.\\nexposure to emerging open-source technologies is preferred.\\ngood number sense, logical thinking, problem-solving and communication skills.\\nhave teamwork skills, work independently and self-study.\\nexperience with data pipeline and workflow management tools: airflow, etc.\\nexperience with big data tools: spark, kafka, etc.\\nexperience with oracle.\\n\\niii. why you will love joining us?\\nfor you to join\\n\\nfinancial well-being: a competitive salary with 13th month salary, annual performance bonus and a variety of allowances.\\nsalary review: annually or on excellent performance.\\nactivities: company trips, team-building, and other customized monthly bonding events.\\nannual leaves: 16 days off and 01 birthday leave per year.\\nhealthcare: annual health check, insurance according to labor law and extra pti insurance package.\\nworking environment: dynamic, friendly environments with working time flexibility (mon-fri), and other perks include snacks, coffee, and healthy food provided daily suited for hardworking, fun, and team collaboration.\\n\\nfor you to grow\\n\\nambition: we are now keeping on with our hyper growth to multicategory, multichannel, multimarket, and expanding into the world largest e-commerce enabler. hence, there will continuously be opportunities to challenge yourself, learn new skills and knowledge.',\n",
       "       '',\n",
       "       'experience by exploring offline & online transaction data, customer activity within apps and actual customer insights.\\nmaintain rigor in analytical excellence in terms of data analytics, a/b test design, and appropriate statistical tests across the product funnel from acquisition, adoption, retention to monetization.\\nliaise with other analytical chapters such as data science, data engineering, etc, to ensure that initiatives are aligned and data integrity standards are adhered to.\\nanalyze our complex and ever-growing data, present insights, and propose strategic options to senior management to drive business decisions.\\ntest and validate solutions through proper experimentation process.\\nimportantly, using data to identify growth opportunities and problem solve so as to achieve business goals with metrics such as adoption rate, gmv, mau, & cohort retention.\\n\\nyou will have the following skills and experience:\\nthis role requires a person who is data driven, a growth marketer will create tests and experiments to positively influence customer acquisition, customer conversion, customer retention and customer lifetime value.',\n",
       "       '', '', '',\n",
       "       'kinh nghiệm xây dựng ml model và các kỹ thuật liên quan như k-fold cross-validation.\\ncó thể xây dựng các mô hình bằng tensorflow hoặc pytorch.\\ncó kinh nghiệm với data visualisation bằng bằng biểu đồ sử dụng python, r hoặc một bi dashboard bất kỳ (tableau, powerbi).\\n\\n\\ncó kinh nghiệm ứng dụng ml model vào các bài toán thực tế.\\nsử dụng thành thạo một ml platform bất kỳ là một lợi thế (mlflow, kubeflow, azure machine learning, vertex ai).\\nlàm việc hiệu quả với các thành viên trong nhóm phát triển sản phẩm và hoàn thành các mục tiêu chung đã được đặt ra trong các giai đoạn cụ thể.',\n",
       "       'yêu cầu ứng viên\\n• trình độ đại học trở lên, học chuyên ngành công nghệ thông tin, hệ thống thông tin hoặc các chuyên ngành liên quan tại các trường đại học công nghệ, đại học công nghiệp, học viện bưu chính viễn thông, đại học bách khoa v,v...• biết sử dụng các công cụ tableau; ngôn ngữ truy vấn sql, python …• có kiến thức cơ bản về các mô hình học máy• có kĩ năng làm việc nhóm và độc lập.• nhanh nhẹn, ham học hỏi, chủ động, thẳng thắn và có tinh thần trách nhiệm cao\\nquyền lợi\\n• nhân viên lương cứng 8 - 12 triệu theo năng lực.• sau khi ký hợp đồng chính thức sẽ được hưởng chế độ thưởng theo quy định công ty.nghỉ phép 12 ngày/năm, nghỉ ốm/nghỉ chế độ thai sản/hiếu hỉ… theo quy định pháp luật lao động, bảo hiểm xã hội• du lịch hàng năm, teambuilding, event.• được tài trợ, tham gia các khóa đào tạo kỹ năng, chuyên môn hàng năm, thi lấy chứng chỉ để phục vụ cho công việc.• review đánh giá công việc 2 lần/ năm;• có khả năng phát triển bản thân, định hướng phát triển công việc lâu dài;• môi trường trẻ, năng động, chuyên nghiệp, được khuyến khích sáng tạo và phát triển các ý tưởng mới, sếp trẻ tâm lý, đồng nghiệp thân thiện, văn hóa trao đổi thẳng thắn, cởi mở trên tinh thần hỗ trợ cùng phát triển;• học hỏi kinh nghiệm trực tiếp từ các senior, chuyên gia giàu kinh nghiệm;\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 07/06/2023\\n\\n\\n',\n",
       "       'experience.\\nwhat you will do:\\n- design the architecture, implement and maintain the data pipelines that are scalable and reliable for kiotviet data platform.\\n- design and implement data warehouse, datamarts to meet the need of querying data and perform descriptive and predictive analytics.\\n- collect, process, store and analyze our ever-growing customer data.\\n- participate in design and implement new generation of our data platform to help push our stakeholders take advantage from data faster.\\n- build high-performance, mission critical apis to allow various customer-facing and internal services to query data, perform analytics.\\n- brainstorm, discuss with various experts from other departments to develop data products that serve various customer-facing problems and how data will help push our business further.',\n",
       "       '',\n",
       "       'kinh nghiệm học tăng cường , học giám sát (reinforcement learning , supervised learning)\\n[lợi thế] kiến thức về ros1/ros2\\nlàm việc trong môi trường linux\\nkhả năng làm việc nhóm và làm việc độc lập tốt.\\nyêu thích/ mong muốn làm về xe tự lái ở việt nam là một lợi thế\\n\\nquyền lợi\\n\\n\\nlương: trợ cấp (2.000.000 – 4.000.000 vnđ).\\ntham gia các hoạt động học tập, đào tạo trong và ngoài công ty.\\nnghỉ thứ 7, chủ nhật + 12 ngày phép/ năm\\ncâu lạc bộ và nhiều hoạt động văn hóa – thể thao – nghệ thuật được công ty tài trợ hoặc hỗ trợ.\\nđảm bảo sức khỏe: khám sức khỏe định kỳ, hỗ trợ mua bảo hiểm sức khỏe chất lượng cao…\\n\\n',\n",
       "       '',\n",
       "       'yêu cầu ứng viên\\n-có kinh nghiệm tối thiểu 01 năm làm việc trong các tổ chức tín dụng, tài chính hoặc ngân hàng;-có kiến thức nền tảng tốt về hệ quản trị cơ sở dữ liệu và mô hình hóa dữ liệu;-sử dụng thành thạo ít nhất một công cụ bi (power bi, tableau) để trực quan hóa dữ liệu;-cẩn thận, tỉ mỉ, làm việc tốt dưới áp lực;-ưu tiên các ứng viên có kinh nghiệm tham gia triển khai các dự án về báo cáo, dữ liệu tại các công ty tài chính/ngân hàng thương mại;-ưu tiên các ứng viên có hiểu biết về phương pháp agile, đã tham gia trong hoạt động thực tế hoạt động theo mô hình scrum team-ưu tiên các ứng viên đã có kinh nghiệm làm ba, phân tích kinh doanh, mis cho phát triển báo cáo tại các ngân hàng/tổ chức tài chính;-có kỹ năng, tư duy lập trình và sử dụng tốt ít nhất một ngôn ngữ lập trình ứng dụng là một lợi thế;-kỹ năng ngôn ngữ và diễn đạt văn bản tốt; sử dụng thành thạo tiếng việt và có khả năng giao tiếp bằng tiếng anh.\\nquyền lợi\\nquyền lợi• thời gian làm việc: t2-t6, nghỉ t7 và cn• lương hấp dẫn (mức lương & thưởng cạnh tranh)• phụ cấp tăng ca, thưởng dự án, thưởng vượt chỉ tiêu, thưởng tháng lương thứ 13,...• được công ty thực hiện đầy đủ nghĩa vụ về bảo hiểm; thai sản, con nhỏ, cưới hỏi, sinh nhật,...• được tham gia các hoạt động teambuilding, du lịch, các hoạt động thể thao, các hoạt động xây dựng tinh thần đồng đội.• định kỳ xét tăng lương 2 lần/năm hoặc đột xuất theo đánh giá.đặc biệt:• thử việc 100% lương• bảo hiểm sức khoẻ mic, chương trình vay ưu đãi đối với cbnv...• thưởng theo kết quả kinh doanh hàng năm của công ty (thường được thưởng 2 tháng lương) .• được cử tham gia các khóa đào tạo mới, đào tạo nâng cao phù hợp với năng lực và nguyện vọng.• môi trường chuyên nghiệp sử dụng phương pháp scrum và agile vào quản lý phát triển sản phẩm\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 30/06/2023\\n\\n\\n',\n",
       "       '', '',\n",
       "       'experience in applying ai/ml/computer vision/ nlp to practical and comprehensive technology solutionsexperience with programming languages such as c++, pythonexperience with one of standard ml frameworks such as pytorch, tensorflow, or kerashands-on knowledge of basic ml/dl algorithms, object-oriented programmingproficient at englishpreferred skillsexperience with innovation acceleratorsbasic knowledge in statistics and mathematics, including probability, linear algebraexperience with ai/ml model deploying on embedded systems/ familiarity with cloud computing environments is a plusgood communication and analytical thinking skillsadditional informationjoin a dynamic english-speaking multi-culture working environmentfurthermore, we also offer you internship allowance during the internship program1 day of birthday leave + 1 day of full-paid leave/ per monthmotivating benefits of trade union activities, team building and company tripopportunity to work in global projects of fast developing company and being a part of the innovation team contributing initiative ideas to the hi-tech worldengage',\n",
       "       'experience amazing learning.\\n\\njob description:\\n\\n•\\tdata management – responsible for data gathering, processing, ensuring data structures are adequate and report design and administration as required. \\n•\\tcore applications development – responsible to work with relevant departments to define requirements for system integration in the schools. working closely with it team and school leaders in isams development plan;liaising with all stakeholders to develop and present the proposed development plan to school leaders.\\n•\\ttraining – planning, coordinating, and conducting core applications specific training for teaching and non-teaching staff for the school to maximise the user experience of the system, as necessary.\\n•\\tsupport – being the primary contact with isams support; with it team in maintaining users and user accounts, troubleshooting issues to do with the isams system and the use of it.\\n•\\treview – monitoring the effectiveness of the isams implementation and adoption and providing feedback regularly for informed planning.\\n•\\tother - comply with regional ict hardware and software procurement process and technology standard. accountable to support the implementation of a disaster recovery plan compliant with regional standards. \\n•\\tworking with regional it team and management heads to identify process improvement opportunities, propose system modifications, and devise data governance strategies. \\n•\\tmaintains a proficient level of knowledge of the data reporting and collection requirements of school leadership team and other requirements including the schools code of conduct\\n•\\tticket and escalation management \\n•\\tadhere to school, region, group policies and procedures\\n•\\tcoordinate with it team (collaboration with it team on daily operation) \\n•\\tdocument knowledgebase, change requests, and project resource.\\n•\\tflexible with regard to working hours and available on occasion to work outside of normal hours in response to support demands of the school and regional office. \\n•\\tactive participation in new infrastructure initiatives that could help our schools improve efficiencies.\\n                                                                                    \\nxem toàn bộ mô tả công việc',\n",
       "       'experience enabled by our own technology ecosystem and operational infrastructure, we are setting the benchmark in online fashion & lifestyle in our markets, and our vision is to be the #1 online destination for fashion & lifestyle in growth markets.',\n",
       "       '',\n",
       "       'experience in technology that will help with updates and developments\\n- required availability for off-shift employment and rotational on-call duties\\n                                                                                    \\nread full job descriptions',\n",
       "       '',\n",
       "       'experience as a bi developer (industry experience is preferred).\\n+ background in data warehouse design.\\n+ in-depth understanding of database management systems.\\n+ deep knowledge of sql queries,web programming (node js, python is a bonus).\\n+ experience about google bigquery, google bigtable.\\n+ analytical mind with a problem-solving aptitude.\\nqualifications:\\n+ bsc/ba in computer science, engineering or relevant field\\nskills:\\n+ knowledge about database architecture, sql, web programming, linux server.\\n+ ability to take instruction and work to deadlines\\n+ troubleshooting skill, strong logic thinking, solve problems creatively and effectively\\n+ management/leadership\\n+ intermediate english.\\n',\n",
       "       'yêu cầu ứng viên\\n- sử dụng tốt một trong các phần mềm thống kê/ xây dựng mô hình/ quản lý dữ',\n",
       "       'yêu cầu công việc\\n\\n1.tuân thủ đúng các quy định của công ty\\n2. quản lý nhân viên\\n3. triển khai chính xác chương trình, chính sách tới các đối tác hợp tác .\\n4. hoàn thành chỉ tiêu doanh thu được giao.\\n- giới tính: nam, nữ (ưu tiêu nam)\\n- tuổi: < 35\\n',\n",
       "       'experience\\nknowledge/experience in risk management and portfolio management\\nbenefitssalary range: up to usd 2,000 gros',\n",
       "       \"experience\\n\\n\\nuniversity degree in it or equivalent.\\nproficient with frameworks: pytorch, tensorflow\\nproficient in python, c/c++ programming languages\\nat least 2,5 years of experience working as an ai engineer, ai researcher, or data scientist position.\\nexperience working with jetson nvidia devices is a plus.\\ngood logical thinking skills, hard working and responsible at work.\\n\\n\\nwhy you'll love working here\\n\\n\\ncompetitive salary: up to $2500\\n14 months' salary a year\\nopportunity to receive bonus shares.\\nto fully participate in the regimes prescribed by the state such as social insurance, health insurance, unemployment insurance, and annual leave.\\nbe trained and work directly with experienced experts in the field of ai.\\nhave the opportunity to do challenging things, develop your full potential\\nparticipate in team building, travel 2-3 times/year.\\nenjoy full benefits (happiness, birthday...);\\nyoung, comfortable working environment, dynamic startup spirit.\\n\\n\",\n",
       "       'yêu cầu ứng viên\\n- có kiến thức về ai/bigdata. kinh nghiệm trên 2 năm- bằng cử nhân hoặc thạc sĩ về khoa học máy tính, kỹ thuật phần mềm hoặc công nghệ thông tin.- hơn 2 năm kinh nghiệm trong các lĩnh vực ai/ml, bigdata.- đã từng thiết kế và triển khai một hệ thống ai hoàn chỉnh từ thu thập dữ liệu đến đào tạo.- kinh nghiệm thực tế trong việc xây dựng, khắc phục sự cố và cung cấp các mô hình ai/ml, bigdata- thành thạo python và các thuật toán tensorflow\\nquyền lợi\\n- lương được xem xét, đánh giá tăng định kỳ một năm 2 lần.- thưởng cuối năm và thưởng các ngày lễ tết.- thời gian làm việc: từ 8h00 - 17h00 (nghỉ trưa 1 tiếng) - từ thứ 2 đến thứ 6',\n",
       "       \"experience\\n\\n• strong postgres experience• maintain and modify existing data sets, data loads, documentation, policies, procedures, and other data solutions• create, design, and develop data models for multiple applications• design and implement etl procedures for intake of data from multiple applications in data warehouse• carry out monitoring, tuning, and database performance analysis• design, implement and maintain analytics and business intelligence platform architecture for data warehouse• perform the design and extension of data marts, meta data, and data models• prepare various code designs and ensure efficient implementation of the same• evaluate all codes and ensure the quality of all project deliverables• knowledge of shell scripting is a plus\\n\\nwhy you'll love working here\\n\\npanasonic r&d center vietnam was established in april 2007, is a company specializing in r&d of panasonic group in vietnam with the aim of enhancing r&d activities in the field of digital home appliances, automation, mobility in vietnam, providing r&d services for software solutions in today's hottest fields such as ai, cloud, iot in a chain of r&d centers of worldwide corporations\",\n",
       "       'yêu cầu ứng viên\\n• vietnamese nationality.• last year of university/university.• good programming skill in one of languages c/c++/python.• familiar with computer vision/machine learning/deep learning or graphic programming (2d & 3d, opengl, pointcloud, etc)• experiences with common frameworks (opencv, caffe, tensor flow, etc).• software design skill (uml, object oriented design) is a plus\\nquyền lợi\\n1. career path developmentclearly defined long-term multi-career roadmap;unlimited development & training opportunities (language training, technical training, soft-skill training, on-job training, etc.)oversea business trips (japan, china, singapore, us, mexico, eu, etc.)2. work-life balanceflexible working time that supports work-life balance (core time: 9:00-16:00; 5 days from monday - friday/ week)flexible lunch time;additional special holiday3. wellnesswell-protected with 24/7 personal accident and medical care insurance;well-designed annual health check-up program;4. activitiesteam-building activities; birthday party; year-end party; sport day/ family daysummer vacation (trip to famous tourist spots domestic/ overseas,…)5. cash benefitsattractive and competitive salary & bonus package depend on abilities, performance and competenciesdiversified allowance scheme6. physical environmentgrade a office with creative workplace and open space.well-equipped facilities/ devices and professional working platforms. application submission\\ncách thức ứng tuyển\\n\\nhết hạn nộp đơn\\n',\n",
       "       '', '', '', '', '',\n",
       "       'yêu cầu công việc- chính sách phát triển, thăng tiến có lộ trình theo từng vị trí, từng phòng ban- cơ hội tiếp cận với các công nghệ mới nhất: cloud, big data…môi trường làm việc- tham gia các câu lạc bộ của công ty: clb bóng đá, chạy bộ, yoga, gym…- được trang bị laptop, các thiết bị công nghệ hiện đại trong quá trình làm việc- môi trường làm việc hiện đại, năng động, khuyến khích tối đa sự sáng tạo của nhân viên- văn phòng làm việc hạng a, không gian mở, tiêu chuẩn 5 sao\\n',\n",
       "       'yêu cầu ứng viên\\nrequirements- from 2-year experience as a data analyst- fluent in writing & speaking english- familiar with databases & cloud storage (google bigquery, snowflake…)- familiar with visualization tools (tableau, powerbi, looker…)- master of sql and python- having experience in 2 domains (mobile application) and (financial investment) is a great advantage- understand the data needs of different departments (marketing, product, finance…)- understand the scopes of data engineers, data scientists to collaborate and take the lead if needed- have a robust problem-solving mindset. be able to turn a simple question to become a comprehensive data dashboard that detects and solves a business problem- good communication skills. be able to deliver, present and explain the results in an effective way for both technical and non-technical parties\\nquyền lợi\\nbenefits- competitive salary with annual salary reviewwork in malaysia: up to 2000 usd with allowanceswork in vietnam: up to 900 usd- an international working environment with friendly, creative colleagues from around the world- an excellent opportunity to grow your career. we encourage you to take the lead, initiate and make decisions- tuition fee sponsorship if you expect to become a data scientist or grow other data skills- enjoy birthday parties and frequent weekend parties and other team-building activities (depending on your work location)\\ncách thức ứng tuyển\\n\\nhết hạn nộp đơn\\n',\n",
       "       'experience in data science and mlops\\ngreat communication skills\\ndesired engineering skills:',\n",
       "       'experience in scripting with sql, spark, r/ python.\\n– possess logical thinking, detail-oriented, strong organizational skills, ability to multi-task and work independently under tight deadlines.\\n– work experience as a data analyst is a plus.\\n– work experience in working with distributed system is a plus.\\niii. benefits \\n– competitive salary: up to $650/month (junior) or upto $2000/month (senior)\\n(negotiable, and periodically reviewed based on your capacity).\\n– truly cares about you and your experience at ghtk – rewards and promotions are available on special occasions.\\n– attractive insurance package – you will be provided with a package of generali premium health insurance, along with other benefits in accordance with vietnam labour law: health insurance, social insurance,…\\n– special and worthy welfare regimes – there are 12 days off per year, 13th-month salary, yearly kick-off & team-building events with various bonding activities at workplace.\\n– amazing culture – our working environment is young and dynamic with many promotion opportunities, creating a sustainable career path.\\n– opportunity to work with the best – we not only hire talents but also collaborative ones.\\n– get maximum support to master operations knowledge with additional leadership skills to meet the job’s requirements.\\n– be empowered, self-determined, and have enough space for self-development in a typical e-logistics environment.\\niv. other information\\n– time of work: 9:00 am – 6:30 pm. from monday to friday and alternate saturdays.\\n– address: ghtk building, 8 pham hung street, me tri ward, nam tu liem district, ha noi.\\nv. how to apply\\n– to apply for the data analyst position, please send us your cv to email: talent.acquisition@ghtk.co.\\n– subject: da – your name.',\n",
       "       'job requirements\\n\\n\\nrequirements/qualifications(must have): • qualifications in business administration/marketing/computer science. • have passion for data analytics, research or project management. • ability to organize & analyze large amount of data to arrive at actionable insights. • effective spoken and written communication skills (both english and vietnamese) with ability to manage multiple stakeholders’ expectations. • experience in excel & power point is required. • experience writing custom queries in sql or other sql-based languages is a plus. • willing and eager to learn. ability to adapt in a fast-moving environment in cross functional and cross-cultural teams. • strong ownership & self-motivated\\n',\n",
       "       '', '',\n",
       "       'kinh nghiệm trong việc xây dựng các dashboard, trực quan hóa báo cáo sử dụng các phần mềm khác nhau như: microsoft power bi, tableau, google data studio, google analytics, …\\nkiến thức về các giải pháp phân tích phổ biến như business intelligence và data warehousing\\ncó kinh nghiệm về sql queries để xây dựng bộ dữ liệu (dataset)\\nkĩ năng đọc tài liệu tiếng anh và làm việc nhóm.\\nkĩ năng xử lý vấn đề.\\n\\nchấp nhận sinh viên mới ra trường có nền tảng theo yêu cầu\\n4. quyền lợi\\n\\nmức lương: thoả thuận theo năng lực\\nmôi trường làm việc đam mê, năng động, sáng tạo, hoà đồng\\nchế độ đãi ngộ tốt\\nthực hiện chế độ theo quy định nhà nước ngay khi kết thúc 02 tháng thử việc.\\nđóng bhxh theo quy định nhà nước\\nthưởng quý,',\n",
       "       'experience enabled by our own technology ecosystem and operational infrastructure, we are setting the benchmark in online fashion & lifestyle in our markets, and our vision is to be the #1 online destination for fashion & lifestyle in growth markets.',\n",
       "       '', '',\n",
       "       'experience in the e-commerce industry.\\nwe are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\\ni. job descriptions\\n\\nbe responsible for strategizing and performing project management techniques to enhance business performance, works closely with stakeholders to perform business partnering, supporting, coordinating & advising\\ncomprehend the company r&r structure and collaborate with relevant teams.\\ndefine, develop and implement the efficient business processes.\\nfollow up kpi tracking, measure & feedback\\nanalyze corporate & business situations as well as propose solution recommendations to make improvements;\\nplan, design and implement an overall risk management process, prepare alternative options & action plans to decrease risk factors; propose recommendations to optimize company resources & work efficiency.\\nusing data for strategic planning, build up reporting system and management dashboard.\\n\\nii. skill and experience\\n\\nbachelor‘s degree or above in business, finance, or economics or related fields;\\nexperiences in corporate development, business partnering, prioritize in the e-commerce or related industry.\\na deep understanding of business models, market and industry trends affecting the collaboration and productivity sector;\\nexcellent in researching, qualitative & quantitative analytical skills;\\nability to develop trusted relationships externally and internally;\\nbe scrappy and an effective cross-functional collaborator;\\na self-starter who has worked in a fast-paced, quickly evolving environment with multiple partners;\\nhave strong presentation and communication skills and the ability to change complex issues into structured frameworks and concrete plans.\\n\\nkey competences\\n\\nhave strong communication and interpersonal skills;\\nhave the ability to analyze business issues and deliver logical conclusions;\\nfamiliar with data consolidation, process analysis & strategic planning;\\nproblem - solving;\\nconflict resolution;\\nhunger for knowledge & strive for continuous improvement.\\n\\niii. why you will love joining us?\\nfor you to join\\n\\n\\n\\nfinancial well-being:',\n",
       "       'kinh nghiệm cần thiết- có hơn 3 năm kinh nghiệm phát triển hệ thống- có kinh nghiệm về c ++, python, scala là một điểm cộng- có kinh nghiệm thao tác sql- người có hứng thú với công việc phân tích dữ liệu.\\nưu tiên- ứng viên có hơn 2 năm kinh nghiệm thiết kế hệ thống cơ bản- ứng viên có kinh nghiệm sử dụng dwh (gcp bigquery, redshift, v.v.)- ứng viên có kinh nghiệm sử dụng các công cụ phân tích tiếp thị đám mây công cộng như aws, gcp và azure- ứng viên có kinh nghiệm sử dụng công cụ kiểu như là bi- ứng viên có kinh nghiệm hỗ trợ khách hàng - ứng viên muốn tự tạo dữ liệu phân tích của riêng mình ngay từ đầu.\\n\\n\\n\\n\\n\\n\\njob detail\\n\\n\\n\\n\\n\\n\\n\\n\\n\\njob code\\n\\n7\\n\\n\\n\\n\\n\\n\\nposition type\\n\\nfull-time\\n\\n\\n\\n\\n\\n\\ncareer level\\n\\ntechnical / engineer\\n\\n\\n\\n\\n\\n\\neducation level\\n\\ndiploma (3 years)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ngender\\n\\nmale / female\\n\\n\\n\\n\\n\\n\\n\\nage\\n\\n26 - 40\\n\\n\\n\\n\\n\\n\\n\\n\\n\\njob categories\\n\\n\\nit - software\\n\\n, \\n\\ninterpreter/ translator (japanese)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ninformation\\n\\n\\n\\n\\n\\n\\n\\n\\nname:\\n\\n\\ncareerlink asia co., ltd.\\n\\n\\n\\n\\n\\n\\n\\n\\n千葉県千葉市美浜区中瀬２丁目6番地1 wbgマリブイースト21階\\n\\n, \\n\\n\\n, \\n\\n\\n, \\n\\njapan\\n\\n\\n\\n\\n\\n\\napplication language:\\njapanese\\n\\n\\n\\n\\n\\n\\n\\n\\nabout company\\n\\n\\n\\n\\n\\n\\n\\n\\ncareerlink asia\\n\\n\\n\\n\\nhttps://corp.careerlink.asia/\\n\\n\\n\\n\\n25 - 99 employees\\n\\n\\n\\n\\ncontact: careerlink asia co., ltd.\\n\\n\\n\\n\\n\\n\\n\\nkhách hàng của công ty careerlink là các công ty it\\n\\n\\n\\n\\nsee more\\n\\n\\n\\nsee less\\n\\n\\n\\n\\n\\n\\n\\nother jobs from this company\\n\\n|\\n\\nsee all\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nkỹ sư phát triển và quản lý dự án trên các nền tảng có quy mô lớn như aws, ci / cd, devops\\n\\n\\ncareerlink asia\\n\\n\\n\\njapan\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nnhân viên sale\\n\\n\\ncareerlink asia\\n\\n\\n\\njapan\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nnhân sự quản lý bộ phận\\n\\n\\ncareerlink asia\\n\\n\\n\\njapan\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nnhân viên lập kế hoạch kinh doanh\\n\\n\\ncareerlink asia\\n\\n\\n\\njapan\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nnhân viên bộ phận quản lý\\n\\n\\ncareerlink asia\\n\\n\\n\\njapan\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ntags\\n\\n\\n\\njapanese n2\\npython developer\\nback-end developer\\n\\n\\n\\n\\nshare\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ncopied\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       "       'experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \\n\\nall locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nmanager, marketing strategy & analytics (bangkok-based, relocation provided)\\napply now\\nbangkok, thailand\\n\\nabout agoda',\n",
       "       '',\n",
       "       \"yêu cầu ứng viên\\nbachelor's degree in computer science, software or computer engineering, applied math, physics, statistics, or a related field, preferredat least 3 years of hands-on working experience in data/software engineering in a highly scalable production environment2 years of experience developing data warehouses on snowflake platform, requiredgood knowledge of architecting large-scale data infrastructure in the cloud platform good knowledge of big data technologies like hadoop,hive,spark, redshift aws or other real-time streaminggood knowledge of server-side programming languages (preferably python) and golang.devops experience (devops or gitlab) delivering continuous improvementsdata visualization and dashboarding experience (power bi, tableau, etc.) \",\n",
       "       '',\n",
       "       'kinh nghiệm lập trình với java hoặc python, sử dụng các bộ thư viện về khai phá dữ\\nliệu, học máy, học sâu.\\n– có kinh nghiệm làm việc với môi trường bigdata, các thuật toán phân tán sử dụng spark\\nvà mapreduce là một lợi thế.\\niii. quyền lợi\\n– lương fresher đến senior: 500$ – 2000$',\n",
       "       'job requirement\\n\\n\\nbs/ms/phd in computer science, electrical engineering, or related technical field\\nat least 3+ years of industry experience in developing ml systems\\nstrong programming skills in python\\nproficiency manipulating big data with apache spark (pyspark)\\nexperience with leading machine learning product development on time-series data (sensor, iot devices, health/fitness tracking, audio, etc.)\\nstrong knowledge in software architecture design, debugging, source control management, testing, performance, scaling, and operations.\\nexperience and demonstrated capability to handle challenges with vague or abstract problem definition\\n\\n\\ntagged as: apache spark, computer science, python',\n",
       "       'experience\\n\\n\\netl architecture',\n",
       "       'experiencebachelor’s degree with at least 3 years of related experienceexperience in pharmaceutical industry is preferredwell versed in microsoft excel, powerpoint and power biknowledge in sql server is preferredpossess strong analytical and communication skillsiqvia is a leading global provider of advanced analytics, technology solutions and clinical research services to the life sciences industry. we believe in pushing the boundaries of human science and data science to make the biggest impact possible – to help our customers create a healthier world. learn more at https://jobs.iqvia.com\\n\\napply now\\nsave job\\nremove saved job\\n \\n\\n\\n\\nno recently viewed jobs.  view all opportunities.\\n\\n\\nexplore location\\n\\n\\n\\n\\n\\n\\nshare this job\\n\\ntwitter\\nlinkedin\\nfacebook\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n5 ways to grow your career\\nfulfil your career aspirations at iqvia by unlocking access to these five development resources.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\na warm welcome\\ngawel shares his recruitment experience and the warm welcome he received upon joining iqvia.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nhow we work\\nwe understand life’s complexities so no matter the role, we strive to find the balance of work flexibility so you can succeed both professionally and personally.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nour benefits\\nour integrated benefits programs are designed to meet individuals’ diverse and changing well-being needs.\\n\\n\\n\\n\\n\\n',\n",
       "       '',\n",
       "       'experience: proven practical experience with strong analytical skills and knowledge in the context of cloud. optimization and profound hyperscaler / public cloud knowledge is also helpful.\\n',\n",
       "       'experience for assigned customer segments:\\n- define customer journey (stage/ step/ touchpoints/ related functions) based on internal process. it could be - - \\n- end-to-end journey but usually specific parts of journey.\\n- define the key metrics & questionnaire to measure the success of customer experience based on customer journey (nps, transactional nps, csat, ces, customer complaints, business metrics…).\\n- coordinate with relevant departments to collect and track customer experience metrics across end-to-end journey.\\n- regularly monitor the metrics to identify potential problematic touchpoints.\\n- propose & conduct necessary qualitative & quantitative research to confirm customer journey, identify customer’s expectation, customer pain points, drop rate during detected journey then report key findings.\\n- coordinate with process analyst & business stakeholders to define potential root causes for improvement solution design.\\n- recommend & coordinate in enhancement activities (ux/ui revision, product/process improvement, people training,…).\\n\\n2. drive customer centricity culture activities:\\norganize activities for exco/ head/ employee to experience company product & services.\\ncoordinate with hr & related functions to organize activities and contests to promote customer centric culture and mindset within the organization.\\n                                                                                    \\nxem toàn bộ mô tả công việc',\n",
       "       '',\n",
       "       'yêu cầu công việc:\\n 1/  trình độ học vấn\\n\\ntốt nghiệp từ đại học trở lên chuyên ngành cntt, điện tử viễn thông hoặc các chuyên ngành tương đương\\n\\n2/ kiến thức/ chuyên môn có liên quan\\n\\nhiểu biết về nghiệp vụ ngân hàng là một lợi thế\\nkiến thức và kỹ năng thực tế về thiết kế và truy vấn cơ sở dữ liệu sql server, sql, oracle,...\\ncó kiến thức về tiêu chuẩn dữ liệu của các miền dữ liệu trong lĩnh vực ngân hàng như miền dữ liệu khách hàng, sản phẩm tiền gửi, sản phẩm tiền vay…\\nyêu cầu thành thạo ngôn ngữ sql/plsql, sql server\\n\\n3/  các kinh nghiệm liên quan\\n\\ncó ít nhất 1 năm kinh nghiệm về phân tích dữ liệu / quản trị dữ liệu / kiểm toán cntt / quản lý siêu dữ liệu.',\n",
       "       \"experience and revenue performance by deep segmentation analysis and proactively develop a timely optimisation plan to maximise sellers' success and revenue performance.possess a hybrid user-focused & data-informed mindset. actively conduct in-depth analysis with big amount of data, research market trends and frequently talk to customers to identify sellers' problems/opportunities; while at the same time work closely with relevant teams to deliver appropriate solutions.work closely with product team to develop product roadmap and play an active role in product development process with product team - from users discovery to solutions ideation, results analysis and optimisation.research on new monetisation schemes and regularly carry out experiments to test new premium packages/features to optimise users’ effectiveness as well as spending.work closely with the go to market specialist to maximise adoption of the product offerings from the target segments.responsible for analysis of sales performance and product/ service effectiveness metrics of the business owner segment who is a reliable seller and qualified by the commercial team.prepare weekly, \",\n",
       "       'experienced data scientists and machine learning engineers to build/improve large-scale learning applications (e.g., demographic prediction, churn detection, email campaign optimization, user segmentation, recommender systems, ad optimization, etc).\\n\\n\\n\\n\\nwork closely with the it team to maintain and improve existing data science applications.\\n\\n\\n\\n\\nproduce comprehensive and clear documentation\\n\\n\\n',\n",
       "       'experience, and creating more value.\\n ',\n",
       "       \"yêu cầu ứng viên\\nbachelor's degree in computer science or a related field.4+ years of experience in backend development or data engineering, etl development, or a similar role.experience working with microservice architecture.proficiency one of langue in .net, java, or python for data processing and scripting.experience working with relational databases, such as one of the database types: postgresql, mysql, oracle, or ms sql server.knowledge of working with document databases, such as one the database types: elasticsearch, redis, mongodb, or apache solr.familiarity with data warehousing concepts and cloud-based data storage solutions (e.g., aws, gcp, azure).strong problem-solving skills, attention to detail, and the ability to work independently and as part of a team.excellent communication and collaboration skills, especially in agile culture environment.\\ufeffnice to have:\",\n",
       "       'experience (3+ years) in business intelligence, data analysis, or a related role, with a track record of successful team leadership.\\nstrong knowledge of tableau and able to develop insightful dashboards and reports that drive business decision making and outcomes;\\nintermediate to advanced database, t-sql, data modelling, etl (ssis, azure data factory …) skills;\\nintermediate powerpoint;\\nexperience in python, c#, vba is a plus\\nunderstand data models, database design development, data mining and segmentation techniques.\\n\\nwhat we offer: we treat people fairly and with dignity, keeping a healthy perspective about life and work and fostering a positive and enjoyable work environment with appealing benefits as below:\\n\\na competitive monthly salary based on your ability\\n13th month tet bonus & bi-annual performance bonus\\nannual salary review\\nattractive employee awards: employee of year, semi-annual outstanding employee\\nsocial insurance and healthcare insurance upon vietnam labor code\\npti insurance package, and annual health check\\nan english-speaking environment\\nan open culture that spurs creativity, innovation, and inclusivity\\na variety of training courses for your career development\\ndiverse activities to foster relationships, including company trips, year-end party, employees’ birthdays\\nan open-space office, a cafeteria, and a range of modern equipment\\nother allowance from referrals and special occasions (weddings, seniority, and new-born baby)\\n\\nwork location: our office is located at 9th floor, ree tower, 9 doan van bo, ward 13, district 4\\nworking hours\\nworking hours can be decided flexibly, however, for the 1st several months it is:\\nmon – fri: 3pm – 6pm (office) & 9pm – 2am (wfh)\\nafterwards, fully remote or shifts like 7pm – 4am or 9pm – 6am can be considered.',\n",
       "       '', 'kinh nghiệm 1 năm',\n",
       "       'job requirementbachelor’s degree or above in data science, computer science, information technology,',\n",
       "       'job requirements:involved in the full cycle of data science product development + deployment, with strong presence in the project.substantial tech experience in all tech aspects of data science work, eda, modelling, testing, bau monitoring.experience with fmcgexperience working with/managing 3rd partiesworking with partners from tech product/platform (ms azure, gcp etc)research for new methodology (from application point of view), writing white papers, product evaluationunilever is an organisation committed to equity, inclusion and diversity to drive our business results and create a better future, every day, for our diverse employees, global consumers, partners, and communities. we believe a diverse workforce allows us to match our growth ambitions and drive inclusion across the business. at unilever we are interested in every individual bringing their ‘whole self’ to work and this includes you! thus if you require any support or access requirements, we encourage you to advise us at the time of your application so that we can support you through your recruitment journey.',\n",
       "       '', '',\n",
       "       'experience in edw bi development, including microsoft sql server reporting services (ssrs) and integration services (ssis).experience in building self-serve reporting, including parameterized reports with drill-down capabilitiesthe environment consists of microsoft sql server databases (versions 2012, 2014 and 2016).experience with t-sql is required (writing optimizing stored procedures, packages and queries).ability to work independently and good team playergood english communication skillhandle multiple assignmentadditional information',\n",
       "       '', '', '', '',\n",
       "       'yêu cầu công việc\\n\\nknowledge and experience:\\nbachelor’s degree in computer science or equivalent with a minimum of',\n",
       "       'kinh nghiệm hơn 04 năm về chuyên môn phân tích hoạt động kinh doanh. ưu tiên ứng viên có kinh nghiệm làm việc trong mô hình chuỗi nhà hàng f&b, chuỗi cửa hàng bán lẻ retails, fmcg, …;\\ntổ chức & phân tích dữ liệu tốt. sử dụng tốt các công cụ về dữ liệu và phân tích dữ liệu (power bi, power query, data studio, …);\\ncó kỹ năng thực hiện phân tích và tổ chức các báo cáo về tài chính, kết quả hoạt động kinh doanh chính xác và có thể đưa ra các nhìn nhận, đánh giá và góp ý hiệu quả;\\ntính cách trung thực, ý thức bảo mật thông tin số liệu tốt;\\ntư duy tốt về kinh doanh và nắm bắt tốt xu hướng kinh doanh của ngành/ thị trường;\\nthái độ tích cực và có tinh thần đồng đội tốt. tinh thần trách nhiệm cao và chịu được áp lực công việc.\\n\\nphúc lợi\\n\\nlương thỏa thuận theo năng lực;\\nthời gian làm việc: thứ 2 - thứ 6, 8h30 - 17h30;\\ncông ty cung cấp đầy đủ trang thiết bị làm việc cần thiết như desktop / laptop;\\nlương tháng 13 + thưởng theo kết quả hoạt động kinh doanh;\\ngiảm giá trên tổng hóa đơn khi dùng bữa tại các nhà hàng thuộc hệ thống của golden gate;\\nmôi trường trẻ trung, năng động. nhiều cơ hội phát triển;\\ncông ty thường xuyên có các hoạt động: du lịch hằng năm, team building, tiệc cuối năm.\\n',\n",
       "       'job requirementprofessional skills:good communication, understanding customer psychology;ability to work under pressure and finish on time;proficient in ms word, excel, powerpoint;proficient in sql or python is a great advantage;planning & strategy skills,',\n",
       "       '', '',\n",
       "       'experience\\ngood knowledge of at least one of the programming languages: java or c++\\nstrong understanding of algorithms and data structures\\ngood understanding of software-hardware performance\\nstrong knowledge and experience of software system design\\nability to understand data - thus, data analytical skills, designing systems based on understanding of data, experience with big data systems\\n\\npreferred qualifications:\\n\\ndeep enough understanding of problems from business and product/user perspective; ability to adjust technical solution based on this\\nability to present things to top management in a clear and concise manner\\nbasic understanding of machine learning\\nstrong team player with ability to grow capacity of the team via development of team members\\nability to work smoothly with other stakeholders - product managers, project managers\\nbusiness oriented mindset\\n\\nsoft skills:\\n\\nable to analytical thinking and result-orientation\\ngood english skills\\ncreative thinker and proactive problem solver\\ngood communication in both verbal and written\\nwell understanding of organizational structure and culture\\ngood organizational and time management skills;\\nability to be adapt quickly to changes\\n\\n---\\nfurther information will be discussed in the interview!interested candidates, please',\n",
       "       \"job requirementmust-have:high proficiency in data management, data analysis and predictive modeling in pythonmachine learning / deep learning work experienceexperience integrating ml models into production systemsgreat-to-have:education or experience in physics or mechanical engineeringnice-to-have:ml ops (aws, k8s, helm)education: master’s degree or higher in computer science, computer engineering, physics or other science/engineering disciplineswhat's on offerawesome colleagueswe will match exceptional talent with exceptional compensation (salary and equity)\",\n",
       "       '',\n",
       "       'kinh nghiệm chuyên môn, kĩ năng của các thành viên; tư vấn và hỗ trợ kịp thời cho các thành viên khi có vướng mắc hoặc phương án xử lý tối ưu trong nhóm;\\n7. khác\\n- đưa ra các đề xuất nhằm nâng cao hiệu quả công việc. thực hiện các công việc khác theo sự phân công của trưởng phòng.\\n                                                                                    \\nxem toàn bộ mô tả công việc',\n",
       "       'yêu cầu công việc\\n\\ntrình độ đại học trở lên chuyên ngành toán – tin, công nghệ thông tin, hệ thống thông tin kinh tế\\ncó ít nhất 1 năm kinh nghiệm trong ngành cntt, phân tích dữ liệu\\ncó khả năng truy vấn, truy xuất dữ liệu (sql, oracle)\\nkỹ năng báo cáo, phân tích sử dụng đa công cụ (excel, tableau, power bi,…)\\n\\ncó khả năng phân tích dữ liệu bằng các ngôn ngữ python, r,..)\\n\\ncó kiến thức tốt về toán logic, toán thống kê, quản trị kho dữ liệu\\ncó kỹ năng làm việc nhóm và giải quyết vấn đề\\nkỹ năng quản lý tổ chức và quản lý công việc\\nkỹ năng quản lý nhân sự\\nkỹ năng đánh giá, phân tích\\n\\n',\n",
       "       'job requirements:\\nb.sc. engineering, computer science, data science, or related majors.solid experience in data analytics specializing in customer data use-cases for a b2c business model: retail, banking, fintech, services, f&b…experiences with supporting business stakeholders with their data-driven marketing/product/cx optimization projects are an advantage',\n",
       "       'experience on the engagement & loyalty mobile app, optimizing analytics efficiency and cost, and optimizing individual department operation\\nwork closely with other departments and stakeholders, including ceo, business, product, finance, marketing, tech, and senior management, to ensure that data-related goals and initiatives are aligned with the organization’s overall strategy\\n\\nstrategy & analytics:\\n\\nlead the data analytics and data warehousing departments in strategy development with regard to the collection, manipulation, and analysis of data for various business functions/departments such as marketing, sales, and operations, among others\\nendeavor to create new data-driven approaches for the purpose of generating business insights through data analytics, information visualization, and addressing unanswered business issues in a proactive manner.lead the team in building data governance framework to provide trusted data across functions\\nin-charge of strategic products including: customer segmentation, personalization engine, anti-fraud engine etc.\\nkeeping up with industry trends and best practices, applying new technologies and techniques to enhance the organization’s data strategy\\n\\ndata management:\\noversee and participate in data management activities, including:\\n\\ndefine, build, and manage the organization’s data architecture, including data models, data flows, data integration patterns, data pipelines, data processing, data warehouses, data marts…\\ncollect and centralize data from various sources, including internal systems, external partners, and third-party providers.\\nensure data privacy and security with appropriate policies and security measures.\\nensure data quality and accuracy with appropriate data quality checks and controls are in place.\\nmanage data throughout its lifecycle, from creation to retirement, to optimize its value and minimize risks.\\n\\n',\n",
       "       '', '',\n",
       "       'yêu cầu ứng viên\\n• trình độ đại học trở lên, học chuyên ngành công nghệ thông tin, hệ thống thông tin hoặc các chuyên ngành liên quan tại các trường đại học công nghệ, đại học công nghiệp, học viện bưu chính viễn thông, đại học bách khoa v,v...• có kinh nghiệm sử dụng ngôn ngữ lập trình python• có kinh nghiệm sử dụng sql• có hiểu biết về elasticsearch, mongodb là một lợi thế• có hiểu biết về airflow, spark là một lợi thế• có kĩ năng làm việc nhóm và độc lập.• nhanh nhẹn, có khả năng tự học tốt và có tinh thần trách nhiệm cao.\\nquyền lợi\\n• nhân viên lương cứng 7 - 12 triệu theo năng lực.• sau khi ký hợp đồng chính thức sẽ được hưởng chế độ thưởng theo quy định công ty.nghỉ phép 12 ngày/năm, nghỉ ốm/nghỉ chế độ thai sản/hiếu hỉ… theo quy định pháp luật lao động, bảo hiểm xã hội• du lịch hàng năm, teambuilding, event.• được tài trợ, tham gia các khóa đào tạo kỹ năng, chuyên môn hàng năm, thi lấy chứng chỉ để phục vụ cho công việc.• review đánh giá công việc 2 lần/ năm;• có khả năng phát triển bản thân, định hướng phát triển công việc lâu dài;• môi trường trẻ, năng động, chuyên nghiệp, được khuyến khích sáng tạo và phát triển các ý tưởng mới, sếp trẻ tâm lý, đồng nghiệp thân thiện, văn hóa trao đổi thẳng thắn, cởi mở trên tinh thần hỗ trợ cùng phát triển;• học hỏi kinh nghiệm trực tiếp từ các senior, chuyên gia giàu kinh nghiệm;\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 07/06/2023\\n\\n\\n',\n",
       "       '', '', '',\n",
       "       'kinh nghiệm tại vị trí tương đương hoặc kế toán/kiểm toán / have 1 or 2 years of experience in similar position or accounting/auditing.\\n\\n\\n\\n\\n\\n\\njob detail\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nposition type\\n\\nfull-time\\n\\n\\n\\n\\n\\n\\ncareer level\\n\\nstaff\\n\\n\\n\\n\\n\\n\\neducation level\\n\\nbachelor\\'s degree\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ngender\\n\\nmale / female\\n\\n\\n\\n\\n\\n\\n\\njob categories\\n\\n\\naccounting / audit\\n\\n, \\n\\nfinance / investment\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ninformation\\n\\n\\n\\n\\n\\n\\n\\n\\nname:\\n\\n\\nhcns\\n\\n\\n\\n\\n\\n\\n\\n\\n18 đại lộ bình dương, vĩnh phú\\n\\n, \\n\\nthuan an city\\n\\n, \\n\\nbinh duong\\n\\n, \\n\\nviet nam\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n- các ứng viên quan tâm vui lòng gửi hồ sơ trực tuyến, gửi kèm file hoặc trực tiếp đến tại công ty.\\n\\n\\n\\n\\n\\n\\napplication language:\\nvietnamese\\n\\n\\n\\n\\n\\n\\n\\n\\nabout company\\n\\n\\n\\n\\n\\n\\n\\n\\ncông ty cổ phần bệnh viện đa khoa quốc tế hạnh phúc\\n\\n\\n\\n\\nhttp://www.hanhphuchospital.com\\n\\n\\n\\n\\n500 - 999 employees\\n\\n\\n\\n\\ncontact: hcns\\n\\n\\n\\n\\n\\n\\n\\nbệnh viện quốc tế hạnh phúc cung cấp các tiện nghi và dịch vụ y tế toàn diện trong lĩnh vực chăm sóc sức khỏe với trọng tâm là ngành sản-phụ khoa và nhi khoa.\\nphương châm của hạnh phúc là \"đón mừng cuộc sống\" phản ánh chính xác tinh thần các dịch vụ mà chúng tôi cung cấp.\\nchúng tôi đang tìm kiếm các cá nhân năng động để cùng chia sẻ hoài bão và là một phần của hạnh phúc.\\ngia nhập với chúng tôi, các bạn sẽ có được:\\n- môi trường làm việc thử thách, năng động, chuyên nghiệp\\n- đào tạo phù hợp với yêu cầu công tác\\n- thu nhập hấp dẫn tương xứng với khả năng làm việc\\n- công việc ổn định và cơ hội thăng tiến trong nghề nghiệp\\n- có xe đưa đón nhân viên từ tp hồ chí minh\\n\\n\\n\\n\\nsee more\\n\\n\\n\\nsee less\\n\\n\\n\\n\\n\\n\\n\\nother jobs from this company\\n\\n|\\n\\nsee all\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[hcm] finance analyst\\n\\n\\ncông ty cổ phần bệnh viện đa khoa quốc tế hạnh phúc\\n\\n\\n\\nho chi minh\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nchuyên viên pháp lý cao cấp\\n\\n\\ncông ty cổ phần bệnh viện đa khoa quốc tế hạnh phúc\\n\\n\\n\\nbinh duong\\nho chi minh\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nwork location\\n\\n\\n\\n\\n\\n18 đại lộ bình dương, vĩnh phú, thuan an city, binh duong\\n\\n\\n\\n\\n\\n\\n\\ntags\\n\\n\\n\\nthuan an town\\nfinance\\nphân tích tài chính\\nfinance analyst\\n\\n\\n\\n\\nshare\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ncopied\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       "       '',\n",
       "       'experienced engineering manager to join the data engineering team. at the wikimedia foundation, we operate the world’s largest collaborative project: a top ten website, reaching a billion people globally every month, while incorporating the values of privacy, transparency and community that are so important to our users.\\nworking closely with other technology and product teams, as well as our community of contributors and readers, you will help deliver the next generation of data usage, analysis and access across all wikimedia projects.\\nthis role is responsible for key data engineering initiatives spanning our work in product analytics, machine learning and search.',\n",
       "       '',\n",
       "       'yêu cầu công việc\\n\\n\\nat least 2+ years using linux os, bash script\\nfamiliar with',\n",
       "       'yêu cầu ứng viên\\n6 months experience using awsexperience designing and building web environments on aws, which includes working with services like (ec2, s3, route53, lambda, cloudwatch,…)experience building and maintaining cloud-native applicationsa solid background in linux/unix and windows server system administrationexperience using devops tools in a cloud environment, such as ansible, artifactory, docker, github, jenkins, kubernetes, maven, and sonar qubeexperience using monitoring solutions like cloudwatch, zabbix, grafanaan understanding of writing infrastructure-as-code (iac), using tools like cloudformation or terraformknowledge of one or more of the most-used programming languages like python, bash shell, power shell\\nquyền lợi\\nhighly competitive salary and bonus, plus several additional benefitsearnings up to 13 months salary/year (including salary and bonus)consider periodic salary increasesopportunity to work on challenging projectsjoin insurance according to vietnamese labor law (social insurance, health insurance, unemployment insurance)\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 24/06/2023\\n\\n\\n',\n",
       "       'qualificationsbachelor’s degree in accounting/finance/business informaticsat least 4 years in same or similar roleacquire strong analytical (quantitative as well as qualitative) skills including building models, prior data miningfamiliar with microsoft excel, power bi, sap and all other financial systemsself-starter with the ability to streamline functions and passion to learn and growmust possess excellent communication and presentation skills in english and vietnamese, and be comfortable interacting with executive-level managementwork and collaborate well with team-matesadditional informationwhy',\n",
       "       '', '',\n",
       "       'experience in the e-commerce industry.we are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end-to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.mô tả công việccoordinate, analyze daily, weekly and monthly reports on operational activities for the management team (excel, power bi..)assist in analyzing cost related reports & find opportunities to minimize/exploit costs;monthly analyze p&l and follow-up actual results in comparison with budget/targetother tasks as assigned by direct managers.',\n",
       "       '', '', '',\n",
       "       'experience\\n\\nqualifications/experience:\\n5+ years’ experience as a data analyst or business intelligence analyst.\\nproficient use of microsoft sql.\\nproficient use of power bi.\\nperfect english skills.\\nhave a good understanding of the data warehouse\\nexcellent presentation and data visualization skills.\\nexcellent communication skills.\\ndegree in data science / data analysis / mathematics is a plus.\\nknowledge about the process of a production company is a plus.\\nhas worked with an investment company is a plus\\nworked in us market or used to study in us is a plus',\n",
       "       'experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \\n\\nall locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nanalyst/senior analyst (flights team, bangkok-based, relocation provided)\\napply now\\nbangkok, thailand\\n\\nabout agoda',\n",
       "       '',\n",
       "       'experience as a cost accountant, cost analyst, accountant or similar role',\n",
       "       'experience in modern data platforms, its components and their purpose in the overall ecosystem and architecture\\napply your knowledge and experience to engineer data from its raw elements from source systems into a useable format for business to derive insights\\napply your experience in modern data modelling techniques\\napply the right mindset, attitude and willingness to learn, grow not only one self, but also help grow others.',\n",
       "       '', '',\n",
       "       'yêu cầu công việc\\n\\ntrình độ học vấn: tốt nghiệp đai học chuyên ngành công nghệ thông tin, khoa học máy tính…\\nkinh nghiệm:\\n• ít nhất 1 năm kinh nghiệm ở vị trí tương đương\\n• có kỹ năng viết sql, pl/sql\\n• có kiến thức cơ bản về hệ quản trị cơ sở dữ liệu: oracle, sql server, my sql…\\n• nắm vững kiến thức về: data warehouse, oracle database, bigdata... thành thạo pl/sql và các công cụ tích hợp dữ liệu elt\\n• có khả năng đọc hiểu tài liệu tiếng anh chuyên ngành\\n',\n",
       "       'experience in work/internship/project is preferred\\ndetail-oriented\\n\\n** following will be plus points:\\n\\nexperience with linux\\nsolid programming skills in python or c++\\nbenefitssalary range: up to usd 3,500 gros',\n",
       "       '', '',\n",
       "       'experience in developing ml systems\\nstrong programming skills in python\\nproficiency in manipulating big data with apache spark (pyspark)\\nexperience with leading machine learning product development on time-series data (sensor, iot devices, health/fitness tracking, audio, etc.)\\nstrong knowledge of software architecture design, debugging, source control management, ',\n",
       "       'yêu cầu ứng viên\\n- sinh viên năm 3, năm 4 khối ngành kinh tế hoặc cntt\\n- tuy duy tốt, nhanh nhạy về số liệu\\n- có khả năng đọc hiểu và phân tích dữ liệu, đưa ra kết luận và giải pháp thông qua các báo cáo\\n- có khả năng làm việc độc lập và trong nhóm, cẩn thận và chính xác trong công việc.\\n- có khả năng giao tiếp tốt, đưa ra ý kiến và thuyết phục được người khác.\\n- có kinh nghiệm làm việc với game là một lợi thế.\\nquyền lợi\\n- hỗ trợ lương thực tập 4.000.000 vnđ/ tháng tùy theo năng lực\\n- thời gian thực tập 2 - 4 tháng - tùy vào năng lực của ứng viên\\n- cam kết cơ hội trở thành nhân viên chính thức sau 2 - 4 tháng thực tập nếu đáp ứng đủ tiêu chí\\n- môi trường làm việc vô cùng thoải mái, sáng tạo, năng động.\\n- được hỗ trợ dấu thực tập nếu ứng viên cần\\n- được tham gia các dự án đang chạy của công ty\\n- được cầm tay chỉ việc, đào tạo kỹ năng và kinh nghiệm làm việc thực tế\\n- hưởng đầy đủ các trợ cấp khác như đi lại, gửi xe như 1 nhân viên chính thức\\n- ăn uống miễn phí đồ ăn, thức uống trong văn phòng\\n- thưởng liên tục: tết âm, tết dương, 8/3, 30/4-1/5, 1/6, trung thu, giữa năm, 2/9, 20/10, giáng sinh.\\n- thời gian làm việc: 7h/ngày (sáng: 9:00 - 12:00, chiều: 13:00 - 17:30, nghỉ giữa chiều 15:00 - 15:30)\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 30/06/2023\\n\\n\\n',\n",
       "       'yêu cầu ứng viêntốt nghiệp đại học trở lên chuyên ngành tài chính, kiểm toán, kinh tế,…có ít nhất 2 năm kinh nghiệm làm công việc tương tự tại hoặc làm cho các công ty kiểm toán (big4).đã học hoặc hoàn thành các chứng chỉ về lĩnh vực tài chính, kiểm toán như: acca, cpa, cfa là lợi thế.tiếng anh giao tiếp khá, nắm được tiếng anh chuyên ngành.nhanh nhẹn, chăm chỉ, tinh thần trách nhiệm cao trong công việc.',\n",
       "       '',\n",
       "       'yêu cầu công việc…;- lương tháng 13 bằng từ 1-3 tháng lương thỏa thuận.thưởng:- thưởng định kỳ theo kết quả kinh doanh chung của tập đoàn theo quý và theo năm;- thưởng đột xuất theo chương trình chung của tập đoàn;- thưởng đột xuất theo thành tích đặc biệt và hoặc các sáng kiến cải tiến trong công việc.chế độ đãi ngộ khác:- được hưởng đầy đủ các chế độ phúc lợi cơ bản theo quy định của nhà nước ngay sau kết thúc thời gian thử việc bao gồm bhxh, bhyt, bhtn, chế độ khám sức khỏe định kỳ...;- được hưởng đầy đủ các chế độ phúc lợi động viên cho bản thân và người thân theo quy định chung của tập đoàn như chế độ thăm hỏi; mừng các ngày lễ trong năm; mừng ngày thành lập tập đoàn; hiếu - hỉ…;- được hưởng đầy đủ các chế độ phúc lợi nâng cao (dành cho cấp quản lý) như: mừng danh hiệu quản lý cuối năm, bảo hiểm sức khỏe cho bản thân và người thân; chăm sóc sức khỏe (tập thể thao, tập gym…); hỗ trợ đi lại; hỗ trợ mua sắm và sử dụng dịch vụ ưu đãi;- được tham gia các hoạt động ngoại khóa, văn hóa đoàn thể hấp dẫn dành cho cbnv;- môi trường làm việc chuyên nghiệp, nhân văn, văn hóa và thân thiện.\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 30/06/2023\\n\\n\\n',\n",
       "       'experience (stored procedures, function, trigger…) and understanding of data warehousing and data modeling;\\nexperienced with business intelligence tools such as microsoft bi stack (e.g., ssis, ssrs, and ssas, azure data warehouse), tableau;\\nintermediate c# or other programming languages;\\nadvanced knowledge of data systems and the ability to transform and shape large usable data sets.\\n\\nwork behavior\\n\\nability to lead, plan and manage in an entrepreneurial, team-oriented environment;\\nhighly organized with strong project management skills, and drive to meet organizational objectives; ability to manage multiple projects on interrelated timelines;\\nstrong written and verbal communication skills;\\ndemonstrate experience in getting things done in dynamic, entrepreneurial environment;\\ndemonstrate a high attention-to-detail in the analysis and reporting of data.\\n\\nwhat we offer: we treat people fairly and with dignity, keeping a healthy perspective about life and work and fostering a positive and enjoyable work environment with appealing benefits as below:\\n\\na competitive monthly salary based on your ability\\n13th month tet bonus & bi-annual performance bonus\\nannual salary review\\nattractive employee awards: employee of year, semi-annual outstanding employee\\nsocial insurance and healthcare insurance upon vietnam labor code\\npvi insurance package, and annual health check\\nan english-speaking environment\\nan open culture that spurs creativity, innovation, and inclusivity\\na variety of training courses for your career development\\ndiverse activities to foster relationships, including company trips, year-end party, employees’ birthdays\\nan open-space office, a cafeteria, and a range of modern equipment\\nother allowance from referrals and special occasions (weddings, seniority, and new-born baby)\\n\\nwork location\\nree tower, 9 doan van bo street, ward 13, district 4, hcmc\\nworking hours\\nmon – fri: 3pm – 6pm (office) & 9pm – 2am (wfh)',\n",
       "       '', '',\n",
       "       'yêu cầu công việc- tốt nghiệp đại học các ngành về phân tích thông tin, toán, khoa học máy tính, thống kê.- có ít nhất 01 năm kinh nghiệm trong lĩnh vực data analyst hoặc business analyst- kỹ năng phân tích tốt.- có tư duy logic có hệ thống, có kỹ năng giải quyết vấn đề, làm việc có tổ chức và tư duy dựa trên dữ liệu- yêu thích tìm hiểu các kỹ thuật khai thác dữ liệu mới cũng như tìm hiểu các điểm nổi bật của dữ liệu- thành thạo ngôn ngữ lập trình phân tích dữ liệu: sql hoặc r hoặc python.quyền lợi- thu nhập từ 25trđ/tháng trở lên- thưởng tháng lương 13 cùng chế độ phúc lợi hấp dẫn- hưởng đầy đủ các chế độ theo luật lao động: nghỉ lễ tết, nghỉ phép, bhxh- tăng lương định kỳ hàng năm và theo hiệu quả công việc- tham gia bảo hiểm sức khỏe- ưu đãi mua hàng nội bộthông tin liên hệ công ty:ms giang– phòng hành chính nhân sựđịa chỉ: tầng 17, tòa nhà 319 bqp, số 63 lê văn lương, phường trung hòa, cầu giấy, hà nội.email: hanhchinhnhansu@elmich.vnsđt:0931.569.633',\n",
       "       '',\n",
       "       'experienced data scientist to:\\n\\nbuild ekyc components (face recognition, ocr, object detection, fraud detection), using state-of-the-art methods\\ndevelop ml models and provide solutions for acquisition, verification, validation, and fraud detection of user data\\n\\nrequirements\\n\\n\\n\\n\\nbs or ms in computer science or related fields\\n2+ years of experience in data science and mlops\\nmust be proficient in software design and software development.\\nmust be proficient in python, scripting language. experience with other programming languages (c++, java, javascript ...) is a plus\\nmust be proficient in linux system, version control system (git), virtualization and sw packaging tool (docker)\\ngreat communication skills\\ndesired skills:\\n\\n\\n\\nexperience with ml framework: tensorflow, pytorch, mxnet, onnx.\\nexperience with managing data science and computer vision toolkit, such as jupyterhub, opencv... is a plus\\nexperience with working with databases and query language is a plus.\\nfamiliar with mlops concept and toolkit is a plus\\nbasic understanding of machine learning techniques and algorithms\\nbs/ms in computer science with focus on machine learning is a plus\\n\\n\\nwhat we offer\\n\\n\\n\\n\\ncompetitive compensation package, including 13th-month salary and performance bonuses\\ncomprehensive health care coverage for you and your dependents\\ngenerous leave policies, including annual leave, sick leave, and flexible work hours\\nconvenient central district 1 office location, next to a future metro station\\nonsite lunch with multiple options, including vegetarian\\ngrab for work allowance and fully equipped workstations\\nfun and engaging team building activities, sponsored sports clubs, and happy hour every thursday\\nunlimited free coffee, tea, snacks, and fruit to keep you energized\\nan opportunity to make a social impact by helping to democratize credit access in emerging markets.\\n\\nabout us\\n\\n\\n\\nwe are an ai fintech company specialized in assessing credit profiles of consumers in emerging markets combining pioneering ai with large alternative data sources. in 2020 we reached our ambitious milestone of credit profiling 1 billion consumers spanning 4 countries - vietnam, indonesia, india & the philippines - and building a platform for the wider industry and the financial services industry, in particular, to provide the \"un & under\" served access to credit. at the core of this initiative has been our strict and unwavering adherence to the norms of consumer data privacy and consumer data rights.\\nbut we\\'re not satisfied as we embark on the next leg of our journey to deliver 100 million credit lines to consumers in the markets where we operate. although this goal is ambitious, we truly believe that by harnessing the power of ai & big data we can deliver financial access at an unprecedented scale.\\nas a firm, we\\'re audacious problem-solvers motivated by our impact on society. we deeply espouse the values of ownership - of our actions and initiatives, integrity in all we do, and agility in execution.\\nwe place great importance on doing what is right, what is best, and what is innovative. if you are smart, driven, and want to make a difference in the world with the most advance and fascinating technology, come join our team. we can satisfy your desire to explore new territory and give you the runway to really make an impact.',\n",
       "       'experience and user interface design.\\nstay up-to-date with the latest industry trends, technologies, and best practices related to self-service bi and saas solutions.\\n',\n",
       "       'experience range: from 3 years\\njob location: hanoi, hcmc\\nduty & responsibilities:\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tthis is a development project. as a hadoop big data engineer, you will operate and monitor scalable and resilient data platform based on hadoop ecosystem to address the business requirements: \\n– engineer reliable data pipelines for sourcing, processing, transforming, enriching and storing data in different ways, using data platform infrastructure effectively\\n– ingest and transform data sets from a variety of data sources\\n– focus on ingesting, storing, processing, and analyzing large datasets\\n– create scalable, high-performance web services for tracking data\\n– using java (spring boot framework) for development tasks\\n\\nrequirements: \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tmust have requirements:\\n– must have 3+ years of experience at a similar role\\n– having hands on experience in hadoop ecosystem (on-prem) including spark, hdfs, mapreduce, yarn, …\\n– good in programming language python.\\n– experience in monitoring large-scale data processing job (batch-processing, stream processing)\\n– having a background of software developing on java spring boot\\ngood to have:\\n– experience with hadoop distributions such as cloudera, hortonworks, comparison and feasibility\\n– experience with data warehouse and data management: data quality, data integration\\n– experience in etl, sql and nosql database\\n– experience with sre, patching & automation: kubernetes or docker & containerization\\n– experience working with big data in a cloud environment\\n– experience in data api\\n– good to have architecture knowledge or experience\\npreferred language for application: english\\n',\n",
       "       '', '',\n",
       "       'yêu cầu công việc\\n\\nindividual skills\\ngood communication skill and business understanding with abilities to drive cross-functional team\\nproactive problem solver, eye for detail, process driven\\nagile trained, can elicit user stories, draw process diagrams\\ndata modelling experience\\ngood understanding of data management - data lineage, meta data, data quality, data governance\\nanalytics experience\\n1.5+ years experience in similar role, experience in distribution / last mile delivery/ fulfillment services is preferable\\nsql and data analysis\\nstrong analytical skills with the ability to collect, organize, analyze, model, and interpret data\\nexperience with an etl framework like airflow, nifi\\nproficient in visualization tools: power bi, tableau, superset, data studio ect.\\nexperience with python\\n\\n\\ntại sao bạn sẽ yêu thích làm việc tại đây\\n\\nbenefit',\n",
       "       '', 'yêu cầu công việc\\n1. bằng cấp/chứng chỉ:',\n",
       "       'experience in the e-commerce industry.\\nwe are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\\ni. job descriptions\\n\\ndevelop and deliver action-oriented, insightful analytics presentations that provide consultative directions to key stakeholders;\\nconsolidate data from multiple sources including sales, supply chain, operations, marketing, and source databases to create integrated views that can be used to drive decision making;\\nleverage bi tools and other software applications to develop data models, conduct data analyzing and visualizing in dashboards and reports\\nwork with/or build several large and complex databases.\\n\\nii. skill and experience\\n\\nat least 3-5 years’ experience in business intelligence or relevant role;\\nbachelor’s degree and above in statistics, business, data analytics, and other related fields;\\nstrong in sql skills;\\nhaving knowledge in design data warehouse architecture;\\nhave experience in using python is a big plus;\\nability to demonstrate a high level of verbal and written (both english and vietnamese) to coordinate with internal stakeholders across departments;\\nbe opened minded, think out of the box and willing to do attitude;\\nexperience in business intelligence in e-commerce/fintech companies is a plus;\\nhaving knowledge in finance, logistics, operation or marketing is a plus;\\nentrepreneurial spirit and start-up mindset.\\n\\niii. why you will love joining us?\\nfor you to join\\n\\n\\n\\nfinancial well-being:',\n",
       "       'yêu cầu công việc\\n\\nkiến thức cần có:\\n\\nhệ điều hành: ubuntu server, window server\\nngôn ngữ lập trình: python, java\\ncơ sở dữ liệu: on-premes: oracle, postgres, mysql (nosql is a plus)\\n\\n\\n\\n\\nhọc vấn: tốt nghiệp đh trở lên 1 trong số các chuyên ngành: computer science, engineering, mathematics hoặc các chuyên ngành có liên quan\\nkiến thức tốt về: datawarehousing, cấu trúc dữ liệu và giải thuật, etl, elt\\ncó các kinh nghiệm làm việc sau đây là lợi thế:\\n\\ncó kinh nghiệm trong việc thiết kế và xây dựng data models, quy trình etl và elt dữ liệu từ nguồn về dwh, tối ưu hóa luồng dữ liệu\\nkinh nghiệm làm việc theo mô hình agile và scrum\\n\\n\\n\\n',\n",
       "       '', 'yêu cầu công việc\\n\\n-', '',\n",
       "       'job requirementsrequired qualifications:1-2 years of working experience as a data scientist or similar role in an it company, university, or research institute;highly analytical with a heavy emphasis on data mining and data visualization (problem formulation, analytical ability, synthesis);experience using statistical computer languages (r, python, slq, etc.) to manipulate data and draw insights from large data sets;experience with statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications;experience with common data machine learning frameworks (tensorflow, scikit-learn, nlp, etc);preferred qualifications:bsc/ba in computer science, engineering, or relevant field; a graduate degree in data science or other quantitative fields is preferred;experience in adverts & advertising network, online marketing;strong communication skills (good english communication skill is a plus);excellent teamwork mindset that can foster teamwork spirit among other members;demonstrating a willingness to learn.\\nquyền lợi\\nhiring processphone screening > home test > onsite interviews > offering.',\n",
       "       'experiences\\n\\neither full-time or part-time (minimum 25hs/week but more hours is welcomed).\\nmust have a laptop with minimum requirements: 8gb ram, ssd and i3.\\nmust have a basic understanding of python, oop (object oriented programming) and database.\\ngood logical thinking in programming.\\nshow your senior your progress (like test or demo).\\n\\n\\n3. why you’ll love working here\\n\\nwill provide support during your job (can discuss more details during the interview).\\npotentially become an official employee with the company benefits.\\nfree coffee, tea and cakes.\\nwe have these clubs for you to join: football, table football, music, english, media and more.\\nget advices for career development.\\n\\nworking hours: morning: 8h30 – 12h00; afternoon: 13h00 – 17h30. (monday to friday).',\n",
       "       \"kinh nghiệm làm data analyst - phân tích dữ liệu tại một công ty công nghệ.- có kinh nghiệm sử dụng toán học, công cụ trực quan hóa dữ liệu, phân tích kinh doanh và công nghệ chuyển đổi khối lượng lớn dữ liệu phức tạp thành giải pháp.- kỹ năng excel và phân tích dữ liệu tốt bao gồm khả năng sử dụng các công cụ bi.- kỹ năng sử dụng các công cụ visualize để chuyển hóa dữ liệu thành biểu đồ, báo cáo.- kiến thức hoặc kinh nghiệm làm việc về phát triển cơ sở dữ liệu sql.- kỹ năng giải quyết vấn đề và tư duy hoàn thành mục tiêu- có kỹ năng phân tích sắc bén, khả năng thu thập, tổ chức, phân tích và phổ biến lượng lớn thông tin một cách chi tiết và chính xác.- có niềm đam mê với dữ liệu.- cẩn thận, kiên nhẫn, chịu khó, ham học hỏi, có tinh thần trách nhiệm.* ngoài ra:- khả năng code cơ bản để xử lý các mô hình dự báo (predictive models) là lợi thế.- kinh nghiệm với google analytics là một lợi thế.- thành thạo tiếng anh và nghiên cứu tài liệu tiếng anh là một điểm cộng lớn. \\n\\n\\n\\n\\n\\n\\njob detail\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nposition type\\n\\nfull-time\\n\\n\\n\\n\\n\\n\\ncareer level\\n\\nstaff\\n\\n\\n\\n\\n\\n\\neducation level\\n\\nbachelor's degree\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ngender\\n\\nmale / female\\n\\n\\n\\n\\n\\n\\n\\njob categories\\n\\n\\nit - software\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ninformation\\n\\n\\n\\n\\n\\n\\n\\n\\nname:\\n\\n\\nphòng nhân sự\\n\\n\\n\\n\\n\\n\\n\\n\\nfhome building - 16 ly thuong kiet,  thach thang\\n\\n, \\n\\nhai chau district\\n\\n, \\n\\nda nang\\n\\n, \\n\\nviet nam\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n- các ứng viên quan tâm vui lòng gửi hồ sơ trực tuyến, gửi kèm file hoặc trực tiếp đến tại công ty \\n\\n\\n\\n\\n\\n\\napplication language:\\nvietnamese\\n\\n\\n\\n\\n\\n\\n\\n\\nabout company\\n\\n\\n\\n\\n\\n\\n\\n\\ncông ty cổ phần nal solutions\\n\\n\\n\\n\\nhttps://nals.vn/\\n\\n\\n\\n\\n100 - 499 employees\\n\\n\\n\\n\\ncontact: phòng nhân sự\\n\\n\\n\\n\\n\\n\\n\\nnal solutions is a vietnam - japan joint venture software technology company under nal holding. at nals, we bring technology solutions and develop diverse and high-tech products encompassing website development, mobile apps, ai & big data, iot ar/vr.\\nwith a board of experienced and skilled technical engineers, a dynamic, enthusiastic, and proactive working environment will always bring quality products and receive certitude from customers. regardless of project type or industry, nals consistently strives to provide comprehensive support from consulting to system development and deliver a great customer experience.\\n\\n\\n\\n\\nsee more\\n\\n\\n\\nsee less\\n\\n\\n\\n\\n\\n\\n\\nother jobs from this company\\n\\n|\\n\\nsee all\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\npython django developer\\n\\n\\ncông ty cổ phần nal solutions\\n\\n\\n\\nda nang\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\njava developer\\n\\n\\ncông ty cổ phần nal solutions\\n\\n\\n\\nda nang\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nphp developer\\n\\n\\ncông ty cổ phần nal solutions\\n\\n\\n\\nda nang\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ntechnical leader\\n\\n\\ncông ty cổ phần nal solutions\\n\\n\\n\\nda nang\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nprocess quality assurance (good at japanese)\\n\\n\\ncông ty cổ phần nal solutions\\n\\n\\n\\nda nang\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nwork location\\n\\n\\n\\n\\n\\nfhome building - 16 ly thuong kiet,  thach thang, hai chau district, da nang\\n\\n\\n\\n\\n\\n\\n\\ntags\\n\\n\\n\\nhai chau district\\nsoftware\\nit\\ndata analyst\\n\\n\\n\\n\\nshare\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ncopied\\n\\n\\n\\n\\n\\n\\n\\n\\n\",\n",
       "       'experience in developing ai solutions in a professional setting.',\n",
       "       'experience requirements\\n• bachelor’s degree in economics, business administration, banking & financeknowledge & skills• at least 03 year experiences of working in insurance/ finance/ banking or equivalent position• must be good knowledge in access, sql & vba. programming language c# (visual studio) is plus• be able to work independently and under pressure to meet the deadline committed in company level• be able to work with details and good analytical skills to deal with large of amount of complex data.• have good english skill (especially speaking and business writing)• possess good communication, problem solving and stakeholder management skills• be careful and responsible.\\ufeffplease click the apply button or contact ms tien ngo at +84 359 341 711 or',\n",
       "       'yêu cầu ứng viên\\nsv năm cuối các ngành có liên quan đến data sciencequen thuộc với linux oskiến thức tốt về data mining, data science / machine learninghiểu biết về databases chẳng hạn sql / mysqlkinh nghiệm sử dụng python, pandas, numpy, matplot, sklearn, pyspark or',\n",
       "       'yêu cầu ứng viên\\n- kinh nghiệm: mới ra trường, ',\n",
       "       'experience\\n\\n\\nbachelor degree in computer science or software engineering\\nspecializing in data science or a higher degree is a big plus.\\nat least 02-year-experience in building data platforms and pipelines for analytics.\\nexcellence at least 2 programming languages like sql, python, java, scala\\nexperience with hadoop, spark\\nexperience with cloud services (aws, gcp, azure)\\n\\nexperience with different database/data warehouse systems: mongodb, postgresql, bigquery, etc\\nexperience with data pipeline and workflow management tools: airflow, cloud composer, dbt, airbyte\\nknowledge of data viz tools like metabase, tableau, looker, etc\\nknowledge of streaming process platform is a plus\\nexposure to emerging open source technologies.\\n\\n\\nwhy you\\'ll love working here\\n\\nbenefit\\ncompetitive salary, 13th-month pay & performance bonus\\nmonthly allowance (transportation)\\nannual health check-ups.\\njoin training courses and tech sharing\\nopen communication with senior engineer & technical leader\\nchallenging working environment with attractive domain as logistics\\ncomfortable private working area for tech team\\nteambuilding + outing trip\\nour culture\\nwe collect, analyze and integrate data into every corner of the enterprise. data team is the backbone of our company. just like the “on-demand delivery” segment, our data team provides \"on-demand technologies\" to serve our fast-changing business needs and evolving market.\\nour data team has the power to try many up-to-date solutions, tools, and technologies such as cloud services, big data distributed systems, machine learning models…\\ncurrently, we have created different data positions to solve a variety of problems that are fun, challenging, and meaningful.\\n\\n',\n",
       "       'job requirementsat least 3 years of experience in software development.hands-on experience with java, spring, and spring boot is required.having a good understanding of messaging brokers is required.good experience working with typescript and angular.good experience working with web services (restful, soap).good knowledge of git workflow and jenkins is a big plus.passionate about software development.good background in software development processes and best practices.good command of english.effective communication both verbally and non-verbally.positive thinking and attitude in every situation.candidates are vietnamese people.work places : ho chi minh, da nang.benefits and incentivesattractive and high – competitive salarypremium healthcare insurance, annual health check up in the prestige and quality hospitalsannual performance review with high bonus and salary increaseonsite opportunities in the silicon valley and others13th month salaryvietnamese public holiday and special holiday bonuses, personal occasions allowances (birthday, newborn baby, marriage, bereavement, sickness,…)overtime payment',\n",
       "       'experienceexperience in office 365 usage and internet browsers.have interests in the position of sales admin/business intelligence/data analyst.ready to learn working with crm and sales financial systems.fluency in microsoft office, especially in excel and bi tools (power bi practice is an advantage).english fluency in speaking and writing.what we offer:working time: mond-fri, flexible working time, wfh is applicable.allowance for full-time internship:',\n",
       "       '', '', '', '',\n",
       "       'experience in a fast-paced startup environment.\\n\\n\\n\\n\\nmodel good leadership behaviour by engaging in peer to peer feedback and code reviews to foster a healthy, collaborative engineering culture as measured by scrum team health checks.\\n\\n\\n\\n\\nuse unit test and agile practices to deliver features continuously to production, measured by feedback and daily releases going smoothly.\\n\\n\\n\\n\\nembrace a fast paced environment and have a keen interest in data / machine learning tech.\\n\\n\\n',\n",
       "       '', '',\n",
       "       'yêu cầu công việc\\n\\n\\nfrom 2-year experience as a data analyst\\nfluent in writing & speaking english\\nmaster of sql and python\\nfamiliar with databases & cloud storage (google bigquery, snowflake…)\\nfamiliar with visualization tools (tableau, powerbi, looker…)\\nhaving experience in 2 domains (mobile application) and (financial investment) is a great advantage\\nunderstand the data needs of different departments (marketing, product, finance…)\\nunderstand the scopes of data engineers, data scientists to collaborate and take the lead if needed\\nhave a robust problem-solving mindset. be able to turn a simple question to become a comprehensive data dashboard that detects and solves a business problem\\ngood communication skills. be able to deliver, present and explain the results in an effective way for both technical and non-technical parties\\n\\n\\ntại sao bạn sẽ yêu thích làm việc tại đây\\n\\n\\ncompetitive salary with annual salary reviewwork in malaysia: up to 2000 usd with allowanceswork in vietnam: up to 900 usd\\n\\nan international working environment with friendly, creative colleagues from around the world\\nan excellent opportunity to grow your career. we encourage you to take the lead, initiate and make decisions\\ntuition fee sponsorship if you expect to become a data scientist or grow other data skills\\nenjoy birthday parties and frequent weekend parties and other team-building activities (depending on your work location)\\n\\n',\n",
       "       'yêu cầu công việc\\n\\n\\n\\n\\n\\n\\n• proven work experience as a personal assistant/secretary/administrator\\n• knowledge of office management systems and procedures\\n• ms office and english proficiency\\n• outstanding organizational and time management skills\\n• ability to multi-task and prioritize daily workload\\n• excellent verbal and written communications skills\\n• proactive, flexible, and self-motivated\\n• problem-solving skills and can work under high pressure\\n\\n\\n',\n",
       "       \"experience. we like to get to know our candidates, challenge them, and be able to give them proper feedback as quickly as possible. here's what our recruitment process looks like:\",\n",
       "       '',\n",
       "       \"job requirements:qualifications:• university/ college degree with marketing/ business majorexperience:• at least 5 years’ experience in market research (2 years' working experience for a market research agency is preferable) and minimum 1 year of working as a ci/ market research manager.job capabilities & behaviors requirements:• execution excellence: take full ownership to resolve difficulties, challenges and deliver the project objectives efficiently with highest standard of quality• working together: work well with different types of people including external research vendors and internal stakeholders; proactively contribute thoughts, ideas in meetings, cross-functional projects• strategic thinking: think a big picture and use good judgment to find hows to approach/ implement one issue/ challenge thoroughly and efficiently• great data analytic skill (i.e either qualitative or quantitative data points)• be a great communicator, both spoken and written english communication\\n\",\n",
       "       'experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \\n\\nall locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nstrategic partnerships – salesforce developer (bangkok- based, relocation provided)\\napply now\\nbangkok, thailand\\n\\nabout agoda',\n",
       "       '', '',\n",
       "       'yêu cầu ứng viên- tư duy logic, khả năng sắp xếp, phân tích, giải quyết vấn đề tốt\\n- có khả năng làm việc độc lập, đồng thời có kỹ năng làm việc nhóm\\n- là người chủ động, trách nhiệm, ham học hỏi, tinh thần tích cực\\n- chịu được áp lực tốt trong công việc và sẵn sàng làm ngoài giờ\\n- ưu tiên có kinh nghiệm phân tích dữ liệu hoặc truyền thông/marketing tối thiểu 6 tháng và sử',\n",
       "       '', '',\n",
       "       'experience across all touchpoints. ultimately, our goal is to minimize risk and optimize portfolio performance metrics for the benefit of our customers.\\nresponsibilities\\n\\n\\n\\nthe ideal candidate will have a passion for utilizing data and analytics to optimize portfolio performance. the successful candidate will be responsible for analyzing large datasets, developing predictive models, and generating actionable insights for credit card portfolio management.\\n\\ndeveloping and implementing credit risk models and analytical tools to assess portfolio performance, credit risk, and profitability.\\nanalyzing and interpreting data to identify trends, patterns, and insights that drive portfolio management decisions.\\nconducting ad-hoc analysis and data mining to support portfolio optimization and strategy development.\\ncollaborating with business stakeholders to understand their needs and requirements, and to develop and implement solutions that meet their needs.\\ncreating and maintaining reports and dashboards that provide insights into portfolio performance and key performance indicators (kpis).\\ndesigning and conducting a/b tests to evaluate the impact of new portfolio strategies and tactics.\\nmaintaining up-to-date knowledge of industry trends, best practices, and regulatory requirements related to credit card portfolio management.\\ncommunicating complex analytical findings and recommendations to non-technical stakeholders, including senior management.\\nmentoring and coaching junior analysts and data scientists on the team.\\npartnering with data engineers and other technical teams to ensure data quality, availability, and scalability.\\nconducting competitive research to stay informed of market trends, customer preferences, and emerging technologies that may impact the credit card portfolio.\\nperform highly complex activities related to financial products, business analysis, and build dashboards for portfolio monitoring.\\nutilize statistical and machine learning techniques to identify patterns and trends in financial data\\ndevelop and implement data-driven investment strategies that optimize portfolio performance\\n\\nrequirements\\n\\n\\n\\n',\n",
       "       '', '',\n",
       "       'yêu cầu ứng viên\\nsinh viên năm 3,4,5 hoặc đã tốt nghiệp trong vòng 06 tháng chuyên ngành cntt hoặc tương đương các trường đại học/ cao đẳng. có thể tham gia parttime (20h/tuần).thời gian thực tập: 3- 6 thángcó đam mê và nắm chắc các kiến thức cơ bản lập trìnhcó đam mê tìm hiểu các công nghệ mới, phát triển các sản phẩm mớikhả năng tư duy tốt, chủ động trong công việc, có tinh thần trách nhiệm cao để hoàn thành công việc được giaocó khả năng làm việc teamwork cũng như làm việc độc lập\\nquyền lợi\\nđược sự hướng dẫn, dìu dắt từ những người có kinh nghiệm nhiều năm, kỹ năng tốt.được tham gia vào dự án thực tế, quy trình làm việc chuyên nghiệp.có lương hỗ trợ: 2m/tháng',\n",
       "       'yêu cầu công việc\\n\\nyêu cầu công việc\\n\\ntốt nghiệp đại học hoặc cao hơn chuyên nghành toán, thống kê, kinh tế, ngân hàng, tài chính, khoa học máy tính, kỹ thuật phần mềm…\\ntối thiểu 5 năm làm việc trong lĩnh vực phân tích dữ liệu, mô hình học máy, học sâu. ưu tiên các ứng viên có kinh nghiệm tại ngân hàng\\ncó hiểu biết sâu sắc và có kinh nghiệm làm việc với các mô hình thống kê, dự báo, các thuật toán học máy, các kỹ thuật phân tích nâng cao\\nthành thạo sql, excel và',\n",
       "       'experience in data engineering, data warehousing, and data streamingstrong experience with sql database.experience with python programing language.experience with',\n",
       "       'experience\\n\\n\\n5+ years relevant work experience with large amounts of data\\neducation background in machine learning, statistics, math, data science, computer science or other closely related area\\nstrong machine learning/statistics background with hands-on experience in academia and/or industry, sourcing, cleaning, manipulating and analyzing large volumes of data\\nexperience with open-source machine learning libraries such as numpy, pandas, scikit-learn, distributed/parallel big data processing architecture (e.g., hadoop, spark, mllib) and deep learning framework (e.g., tensorflow, pytorch)\\nunderstand the business domain (fintech, adtech knowledge is a plus)\\ncan plan, prioritize and troubleshoot\\nexperience with recommendation systems is a plus\\nexperience with data science models in finance domain or crm (e.g., credit scoring, clv, churn, etc) is a plus.',\n",
       "       '', '',\n",
       "       'yêu cầu ứng viên\\n• advanced data analytics (azure data factory, data bricks, data lake, hd insights)• sql migration / modernization experience• azure sql database (standalone, elastic pool, serverless, managed instance, hyperscale)• azure synapse analytics• nosql: azure cosmos db, mongodb, cassandra• azure blob storage, azure data lake store• power bi and analysis services• machine learning services/cognitive services• 2+ years’ experience working with bi technologies and tools like microsoft power bi, tableau.• 2 years of experience with azure (da-100 certification acts as a plus)• 3+ years’ using programming languages such as java, dax, mdx, sql, python.• 2+ years’ bi related experience using etl, data warehousing management, data mining, report designer, or development; ability to write complex sql queries against a variety of data sources.• 3+ years’ heterogeneous database management systems like ms sql, oracle, mysql, sap etc. and working knowledge with various data sources like flat files (csv, delimited), web api, xml.• proven ability to build consensus between teams with differing architecture and design viewpoints and perspectives.• good understanding of data and query optimization, query profiling, and query performance monitoring tools and techniques.• experience implementing solutions on multiple hardware platforms and operating systems.• must be self-motivated, responsible, conscientious, and detail oriented. proven ability to follow priorities and timelines.• must have strong analytical and problem-solving skills.• english communication.\\nquyền lợi\\n- 13th month salary, social insurance- opportunity to work on new technologies and tools- opportunity to work with multicultural environment and travel.- performance review and adjust salary twice a year- very attractive remuneration package- a flat hierarchy and a culture of collaboration across all disciplines- modern workplace\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 30/06/2023\\n\\n\\n',\n",
       "       '',\n",
       "       'experience in deep learning and machine learning in the area of computer vision\\nexperience in building and optimizing microservices, data pipelines, and data sets\\nexperience working with cloud infrastructure such as aws, azure or gcp\\nproficient in python programming language\\nknowledge of react js advantageous, but not mandatory\\nexperience in restful api service development and familiarity with http / tcp\\nexperience in parallel and concurrent computation preferred\\nfamiliarity with devops container techniques including docker and kubernetes preferred\\n\\n\\n\\napplication form\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nupload maximum 1.5mb\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\n\\n\\n\\n\\nsubmit \\n \\n\\n\\n',\n",
       "       'kinh nghiệm\\n\\nkỹ năng giao tiếp, đàm phán và giao tiếp mạnh mẽ, để liên lạc với đồng nghiệp, khách hàng\\nkhả năng làm việc với cơ sở dữ liệu và nguồn tài nguyên cntt, khả năng sử dụng phần mềm báo cáo quản trị để thu thập và quản lý thông tin\\ntối thiểu 2 năm kinh nghiệm tại vị trí tương tự\\ntiếng anh thành thạo (cả nói và viết)\\n\\ntính cách\\n\\nchú ý đến chi tiết và hướng đến kết quả\\nkỹ năng viết báo cáo và phân tích mạnh mẽ\\nhiểu các nguyên tắc và thực hành chăm sóc khách hàng\\nkỹ năng giao tiếp, giao tiếp và viết lách tuyệt vời\\nthúc đẩy, năng lực, linh hoạt và sẵn sàng học hỏi\\nkỹ năng tổ chức và quản lý thời gian tuyệt vời với khả năng đa tác vụ\\nkhả năng viết báo cáo và thuyết trình tốt\\nkhả năng làm việc hiệu quả dưới áp lực\\nsáng tạo, trí tưởng tượng và khả năng sử dụng sáng kiến\\nkỹ năng làm việc nhóm, phân tích và giải quyết vấn đề tốt\\nnhận thức tốt về các hoạt độngkinh doanh và kiến thức tốt về các vấn đề hiện tại\\n\\nđể sắp xếp phỏng vấn cùng savills, hãy gửi cv của bạn đến chúng tôi và cho biết vì sao bạn tin tưởng rằng mình sẽ phù hợp với vị trí ứng tuyển.\\nbên cạnh những thông báo tuyển dụng cụ thể, savills việt nam rất chào đón những cá nhân xuất sắc, những người tin rằng mình sẽ thành công tại savills và trên thị trường bất động sản.\\nđể ứng tuyển vào các vị trí tuyển dụng của savills, vui lòng email bản cv của bạn đến địa chỉ  careers-hcmc@savills.com.vn\\nứng tuyển\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ncontact\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       "       'yêu cầu công việc\\n\\ncác yêu cầu về bằng cấp/chứng chỉtốt nghiệp loại khá trở lên chuyên ngành ngân hàng hoặc cntt hoặc các lĩnh vực có liên quanyêu cầu về kinh nghiệm/kiến thức\\ncó ít nhất 4 năm kinh nghiệm trong việc xây dựng chỉ số phân tích dữ liệu và thực hiện báo cáo.\\ncó 3 - 5 năm kinh nghiệm thực tiễn về',\n",
       "       'experience range: from 3 years\\njob location: hanoi, hcmc\\nduty & responsibilities:\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tas a hadoop big data engineer, you will operate and monitor scalable and resilient data platform based on hadoop ecosystem to address the business requirements:  \\ndevelopment tasks (30%)\\n– engineer reliable data pipelines for sourcing, processing, transforming, enriching and storing data in different ways, using data platform infrastructure effectively\\n– ingest and transform data sets from a variety of data sources\\n– focus on ingesting, storing, processing, and analyzing large datasets\\n– create scalable, high-performance web services for tracking data \\nsupporting tasks (70%) \\n– provide high operational excellence guaranteeing high availability and platform stability.\\n– technical analysis, trouble shooting and fixing the production incidents, problem tickets and changes\\n– take ownership of (data processing/batch jobs) applications from a support & maintenance perspective\\n– work on small enhancements (analysis, build/test, deployment/release support) \\n\\nrequirements: \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tmust have requirements:\\n– must have 3+ years of experience at a similar role\\n– having hands on experience in hadoop ecosystem (on-prem) including spark, hdfs, mapreduce, yarn, …\\n– good in programming language python\\n– experience in monitoring large-scale data processing job (batch-processing, stream processing)\\n– understanding of sla and meeting timelines for support activities \\ngood to have: \\n– experience with hadoop distributions such as cloudera, hortonworks, comparison and feasibility\\n– experience with data warehouse and data management: data quality, data integration\\n– experience in etl, sql and nosql database\\n– experience with sre, patching & automation: kubernetes or docker & containerization\\n– experience working with big data in a cloud environment\\n– experience in backend development using java\\n– experience in data api\\n– good to have architecture knowledge or experience \\npreferred language for application: english\\n',\n",
       "       \"experience in one or more areas of ai, such as machine learning, computer vision, image processing, natural language processinggood understanding of the latest research and technologies in artificial intelligence;experience in programming languages such as python, r, matlab, c++, java;hands-on experience with one or more deep learning frameworks (tensorflow, caffe, theano, pytorch);technical hands-on experience in system integration;communicate technical concepts effectively to non-technical audience;strong communication and documentation skills, adaptable and a team player.additional informationwhy bosch?because we don't just follow trends, we create them.because together we turn ideas into reality, working every day to make the world of tomorrow a better place. do you have high standards when it comes to your job? so do we. at bosch, you will discover more than just work.benefits and career opportunitiesworking in one of the best places to work in vietnamjoin a dynamic and fast growing global company (english-speaking environment)13th-month salary bonus + attractive performance bonus (you'll love it!) + annual performance appraisal100% monthly basic salary and mandatory social insurances in 2-month probationonsite opportunities: short-term and long-term assignments15++ days of annual leave + 1 day of birthday leavepremium health insurance for employee and 02 family membersflexible working timelunch and parking allowancevarious training on hot-trend technologies/ foreign language (english/chinese/japanese) and soft-skillsfitness & sport activities: football, badminton, yoga, aerobicfree in-house entertainment facilities and snackjoin in various team building, company trip, year-end party, tech talks and a lot of charity event\",\n",
       "       '',\n",
       "       'experienced analysts.\\n                                                                                    \\nxem toàn bộ mô tả công việc',\n",
       "       'experience\\n\\nrequirements\\npossession of a solid problem-solving mindset with the support of tools and technologies.\\nminimum three years of working experience in data engineering or jvm-based backend development.\\nefficient coding skills in sql, python, java/scala, and bash scripting.\\ncomfortable working with modern data technologies, including spark, airflow, and kafka.\\ngood understanding of different types of common data formats and data storage technologies.',\n",
       "       '', '',\n",
       "       'yêu cầu ứng viên\\ntrình độ học vấn: cao đẳng trở lên chuyên ngành quản trị kinh doanh hoặc các chuyên ngành kinh tế.có ít nhất 6 tháng - 1 năm kinh nghiệm làm việc liên quan đến xử lý, thống kê dữ liệu.sử dụng thành thạo công cụ excel.cẩn thận, chi tiết, chủ động trong công việc, tư duy hệ thống và chịu được áp lực cao.kỹ năng làm việc độc lập.kỹ năng giải quyết vấn đề.kỹ năng giao tiếp và làm việc nhóm.\\nquyền lợi\\nlàm việc trong môi trường vui vẻ, cởi mở, tôn trọng lẫn nhau.được đào tạo, tạo điều kiện học hỏi, khẳng định bản thân và thăng tiến.tham gia các hoạt động teambuilding.hưởng các chế độ khác theo quy định của nhà nước.\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 09/06/2023\\n\\n\\n',\n",
       "       'kinh nghiệm trong việc làm báo cáo phân tích hiệu quả kinh doanh, phân tích dữ liệu hoặc làm ở vị trí tương tự- có kiến thức về phương pháp luận phân tích dữ liệu toán thống kê và phân tích định lượng. kiến thức chung về hoạt động quản trị kinh doanh, mô hình kinh doanh, kinh tế- giao tiếp tự tin, có tư duy logic, kỹ năng giải quyết vấn đề - tư duy phản biện tốt\\n\\nđịa điểm làm việc\\n- trụ sở yody: đường an định, phường việt hoà, tp hải dương- văn phòng hà nội: 90 nguyễn tuân, thanh xuân, hà nội- ứng viên có thể làm việc tại hà nội, 1 tuần về hải dương 2 ngày- có xe đưa đón hà nội - hải dương hoặc sắp xếp nơi ở miễn phí tại hải dương (nếu làm việc cố định tại hải dương)\\n\\nquyền lợi\\n+ thu nhập 20-35 tr/tháng+ thưởng cuối năm: 1 - 3 tháng thu nhập, thưởng theo doanh thu, thưởng các ngày lễ, tết+ nghỉ chủ nhật, năm có 12 ngày nghỉ phép+ đóng bảo hiểm khi chính thức theo quy định+ phụ cấp ăn trưa miễn phí tại công ty+ cung cấp máy tính/thiết bị làm việc+ được tổ chức sinh nhật, du lịch 1-2 lần/năm, hưởng các chính sách đãi ngộ đặc biệt từ công ty+ hỗ trợ xe đưa đón hà nội - hải dương, chỗ ở miễn phí tại hải dương\\n\\nkết nối với yody\\n- hotline/zalo - ms quyên 0344 367 752- email:',\n",
       "       '', '',\n",
       "       'experience\\n2+ years of experience in relevant role\\nproficientwith some of the modern relational databases such as oracle, db2, and sql server\\nhand-on experiences on designing and developing etl solution by using ssis or other etl tools\\nstrong in writing t-sql, pl/sql\\ngood understanding of data modelling, processing and warehouse techniques\\nskilled at optimizing large complicated sql statements\\ncapable of troubleshooting common database issues\\nknowledge at reporting development with microsoft ssis and ssrs\\nanalytical thinking\\ngood interpersonal and communication skills\\ntime management and planning skill\\n\\nequal opportunity',\n",
       "       '', '',\n",
       "       'experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \\n\\nall locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nsenior analyst (supply analytics team, bangkok-based, relocation provided)\\napply now\\nbangkok, thailand\\n\\nabout agoda',\n",
       "       'job requirements:qualifications ',\n",
       "       'job requirements qualificationsdegree in business, mathematics, statistics, engineering, computer science, or other quantitative disciplineexperience min 2-3 years of solid experience in business intelligence/ business analyticsknowledge and skill ability to interpret data and translate them into actionable insightsknowledge of statistical and predictive modeling concepts, machine learning approaches, clustering and classification techniques/ recommendation and optimization algorithms is preferredskilled in sql and excelfamiliarity with one of the programming language r/python is a plusinherently curious about data with a strong desire to keep up to date with the latest developments in analytics and machine learningattention to detailscritical thinkingcan-do attitudedecent communication skills\\n',\n",
       "       'experience in the field of business intelligence within the fast-paced environment of zalopay. we are seeking someone who is eager to learn, detail-oriented, and passionate about using data to drive marketing strategies and business growth.main responsibilities:1. analytics & insights (40%)use sql and other query language (training will be provided) to retrieve data for analysis/planning.help identify and analyze trends, patterns, and insights through retrieved data.use excel and other visualization tool (training will be provided) to visualize data for communicating between stakeholdershelp the team with developing reports, dashboards, and visualizations to track key performance indicators (kpis) and campaign effectiveness.2. campaign operations (40%)help with documentation for campaign.help setup and organize meeting between cross-functional teams for campaign discussionnote taking between meetings and providing meeting recap afterward.work closely with cross-functional teams to understand business requirements and provide data-backed recommendations.3. planning & forecast (20%)retrieve and utilize historical data to help with campaign planning and forecast.assist the team in forming planning & forecast model to meet target kpis.\\n',\n",
       "       '', '',\n",
       "       'yêu cầu công việc:trình độ cử nhân trở lên, ưu tiên chuyên ngành tài chính, ngân hàng, kinh tế, kế toán, công nghệ thông tin, tin học;\\ntối thiểu 7 năm (chuyên gia)/ 5 năm (chuyên viên cao cấp)/ 3 năm (chuyên viên chính)/ 2 năm (chuyên viên)/ưu tiên có (nhân viên) kinh nghiệm làm việc trong lĩnh vực tài chính, ngân hàng tại các tổ chức dịch vụ tài chính liên quan đến xử lý dữ liệu hệ thống, phân tích dữ liệu, lập báo cáo;\\ntối thiểu 1 năm kinh nghiệm làm việc trong lĩnh vực lập trình vba trên excel: khả năng advance/excellent;\\nkinh nghiệm lập trình và cấu trúc dữ liệu cơ bản;\\nkiến thức sql căn bản;\\nkỹ năng phân tích, quản lý hoạt động và quản lý thời gian tốt; tư duy logic;\\nkỹ năng tiếng anh cơ bản (ưu tiên). \\n\\n\\n\\nchia sẻ công việc này\\n\\n\\n\\t\\t\\t\\t\\t\\tfacebook\\n\\t\\t\\t\\t\\t\\n\\n\\t\\t\\t\\t\\t\\tlinkedin\\n\\t\\t\\t\\t\\t\\n\\n\\n',\n",
       "       \"experience in the relevant technologies\\x84bachelor degree in it/ computer science or relevant background\\x84experience in the hadoop ecosystem and its components: hdfs, yarn, mapreduce, apache spark (python/scala), apache sqoop, apache impala, apache avro, apache flume, apache kafka\\x84preferred: having certificate cca175 – spark and hadoop developer\\x84designed and developed etl process\\x84experienced in unix with scripting experience is preferred\\x84should have strong knowledge on concepts of data warehousing models, data ingestion patterns, data quality and data governance\\x84experience on the hadoop systems with good understanding and knowledge of hadoop cluster\\x84good at english communication skillsadditional informationwhy bosch?because we don't just follow trends, we create them.because together we turn ideas into reality, working every day to make the world of tomorrow a better place. do you have high standards when it comes to your job? so do we. at bosch, you will discover more than just work.benefits and career opportunitiesworking in one of the best places to work in vietnamjoin a dynamic and fast growing global company (english-speaking environment)13th-month salary bonus + attractive performance bonus (you'll love it!) + annual performance appraisal100% monthly basic salary and mandatory social insurances in 2-month probationonsite opportunities: short-term and long-term assignments15++ days of annual leave + 1 day of birthday leavepremium health insurance for employee and 02 family membersflexible working timelunch and parking allowancevarious training on hot-trend technologies/ foreign language (english/chinese/japanese) and soft-skillsfitness & sport activities: football, badminton, yoga, aerobicfree in-house entertainment facilities and snackjoin in various team building, company trip, year-end party, tech talks and a lot of charity event\",\n",
       "       '',\n",
       "       'experience\\n                                                                                    \\nxem toàn bộ mô tả công việc',\n",
       "       'kinh nghiệm >1 năm trong việc xây dựng csdl (biết xây dựng trên ms sql là một lợi thế)\\ncó kinh nghiệm >1 năm trong xây dựng gói trích xuất dữ liệu (etl/ elt, biết xây dựng trên ms sql là một lợi thế)\\ncó kinh nghiệm về sql queries, stored procedures, and functions\\ncó kinh nghiệm về xây dựng ssis package\\nkinh nghiệm trong xây dựng reports and dashboards dùng ssrs hoặc các phân mềm khác (lợi thế)\\ncó khả năng điều chỉnh và cải thiện hiệu suất hoạt động của hệ thống (indexing, analyzing query execution plans) (lợi thế)\\nkĩ năng làm việc nhóm\\nkĩ năng xử lý vấn đề\\n\\n1-2 năm kinh nghiệm trong lĩnh vực\\n4. quyền lợi:\\n\\nmức lương: thoả thuận theo năng lực\\nmôi trường làm việc đam mê, năng động, sáng tạo, hoà đồng\\nchế độ đãi ngộ tốt\\nthực hiện chế độ theo quy định nhà nước ngay khi kết thúc 02 tháng thử việc.\\nđóng bhxh theo quy định nhà nước\\nthưởng quý,',\n",
       "       '',\n",
       "       \"experience in cpg sales, trade marketing, retailer - key account, merchandising.bachelor's degreeknowledge of sales processes in cpg companies, customers, modern and traditional markets.good knowledge of nielsen iq products, services and data preferreddigital knowledge, salesforceexcellent business english and vietnamese, both verbal and writtenproven sales acumenexcellent problem solving skills, solution oriented and good analytical skillvery good client-facing and communication/presentation skillsfinancial understanding (eg. p&l, ebitda) and how this relates to business successstrong collaboration and networking skillsadditional informationabout niqniq, the world’s leading consumer intelligence company, reveals new pathways to growth for retailers and consumer goods manufacturers. with operations in more than 100 countries, niq delivers the most complete and clear understanding of consumer buying behavior through an advanced business intelligence platform with integrated predictive analytics. niq delivers the full view.\",\n",
       "       \"experience- utilise our unique partnership with google and your knowledge of ga360 to implement, optimise and analyse performance for our clients- be highly proficient in javascript and sql- have strong communication and presentation skills, including training experience- join a high growth, values-driven company- enjoy flexible/remote working, with the ability to collaborate irl with teams in sydney, wollongong, or brisbane. for the right candidate we will consider other locations, including melbourne.what you will do with usreporting to the head of martech, you will play a key role within xpon technologies as one of our data analytics specialists, where you will liaise with clients, set the strategy, and drive the implementation of their ga 360.you will work closely with our clients to understand their business needs and requirements, and translate these into functional technical solutions across ga 360 and gtm implementations.you will be focused on working with our team to provide the best possible outcomes for our clients, and will:- understand and translate complex business requirements into a functional technical architecture that can be implemented and activated by clients.- implement and manage the delivery of solutions by working collaboratively with google gmp teams, internal teams, and delivery partners.- develop and maintain product knowledge about core competencies of google technologies, and other industry technology solutions.- document the current state of the client's technology and outline systems enhancements needed. serve as technical leader for xpon technologies' clients, with regards to programmatic advertising, analytics, measurement, attribution and marketing activation strategies.- develop deep business partnerships and trusted relationships with both partners and decision-makers at the c-suite level.- conduct effective and efficient troubleshooting, testing and qa analytics implementations.- be involved in weekly one on ones with actions to drive performance.- compile marketing reports and roi analysis.- contribute to strategy documentation and scoping for clients.a day of in the life of this role could include:- conducting discovery/audits to determine the foundation of a client's current set up.- establishing client side stakeholders/owners.- establishing architecture requirements for ga 360.- implementing technical gtm/ga solutions.- briefing internal teams on the solution.- working closely with the client and internal build team to deliver the required insights.- working to establish the right data foundations.- post implementation conducting monthly hygiene checks for ways to improve the data set.- providing ga & gtm training to client teams. \",\n",
       "       'yêu cầu ứng viên\\ntốt nghiệp đại học trở lên chuyên ngành: thống kê kinh tế- xã hội, tài chính.giao tiếp tốt .có khả năng diễn đạt, thuyết trìnhcó tinh thần trách nhiệm,cẩn thận, trung thực, nhiệt tình trong công việcưu tiên những ứng viên có thành tích học tập giỏi, xuất sắc (chưa có kinh nghiệm sẽ được đào tạo, tư vấn và chia sẻ về nghiệp vụ, kiến thức chuyên môn và kỹ năng mềm).\\nquyền lợi\\nmức lương thỏa thuận theo năng lực,kết quả làm việc.làm việc trong môi trường nghiên cứu, hiện đại, chuyên nghiệp, năng động, bình đẳng, phát huy tối đa khả năng chủ động và sáng tạo;được trang bị đầy đủ trang thiết bị phục vụ công việc;được đóng các chế độ bhyt, bhxh, theo quy định của nhà nước;hưởng các chính sách khen thưởng, phúc lợi theo quy định của công ty.\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 07/06/2023\\n\\n\\n',\n",
       "       'kinh nghiệm trong xây dựng data modeling và xây dựng logical data model (ldm), physical data model (pdm).\\ncó nền tảng kiến thức / kinh nghiệm làm việc với mdm tools and implementation\\ncó nền tảng kiến thức/ kinh nghiệm làm việc với mdm integration patterns (near realtime, batch)\\nxây dựng báo có dùng ssrs\\ncó khả năng lập trình, cấu hình và triển khai trên các nền tảng công nghệ của microsoft.\\ncó kĩ năng thực hiện test cases/ automation test là một lợi thế\\n\\nchấp nhận sinh viên mới ra trường có nền tảng theo yêu cầu\\n4. quyền lợi:\\n\\nmức lương: thoả thuận theo năng lực\\nmôi trường làm việc đam mê, năng động, sáng tạo, hoà đồng\\nchế độ đãi ngộ tốt\\nthực hiện chế độ theo quy định nhà nước ngay khi kết thúc 02 tháng thử việc.\\nđóng bhxh theo quy định nhà nước\\nthưởng quý,',\n",
       "       'yêu cầu công việc\\n\\n\\nđại học chuyên ngành kinh tế, qtkd, tài chính, marketing;\\ncó khả năng phân tích số liệu và thuyết trình;\\ncó hiểu biết về nghiên cứu thị trường;\\ncó kinh nghiệm làm việc ở vị trí tương đương tối thiểu 3 năm, ưu tiên trong ngành hàng fmcg;\\ntiếng anh và các công cụ microsoft office thành thạo; công cụ phân tích số liệu\\n\\ntổ chức, sắp xếp công việc khoa học; khả năng chịu',\n",
       "       '', '',\n",
       "       'job requirements\\n\\nat least 6-8 years of experience related field.\\nskills in strategic planning, logical thinking, problem solving, analytics\\nmanagement skill (better to have)\\nadvanced knowledge and mindset of digital marketing\\ntrendy & entertainment\\nproduction knowledge\\nsolid experience with sns digital marketing\\nexcellence in communication skill\\noutstanding presentation skills.\\n\\n\\nbenefits \\n\\nsalary: negotiable \\ninternational, challenging, and friendly working environment\\nsalary for 13th month\\nfull of social welfare under vietnamese labor law (insurance, annual leave, etc.)\\nannual travel, team building activities, and periodic health check\\n12 annual leave days and 3 paid summer holidays\\ntraining: trained in soft and technical skills\\n\\n\\napply online or feel free to contact me directly for more information about this opportunity. due to the high volume of applicants, we regret to inform that only shortlisted candidates will be notified. thank you for your understanding.\\n',\n",
       "       '', '', '',\n",
       "       'experienced researchers in machine learning, expert systems, or artificial\\n– intelligence to apply such technologies toward the development of an expert system that can help research worldwide financial markets. candidates need not have prior knowledge of financial markets, as the new hire will work closely with our highly accomplished quantitative researchers in the financial markets \\nwe offer outstanding career opportunities, which include:\\n– competitive financial rewards, relative to performance and position\\n– friendly and collegial working environment\\n– opportunity for promotion and career advancement\\n– opportunity to work with a team of highly accomplished experts in the financial markets to develop a industry frontier machine learning system.\\njob qualifications:\\n– ph.d. or m.s. degree from a top university in machine learning, expert systems, or artificial intelligence\\n– machine learning related working experience at top tier companies.\\n– have on-hand machine learning experience in resolving realistic large scale machine learning projects.\\n– industrial experiences in expert system, game theory, mcts, deep learning related projects are a big plus.\\n– proficient in c++ or python programming; knowledge of database is plus; knowledge of parallel computation is plus.\\n– experience with time-series data analysis is a plus.\\n– have a research scientist mind-set, i.e., be a deep thinker, creative, persevering, smart, a self-starter, etc.\\n– possess good english language skills\\n– have a strong interest in learning about worldwide financial markets\\n– have a strong work ethic\\nposition based in hanoi, vietnam.\\n',\n",
       "       '',\n",
       "       'yêu cầu công việc\\n\\n\\nstrong problem solving skills with an emphasis on product development.\\nexperience working with search engines: elasticsearch, sorl.\\nexperience working with machine learning operations (mlops)\\nexperience working with and creating data architectures and designing data warehouse\\nexperience working with sql / nosql database\\nexperience visualizing/presenting data for stakeholders using: ggplot, powerpoint, powerbi, metabase, etc. periscope,\\nexcellent written and verbal communication skills for coordinating across teams.\\na drive to learn and master new technologies and techniques.\\n\\n\\ntại sao bạn sẽ yêu thích làm việc tại đây\\n\\n\\nfastest growing fintech startup with state-of-the-arts technology\\ntop notch engineering team\\ncompetitive salary with regular review and advancement\\nopportunity to take charge of your own works and directly contribute to company products\\nsmall, young and close-knit team. we move fast, work hard and play hard.\\n\\n',\n",
       "       '',\n",
       "       'experience will be an advantage.good at english communication.opportunity to working in an international team and global projects.additional informationcommitted 13-month bonus and collaborative yearly performance bonus.15-day annual leave + birthday leave and will be added 1 more every 3 years.meal & parking allowances (60.000 vnd/day).premium insurance (pvi) for employee and 2 family members.overseas training programs and working onsite opportunity.good benefits of trade union activities, team building and company trip.global career path and transparent performance review system.loyalty bonus and day off for your long-service award every 5, 10, 15... year.opportunity to work in global projects of fast developing company being a part of innovation team contributing initiative ideas to the hi-tech world.engage in our diverse training programs which surely help strengthen both your personal and professional skills',\n",
       "       \"yêu cầu ứng viên\\n- bachelor’s degree in engineering, computer science (or equivalent experience)\\n- at least 6 months of relevant experience as a data analysis\\n- 3+ years of experience working as business analyst\\n- in-depth knowledge of car domain is nice to have.\\n- extensive experience working with data analytics and related technologies.\\n- demonstrable experience and skills with ms excel and ms powerpoint\\n- thorough knowledge of the relevant business units\\n- basic knowledge of data management issues\\n- significant data quality and metadata management expertise\\n- some familiarity with product and project management is desirable.\\n- nice to have prior fintech experience.\\n- in-depth knowledge of sql (complex join, subqueries, unions,e.g…) and powerbi is nice to have\\n- excellent understanding of business architecture ideas and how they're used.\\n- excellent written english communication skills\\n- ability to move fast and be efficient, making decisions on objective data evidence.\\n- ability to work independently.\\nquyền lợi\\n- salary up to 1800$\\n- health-care insurance tic\\n- working hour: 8h00-17h30 or 8h30 - 18h00 mon - fri\\n- salary package 14-16 months/ year\\n- performance review at least 1/ year\\n- team building, yep\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 10/06/2023\\n\\n\\n\",\n",
       "       'experiences\\n \\n\\nat least 02 years of working experience in banking data processing or related fields in mis, \\ndata warehouse\\n\\n \\n5.',\n",
       "       '',\n",
       "       'yêu cầu công việc\\n\\n\\ntốt nghiệp đại học, chuyên ngành toán, thống kê, ngân hàng, kinh tế, quản trị kinh doanh là một lợi thế\\ntối thiểu 1 năm kinh nghiệm lĩnh vực liên quan\\nthành thạo tiếng anh và việt\\nkỹ năng phân tích và tư duy logic\\nsử dụng thành thạo các công cụ báo cáo (sql/ python)\\n\\n',\n",
       "       '',\n",
       "       'experience:    strong technical experience of 7-12 years working with data projects preferably in cloud (aws, google, azure) and with at least 3 end-to-end production implementations in cloud hands-on experience of over 5 years in working with python, pyspark and its associated common packages to load and transform data hand-on experience of over 5 years working in cloud technologies like s3, glue, lambda, dynamodb or similar technologies  understanding and exposure of over 4 years in managing end-to-end data pipeline process and procedures experience of over 5 years in managing and driving conversations with business teams strong understanding and implementation experience of agile methodologies strong exposure and experience of over 5 years in code promotion process following devops processes in cloud self-motivated and comes with a can-do attitude with experience working in fast paced environment experience managing a team of data engineers and resolving technical issues faced by them    preferred experience:  demonstrates experience in translating high level business capability requirements into executable technical solutions broad experience of projects involving one/more of relevant data analytics technology areas viz big data engineering, data warehousing, data integration, data quality, data modelling, visualization, analytics prior experience in creating data models for building data pipelines across various layers of a data lake on cloud and on-prem setup.  prior experience working and co-ordinating directly with customer and multiple vendors across multiple locations for project delivery.required technical and professional expertiseas abovepreferred technical and professional expertiseas abov',\n",
       "       'yêu cầu ứng viên\\nsinh viên từ năm 2 chuyên ngành công nghệ thông tin, điện tử viễn thông, khoa học máy tính, toán tin ứng dụng và các chuyên ngành liên quan.có kinh nghiệm lập trình python/ đã làm các bài tập project liên quan đến pythonđã làm một số project cá nhân yêu cầu kỹ năng từ một trong số các ngôn ngữ lập trình hướng đối tượngbiết sử dụng docker, git là một lợi thế.tiếng anh giao tiếp cơ bản (kỹ năng nghe nói tương đương ielts 6.5 trở lên)\\nquyền lợi\\nhỗ trợ cơ bản up to 5.000.000 vnd/tháng, cùng thêm các phụ phí phát sinh trong quá trình làm việc như ăn trưa, gửi xe, kinh phí chạy thí nghiệmđược làm việc trực tiếp cùng mentor nước ngoài giàu kinh nghiệmđược cung cấp laptop cá nhâncó lộ trình thăng tiến lên nhân viên chính thức rõ ràngmôi trường làm việc cởi mở và năng động, khuyến khích trao đổi ý tưởng ở mọi cấp. bạn được chủ động làm việc, sáng tạo theo cách riêngcó hỗ trợ chứng nhận thực tập tốt nghiệp\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 30/06/2023\\n\\n\\n',\n",
       "       'yêu cầu ứng viên\\n● kiến thức:- tốt nghiệp cử nhân chuyên ngành công nghệ thông tin, điện tử viễn thông, tài chính, ngân hàng, kinh tế hoặc tương đương. ưu tiên ứng viên có bằng tốt nghiệp loại giỏi hoặc tốt nghiệp tại nước ngoài- ưu tiên có các chứng chỉ chuyên nghành data engineer, data analytics, data science cho xử lý dữ liệu lớn● kinh nghiệm:- tối thiểu 2 năm kinh nghiệm làm việc trực tiếp tại các công ty, dự án về ds- có kiến thức cơ bản về data mining- có kiến thức về phân tích và visualization dữ liệu- có kiến thức về machine learning, deep machine learning- biết cài đặt trên hadoop eco-sys, aws, gcp,… cùng các tech stack thông dụng như sparkml, jupiternotebook, airflow, vs code với các thuật toán, thư viện thông dụng hiện nay- sử dụng thành thạo python, scala và java là lợi thế- có kinh nghiệm làm việc theo mô hình agile- có kinh nghiệm trong lĩnh vực tài chính ngân hàng- có khả năng đọc viết tiếng anh (cơ bản) nghe nói (nếu có thể).\\nquyền lợi\\n● thu nhập cực hấp dẫn: upto 32m gross ( thỏa thuận mức lương tương xứng với năng lực và kinh nghiệm làm việc)● hỗ trợ kí hợp đồng chính thức, nhận 100% lương và đóng bảo hiểm từ ngày đầu tiên đi làm● thưởng dự án, gói thưởng lễ tết lên đến 14m/year (bonus at tết dương lịch, tết âm lịch, lễ 2/9, quà tết, quà trung thu, sinh nhật công ty, tập đoàn,. )● xét tăng lương cố định hàng năm hoặc 6 tháng/ năm theo đánh giá năng lực● được hưởng bhxh, bhyt, bhtn theo chế độ nhà nước ban hành và tặng thêm gói bhxh sức khỏe “nms care” cho nhân viên● tận hưởng nhiều sự kiện của công ty, từ thi đấu thể thao, tiệc sinh nhật hàng tháng, xây dựng đội ngũ hàng quý đến tiệc năm mới, chuyến đi công ty, du lịch hè, teambuilding, liên hoan, gala định kì gắn kết tình cảm',\n",
       "       \"experience requirements\\n5-7+ years of professional experience in data analysis, visualization, and deep-dive ad-hoc analysis.industry experience in fmcg/nutrition/pharma/consulting is advantageous.strong background in business intelligence, data analytics, and visualization, including dwh and bi tools.proficient in data extraction, aggregation, transformation, and modeling.advanced skills in sql, r, python, sas, and other relevant tools for working with databases.familiarity with machine learning models, supervised and unsupervised learning, and artificial intelligence.competency in bi technologies like integration services, sql server, mongodb, analysis services, automl, power bi, and qlik. education requirements\\nbachelor's degree in a relevant field is required (e.g., data science, computer science, statistics, business analytics).please click the\",\n",
       "       'yêu cầu ứng viên\\nđam mê và tham vọng trở thành tên tuổi trong lĩnh vực quantitative finance (những tỷ phú công nghệ)+ nắm vững kiến thức toán từ lớp 1 đến lớp 12+ biết ít nhất 1 ngôn ngữ lập trình hướng đối tượng+ đọc hiểu các tài liệu tiếng anh+ ',\n",
       "       '',\n",
       "       'kinh nghiệm đọc hiểu, xử lý số liệu (ưu tiên biết corebanking (t24) và bi –tool),',\n",
       "       'experience is one of the core components of fun games that are played for decades and remembered forever. \\nwe are looking for a data analyst with a passion for helping millions of players to enjoy our games in a trouble-free way. in this role you will be coordinating our external analysts with their data needs as well as our internal needs for your brains. the ideal candidate is someone with a strong analytical mindset and interest in analysing player behavior. someone always on the lookout for new ways to help us serve players better and improve overall player experience with new ideas and approaches.\\nresponsibilities\\n\\nsupport the player experience team and external analysts with their data needs\\ndefine what data should be collected and what types of analysis that data enables\\nproactively provide actionable insights and shed light on previously unexplored aspects of player experience\\ntogether with the rest of the team, develop vision and strategy for continuous improvement of support quality\\nwork side by side with subcontractors, external partners and internal tech teams\\n\\nrequirements\\n\\nexperience in a data analyst, manager or scientist role, interpreting and visualizing data to provide actionable insight and conclusions on player behavior\\nexpert knowledge of sql\\ncoding skills with r or python, and sql at a proficient level and some experience with bi tools like qliksenser or tableau\\nfluent in the data science workflow, applying statistics, understanding biases\\ngreat communication skills, both written and spoken, especially for non-technical audience\\nskills to work with a team but also work autonomously\\nproactive drive to improve our games and yourself, to',\n",
       "       'yêu cầu ứng viên\\n• bằng đại học các ngành liên quan: khoa học máy tính, kỹ thuật, vật lý, toán, tài chính, kinh tế...',\n",
       "       '',\n",
       "       'experience required.\\nuniversity graduate.\\nproficiency in excel’s advanced features is an advantage.\\nability to search for information, update content trends on social networks, forums and n\\nhonesty, carefulness, hard work.\\nhigh sense of responsibility.\\n\\n',\n",
       "       'kinh nghiệm từ 1,5 năm làm việc về các hệ thống big data,</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-weight: 400; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">nắm vững kiến thức cơ bản về khoa học dữ liệu, giải thuật, có tư duy lập trình hướng đối tượng và cơ sở dữ liệu.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 10pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 12pt 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">kiến thức về </span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">data-warehouse</span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">, xử lý dữ liệu phân tán, xử lý dữ liệu lớn (</span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">hadoop, spark,</span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\"> …)&nbsp;</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 10pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">kiến thức về xây dựng luồng xử lý dữ liệu (batch processing, stream processing...), và các công cụ quản lý workflow (luigi, airflow…)</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">kiến thức và kinh nghiệm xây dựng hệ thống chuyên sâu về dữ liệu với kiến trúc lambda/kappa/data lake</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">có kinh nghiệm làm việc về các hệ thống big data, data-warehouse, bi, sử dụng các mã nguồn mở như hadoop ecosystem, spark, hive, kudu, kafka, hbase, cassandra;</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 10pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">khả năng lập trình chuyên sâu&nbsp; </span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">java, scala, python</span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">...</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">lập trình thông thạo spark, spark-streaming;</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">kỹ năng sử dụng một trong các loại csdl </span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">(rdbms, graph databases, nosql, ...)</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.8; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">tư duy tốt, có khả năng nghiên cứu, đánh giá và cập nhật công nghệ mới.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">tiếng anh đọc hiểu tài liệu kỹ thuật.</span></p></li></ul><p dir=\"ltr\" style=\"line-height: 1.5; margin-left: -0.1pt; text-indent: -0.1pt; text-align: justify; margin-top: 14pt; margin-bottom: 0pt; padding: 0pt 0pt 14pt 0.1pt;\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;\">lý do để đồng hành với elcom</span></p><p dir=\"ltr\" style=\"line-height: 1.5; margin-left: -0.1pt; text-indent: -0.1pt; text-align: justify; margin-top: 0pt; margin-bottom: 14pt; padding: 0pt 0pt 0pt 0.1pt;\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">môi trường chuyên nghiệp, cởi mở, trao quyền và đề cao sự sáng tạo:</span></p><ul style=\"margin-bottom: 0px; padding-inline-start: 48px;\"><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 14pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">được mentor bởi đội ngũ quản lý, manager dày dặn kinh nghiệm, hỗ trợ sát sao, nhiệt tình.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 14pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">tham gia vào những dự án lớn, ứng dụng các công nghệ hàng đầu.</span></p></li></ul><p dir=\"ltr\" style=\"line-height: 1.5; margin-left: -0.1pt; text-indent: -0.1pt; text-align: justify; margin-top: 14pt; margin-bottom: 14pt; padding: 0pt 0pt 0pt 0.1pt;\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">tập trung hỗ trợ sự phát triển cá nhân:</span></p><ul style=\"margin-bottom: 0px; padding-inline-start: 48px;\"><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 14pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">được tư vấn, đồng hành và hỗ trợ phát triển sự nghiệp cùng với hệ thống career path (phát triển theo hướng chuyên gia hoặc hướng quản lý).</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 14pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">chính sách hỗ trợ các hoạt động học tập, phát triển bản thân</span></p></li></ul><p dir=\"ltr\" style=\"line-height: 1.5; margin-left: -0.1pt; text-indent: -0.1pt; text-align: justify; margin-top: 14pt; margin-bottom: 14pt; padding: 0pt 0pt 0pt 0.1pt;\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">quan tâm đặc biệt tới nhân viên:</span></p><ul style=\"margin-bottom: 0px; padding-inline-start: 48px;\"><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 14pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">văn phòng làm việc hiện đại với không gian mở; môi trường trẻ trung, năng động, sáng tạo và phát triển.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">gói đãi ngộ cạnh tranh với mức thu nhập hấp dẫn </span><span style=\"font-size: 11pt; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">(up to 1300 usd)</span><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\"> cùng chính sách nâng lương linh hoạt( 2 lần/ năm).</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">chính sách </span><span style=\"font-size: 11pt; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">thưởng hấp dẫn trực tiếp từ lợi nhuận công ty,</span><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\"> 6 khoản thưởng cho các ngày lễ khác trong năm. </span><span style=\"font-size: 11pt; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">gói thu nhập lên tới 14, 15 tháng lương/ năm.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">chăm sóc sức khỏe toàn diện với gói </span><span style=\"font-size: 11pt; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">bảo hiểm sức khỏe elcom care</span><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\"> do pti cung cấp được thiết kế riêng cho cbnv.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">khám sức khỏe thường niên tại bệnh viện hàng đầu cả nước.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">được hưởng toàn bộ các quyền lợi theo luật lao động ban hành về chế độ tham gia bảo hiểm xã hội, nghỉ lễ, nghỉ phép năm.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">bữa trưa </span><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">được phục vụ miễn phí tại văn phòng</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">các hoạt động văn hóa, giải trí phong phú:</span><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">du lịch, teambuilding, ngày hội sinh nhật công ty tại các địa điểm du lịch, resort cao cấp.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">ngoài ra, bạn sẽ được tham gia nhiều hoạt động thú vị như: office happy hours, team outings, tham gia các câu lạc bộ cực cool như clb thể thao (zumba, bóng bàn, bóng đá, cầu lông), chơi bi-a, âm nhạc,…</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 14pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">thời gian làm việc: thứ 2 đến thứ 6.</span></p></li></ul></span>\\n                                                    ',\n",
       "       'experience requirements\\n• 5+ years experience in a developer role• advanced working sql knowledge and experience working with relational databases, query authoring (sql) as well as working familiarity with a variety of databases.• experience with data warehousing architecture and data modeling• experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.• experienced in manipulating, processing and extracting data from various source systems.• experienced in implementing concepts such as slowly changing dimension (scd type) and change data capture (cdc) functionality in both an oltp (relational modeling) and olap (dimensional modeling) environments.• able to work independently with minimum supervision.• experience with testing methodologies with the stated major development language(s)/technology education requirements\\n• bachelor’s degree in computer science, engineering, mathematics, or a related technical discipline. contact person\\n\\n',\n",
       "       'experience in data analysis and reporting servicesgood knowledge in data transformation (etl) and processing solutions and sql database.experience with python programing language and reporting tools (bi, tableau, etc)experience in database performance monitoring and tuningknowledge of data modeling and data relationship analysis for the large',\n",
       "       'experiences in analytics and computer vision but any other field of ai will be considered too.\\n\\n\\n\\nwhat you will do:\\n\\n- getting involved in data science project from its inception to its delivery\\n\\n- researching our clients’ problem and dataset to assess the potential added value of data science and analytics solutions\\n\\n- selecting, acquiring and integrating client data for analysis\\n\\n- developing data hypotheses and methods and evaluating analytics and/or models\\n\\n- advising clients on the effectiveness of specific techniques based on project findings and comprehensive research\\n\\n- when required, working alongside engineers to implement data pipeline to provide data solution to clients’ problem\\n\\n- programming language for data science: python\\n\\n- cloud environment: aws, microsoft azure, google cloud platform\\n\\n\\n\\n- have strong experience/knowledge related to analysis/computer vision/other ml/ai fields\\n\\n- have good problem-solving skills\\n\\n- have hands on experience in industries as data scientist and/or r&d researcher\\n\\n- be proficient in at least one programming language, preferably python.\\n\\n- have experience/knowledge of working on the cloud (aws or azure or gcp etc)\\n\\n- have experiences/knowledge of databases\\n\\n- have experiences/knowledge of dnn, machine learning\\n\\n- have sufficient background in mathematics, statistics\\n\\n- have experience working on ai related projects\\n\\n- (senior) have deep understanding of a knowledge domain / industry vertical\\n\\n- (senior) must have experiences with leading projects and teams\\n\\n- be fluent in english\\n\\n- have a great ambition and ability to study the most leading-edge research by yourself and apply them to your own development.\\n                                                                                    \\nxem toàn bộ mô tả công việc',\n",
       "       '', '', '', '', '', 'job requirements:\\n', '',\n",
       "       'experience >• language skills: english - intermediate level (good english communication both verbal and written.)• educational background: bachelor degree in marketing, business, or related.• experience: - at least 2 years experience in marketing position, strong experience in market research, data analysis- experience in power bi and dax queries is plus.- knowledge of marketing principal and digital marketing.＜preferable experience＞- experience in electrical products will be plus                                    \\n\\n',\n",
       "       'yêu cầu ứng viên\\nproven experience as a machine learning engineer or similar role\\nunderstanding of data structures, data modeling and software architecture\\ndeep knowledge of math, probability, statistics and algorithms\\nability to write robust code in python, java and r\\nfamiliarity with machine learning frameworks (like keras or pytorch) and libraries (like scikit-learn)\\nexcellent communication skillsability to work in a team\\noutstanding analytical and problem-solving skills\\nbsc in computer science, mathematics or similar field; master’s degree is a plus\\nquyền lợi\\n● package: 13, 14 salary month + project bonus ● extra package: 16 mil /employee/year (bonus at: tet, new year, your birthday, cmc corp’s birthday, 2/9 and tet’s gift, middle-autumn gift, …) ● salary review 2 times/year or on excellent performance. ● opportunity to approach newest technology trends; development of your career within an international company ● building large-scale & global software products for our clients. ● onsite opportunities: short-term and long-term assignments in us, europe, asia. ● paid annual leave: 12 days ● company’s labor policy completely pursuant to vietnamese labor legislation plus other benefits offered by the company (pti care premium, company trip, holiday, sum-up, etc) ● exciting leisure: sport and art events (football club, family day, happy hour,…) ● working time: 8h/day (from monday to friday) , flexible working time (check in: 7h30-9h00 ; check out: 16h30-18h00\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 17/06/2023\\n\\n\\n',\n",
       "       '',\n",
       "       'experience in the relevant technologiesexperience in the hadoop ecosystem and its components: hdfs, yarn, mapreduce, apache spark (python/scala), apache sqoop, apache impala, apache avro, apache flume, apache kafkapreferred: having certificate cca175 – spark and hadoop developerdesigned and developed etl processexperienced in unix with scripting experience is preferredshould have strong knowledge on concepts of data warehousing models, data ingestion patterns, data quality and data governanceexperience on the hadoop systems with good understanding and knowledge of hadoop clustergood at english communication skillsadditional information',\n",
       "       'experience in data analytics, cost/pricing/promotional analysis, accounts payable review, retail buying/procurement, internal auditing, freight/logistics/supply chain, business intelligence….\\nworking time: monday- friday, 08:00 – 17:00',\n",
       "       'kinh nghiệm khoảng 03 năm trở lên về chuyên môn phân tích tài chính doanh nghiệp / phân tích kết quả hoạt động kinh doanh, ....;\\nưu tiên ứng viên có kinh nghiệm làm việc trong mô hình chuỗi nhà hàng f&b, chuỗi cửa hàng bán lẻ retails, fmcg, …;\\nkỹ năng tổng hợp & phân tích dữ liệu tốt. thành thạo excel và các công cụ tổng, phân tích và trình bày dữ liệu như power bi - sql, power query, data studio, …ưu tiên ứng viên có kinh nghiệm làm việc với hệ thống sap / bravo / oracle;\\ncó kỹ năng thực hiện phân tích và tổ chức các báo cáo về tài chính, kết quả hoạt động kinh doanh chính xác và có thể đưa ra các nhìn nhận, đánh giá và góp ý hiệu quả;\\ntính cách trung thực, ý thức bảo mật thông tin số liệu tốt;\\ntư duy tốt về kinh doanh và nắm bắt tốt xu hướng kinh doanh của ngành/ thị trường;\\nthái độ tích cực và có tinh thần đồng đội tốt. tinh thần trách nhiệm cao và chịu được áp lực công việc.\\n\\nphúc lợi\\n\\nđịa điểm làm việc: lầu 7 - gigamall phạm văn đồng, 242 phạm văn đồng, hiệp bình chánh, thủ đức, tp hồ chí minh\\nlương thỏa thuận theo năng lực;\\nthời gian làm việc: thứ 2 - thứ 6, 8h30 - 17h30;\\ncông ty cung cấp đầy đủ trang thiết bị làm việc cần thiết như desktop / laptop;\\nđảm bảo đầy đủ chế độ phúc lợi theo quy định của luật như: đóng bảo hiểm full 100% lương, bảo hiểm tai nạn 24/7, ... ngoài ra còn có gói bảo hiểm sức khỏe cá nhân (đối với các vị trí từ level supervisor trở lên);\\nlương tháng 13 + thưởng theo kết quả hoạt động kinh doanh;\\ngiảm giá trên tổng hóa đơn khi dùng bữa tại các nhà hàng thuộc hệ thống của golden gate;\\nmôi trường trẻ trung, năng động. nhiều cơ hội phát triển;\\ncông ty thường xuyên có các hoạt động: du lịch hằng năm, team building, tiệc cuối năm.\\n',\n",
       "       \"experience\\n\\nwhat we are looking for:\\nbachelor’s degree in mis, information technology, computer science, or other quantitative major. an understanding of basic accounting/finance is a plus;\\nsignificant data management and analysis experience;\\nstrong knowledge of tableau and able to develop insightful dashboards and reports that drive business decision making and outcomes;\\nintermediate to advanced database and transact sql skills;\\nintermediate powerpoint;\\nexperience in python, c#, vba, and ssis packages is a plus;\\nunderstand data models, database design development, data mining and segmentation techniques.\\nwork behavior\\nability to lead, plan and manage in an entrepreneurial, team-oriented environment;\\nhighly organized with strong project management skills, and drive to meet organizational objectives; ability to manage multiple projects on interrelated timelines;\\nstrong written and verbal communication skills;\\ndemonstrate experience in getting things done in dynamic, entrepreneurial environment;\\ndemonstrate a high attention-to-detail in the analysis and reporting of data.\\n\\n\\nwhy you'll love working here\\n\\nwe treat people fairly and with dignity, keeping a healthy perspective about life and work and fostering a positive and enjoyable work environment with appealing benefits as below:\\na competitive monthly salary based on your ability\\n13th month tet bonus & bi-annual performance bonus\\nannual salary review\\nattractive employee awards: employee of year, semi-annual outstanding employee\\nsocial insurance and healthcare insurance upon vietnam labor code\\npvi insurance package, and annual health check\\nan english-speaking environment\\nan open culture that spurs creativity, innovation, and inclusivity\\na variety of training courses for your career development\\ndiverse activities to foster relationships, including company trips, year-end party, employees’ birthdays\\nan open-space office, a cafeteria, and a range of modern equipment\\nother allowance from referrals and special occasions (weddings, seniority, and new-born baby)\\n\\n\",\n",
       "       'job requirement• bachelor’s degree or higher in accounting or finance.• at least 03 years of experience at the same position in fmcg/ mnc/ manufacturing companies.• knowledge of accepted local accounting practices and principles.• knowledge of applicable laws, codes and regulations.• attention to detail and accuracy, adaptive to change.• strong data analysis skills (ms power bi, sql, etc.) is a plus.• strong communication, teamwork skills, planning and organizing skills.• good judgment and problem solving skills.',\n",
       "       'yêu cầu công việc\\n\\nđam mê các lĩnh vực mô hình tài chính, quản trị hiệu quả tài chính, phân tích kinh doanh\\ncó kiến thức về phương pháp luận phân tích dữ liệu toán thống kê và phân tích định lượng.\\ncó kiến thức chung về hoạt động quản trị kinh doanh, mô hình kinh doanh\\ncó am hiểu chuyên sâu về mô hình giá/phí của các sản phẩm trong dịch vụ ngân hàng.\\nkỹ năng phân tích, kỹ năng lập kế hoạch, thống kê tổng hợp số liệu, tư duy kinh doanh\\ncó khả năng diễn giải dữ liệu, kết quả, báo cáo phân tích bằng ngôn ngữ kinh doanh\\ncó kỹ năng làm việc và giao tiếp với các bên liên quan, có tư duy logic, kỹ năng giải quyết vấn đề\\ncó khả năng tự định hướng và tính tự tổ chức cao\\nkhả năng giao tiếp và hoạt động chuyên nghiệp với tất cả các cấp nhân sự và các phòng ban khác trong toàn tổ chức.\\nquen thuộc với nhiều khái niệm, thực hành của lĩnh vực này.\\ntư duy phản biện: có thể xử lý dữ liệu theo cách để đưa ra các đề xuất cần có tư duy phản biện.\\ntốt nghiệp đại học trở lên với chuyên ngành tập trung vào tài chính, ngân hàng, quản trị kinh doanh,\\n8 năm kinh nghiệm chuyên môn trong lĩnh vực tài chính/ngân hàng\\nkinh nghiệm phân tích kinh doanh tối thiểu 5 năm.\\ncó kinh nghiệm liên quan đến xây dựng và quản trị mô hình tài chính\\nthành thạo power bi, excel, spss, python…\\n',\n",
       "       \"job requirements\\n\\n\\n•\\t3+ yoe in analytics, project management, strategy and/or tech consulting, or other related fields. experience in e-commerce is a plus.•\\tsharp critical thinking, strong analytical and numerical skills. good communication skills•\\teager to work in a fast-paced and ambiguous environment•\\tsolid knowlegde of sql and other programming language. hands-on experience in data extraction, cleaning, preparation, and dashboard development•\\thighly energetic and self-motivated. willingness to learn attitude with ability to work under pressure•\\tbachelor’s or master's degree in relevant field of study.\\n\",\n",
       "       'experience and contribute to the development of business applications using microsoft powerapps. you will work closely with the development team and under the guidance of experienced professionals to learn and apply powerapps development techniques, best practices, and design principles. this internship will provide you with valuable exposure to low-code development, business process automation, and the power platform.\\nresponsibilities:\\n\\n application development: collaborate with the development team to design and develop powerapps solutions, including canvas apps and model-driven apps, following established development practices and guidelines.\\n requirement understanding: assist in gathering and documenting business requirements by engaging with stakeholders and end users to ensure clear understanding of application needs.\\n user interface design: contribute to the creation of user-friendly and visually appealing user interfaces, considering usability and accessibility standards.\\n data integration: assist in integrating powerapps with various data sources, such as sharepoint, sql databases, excel, and external apis, under the guidance of senior developers.\\n testing and quality assurance: support the testing efforts by conducting functional testing, identifying bugs or issues, and participating in debugging and troubleshooting activities.\\n documentation and reporting: contribute to the documentation of technical specifications, user guides, and other relevant materials to ensure knowledge sharing and support future maintenance.\\n learning and skill development: actively participate in training sessions, workshops, and knowledge-sharing activities to enhance your powerapps development skills and stay up-to-date with industry trends.\\n collaboration and communication: collaborate with team members, actively participate in meetings, and communicate progress, challenges, and ideas effectively.\\n\\nrequirements:\\neducation/knowledge:\\n\\n education: currently pursuing a degree in computer science, information technology, or a related field. familiarity with low-code development platforms and a strong interest in business process automation is preferred.\\n technical skills: basic understanding of microsoft powerapps, power platform, or related technologies.\\n\\npersonalities/skills:\\n\\nhave a good analytical thinking.\\nhave the ability to work well independently and in teams.\\ngood in communication skills.\\nstrong ability to manage time.',\n",
       "       '',\n",
       "       \"experience\\n\\n\\nexperience in relational database design and implementation (ms sql is a plus).\\nbasic knowledge of transaction locking, sql server broker.\\nstrong analytical skills and be able to show initiative and take a proactive approach to your work.\\ngood english skills.\\nyears of experience: 03\\nprefer candidates who have a passion for long-term engagement.\\n\\n\\nwhy you'll love working here\\n\\n\\nattractive salary plus 13th-month salary.\\nhigh bonus and incentive-based on performance, seniority.\\nwork in a dynamic environment alongside team members who are talented and passionate about what they do.\\nin-house health club: gym, swimming pool, soccer field, volleyball court, and entertainment area.\\nannual health check.\\npersonal accident & health insurance.\\nsocial – health – insurance paid fully.\\nteam building events are fully sponsored by the company.\\ncomplimentary duty meals, snacks & beverages.\\noutstanding annual company trip.\\nlong-term service award.\\nquarterly and yearly incentive awards for best-performing employees.\\n\\n\",\n",
       "       'yêu cầu công việc:\\n- tốt nghiệp đại học trở lên về các chuyên ngành: bảo hiểm, toán học, kinh tế, quản trị hoặc các chuyên ngành liên quan;\\n- ít nhất 03 năm kinh nghiệm làm việc ở vị trí tương đương tại các công ty bảo hiểm nhân thọ;\\n- ưu tiên các ứng viên đã thi soa;\\n- tiếng anh tốt 4 kỹ năng;\\n- thời gian làm việc: thứ 2 - thứ 6 từ 08:30 - 17:30\\n- địa điểm làm việc: ',\n",
       "       'experience of progressively responsible experience in a directly related area, during which both professional and management capabilities have been clearly demonstrated (managed at least 15 people).\\n- statistics\\n- sas knowledge\\n- financial services experience \\n',\n",
       "       'kinh nghiệm tại vị trí tương đương\\ncó kiến thức về nghiên cứu và phân tích thị trường\\ncó kinh nghiệm về thu thập dữ liệu, quản lý hệ thống dữ liệu\\nsử dụng tiếng anh thành thạo và ưu tiên ứng viên biết thêm ngôn ngữ khác\\ntối thiểu đạt điểm b- ở các bài test bằng tiếng anh và kỹ năng viết báo cáo bằng tiếng anh tốt\\n\\nứng tuyển\\nđể sắp xếp phỏng vấn cùng savills, hãy gửi cv của bạn đến chúng tôi và cho biết vì sao bạn tin tưởng rằng mình sẽ phù hợp với vị trí ứng tuyển.\\nbên cạnh những thông báo tuyển dụng cụ thể, savills việt nam rất chào đón những cá nhân xuất sắc, những người tin rằng mình sẽ thành công tại savills và trên thị trường bất động sản.\\nđể ứng tuyển vào các vị trí tuyển dụng của savills, vui lòng email bản cv của bạn đến địa chỉ careers@savills.com.vn\\nứng tuyển vị trí này\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ncontact\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n              lưu tuyết \\n              hạnh\\n            \\n\\n\\nquản lý cấp caobộ phận hành chính & nhân sựhanoi\\n\\n+84 24 7301 9888\\n\\n\\nliên hệ ngay\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       "       'yêu cầu ứng viên\\nuniversity degree in computer science or information technology, finance, banking or related majorfemale; experience in sql, powerbi is compulsorystrong analytical thinking and ability to learn quickly with can do attitudeadvanced excel skill with knowledge in power query, power pivots- preferably working in financial & banking institution.\\nquyền lợi\\n• làm việc giờ hành chính từ t2-t6 (nghỉ t7 & cn)• thu nhập ổn định• được đóng bhxh và bhyt theo quy định của nhà nước• chế độ phúc lợi về sức khỏe, du lịch hàng năm• chương trình đào tạo nghiệp vụ dành riêng cho nhân viên• lộ trình thăng tiến rõ ràng• các phúc lợi khác theo quy định của ngân hàng.\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 01/07/2023\\n\\n\\n',\n",
       "       '', '', '', '', '', '', '', '', '', '', '',\n",
       "       'experience: 2-3 years experienced in data analytics. experience in retail industry, f&b and fmcg is a plus.\\n\\nskill:',\n",
       "       'experience in running campaigns on various search platforms such as google, search engines and onsite search tools of ecommerce platforms.familiar with agency environment (3+ years) - experienced in serving top fmcg clients - can handle working under pressure and leads junior membersstrong in search performance & search concept (user intention - keywords exploration| bidding| mapping - negative exclusion - technical set up) - proven record in seo-sem, onsite search (marketplace) or related fieldspay attention to details, comfortable working with data on daily basisknow how to use super metric, google studio & advance in excel (macro, advance formula, etc.) is a plus hands-on experience with seo/sem, google analytics sense of ownership and pride in your performance and its impact on a company’s successteamwork, time-management, and data analyst skillsknowledge on data visualization tool (google studio, tableau, power bi, power point) is a plusknowledge on other paid ads: cpas, programmatic, messenger, tiktok shop is a plusadditional informationan off-beat perspective and the courage to look at challenges.responsible and dedicated.a cheerful, humble individual who is very willing to learn every day, easy to manage and highly collaborative.someone who is honest, responsible, down to earth, hardworking, and passionate',\n",
       "       '',\n",
       "       'experiences in power bi developmentat least 1-2 year of experience working with data warehouse systems: ms sql, oracle sql, …at least 1-2 year of experiences in machine learning / ai developmenthave python programming',\n",
       "       'yêu cầu ứng viên\\nhọc vấn, kinh nghiệm:tốt nghiệp cao đẳng, đại học, ưu tiên chuyên ngành it.\\ncó từ 2 đến 4 năm kinh nghiệm trong phân tích dữ liệu hoặc vai trò liên quan trong các ngành hàng bán lẻ.\\ncó kinh nghiệm tạo báo cáo, trang tổng quan và bản trình bày.\\ncó kinh nghiệm với phân tích dữ liệu và các công cụ bi như tableau, qlikview, spark, powerbi.\\ncó kinh nghiệm sử dụng toán học, công cụ trực quan hóa dữ liệu, phân tích kinh doanh và công nghệ chuyển đổi khối lượng lớn dữ liệu phức tạp thành giải pháp.',\n",
       "       'job requirementmust have:bsc/m.sc. from a leading university in computer science, engineering, or a related disciplineexperience developing scalable and robust softwareexperience building distributed or data-intensive systemsexperience programming production systems in python and c++knowledge of parallelization, threading, multiprocessing, etc.familiar with workflow scheduling (e.g. airflow)experience working in linux environmentsstrong communication skills; ability to express complex concepts in simple termsnice to have:experience in deploying machine learning frameworks in productionexperience with kubernetes and kafkawork with leading cloud technologies (such as aws, and gcp)experience with sql databases (mysql, postgresql)familiar with deep learning frameworks (pytorch)',\n",
       "       'yêu cầu ứng viên:có ít nhất 01 năm kinh nghiệm ở các vị trí tương đương trong các công ty về logistics, ecommerce,…có tư duy phân tích và tối ưu vận hànhcẩn thận, tỉ mỉ trong công việc, tính chính xác caokỹ năng trung bình về sql/ google sheetskỹ năng trình bày, truyền đạt thông tin tốtkhả năng nhìn nhận tổng thể bức tranh toàn cảnh',\n",
       "       '', '', '', '',\n",
       "       'experience.pintu is looking for a quant trader/researcher who will lead and execute proprietary market-making operations for our exchange. the position reports directly to cfo. the quant trader/researcher will work closely with the engineering, risk management, and treasury ops team.job description : develop proprietary market-making (”mm”) operations for pintu exchange: develop in-house quantitative trading & risk management strategies/models for mm at pintu exchange that supports mm goal priorities. collaborate with engineering, risk management, and treasury ops teams to orchestrate the implementation of semi/fully-automated quantitative trading strategies.   build & manage a team of mm quantitative researcher/trader(s), including task allocation & mentorship. quant strategies monitoring & improvement : continuously monitor model parameters and back-test existing in-house mm strategies to meet the mm goal priorities research & identify new quantitative trading strategies that meets mm goal priorities   imm goal priorities: supports the improvement of pintu exchange liquidity; satisfies internal risk parameters; improves mm’s risk-adjusted returns requirements: 5+ past professional quantitative research/trading experience in global/ regional mm firms. ideally has a minimum of 3 years in crypto and 2 years in trade-fi quant research/trading experience. good understanding of market structures in both crypto (cex & dex) and financial markets (e.g. fx). past academic background in either in comp-sci, statistics, financial engineering/operation research, or mathematics. extensive experience in programming languages such as python/r/etc, or similar applicable programming languages. excellent understanding of high frequency trading (”hft”) strategies (a must) and/or algo-trading (plus). excellent communication, leadership, & interpersonal skills. had experience in managing a team. cfa & frm is a plus. timezone: max 3 time zones away from jkt/sg (or willing to relocate to singapore/bali/jakarta). ',\n",
       "       'experience in the e-commerce industry.\\nwe are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\\ni. job descriptions\\ndata mart & data warehouse\\n\\ncollaborate with the data engineer and data analyst team to build up, centralize data and improve the quality control process from multiple sources.\\nmanage the data collection process to be adaptable to the company’s continuous expansion, more advance analytic.\\n\\ndata analysis and reporting\\n\\nassisting line manager by preparing management reports and ad-hoc analysis.\\nautomate ar, ap report and forecast payment schedule.\\ndeepdive and control payment from system of amazon, walmart ensuring timing, accuracy and completeness of cash collection. build up dashboard to get things control more efficiently.\\nbuild up tools to optimize financing fee for cashflow.\\nautomate operational p&l and cashflow. connect with key metrics from s&op to give a full picture of fluctuation and figure out the root causes.\\ntogether with finance build up automate report/dashboard for evaluating performance of portfolio by various perspectives.\\nbuild up report/dashboard integrating key metrics relate to finance and s&op to give greater visibility of the relationships between resources, capabilities, and results.\\n\\nii. skill and experience\\n\\nbachelor‘s degree in business, finance, or other analytical disciplines.\\nminimum 02 years working experience in data analyst/business analyst/business intelligence. have experience in finance/fintech is an advantage\\nproficiency in excel & sql is required. knowing python or r is an advantage.\\nknowledgeable of statistics such as regression, normal distribution, etc\\nimpressive data visualization (not limited to tableau tools, google data studio, power bi, superset, etc.)\\n\\niii. why you will love joining us?\\nfor you to join\\n\\n\\n\\nfinancial well-being:',\n",
       "       \"kinh nghiệm làm việc ở vị trí nhân sự, kế toán hoặc các công việc tương đương - yêu thích làm việc với các con số. - thái độ làm việc tích cực, trung thực, nhanh nhẹn, nhiệt tình và tinh thần trách nhiệm cao\\n\\n\\n\\n\\n\\n\\njob detail\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nposition type\\n\\nfull-time\\n\\n\\n\\n\\n\\n\\ncareer level\\n\\nstaff\\n\\n\\n\\n\\n\\n\\neducation level\\n\\nbachelor's degree\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ngender\\n\\nfemale\\n\\n\\n\\n\\n\\n\\n\\nage\\n\\n25 - 33\\n\\n\\n\\n\\n\\n\\n\\n\\n\\njob categories\\n\\n\\nclerical / administrative\\n\\n, \\n\\nhuman resources\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ninformation\\n\\n\\n\\n\\n\\n\\n\\n\\nname:\\n\\n\\nphòng nhân sự\\n\\n\\n\\n\\n\\n\\n\\n\\nlầu 19, cao ốc flemington, 182 lê đại hành, p.15\\n\\n, \\n\\ndistrict 11\\n\\n, \\n\\nho chi minh\\n\\n, \\n\\nviet nam\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n- các ứng viên quan tâm có thể nộp hồ sơ trực tuyến, đính kèm file qua email hoặc trực tiếp đến tại công ty\\n\\n\\n\\n\\n\\n\\napplication language:\\nvietnamese\\n\\n\\n\\n\\n\\n\\n\\n\\nabout company\\n\\n\\n\\n\\n\\n\\n\\n\\ncông ty tnhh điều hòa gree (việt nam)\\n\\n\\n\\n\\nhttps://www.gree.com.vn\\n\\n\\n\\n\\n25 - 99 employees\\n\\n\\n\\n\\ncontact: phòng nhân sự\\n\\n\\n\\n\\n\\n\\n\\nđược thành lập vào năm 1991, từ một xưởng sản xuất nhỏ hiện tại gree đã phát triển thành là một tập đoàn hàng đầu thế giới về điều hòa không khí. gree là thương hiệu điều hòa số 1 thế giới năm 2015 do tập đoàn nghiên cứu thị trường euromonitor international bình chọn. năm 2015 gree đạt doanh số 25 tỷ usd, tốc độ tăng trưởng đạt 38% so với cùng kỳ năm trước và năm 2020 được xếp hạng 246 trong danh sách 2000 công ty lớn nhất theo bình chọn và thống kê của tạp chí forbes.\\nmỗi năm gree cung cấp ra thị trường thế giới 60 triệu bộ điều hòa dân dụng và 5,5 triệu bộ điều hòa thương mại, chiếm 1/3 sản lượng điều hòa thế giới, có nghĩa là cứ 3 bộ điều hòa bán ra trên thế giới thì có 1 bộ điều hòa do gree sản xuất. bên cạnh đó gree còn sở hữu hơn 14000 bằng sáng chế kỹ thuật, trong đó có hơn 5000 bằng sáng chế phát minh trong ngành điều hòa thế giới. điển hình trong đó là công nghệ g10 inverter, đây là công nghệ inverter tiên tiến nhất trên thế giới hiện nay giúp tiết kiệm 60% điện năng tiêu thụ, hoạt động ổn định và độ ồn cực thấp. công nghệ điều hòa thương mại sử dụng năng lượng mặt trời, công nghệ chiller ly tâm quang điện công suất tối đa 2000 hp. đồng thời gree cũng sở hữu nhiều môi chất lạnh thân thiện môi trường như: r410a; r290; r134; r407.\\nvề gree việt nam, công ty đã chính thức có mặt tại việt nam năm 2013 và đang có những bước tiến mạnh mẽ trên thị trường. trong khoảng thời gian từ 2013 đến 2015 gree đã đạt tốc độ tăng trưởng cao nhất thị trường với con số lên đến 65%. định hướng sắp tới của gree việt nam sẽ tiếp tục cung cấp đến khách hàng những sản phẩm chất lượng với nhiều tính năng vượt trội, tiết kiệm điện năng và thân thiện với môi trường. bên cạnh đó là những dịch vụ hậu mãi hấp dẫn đúng với phương châm luôn đặt sự hài lòng của khách hàng lên hàng đầu từ trước đến nay của gree.\\n\\n\\n\\n\\nsee more\\n\\n\\n\\nsee less\\n\\n\\n\\n\\n\\n\\n\\nother jobs from this company\\n\\n|\\n\\nsee all\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ntrợ lý kinh doanh (tiếng trung)\\n\\n\\ncông ty tnhh điều hòa gree (việt nam)\\n\\n\\n\\nho chi minh\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[hcm] phó giám đốc hành chính nhân sự\\n\\n\\ncông ty tnhh điều hòa gree (việt nam)\\n\\n\\n\\nho chi minh\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[hn] nhân viên tài xế\\n\\n\\ncông ty tnhh điều hòa gree (việt nam)\\n\\n\\n\\nha noi\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[hồ chí minh] chuyên viên hành chính lễ tân - tiếng hoa cơ bản\\n\\n\\ncông ty tnhh điều hòa gree (việt nam)\\n\\n\\n\\nho chi minh\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[hcm] chuyên viên xuất nhập khẩu - thời vụ\\n\\n\\ncông ty tnhh điều hòa gree (việt nam)\\n\\n\\n\\nho chi minh\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nphotos\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nwork location\\n\\n\\n\\n\\n\\nlầu 19, cao ốc flemington, 182 lê đại hành, p.15, district 11, ho chi minh\\n\\n\\n\\n\\n\\n\\n\\ntags\\n\\n\\n\\nchinese\\noffice worker\\ndistrict 11\\nrecruitment\\nhuman resource\\nkpi\\n\\n\\n\\n\\nshare\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ncopied\\n\\n\\n\\n\\n\\n\\n\\n\\n\",\n",
       "       'yêu cầu ứng viên\\nyêu cầu > 1 năm kinh nghiệm ở các vị trí data engineer hoặc big data engineer hoặc data scientist;ưu tiên hiểu biết 1 trong các hệ thống như hadoop eco system (on premise), spark, hive, kafka, cassandra, neo4j, elastic search…thành thạo 1 trong các ngôn ngữ lập trình: python, sql, pl/sql, java, .net, scala,…có kinh nghiệm với 1 trong các hệ thống csdl như sql server, oracle, hbase, cassandra, clickhouse, mongodb, maria db, redis,...kỹ năng làm việc nhóm và làm việc độc lập tốtcó khả năng làm việc dưới môi trường áp lực.\\nquyền lợi\\nrank lương không giới hạnmức lương cạnh tranh, 13 tháng lươngđược đào tạo bài bản, lộ trình thăng tiến rõ ràngcung cấp laptop/ pcnghỉ thứ 7, chủ nhật, 12 ngày phép/ nămcompany trip, team buildinghappy hours hàng tháng, free snacks, hoa quả, đồ uốngtổ chức sinh nhật, team lunch, …làm việc với khách hàng khối ngân hàng, công việc ổn định và lâu dài\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 22/06/2023\\n\\n\\n',\n",
       "       '', '',\n",
       "       'yêu cầu công việc\\n\\ntechnical requirements:\\nunderstanding ms power platform (power apps, power automate)\\nreport building and data visualization\\nknowing background in database analytics and data mining\\nknowing the program power platform ',\n",
       "       '',\n",
       "       'kinh nghiệm\\n\\ntối thiểu 2 - 3 năm kinh nghiệm ở vị trí tương tự\\nkỹ năng giao tiếp, đàm phán và giao tiếp mạnh mẽ, để liên lạc với đồng nghiệp, khách hàng\\nkhả năng làm việc với các tài nguyên cntt như cơ sở dữ liệu và bảng tính để thu thập và quản lý thông tin\\n\\ntính cách\\n\\nhiểu biết sâu sắc về nghiên cứu thị trường và phân tích thị trường\\nphải hiểu các nguyên tắc và thực hành chăm sóc khách hàng\\nchú ý đến chi tiết và hướng đến kết quả\\nmô hình định tính và định lượng mạnh\\nkỹ năng viết báo cáo và phân tích mạnh mẽ\\nkiểm soát độ chính xác / chất lượng\\nthúc đẩy tăng trưởng trong một môi trường chuyển tiếp\\nkỹ năng giao tiếp, giao tiếp, thuyết trình và viết lách tuyệt vời\\nthúc đẩy, năng lực, linh hoạt và sẵn sàng học hỏi\\nkỹ năng tổ chức và quản lý thời gian tuyệt vời với khả năng đa tác vụ\\nkhả năng làm việc hiệu quả dưới áp lực\\nsáng tạo, trí tưởng tượng và khả năng sử dụng sáng kiến\\nkỹ năng làm việc nhóm, phân tích và giải quyết vấn đề tốt\\nnhận thức liên quan đến kinh doanh và kiến thức tốt về các vấn đề hiện tại\\n\\nđể sắp xếp phỏng vấn cùng savills, hãy gửi cv của bạn đến chúng tôi và cho biết vì sao bạn tin tưởng rằng mình sẽ phù hợp với vị trí ứng tuyển.\\nbên cạnh những thông báo tuyển dụng cụ thể, savills việt nam rất chào đón những cá nhân xuất sắc, những người tin rằng mình sẽ thành công tại savills và trên thị trường bất động sản.\\nđể ứng tuyển vào các vị trí tuyển dụng của savills, vui lòng email bản cv của bạn đến địa chỉ careers-hcmc@savills.com.vn\\nứng tuyển\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ncontact\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       "       '',\n",
       "       'yêu cầu công việc\\n\\n• tốt nghiệp đại học trở lên các khối trường kinh tế, tài chính, ngân hàng...\\n• có kỹ năng tổng hợp, phân tích số liệu, thông tin, lên báo cáo;\\n• có khả năng làm việc độc lập;\\n• có kỹ năng về phân tích định lượng, tư duy logic, giải quyết vấn đề\\n• sử dụng thành thạo tin học văn phòng (word, excel…); sql; vba...\\n\\n\\njob tags:\\nchuyên viên kế hoạch\\nnhân viên kế hoạch\\nplanning specialist\\nnhân viên kế hoạch thư ký\\nplanning staff\\nstrategic planning executive\\nstrategic planning staff\\nchuyên viên phân tích kinh doanh\\nchuyên viên phân tích kinh doanh\\n',\n",
       "       '',\n",
       "       \"experience\\n\\n- bachelor degree in it/ computer science or relevant background.- have at least 5 year of experience in the relevant technologies.- expertise in implementation of modern data warehouse and lakehouse solutions, data quality and metadata management.- strong experience with azure synapse analytics, dedicated and serverless sql pools, adls gen2, azure data factory, databricks, stream analytics.- extensive etl/elt experience with azure data movement and transformation capabilities (azure synapse pipelines, azure data flow).- excellent working knowledge on sql/tsql.- deep knowledge of azure synapse data pipeline orchestration and computation framework azure synapse with spark pools.- strong experience on data modelling of dimensional, temporal, slowly changing dimensions and full/incremental/delta data loading processes.- familiarity with data visualization techniques using power bi cloud, tableau is a plus.- microsoft azure data engineer associate (dp-203) preferred.- good at english communication skills.\\n\\nwhy you'll love working here\\n\\nwhy bosch?because we don't just follow trends, we create them.because together we turn ideas into reality, working every day to make the world of tomorrow a better place. do you have high standards when it comes to your job? so do we. at bosch, you will discover more than just work.benefits and career opportunities\\nworking in one of the best places to work in vietnam\\njoin a dynamic and fast growing global company (english-speaking environment)\\n\\n13th-month salary bonus + attractive performance bonus (you'll love it!) + annual performance appraisal\\n\\n100% monthly basic salary and mandatory social insurances in 2-month probation\\n\\nonsite opportunities: short-term and long-term assignments\\n\\n15++ days of annual leave + 1 day of birthday leave\\npremium health insurance for employee and 02 family members\\n\\nflexible working time\\nlunch and parking allowance\\nvarious training on hot-trend technologies/ foreign language (english/chinese/japanese) and soft-skills\\n\\nfitness & sport activities: football, badminton, yoga, aerobic\\nfree in-house entertainment facilities and snack\\njoin in various team building, company trip, year-end party, tech talks and a lot of charity events\\n\\n\",\n",
       "       '',\n",
       "       \"experience.\\ncollaborating closely with various teams, including game designers, developers, ua, and product managers, to comprehend game objectives and offer data-driven recommendations.\\ncreating and maintaining comprehensive dashboards, reports, and visualizations to effectively communicate key performance indicators to stakeholders.\\nidentifying potential areas of growth and optimization through the analysis of player behavior, in-game economy, and content performance.\\ndesigning and implementing a/b tests to evaluate the effectiveness of proposed changes and support informed decision-making.\\ncontinuously monitoring and analyzing game performance to ensure product goals are met and to inform future development strategies.\\nstaying current with industry trends, tools, and best practices in gaming analytics to drive ongoing improvement within the team.\\n\\n\\nyour skills and experience\\n\\n\\nbachelor's or master's degree in computer science, statistics, mathematics, or a related field.\\na minimum of 2 years of experience in data analytics, preferably within the gaming industry.\\nproficiency in sql and experience handling large datasets and complex data structures.\\nfamiliarity with data visualization tools (e.g., looker studio, power bi) and a strong ability to present data effectively.\\nproficient in statistical analysis and data modeling techniques.\\nexperience with a/b testing and experimental design principles.\\nexceptional problem-solving skills and a keen eye for detail.\\nexcellent communication and teamwork abilities, with the capacity to work well in a dynamic, team-focused environment.\\na passion for gaming and a deep understanding of game mechanics and player behavior.\\n\\n\\nwhy you'll love working here\\n\\n\\ngreat facility to work. you will have a macbook and extra high definition screens\\nremote work 12 days / annual leave 12 days / sick leave 2 days\\npremium health insurance package for you and your relatives\\nannual health check-up at the premium clinic\\ndevelopment opportunity: sponsorship for all training courses includes business english...\\ninteresting workout activities: gym/fitness, yoga, kick-boxing, football after work\\nwith regular discussions, you will have a lot of opportunities to learn from experts in their fields\\n13th-month salary + annual bonus + project bonus\\ntwice yearly performance review and one-time salary review per year\\nreward & recognition in mobile platform\\ninternational opportunity to expose and grow\\nprofessional, creative working environment and talented teams, equal-opportunities & agile culture\\nat least one abroad travel every year. we often send our elites to international conferences like gdc, wwdc, google i/o... to update the latest technology\\n1-2 annual luxury company trip, team building\\nfree food & drinks, kitchen at work, playstation & billiards corner\\nfriday evening party, happy hours, team activities, and awesome parties\\nthe remaining annual leave will be transferred to the next working year\\nadditional allowance, gifts for birthdays, giving-birth, weddings, illness, mid-autumn festival, lunar new year, 1/1, 1/5, 1/6…\\npaternity leave policy offers more than 10 days of paid leave, not including days-off according to vietnam labor law regulations\\nfree parking\\n\\n\",\n",
       "       '', '',\n",
       "       'yêu cầu ứng viên\\n- tốt nghiệp đại học trở lên các chuyên ngành công nghệ thông tin hoặc các ngành có liên quan.- tiếng anh: khả năng giao tiếp; đọc hiểu tài liệu kỹ thuật.có ít nhất một trong các nhóm kỹ năng sau:- nắm vững kiến thức về database (oracle, sql, server), thành thạo pl/sql và các công cụ tích hợp dữ liệu elt.- có kinh nghiệm tối thiểu 1 năm làm việc với các công cụ bi (obiee/oas)- có kinh nghiệm tối thiều 1 năm phân tích dữ liệu, sử dụng các ngôn ngữ r, python,... sử dụng công cụ sas.có các kinh nghiệm sau là lợi thế:- có\\u202fcác\\u202fchứng\\u202fchỉ\\u202fcông\\u202fnghệ\\u202fliên\\u202fquan\\u202fđến\\u202fhệ\\u202fthống\\u202fmis/dw\\u202fnhư: oracle,bi, data analytics\\u202f.- có\\u202fkinh\\u202fnghiệm\\u202fsử\\u202fdụng\\u202fcông\\u202fcụ\\u202fetl: datastage, ssis, odi, informatica,.. ',\n",
       "       'yêu cầu ứng viên\\n- tốt nghiệp đại học trở lên chuyên ngành liên quan đến digital marketing, market research, toán, khoa học máy tính, quản trị thông tin, công nghệ thông tin, thống kê,....- có kỹ năng đọc và viết tiếng anh tốt- biết và code cơ bản r, python- sử dụng thành thạo công cụ phổ biến như: google data studio, sql server, powerbi, tableau, sas…- có kỹ năng sử dụng các công cụ visualize để chuyển hóa dữ liệu thành graphics; kỹ năng chuyển hóa dữ liệu thành actionable insight- có kỹ năng phân tích sắc bén, khả năng thu thập, tổ chức, phân tích và phổ biến lớn thông tin một cách chi tiết và chính xác- có kỹ năng lập kế hoạch, kiểm soát việc thực hiện kế hoạch- có ít nhất 03 năm kinh nghiệm trong lĩnh vực phân tích dữ liệu- kỹ năng áp dụng kỹ thuật trực quan hóa và khám phá dữ liệu hiện đại để cung cấp thông tin chi tiết hữu ích\\nquyền lợi\\n- được hưởng đầy đủ các chế độ phúc lợi xã hội như: bhyt, bhxh, bh thất nghiệp và nghỉ mát hàng năm;- mức lương thỏa thuận đảm bảo xứng đáng với sự đóng góp của mỗi người. cơ chế lương thưởng linh hoạt và khuyến khích sự phát triển của mỗi cá nhân.- môi trường làm việc chuyên nghiệp, sáng tạo, được đào tạo nâng cao kĩ năng trong quá trình làm việc, có nhiều cơ hội khẳng định bản thân và thăng tiến trong nghề nghiệp.- thời gian làm việc: 8h30 - 17h30 các ngày từ thứ 2 đến thứ 6 trong tuần;- nghỉ thứ 7, chủ nhật và các ngày lễ khác, phép năm theo quy định của luật lao động.\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 30/06/2023\\n\\n\\n',\n",
       "       \"experience in online education.about usfluentu is an online education company that helps people learn languages with real-world videos, including movie trailers, music videos, news and inspiring talks. we have a website, ios app (usually among the top 50 grossing ios education apps), and android app. founded in 2011, we’re a profitable, stable company with long-term focus, and we’re proudly self-funded. and we've been remote/distributed since day one.we get 5 million visitors per month on our blogs, 100,000+ people on our email list, and many more receiving web and mobile notifications.this is a unique opportunity to play a pivotal role on our business intelligence strategy, which is still in the early stages. we've worked with a reputable consultancy until now, and you'll be our first dedicated hire focused specifically on bi data engineering, empowered to build a program from the foundation up.job descriptionas our first analytics engineer, you will be responsible for:working in an agile/kanban style methodology while balancing long-term data modeling & infrastructure planninginterpreting & executing analytics feature requests from senior stakeholdersplanning & documenting work to be done, with regular feedback to stakeholders to minimize unnecessary workmaintaining & improving the entire data pipeline from start to finish, from extracting data from saas api's to configuring display options/creating charts for end users in looker, eg:using data-extractor-as-a-service tools such as stitch to extract data on a scheduled basis & oversee automated loading behaviorcreating & maintaining proprietary extraction tools, such as bash scripts on google cloud instancesmanaging the dbt etl pipelineacting as looker admin (development, security & administration)using software engineering best-practices (such as version control, component-based software/architecture, dry code etc).implementing testing frameworks & subjecting all work to qayou would work closely with the founder of fluentu and our other leadership.how we workwe’re a 100% distributed/remote team. here’s a little bit more about how we work:almost all of our communication is text-based (mostly via asana) and we value clear communication, among other things.most things are not urgent. we take pride in having a calm work environment.we also have a flat collaborative environment.we make decisions based on logic/reason.we believe in getting things done and continuous improvement.qualificationsour ideal candidate:can work in a fast-paced environment and be responsive to new requirementsis terrific at written communicationcan explain technical concepts to a non-technical audienceunderstands basic principles around content marketingis comfortable managing their own time and workflow independentlycan juggle multiple projects & work streams concurrentlyhas most or all of the following technical skills:experience working collaboratively using githas strong sql skills (we use bigquery standard sql)understands data modelling concepts, à la kimball dimensional modellingexceptional understanding of data manipulation (ie joins, data granularity, referential integrity, uniqueness/primary/foreign keys etc)some knowledge of sql database performancelooker, dbt & google cloud knowledge (can be easily learned if you possess the above skills)ideally linux/cloud architecture & python skills but these are not mandatory.has a deep interest in language learning or online education.is able to work a minimum of 25+ hours per week (pay is hourly) and is looking for something long-term.how to applyplease click here and fill out the form.\\n\\n\",\n",
       "       'experience. we stand for benchmark-setting customer service, delivery options, returns policies, and curation of brands.the data squadour data team knows our customers and their shopping habits better than they do. have you ever noticed suggested items when shopping online? or maybe a matching item for something you have just added to your bag? that’s our team!',\n",
       "       'experience etc.)', '',\n",
       "       'job requirementph.d. or m.s. degree from a leading university in a quantitative or highly analytical field (e.g.',\n",
       "       'experience in cybersecurity incident handling and experience in security operation center in banking/finance.\\nknowledge of security policy and technical standard development, multi-tiered trust zone structures, and complex edr, xdr management systems.\\nexperience with splunk and other similar tools/platforms.\\nexperience in improving and automating reports.\\nprogramming or scripting experience with python or others.\\nstrong verbal and writing english skills\\nattention to detail and task completeness\\na self-starter who can work unsupervised and delivery on their commitments\\nstrong interpersonal and communication skills with the ability to lead and work as part of a team\\nknowledge with iso 27000 series, nist scf…\\n',\n",
       "       'yêu cầu ứng viên\\ntốt nghiệp chính quy loại khá trở lên chuyên ngành khoa học máy tính, cntt, toán học ứng dụng, điện tử; ..trình độ tiếng anh toeic 650 trở lên hoặc tương đươngkinh nghiệm 1 năm trở lên với vai trò ai engineer hoặc tương đươngưu tiên: đã tham gia xây dựng, triển khai >= 2 sản phẩm, giải pháp ai\\nquyền lợi\\nchế độ lương thưởng hấp dẫn với lương tháng 13đánh giá hiệu suất: 2 lần/nămcơ hội thăng tiến và thu nhập phù hợp tùy vào chuyên môn hoặc khả năng quản lý.được học hỏi: sds tạo điều kiện cho mọi người rèn luyện ở mọi lúc mọi nơi, đồng hành và thúc đẩy phát triển cá nhân từ đồng nghiệp và quản lý giàu kinh nghiệmđược thử sức trong một môi trường làm việc trẻ trung, cởi mở với chính sách đãi ngộ tốtdu lịch hằng năm với địa điểm hấp dẫn, thường xuyên tổ chức các hoạt động team building gắn kết cộng đồng, các hoạt động vui chơi giải trí cho nhân viên.tham gia chương trình hàng tháng, các buổi liên hoan, sinh nhật hàng tháng, tiệc noel, tất niên,…được tham gia bhxh, bhyt, bhtn, chế độ nghỉ phép ',\n",
       "       '',\n",
       "       'job requirements:\\n\\nbachelor’s degree in marketing, economics, business administration, or related fields.\\nat least 1 year experience in a research/insight role or related position.\\nhaving experience in social listening is an advantage.\\nworking at an agency is a plus.\\nbe enthusiastic about social media empowerment and its possibilities to build strong brand propositions.\\nbe convenient for analyzing a variety of data types (number, text, image…) analysis.\\ngood at analytical and report writing skills.\\ntrend catching.\\nwillingness to analyze data points for large databases.\\nstrong interpersonal, negotiation and communication skills for liaising with colleagues, customers..\\nenglish proficiency, especially in developing reports.\\nproficient in office informatics, especially excel and powerpoint.\\n\\nwhy you’ll love working here: \\n\\nyoung, dynamic environment and freedom to creative.\\ntransparency and honesty are the 2 factors from our core value.\\ntrust with customer and commitment through standard quality products and solutions.\\nhuman oriented.\\n\\nbenefits include: \\n\\n100% salary during probation.\\nworking monday – friday.\\ncompany trip, team-building and other social activities.\\nwork from home policy\\nsalary bonus, performance review\\ngifts on holidays, birthday\\n13th-month salary\\ntraining-on-the-job\\n\\ncontact info:\\n\\nemail: recruitment@kompa.ai\\nfacebook: kompa life\\n',\n",
       "       'kinh nghiệm về data streaming (kafka/ storm/ samza/ aws kinesis...)- có kinh nghiệm sử dụng message queue (rabbitmq / google pubsub/ aws sns/ active mq)',\n",
       "       '',\n",
       "       'experience in data/software engineering in a highly scalable production environment\\n2 years of experience developing data warehouses on snowflake platform, required\\ngood knowledge of architecting large-scale data infrastructure in the cloud platform good knowledge of big data technologies like hadoop,hive,spark, redshift aws or other real-time streaming\\ngood knowledge of server-side programming languages (preferably python) and golang.\\ndevops experience (devops or gitlab) delivering continuous improvements\\ndata visualization and dashboarding experience (power bi, tableau, etc.)',\n",
       "       'experience working in unix/linux; familiar with bash scripting\\n– the candidate must have knowledge of computer systems, object oriented design, data structures and algorithms and familiarity with at least one major programming language (perl, python, java, c++), experience with relational databases (mysql)\\n– bachelor’s degree required; degree in computer science/electrical engineering or\\nrelated field preferred\\n– strong written and verbal communication skills\\n– excellent analytical skills and a passion for solving problems\\n– be detail oriented and capable of multitasking and delivering in fast-paced work environment\\n',\n",
       "       'yêu cầu ứng viên\\nhọc vấn: tốt nghiệp đại học các chuyên ngành: qtkd/ kinh tế/ toán tin ứng dụng/toán thống kê/ tài chính hoặc các ngành có liên quan.kinh nghiệm từ 1-3 năm tại vị trí tương đương ngành hàng bán lẻ, chuỗi siêu thị, fmcg ...kỹ năng cần thiết: phân tích dữ liệu (excel, power bi, ...)kỹ năng trình bày báo cáo, thuyết trìnhtư duy logic\\nquyền lợi\\nlương cạnh tranh, lương tháng 13++, thưởng cuối năm.phụ cấp cơm 50.000/ngàythời gian làm việc: từ 8h-17h00, t2-t6phụ cấp ngoại ngữ hấp dẫn, lên đến 3.000.000/tháng (anh, hàn)chế độ bhxh, bhyt, bhtn trên tổng thu nhập; bảo hiểm tai nạn 24h; bảo hiểm chăm sóc sức khỏe.môi trường làm việc năng động, có nhiều cơ hội đào tạo và thăng tiến.\\ncách thức ứng tuyển\\n\\nhết hạn nộp đơn\\n',\n",
       "       \"experience in power bi developmenthands-on \\x84experience in sql query in sql server\\x84hands-on \\x84experience in sql server integration services (ssis)\\x84hands-on \\x84experience in  sql server reporting services (ssrs)\\x84good at unit testing and integration test strategies\\x84willing to support team members/others on db-related tasks\\x84good english communication skills\\x84must be able to multi-task and deal with changing prioritiesadditional informationwhy bosch?because we don't just follow trends, we create them.because together we turn ideas into reality, working every day to make the world of tomorrow a better place. do you have high standards when it comes to your job? so do we. at bosch, you will discover more than just work.benefits and career opportunitiesworking in one of the best places to work in vietnamjoin a dynamic and fast growing global company (english-speaking environment)13th-month salary bonus + attractive performance bonus (you'll love it!) + annual performance appraisal100% monthly basic salary and mandatory social insurances in 2-month probationonsite opportunities: short-term and long-term assignments15++ days of annual leave + 1 day of birthday leavepremium health insurance for employee and 02 family membersflexible working timelunch and parking allowancevarious training on hot-trend technologies/ foreign language (english/chinese/japanese) and soft-skillsfitness & sport activities: football, badminton, yoga, aerobicfree in-house entertainment facilities and snackjoin in various team building, company trip, year-end party, tech talks and a lot of charity event\",\n",
       "       '', '',\n",
       "       'kinh nghiệm\\n\\nít nhất 5 năm kinh nghiệm trong mảng phân tích số liệu (bi).\\nít nhất 2 năm kinh nghiệm quản lý đội ngũ phân tích số liệu có từ 3 chuyên viên trở lên.\\n\\n3. kỹ năng, yêu cầu khác\\n\\nam hiểu sản phẩm, dịch vụ ngành ngân hàng.\\nkỹ năng phân tích và giải quyết vấn đề tốt.\\nkỹ năng giao tiếp, thuyết trình, thuyết phục và quản lý dự án tốt.\\nquen thuộc với cơ sở dữ liệu (sử dụng ngôn ngữ sql), hiểu được mô hình dữ liệu và các liên hệ. có thể làm việc được với các kỹ sư dữ liệu và chuyên viên phân tích dữ liệu để xây dựng các bảng dữ liệu, các data marts cần cho công việc của bộ phận.\\ncó kỹ năng xây dựng dashboard bằng các công cụ như power bi, data studio ….\\nquen thuộc với python và các công cụ để hỗ trợ xử lý dữ liệu lớn.\\n',\n",
       "       '',\n",
       "       'experience in relevant domain (crm, big data, business intelligence, analytics reporting).\\nexperience with etl, data management, transformation, and modelling•experience with cloud technologies•required knowledge in sql, c#, .net.\\nexperience with reporting service like ssrs.\\nknowledge and experience in end-to-end project delivery, hybrid / agile delivery methodologies•previous experience as a data engineer or in a similar role.\\ntechnical expertise with data models, data mining, and segmentation techniques.\\nknowledge of programming languages •hands-on experience with sql database design.\\ngreat numerical and analytical skills•degree in computer science, it, or similar field•data engineering certification will be plus•good communication skill.\\n\\nqualification\\n\\nbachelors or masters in it or computer science.\\nmaster or equivalent.\\n\\nsoft skills\\n\\nexcellent written and verbalcommunication skills.\\ncapacity to manage high stress situations.\\nability to multi-task and manage various project elements simultaneously.\\nleadership skills•big picture thinking and vision.\\nattention to detail•conflict resolution skills.\\n\\nto apply for an interview with savills, please send your cv (with your photo attached) and a clear summary of why you believe you have a strong fit with savills. further to specific advertised vacancies, savills vietnam encourages applications from talented individuals who feel they have what it takes to succeed at savills and in the real estate market.\\nfor career opportunities, please email your cv and cover letter to careers-hcmc@savills.com.vn\\napply now\\n\\n\\n\\n\\n\\n\\n\\n\\ncontact\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       "       \"experience in developing machine learning/data science applicationstrong experience in computer visionstrong programming skills in python, javascriptgood foundation in math and algorithmshave knowledge of neural networksexperience in using ml frameworks such as tensorflow/ keras/ pytorchadditional informationperks you'll enjoy\",\n",
       "       '',\n",
       "       'kinh nghiệm sẽ thỏa thuận dựa trên năng lực, đảm bảo mức cạnh tranh so với thị trường.\\n- hưởng từ 13-16 tháng lương/năm, chưa tính các khoản thưởng khác.\\n- được tham gia vào các dự án lớn đang đang triển khai tại các cơ quan nhà nước, các tập đoàn, ',\n",
       "       '',\n",
       "       'yêu cầu công việc\\n\\n• bachelor degree in supply chain management, business analytics, business administration\\n• more than 2',\n",
       "       '', '',\n",
       "       \"experienced leadership team, owning more than 40% of our equity, have delivered industry-leading investment returns for shareholders.job descriptionfollow line manager to lead the team conducting the valuation for residential & commercial real estate properties.build, maintain, expanse and enhance client relationships in order to achieve the business plan for valuation & advisory team.responsible for administering, managing and controlling the operation of the team to achieve the business performance as well as to ensure compliance of valuation standards (both international and vietnam), vietnam laws. ensuring that all policies and procedures are adhered to so that consistent and standard practice is achieved across the colliers group.recruit, supervising, training, developing staff on valuation and client requirements as well as assessing staff performance. leading and training the team in valuation approach (income approach; market approach, cost approach), carry out feasibility study and market research, highest and best use report for real estate development consulting.design and implement databases for ease of reference of up-to-date market information and establish systems to ensure that those databases are accurate and up to date at all times.prepare as required market weekly and monthly reports and other studies, documents as instructed by the line manager.at all times to be aware of activity within the marketplace relevant to your field of operation and be mindful of developing such information received into business opportunities for the company.various other job related tasks as assigned by the bod.qualificationsbachelor's degree in finance, economics or related fieldmof license or mrics is in a must.5+ years of property valuation consulting experience.in-depth knowledge of valuation approaches: cost, market, and income approach; experience in financial modelling, real estate project feasibility study.strong analytical and problem-solving skills, as well as strong team building, interpersonal and communication skills (both written and oral).presentation skill is required.ability to work independently, exercising good initiative and judgementproficiency with microsoft excel, word, and powerpoint.flexibility for travel to conduct the sites inspection and market research\",\n",
       "       'experience as a developer\\n    knowledge of oracle / pro c / pl-sql\\n    good command of french is a plus\\n    experience with network programing, unit environment and good knowledge of the voip network is a plus.\\n\\npersonality requirements\\n\\n- hard working, responsible, creative, strong interpersonal and communication skills.\\n\\n- ability of working independent and teamwork\\n\\n\\t                \\t                    we offer: \\n\\t                \\t            \\nsuccessful candidate will come in one of the european subsidiaries for 3 months internal training to our methods and product.\\nopportunity to work with international company, high reputation clients on the financial, commercial financial fields: silicon valley bank, bnp parisbas, societe generale, ge capital, ups capital kbc, barclays, bbva, france telecom orange, etc.\\nsalary range: attractive, or negotiable depending your expertise and experience.\\nsocial and health insurance: according to the current government regulations competitive remuneration package including performance driven benefits:soft skill training, 13th month salary, project bonus, loyalty program (3% of your total annual income), key person package (yearly bonus, monthly telephone fee, health insurance for your dependents), additional health care program - generali, annual health examination, lunch allowance (840,000 vnd/month), activities: company trip, football, volleyball ...\\ntrainings and continuous investment into your professional development\\nfriendly work environment with international working standards\\n                                                send your cv by clicking \\n                            \\n                                here. apply now!\\n                            we are eager to meet you!',\n",
       "       '', '', '',\n",
       "       'experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \\n\\nall locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nsenior business intelligence analyst (bangkok based, relocation provided)\\napply now\\nbangkok, thailand\\n\\nabout agoda',\n",
       "       '',\n",
       "       \"yêu cầu ứng viên\\n- tốt nghiệp đại học, cao đẳng về chuyên ngành kinh doanh, công nghệ thông tin, toán học hoặc các chuyên ngành liên quan khác.- có kinh nghiệm làm việc trong ngành phân tích dữ liệu là một lợi thế. hoặc bạn sẽ phải chấp nhận làm thực tập sinh hoặc nhân viên học việc tại các doanh nghiệp.- có khả năng sử dụng các công cụ, phần mềm phân tích dữ liệu- có khả năng code cơ bản với các ngôn ngữ lập trình như sql, python để xử lý mô hình dự báo.- có kỹ năng phân tích sắc bén, khả năng thu thập, tổ chức, phân tích và phổ biến lượng lớn thông tin một cách chi tiết và chính xác- kỹ năng lập kế hoạch, kiểm soát việc thực hiện kế hoạch.- cẩn thận, kiên nhẫn, chịu khó, ham học hỏi, có tinh thần trách nhiệm\\nquyền lợi\\n'- mức lương: \",\n",
       "       '',\n",
       "       'job requirement:minimum 4 years experience in it, data analyzing, building system for employee information management.familiar with power bi, sql, excelbachelor/ college degree in hr, business administration, it or related field.good communication in english and presentation skills.high pressure ability\\n',\n",
       "       'experience on machine learning, deep learning, statistics\\nskillful in using excel, powerpoint and word as the primary working tools\\n\\n3/ skills\\n\\nquick and flexible learning skills to adapt to new things and work on multiple tasks\\nskill of communication, human relations, building relationships with stakeholders.\\nidentification and problem-solving skills\\ncritical thinking skills\\nteamwork skill\\npresentation and negotiation skills\\nanalysis and conflict management skills\\ncoordinating personnel and work skills\\nbuilding relationships with customers skills\\n\\n4/ relevant experiences\\n\\n+3 years of experience in advanced analytics/ machine learning/ deep learning\\nhaving a broad knowledge of business related to advanced analysis\\n\\n5/ personal characteristic\\n\\nhigh sense of responsibility, honest, careful, accurate and sensitive in work\\ncreativity and creating team spirit\\nbe proactive and enthusiastic in work\\nconfident, creative, dynamic\\nhigh customer service spirit\\nhave the spirit of cooperation and support each other\\n',\n",
       "       'experience in sales, management, customer service, finance, administration, or related field;have business knowledge, grasp the psychology and behavior of customers;data-driven decision-making;programming (python, sql) and data science knowledge is a plus;strong verbal and written communication skills;analytical mind for problem-solving;actively innovative attitude; well-ordered method of working.benefitssalary range: up to 25m/month;competitive salary and benefits (macbook & pvi insurance);13th salary & performance pay;on-job training about programming languages (python, sql) and tools/ platforms (metabase, integromat, hubspot, data studio, zendesk, coda);working 5 days/week;yearly performance review;regular team building events, happy hour,...;sharp, motivated creative and supportive colleagues in a fun office environment;address: rivera park tower, 7/28 thanh thai street, 10 ward, ho chi minh city',\n",
       "       'yêu cầu ứng viên\\nsinh viên năm 2, năm 3, ưu tiên các bạn yêu thích ngành marketing, digital marketing, market research.\\n- yêu thích công việc trên máy tính, làm việc với con số và chữ, có khả năng tìm kiếm trên google, am hiểu internet, các mạng xã hội.\\n- yêu cầu tính cách: cẩn thận, kiên nhẫn, chịu khó, ham học hỏi, có tinh thần trách nhiệm và tự giác\\n- yêu cầu kỹ năng: microsoft office (word, excel, powerpoint), spss,…\\n- thời gian làm việc: full-time/part-time\\ntrong cv yêu cầu ghi rõ về kinh nghiệm làm việc và quá trình học tập của bản thân.\\nquyền lợi\\n- được huấn luyện chi tiết các kĩ năng thu thập và phân tích dữ liệu, cơ hội cập nhật thông tin và xu hướng thị trường\\n- theo đuổi định hướng chuyên sâu ngành marketing, digital marketing hoặc market research\\n- được làm việc trong môi trường chuyên nghiệp, vui vẻ và hòa đồng.\\n\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 17/06/2023\\n\\n\\n',\n",
       "       '', '', '', '', '',\n",
       "       'yêu cầu công việc\\n\\ncó kiến thức về phương pháp luận phân tích dữ liệu toán thống kê và phân tích định lượng.\\ncó kiến thức chung về hoạt động quản trị kinh doanh, mô hình kinh doanh\\ncó am hiểu chuyên sâu về mô hình giá/phí của các sản phẩm trong dịch vụ ngân hàng.\\nkỹ năng phân tích, kỹ năng lập kế hoạch, thống kê tổng hợp số liệu, tư duy kinh doanh\\ncó khả năng diễn giải dữ liệu, kết quả, báo cáo phân tích bằng ngôn ngữ kinh doanh\\ncó kỹ năng làm việc và giao tiếp với các bên liên quan, có tư duy logic, kỹ năng giải quyết vấn đề\\ncó khả năng tự định hướng và tính tự tổ chức cao\\ntư duy phản biện: có thể xử lý dữ liệu theo cách để đưa ra các đề xuất cần có tư duy phản biện.\\ntốt nghiệp đại học trở lên với chuyên ngành tập trung vào tài chính, ngân hàng, quản trị kinh doanh,\\ncó ít nhất 2 năm kinh nghiệm chuyên môn trong lĩnh vực tài chính/ngân hàng\\nkinh nghiệm phân tích kinh doanh tối thiểu 1 năm.\\ncó kinh nghiệm liên quan đến xây dựng và quản trị mô hình tài chính\\nthành thạo power bi, excel, spss, python…\\n',\n",
       "       '', '', '', '', '',\n",
       "       'experience working in the solution architect position\\n\\n\\t\\tstrong knowledge about tech-stacks:\\n\\n\\n\\nfullstack: django / mysql / jquery / bootstrap / docker\\n\\nse: c++, python\\n\\ncloud: aws (ec2, api gateway, lamda, vpc, …)\\n\\n\\n\\n\\t\\tproven experience in developing strategic system architecture plans\\n\\n\\t\\texperience in designing vms (video management system), cloud systems\\n\\n\\t\\tstrong knowledge of software evaluation principles and practices\\n\\n\\t\\tsolid understanding of information processing fundamentals and best practices\\n\\n\\t\\texcellent written and verbal communication skills\\n\\n\\t\\texperience conducting technology, trends, standards and products research\\n\\n\\t\\tsolid track record in prioritizing and executing tasks when under extreme pressure\\n\\n\\t\\texperience providing guidance and leadership to novice systems engineers\\n\\n\\t\\tproven experience identifying, analyzing and resolving system problems\\n\\n\\t\\tbusiness english\\n\\n\\n\\t',\n",
       "       \"yêu cầu công việc\\n\\n• university graduate major: economics/ management/banking/ finance\\n• at least 3 years in banking industry, in which at least 1 year working in operations of a bank.\\n• having knowledge & experience at planning/ performance management/ analytics role in financial service is an advantage.\\n• good understanding of data modelling and prediction.\\n• strong critical & analytical thinking\\n• logical & assertive communication\\n• influencing skill\\n• curiosity, agility, high adaptability to vuca contexts & demanding stakeholders\\n• passionate, proactive, self-motivated\\nbenefits\\n• attractive income, competitive salary and bonus according to ability\\n• bonus on holidays and new year (according to banking policy from time to time)\\nget preferential loans according to the bank's policy from time to time\\n• attractive leave mode according to job rank\\n• compulsory insurance according to labor law & vpbank care insurance for employees depending on rank and working time\\n• participate in training courses depending on the training framework for each position\\n• working time: monday - friday & saturday morning (two saturday mornings/month off)\\n• dynamic, friendly working environment with many opportunities for training, learning and development; participate in many interesting cultural activities (sports event, talents, teambuilding activities...)\\n\\n\\njob tags:\\nhead of performance management - hanoi - ta\\nhead of performance management operation division - hanoi - ta\\n\",\n",
       "       'experience in the e-commerce industry.\\nwe are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end-to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\\n\\ni. job descriptions\\n\\n•\\tbe responsible for strategic analysis and recommendations directly for board of directors. be actively involved in and provide an input into the strategic planning process for a company’s business that currently operated in usa and is expanding to international markets.\\n•\\tbe accountable for monthly strategic reports which using wide range of data to provide meaningful insight and assists in business strategy at the highest level.\\n•\\tresponsible for the detail of management dashboard metric and data analysis.\\n•\\tconduct project management in a wide range of insightful and strategic research for the senior leadership team gain a deeper understanding of existing and new markets (including detailed market sizing and market share analysis), as well as enhance knowledge of key competitors in each of our markets.\\n•\\tresponsible for identifying not only key business opportunities but also potential risks, putting forward recommendations and presenting the conclusions to the leadership team for consideration\\n•\\tclosely work with internal stakeholders in different departments to clarify and suggest any improvement in processes, business strategy and risk managements.\\n•\\treview internal business operation, consolidating reports and challenging the financial indicators, market sizing assumptions, business opportunities, product qualities, saving, customers review and others business aspects from different departments.\\n•\\tleverage insights to evaluate organizational operation health, identify potential business issues, and potential growth. connecting all the dots from internal to external data to assist corporate development senior manager and strategy director to define segment’s future short, medium and long-term strategy.\\n                                                                                    \\nxem toàn bộ mô tả công việc',\n",
       "       '',\n",
       "       'experience in budget controlling, forecasting, and budgeting. a candidate who used to work in big 4 firms is preferable.good knowledge in ifrs, vas and tax laws/regulations.ms. office (word, excel, power-point), data knowledge and process, sql or power bi skill is an advantage.strong written and spoken english language skills, including the ability to structure communications clearly, confidently, and logically.hard-working, honest, and self-responsibility. able to work under high pressure',\n",
       "       'experience in it and 5+ year of', '',\n",
       "       'yêu cầu ứng viên\\n\\uf0b7 completion of a degree or diploma in computer science, information technology, engineering or a related discipline.\\uf0b7 english proficiency is required\\uf0b7 at least three years of hands-on experience, preferably in big data infrastructure\\uf0b7 experienced with data-lake, data warehouse, data mart\\uf0b7 have experience with a programming language (python / go / javascript) for data processing and analysis.\\uf0b7 experience designing sql tables, indexing, tuning queries, and optimizations across different functional environments',\n",
       "       'experience range: from 3 years\\njob location: hcmc\\nduty & responsibilities:\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tyou will be responsible for building and running the data processing pipeline on google cloud platform \\n– work with implementation teams from concept to operations, providing deep technical expertise for successfully deploying large scale data solutions in the enterprise, using modern data/analytics technologies on gcp\\n– design pipelines and architectures for data processing\\n– implement methods for devops automation of all parts of the build data pipelines to deploy from development to production\\n– formulate business problems as technical data problems while ensuring key business drivers are captured in collaboration with product management\\n– extract, load, transform, clean and validate data\\n– supporting and debugging data pipelines \\n\\nrequirements: \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tmust-have requirements\\n– at least 4 years of experience working as a data engineer\\n– good development experience in data warehouse platform\\n– experience with data staging, data transformation and change data management\\n– good experience in advanced sql\\n– good python skills\\n– experience in a cloud datawarehouse platform (can be any but big query is mostly preferred)\\n– good command of english communication\\ngood-to-have requirements\\n– experience with gcp\\n– relative experience in containerization: docker and kubernetes\\n– relative experience in declarative ci/cd or devops\\n– relative experience in infrastructure as a code (iaac) (i.e., terraform, cloud build)\\n– experience with automated testing (ideally robot framework)\\n– relative experience in data management: data governance, data architecture, data modelling, data quality, data integration\\npreferred language for application: english\\n',\n",
       "       '', '',\n",
       "       'yêu cầu ứng viên\\nat least 3 years experience in administration or financial service sectorgood computer skill (especially in ms excel, power bi know-how, word, power point, data analysis), life insurance or accounting is preferable, basic english.bachelor degree (full-time university degree with majors in economics / insurance / business administration / marketing / banking / finance / accounting).good communicate skill, strong interpersonal and customer service skill.carefulness\\nquyền lợi\\nchế độ bảo hiểmdu lịchphụ cấpđồng phụcchế độ thưởngchăm sóc sức khỏeđào tạotăng lươngnghỉ phép năm\\ncách thức ứng tuyển\\n\\nhết hạn nộp đơn\\n',\n",
       "       '',\n",
       "       'yêu cầu ứng viên\\ntối thiểu 2 kinh nghiệm trong vai trò data engineerkiến thức về lập trình, cấu trúc dữ liệu & giải thuật tốtlập trình thành thạo một trong những ngôn ngữ như python, javathành thạo các ngôn ngữ xử lý dữ liệu như sql, nosql, mongodb, big querykiến thức về lập trình lưu trữ, xử lý dữ liệu phân tán, xử lý dữ liệu lớn (hadoop, spark, elastic search…)kiến thức về xây dựng luồng xử lý dữ liệu (batch processing, stream procesing, ...)khả năng học hỏi và thích ứng nhanh với công nghệ mới.là người tỉ mỉ, năng động và có trách nhiệmbiết quản lý thời gian, có kỹ năng phân tích và giải quyết vấn đềkhả năng làm việc độc lập & làm việc nhómkỹ năng giao tiếp tốt\\nquyền lợi\\n1. mức lương: up to 40.000.000đ2. thời gian, địa điểm làm việctừ thứ hai đến thứ sáu hàng tuần và thứ bảy cách tuần.sáng: ',\n",
       "       'yêu cầu công việc\\nbắt buộc\\n– kinh nghiệm làm việc tối thiểu 2 năm trong lĩnh vực data\\n– thành thạo truy vấn sql và các ngôn ngữ tương tự (oracle, mysql, postgresql…)\\n– sử dụng thành thạo bi tools (power bi là điểm cộng) và r/python\\nđiểm cộng\\n– có kinh nghiệm triển khai các mô hình phân tích định lượng vào thực tế là lợi thế\\n– ứng viên có kinh nghiệm làm việc trong ngành tài chính nói chung và công ty chứng khoán nói riêng.\\n',\n",
       "       'experience as a financial analyst, financial analyst, financial planning, analysis, modeling, or in a similar position. knowledge of the e-commerce market is preferable.\\nstrong critical thinking, analytical thinking, systematic problem-solving skills. \\nhigh proficiency with the use of ms office, especially excel (intermediate and above). knowing about bi tool is an advantage\\nability to learn new concepts and tasks quickly, detail-oriented and able to perform in a high-pressure environment.\\ngood communication in english spoken & written skills.\\n\\n\\n\\n\\nbenefits\\n\\nat crossian, our people are the key to our success. we believe in creating an attractive total compensation package (tcp) that not only retains employees but allows them to excel in their profession. these include:\\ncompetitive gross salary (14-30 million vnđ depending on what you bring to the table)\\nfull salary during probation\\n20 days work-from-home & 12 days of paid annual leave\\nglobal health insurance package for yourself and direct family members\\nguaranteed 13th month salary\\nquarterly bonus & year-end bonus as part of our profit sharing program\\na pantry & a crossian cafe stocked with goodies, ready to serve\\nlots of other company benefits including 5* annual company trip, budget for frequent team building activities and other monthly / quarterly / annual company events\\ngeneral company t&d program + dedicated t&d budget for managers',\n",
       "       'experienced                \\n\\n\\n\\n\\n                    share\\n                \\n\\n\\n\\n\\n\\n\\n\\nmangtas is looking for a data analyst to join our team in our remote office. the data analyst is responsible for managing our master data set and developing respective reports/visualizations.the ideal person for this position has an exceptional eye for detail, expertise as a data analyst, and a solid understanding of popular data analysis tools. he/she will work closely with product owners across various lines of business to understand the objectives of the organization and prioritize any requirements.responsibilities:',\n",
       "       'qualification: bachelor of information technology, computer science or related field eg. business, economic and trading.certificate in da/ba/bigood understanding of etl good knowledge of application & database design and development skills.competencies & skillsgood communication in english (speaking, listening and writing)good collaboration high responsibility, reliability, flexibility and service mind.\\n',\n",
       "       'experience. experience in big4 audit firms and/or logistics industry is preferable.\\nhighly analytical and ability to analyze large data sets to extract actionable insights to provide creative recommendations to management and business partners.\\nhighly proficiency in excel is a must, knowledge of sql is a plus.\\nhighly curious, logical, self-motivated, independent, proactive, and result oriented.\\nability to work cross-functionally, to thrive in a dynamic and fast-paced environment, and to manage and prioritize multiple projects with tight deadlines.\\ndemonstrate strong leadership skills, with exceptional interpersonal and communication skills (both written and verbal) to influence other leaders in finance and business.\\nfluent in english.\\n\\n\\napply now\\n',\n",
       "       'experiences\\nmust have:\\n\\nup to 2-3 years of experience as a data engineer or software engineer.\\nworking experience with 1 or more languages / frameworks (java, scala, python).\\nstrong interest to learn and develop skills in analyzing and implementing data pipelines for structured and unstructured data.\\ngood at multi-threading, atomic operations, computation framework: spark (dataframe, sql,…), distributed storage, distributed computing.\\nexperience with aws (ec2, s3, lambda, rds, emr, redshift, glue) is an added advantage.\\nexperience with rdbms (postgresql) and nosql (dynamo) databases is an advantage.\\nexperience with big data tools (hadoop, spark, kafka) is an added advantage.\\nexperience with etl tools (airflow, airbyte, talend) is an added advantage.\\nunderstand designs of resilience, fault-tolerance, high availability, and high scalability, …\\ntools: ci/cd, gitlab,…\\ngood at communication & team working.\\nbeing open-minded, willing to learn new things.\\n\\nbonus points:\\n\\ncloud experience (aws, gcp, etc), aws is a plus.\\nexperience in performance tuning/optimizing big data programs.\\nhaving knowledge of distributed query engines: presto, hive,…\\n\\n\\n3. why you’ll love working here\\n\\nincome = net salary + benefit + performance bonus (>14 months salary).\\nreview salary twice per year base on your performance and output.\\nhealth check once per year.\\nhealth insurance pvi care if you work here more than one year.\\nenjoy all of our company policies: insurance, vacation, public holiday, party, birthday and more.\\nfree coffee, tea and cakes.\\nwe have these clubs for you to join: football, table football, music, english, media and more.\\nhave a chance to involved and learn from our senior.\\nhave our senior to review your works, instruct you during the project using scrum.\\nget advices for career development.\\n\\nworking hours: 8h30 am -12h00 pm & 1h00 pm – 5h30 pm. (monday to friday)',\n",
       "       '', 'job requirementsjob benefitapply/  refe', '',\n",
       "       'kinh nghiệm về công nghệ lưu trữ và xử lý dữ liệu lớn, lập trình;\\ncó khả năng thiết kế và triển khai các mô hình dữ liệu đa chiều, thiết kế pipeline và triển khai các công cụ etl.\\ncó kinh nghiệm\\ntư duy tổng thể tốt và có khả năng triển khai chi tiết.\\nưu tiên:\\n\\n\\nứng viên có kinh nghiệm trong mảng tài chính, chứng khoán.\\nứng viên có kinh nghiệm làm việc với azure hoặc aws.\\ncó kinh nghiệm xử lý etl dữ liệu với ssis và ssas là một lợi thế.\\n\\n\\n\\n\\n quyền lợi: \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nthời gian làm việc 5 ngày/tuần (từ thứ hai đến thứ sáu).\\ncơ hội thăng tiến, phát triển nghề nghiệp công bằng.\\nthu nhập hấp dẫn, cạnh tranh.\\nđược hưởng chế độ bhxh, bhyt, bhtn, bảo hiểm sức khỏe theo quy định của công ty.\\nđược tham gia các chương trình đào tạo, huấn luyện của công ty.\\nmôi trường làm việc chuyên nghiệp, thân thiện, năng động.\\nmức lương: thỏa thuận\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n hồ sơ yêu cầu: \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nbản thông tin ứng viên theo mẫu của mbs.\\ncác mẫu thông tin ứng viên/cv khác không theo mẫu mbs là hồ sơ không hợp lệ.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n thời hạn nhận hồ sơ:  phỏng vấn cuốn chiếu ngay khi nhận được hồ sơ đến khi tuyển được ứng viên phù hợp\\nnơi nhận hồ sơ: \\n\\n\\n\\n\\n\\nnộp bản thông tin ứng viên theo mẫu của mbs theo hình thức sau:\\n\\nnộp hồ sơ online trên website tuyển dụng/gửi qua email:',\n",
       "       '',\n",
       "       'experience in the e-commerce industry.\\nwe are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end-to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\\ni. job descriptions\\n1. supply chain expansion, optimization & process standardization: \\n\\ndetect and realize cost - cash - service level optimization opportunities by fine-tuning supply chain configurations and driving for smooth applications: incoterms, lead time, moq, multi-sourcing, port of loading, forms of loading, etc., at product, market and seasonality levels.\\nwork on ongoing supply chain development projects, that strongly bond with the hyper growth across product selections, channels, platforms, sources (supply-based) and markets (demand-based) of the company. \\ndevelop product pricing strategy with sales, marketing and sourcing teams to optimize physical flow and financial flow;\\ninvolve in supply & demand planning for multinational markets;\\nhead to the automation, standardization and scalability of all the expansion projects.\\n\\n2. data analysis, interpretation and visualization: \\n\\nperform operational analytics in various but strongly connected fields: pricing, demand forecast, inventory, sales, etc. with the highest curiosity and eagerness for value creation.\\ncollaborate with cross-functional teams to form effective hypotheses based on business needs.\\ntest hypotheses; examine the results; do scenario, sensitivity, etc. analyses to spot out growth opportunities.\\nbuild interactive trackers, creative visualizations as well as concrete management reports to govern project outcomes and support bias-for-action decision-making.\\nconduct deep-dive / root cause analyses for long-term fixes.\\n\\n3. project management: \\n\\ninitiate, set up plans and timelines; coordinate and follow up with cross-functional departments to drive the projects.\\nactively communicate the objectives & progress to the stakeholders based on aligned success metrics, deep-dive on arising issues and take reaction plans to ensure high-quality deliverables at a timely manner\\n\\nii. skill and experience\\n\\nbachelor degree and above in supply chain, business or data analytics.\\n1 year of experience in supply chain/business/data analytics. retail supply chain and/or e-commerce experience is highly valued. fresher with excellent analytical and academic background is also welcome.\\nadvanced ms office is compulsory. be fluent in at least one query/code language (r, mysql & python are preferred).\\ngreat attention to detail, strong analytical and data story-telling sense with a “continuous improvement” mindset.\\ngood command of spoken & written english and vietnamese is a must.\\ngood at time management, teamwork, and multitasking. have strong ownership and responsibility for deliverables.\\nwilling to learn, thrive in a fast-paced environment and have a can-do attitude',\n",
       "       'experience working under linux environment, familiar with vi or emacs for editing files\\n– interested in applying technology to real world situation, comfortable working in fast paced work environment, detail oriented and capable performing tasks under time pressure\\n– experience with programming in c/c++, familiar with common algorithms and data structures (binary tree, sorting, etc), object oriented programming and design patterns. familiarity with compilers, debuggers under linux (gcc, g++, gdb).\\n– experience with scripting languages, such as perl, python, and shell scripting\\n– knowledge of basic statistics/probability, familiar with concepts such as correlation, standard deviation and how to compute\\n– familiarity with databases (such as mysql)\\nposition based in hanoi, vietnam.\\n',\n",
       "       'experience in a similar role \\ngraduate degree in computer science, statistics, informatics, information systems, or another quantitative field\\nexperience building and optimizing ‘big data’ data pipelines, architectures, and data sets.\\nexperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.\\nexperience supporting and working with cross-functional teams in a dynamic environment.\\nadvanced working sql knowledge and experience working with relational databases, query authoring (sql) as well as working familiarity with a variety of databases.\\nstrong analytic skills related to working with unstructured datasets.\\nbuild processes supporting data transformation, data structures, metadata, dependency, and workload management.\\na successful history of manipulating, processing, and extracting value from large, disconnected datasets.\\nworking knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores\\n\\n',\n",
       "       '',\n",
       "       'experience, you will be curious about the payments industry, results-driven and client-centric. as a candidate you should have both technical and business acumen:degree (masters or ph.d. would be an advantage) in quantitative field such as statistics, mathematics, operational research, computer science, economics, or engineering or equivalent experienceminimum 8 years of analytical expertise in applying statistical solutions to business problemshands on experience with one or',\n",
       "       '', 'kinh nghiệm.',\n",
       "       'experience in data processingstrong quality & detail orientationsolid problem solvingability to work well in a fast-face environmentable to work effectively within team and stakeholder (cs/oo/io_delivery team)logical thinking, strong analytical and problem-solving skillsgood communication skillsadditional informationabout nielseniqnielseniq is a global measurement and data analytics company providing the most complete and trusted view of consumers and markets in 90 countries covering 90% of the world’s population. focusing on consumer-packaged goods manufacturers and fmcg and retailers, we enable customers to defy what’s possible. how? we combine unparalleled datasets, pioneering',\n",
       "       \"experience level:1+ years (expertise in database development)qualifications:bachelor degree in it/ computer sciencehands-on experience in oracle database developmenthands on experience in development using sql, pl/sqlgood english communication skillsbe flexible/ comfortable if working in shiftadditional informationjob location:hcmc: etown 2, 364 cong hoa, ward 13, tan binh dist., hcmchanoi: 29 lieu giai, ngoc khanh, ba dinh dist., hanoiso... why bosch?\\nbecause - together - we turn the ideas into reality, working every day to make the world of tomorrow a better place.as a boschler, you will have a chance to:work in one of the best places to work in vietnamjoin a dynamic and fast growing global company (english-speaking environment)get 13th-month salary bonus + attractive performance bonus (you'll love it!) + annual performance appraisal100% monthly basic salary and mandatory social insurances in 2-month probationonsite opportunities: short-term and long-term assignments15++ days of annual leave + 1 day of birthday leavepremium health insurance for employee and 02 family membersflexible working timelunch and parking allowancegood benefits of company activitiesopportunity to work in global projects of fast developing company and being a part of innovation team contributing initiative ideas to the hi-tech world.engage in our diverse training programs which surely help strengthen both your personal\",\n",
       "       '',\n",
       "       'yêu cầu ứng viên\\ntrình độ & kinh nghiệm- người có bằng cấp về kinh doanh, tài chính, kế toán, luật hoặc các ngành học liên quan khác.- có từ 1 năm kinh nghiệm về quản lý ngân sách hoặc các vị trí liên quan.',\n",
       "       '', '', '', '',\n",
       "       'kinh nghiệm làm việc tại các vị trí liên quan trong lĩnh vực tài chính ngân hàng hoặc nhóm ngành công nghệ thông tin;\\nam hiểu về khai thác dữ liệu (data mining), lập mô hình thống kê, phân tích dữ liệu số và hoạt động kinh doanh;\\nthành thạo các công cụ báo cáo bi như tableau, qlikview & powerbi;\\nkỹ năng trình bày và thuyết trình tốt;\\nkỹ năng phân tích và đọc hiểu báo cáo tốt;\\n',\n",
       "       '', '',\n",
       "       'yêu cầu công việc\\n– nam/nữ, tuổi từ 25 – 35\\n– tốt nghiệp đại học chuyên ngành kiểm toán, tài chính, …\\n– tối thiểu 3 năm kinh nghiệm kế toán/ tài chính\\n– kỹ năng thiết lập, trình bày báo cáo; phân tích đánh giá dữ liệu; xây dựng aop-kpi và quản trị giá thành (công ty sản xuất)\\n– ưu tiên đã từng tham gia triển khai sap/ sử dụng sap\\n',\n",
       "       '', '',\n",
       "       'qualifications● tốt nghiệp cao đẳng trở lên các ngành lên quan tới toán thống kê, quản lý dữ liệu, it...● có hiểu biết về các phương pháp và công cụ phân tích dữ liệu / quản lý dữ liệu● sử dụng tốt các công cụ thống kê như excel, spss, sas...● tư duy logic và có khả năng trình bày báo cáo rõ ràng, rành mạch, dễ hiểu.additional informationrecruiter in charge: ms. minh minh - [email',\n",
       "       'yêu cầu công việc\\n\\n\\ntốt nghiệp',\n",
       "       \"experience, and data accuracy.\\nyour skills and experience\\nwe at parcel perform believe in innovation, energy and resourcefulness for everything we do. we will not stop delivering an outstanding product that we can be proud of and need you to help us inform the world. you need to feel the same way about our offering and bring along the following things:\\n\\nat least 5 years of working as a data engineer\\nsolid foundation in python and at least another language in the jvm family\\ndeep knowledge of sql database design\\nexperience with distributed systems, high volume databases, and etl pipelines\\nfamiliarity with big data analysis\\nexposure to a wide range of nosql solutions\\nexcellent critical thinking, organizational and communication skills\\nstrong ownership and good collaboration skills to work in a team\\ngood english communication\\n\\nwhy you'll love working here\\nwe at parcel perform are dedicated to being a platform for growth for all our team members, regardless of function and location.\\n\\nthe opportunity to work in a fast-growing, super exciting and innovative business that will revolutionize the e-commerce logistics industry. you will be the needle of success on the growth of a global product that will become a key platform behind successful e-commerce logistics worldwide.\\nthe ability to continuously learn and develop in an international setting with you being a critical driver behind the success of us achieving our mission.\\nan environment where everybody never stops growing and focuses on succeeding - we continuously work with you on your strengths and weaknesses across many important dimensions and look at ways for you to address them and further your development\\nyour entry ticket into being part of the parcel perform journey, where you will work with and alongside people from around the world that share the same passion and dedication.\\n\\nwho are we at parcel perform!\\nparcel perform is the leading delivery experience platform. it enables modern e-commerce enterprises to create unique end-to-end customer journeys and optimize logistics operations with powerful data integrations, parcel tracking, delivery notifications and logistics performance reports in real-time.\\nparcel perform's scalable saas platform executes more than 100m parcel updates daily and integrates with 800+ carriers. the data-first company is pioneering innovative ml / ai use cases in e-commerce logistics including its 'date of arrival' prediction engine. parcel perform is the partner of choice for top brands, marketplaces and carriers across all major verticals globally.\\n \",\n",
       "       'job requirements\\nuniversity degree, ideally in a relevant degree such as data analyst or similar;minimum of 1 year of proven experience in a relevant position;proficient in english communicationdemonstrated ability to create and analyze quality reportsadvanced knowledge in real time management analysis with strong decision making skillscontent moderation familiarity is a plusexcellent data analysis skills with strong logical thinking mindset; ability to organize and analyze data in a structured mannerintermediate knowledge in performing root cause analysis.highly proficient in using ms excelimpeccable attention to detail.\\nwhat benefits you will get\\n1. salary and benefits\\nattractive salary and benefits (competitive basic salary, lunch allowance, 13th salary, additional bonus, profit sharing) and annual salary review.100% compulsory insurance covered by the company after the probation.premium healthcare and mental health care service for you, 100% covered by the company.extra bonus per personal events (wedding, funeral, hospitalization, newborn baby) and a very cute baby box for staff who are going to welcome a new baby angel to the world.annual health check, annual flu vaccination.fantastic internal events.summer vacation (paid days off and bonus).paid leave (12 days/year).\\n2. working environment\\n5 shifts per week, night shifts included (equivalent to 40 working hours/ week).international, fun and professional working environmentstanding desks if you like, modern hardware, no dress code, free drinks (coffee, tea, etc.)english working environmentinternal english class fully sponsored by the company with a native teacher during working time.training and career development opportunities.\\nall interested candidates are welcome to apply. please send your resume expressing your interest to us. kindly note that only shortlisted candidates will be contacted by our hr team.',\n",
       "       'experienced', '',\n",
       "       'yêu cầu công việc\\n\\n1.tuân thủ đúng các quy định của công ty\\n2. quản lý nhân viên\\n3. triển khai chính xác chương trình, chính sách tới các đối tác hợp tác .\\n4. hoàn thành chỉ tiêu doanh thu được giao.\\n- giới tính: nam, nữ (ưu tiêu nam)\\n- tuổi: < 35\\n',\n",
       "       '',\n",
       "       'yêu cầu ứng viên\\nsinh viên đã tốt nghiệp chuyên ngành cntt, đtvt, đktđ các trường đại học.',\n",
       "       'experience working with large financial datasets and time-series data',\n",
       "       '',\n",
       "       'yêu cầu công việc- được tham gia các chế độ bhxh, bhyt, bhtn theo pháp luật hiện hành- các chế độ phúc lợi khác theo quy định của công ty như nghỉ mát hàng năm, sinh nhật, thăm hỏi ốm đau, hiếu, hỉ. \\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 03/06/2023\\n\\n\\n',\n",
       "       '',\n",
       "       'yêu cầu ứng viên\\n- kinh nghiệm: kinh nghiệm từ 01 năm lĩnh vực lập trình machine vision(đối với ứng viên mới ra trường/ chưa có kinh nghiệm: công ty có đào tạo tại cơ sở hà nội từ 03-06 tháng, có lương)- học vấn: tốt nghiệp các trường kỹ thuật ( bách khoa, công nghiệp, học viện kỹ thuật quân sự, giao thông vận tải và các trường kỹ thuật khác)',\n",
       "       '',\n",
       "       'experience working on large-scale data projects in a fast-paced environment.\\nresponsibilities\\nqualifications\\nwhat we offer\\nadditional inf',\n",
       "       'experience in data analytics working closely with business functions.\\n- knowledge of statistical and predictive modeling concepts, machine learning approaches, clustering and classification techniques/ recommendation and optimization algorithms is preferred.\\n- proficient in microsoft excel, sql and visualization tools. power bi experience is a plus.\\n- experience with python/ r programming is a plus.\\n- experience in the retail/ fnb industry is highly desirable but not mandatory.\\n- attention to details.\\n- critical thinking.\\n- can-do attitude.\\n- decent communication skills.',\n",
       "       '', '', 'experience, and creating more value', '', '',\n",
       "       'job requirements:\\n1 year+ in python, a basic understanding of java.basic knowledge of git, *nix; kubernetes is a plus.a hungry learner and a good writer. you will be the subject matter expert at a variety of external integrated services. adaptability and a strong sense of quality communication and documentation will be great edges.have an appreciation of sound and evolvable data schema design. on the opposite side, having a solid sense and ability to detect schema design smells.\\nspecial benefits:\\nbe trained with data engineering experts and specialists.being a part of the incredible team building',\n",
       "       'experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \\n\\nall locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nhead of paid search (bangkok based, relocation provided)\\napply now\\nbangkok, thailand\\n\\nabout agoda',\n",
       "       'yêu cầu công việc\\n1. bằng cấp/chứng chỉ:',\n",
       "       \"experience, technical and design capabilities, manufacturing know-how, supply chain insights and global product management expertise to enable success for the world’s leading brands. we are driven by a common purpose to make a positive impact for each other, our communities, and the environment.\\njob description\\n job summary  responsible to serve as the customer interface for the demand plan and shipment information, develop feasible operational plan and maintain ownership over the execution of the operational plan, achieve the objective of customer satisfaction, minimize jabil liability and continuously improve the performance of the planning metrics.  essential duties and responsibilities  · work with bu and customer to develop a collaborative demand plan through properly executing the demand management process  · create a master schedule through resource analysis including material sizing and capacity sizing  · load master schedule into the jabil erp system.  · create and maintain a feasible production plan and closely work with operation team to achieve successful execution of the plan.  · develop revenue forecast and closely monitor the actual performance and drive for immediate corrective action and recovery plan in case there is potential miss to the revenue target.  · monitor planning metrics and drive for continuous improvement  · comply and follow all procedures within the company security policy and the rules of the road  · may perform other duties and responsibilities as assigned  management & supervisory responsibilities  · typically reports to management . direct supervisor job title(s) typically include: planning supervisor, planning manager.  · job is not directly responsible for managing other employees (e.g., hiring/termination and/or pay decisions, performance management).  please do not change any wording in this section. only include who the direct supervisor is.  job qualifications  knowledge requirements  · thorough knowledge of erp/mrp  · 1 to 2 years materials related experiences  · advanced pc skills including knowledge of jabil's software packages  · ability to read and interpret documents such as safety rules, operating and maintenance instructions, and procedure manuals.  · ability to write routine reports and correspondence.  · ability to speak effectively before groups of customers or employees of organization, strong communication skills.  · ability to apply common sense understanding to carry out instructions furnished in written, oral, or diagram form.  · ability to deal with problems involving several concrete variables in standardized situations.  · ability to calculate figures and amounts such as discounts, interest, commissions, proportions, percentages, area, circumference, and volume.  · ability to apply concepts of basic algebra and geometry.  · strong proficiency in determining logistics requirements to enable company’s business goals and objectives with ability to devise and implement strategy to achieve targets.  · proficient verbal and written english skill  education & experience requirements  bachelor’s degree required.  or an equivalent combination of education, training, or experience. \\n\\njabil, including its subsidiaries, is an equal opportunity employer and considers qualified applicants for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identify, age, disability, genetic information, veteran status, or any other characteristic protected by law.\\n\\n\\n                        be aware of fraud: when applying for a job at jabil you will be contacted via correspondence through our official job portal with a jabil.com e-mail address; direct phone call from a member of the jabil team; or direct e-mail with a jabil.com e-mail address. jabil does not request payments for interviews or at any other point during the hiring process. jabil will not ask for your personal identifying information such as a social security number, birth certificate, financial institution, driver’s license number or passport information over the phone or via e-mail. if you believe you are a victim of identity theft, contact your local police department. any scam job listings should be reported to whatever website it was posted in.\\n                    \\naccessibility accommodation\\nif you are a qualified individual with a disability, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access\",\n",
       "       '', 'experience\\n\\n', '', '',\n",
       "       'experience.\\n2 type for this positions:\\n\\nfull - time job, definite term contract (1 - 3 years)\\nfull - time job, permanent contract',\n",
       "       'experience in team leadership and management\\nproven experience in project management\\nminimum of 3 years of experience in a similar role\\n\\n',\n",
       "       'yêu cầu ứng viên\\ntốt nghiệp chuyên ngành các khối ngành về hệ thống thông tin,…có chứng chỉ về phân tích dữ liệu: power bi.tiếng anh giao tiếp với khách hàng mức khá tốt.khả năng làm việc độc lập và đảm nhận vai trò lãnh đạo trong nhóm.khả năng giao tiếp hiệu quả để thiết lập mối quan hệ làm việc với khách hàng.có khả năng phân tích, lập mô hình dữ liệu trong môi trường hoặc tập dữ liệu lớn.ưu tiên có sự hiểu về biết về lĩnh vực dầu khíthành thạo phân tích, triển khai báo cáo trên power bi và các công cụ etl & dwh khác (sap bw, azure, sql, power query,...)có kinh nghiệm làm việc với r và python, power apps, power automate,..có kinh nghiệm làm việc với các công cụ và công nghệ quản lý dữ liệu chủ (mdm)kỹ năng tư duy phân tích và khái niệm nâng cao.\\nquyền lợi\\nlương cứng thỏa thuận theo kinh nghiệm và năng lực.có lương tháng thứ 13, thưởng lễ tết, thưởng theo kết quả kinh doanh của công ty (gói thu nhập năm 14-16 tháng/năm)',\n",
       "       'kinh nghiệm làm việc với java, csdl nosql.\\n– là lợi thế nếu:\\n+ có kinh nghiệm làm việc với ít nhất một trong các khung nền tảng sau, ví dụ: kubeflow, mlflow,\\naws sagemaker, google ai platform, azure machine learning, datarobot, mlflow.\\n+ có kinh nghiệm huấn luyện và triển khai các mô hình học máy/trí tuệ nhân tạo.\\niii. quyền lợi\\n– lương fresher đến senior: 500$ – 2000$ (đánh giá tăng lương theo năng lực định kỳ);\\n– bảo hiểm sức khỏe cao cấp generali;\\n– môi trường làm việc trẻ trung, năng động, thời gian làm việc linh hoạt;\\n– làm việc cùng đội ngũ công nghệ giỏi chuyên môn, có cơ hội để phát huy tối đa năng lực của bản thân;\\n– liên tục được đào tạo về kiến thức, kỹ năng liên quan đến các lĩnh vực hoạt động của công ty;\\n– được cung cấp đầy đủ phương tiện làm việc theo yêu cầu của tính chất công việc;\\n– các hoạt động tập thể, giải trí đa dạng (clb bóng đá, game, bi lắc, …); sự kiện team-building hàng năm;\\n– được đảm bảo đầy đủ các chế độ phúc lợi theo quy định của pháp luật hiện hành và của công ty;\\n– thưởng tết nguyên đán, tết dương lịch, ngày lễ khác và thưởng thành tích nổi bật.\\niv. thông tin khác\\n– thời gian làm việc: 9:00 – 18:30; thứ hai – thứ sáu và hai ngày thứ bảy trong tháng luân\\nphiên\\n– địa chỉ: toà nhà ghtk, đường phạm hùng, phường mễ trì, quận nam từ liêm, hà nội.\\nv. cách thức ứng tuyển\\nđể ứng tuyển vị trí ai/mlops, vui lòng gửi cv & cover letter về email: talent.acquisition@ghtk.co\\ntiêu đề: ai/mlops_họ tên.',\n",
       "       '',\n",
       "       'experience.able to work independently under remote supervision by expatessential skillsbachelor’s degree and academic excellence from quantitative field.msc level in engineering, operations, statistics, physics, mathematics or equivalent technical field.microsoft office (intermediate)fluent english competency (toeic 700 or above)benefits13th month salaryinternal healthcare plan16 days annual leavecareer data analyst data scientistdata analystmodec management servicesthe job was closedappl',\n",
       "       '',\n",
       "       'kinh nghiệm phát triển etl hoặc báo cáo như: sql, datastage, tableau, powerbi, python..\\n– có kinh nghiệm tham gia một trong các loại hình dự án data analytics, business inteligence, data warehouse, data lake, bigdata…\\n– ưu tiên các ứng viên có hiểu biết về giải pháp data của ibm như cloud pak for data, singlestore\\n– có khả năng giao tiếp & đọc hiểu tài liệu kỹ thuật tiếng anh.\\n– kỹ năng ứng xử, giao tiếp, thuyết trình tốt\\n– kỹ năng giải quyết vấn đề và làm việc theo nhóm\\n– có khả năng làm việc độc lập, chủ động, trách nhiệm, nhiệt tình trong công việc.\\nyêu cầu khác\\n– sức khỏe, tính tuân thủ kỷ luật;\\n– có khả năng học hỏi và làm việc trong môi trường chịu áp lực cao.\\n\\n\\n\\nbenefit\\n\\n– thưởng kpi hàng tháng 20% lương.\\n– thưởng nhân viên xuất sắc tháng.\\n– thưởng các dịp lễ\\n– thưởng tháng lương thứ 13: chuyển tự động vào cuối tháng 12 hàng năm.\\n– thưởng dự án.\\n– bảo hiểm sức khỏe 24/7.\\n\\n',\n",
       "       '',\n",
       "       'experience at the same position for multinational companies\\n- advanced ms excel including experience modeling transactions, word, power point, familiarity with applications used for business.\\n- good communication in english. \\n',\n",
       "       \"experience is fine\\ngood linguistic competence in english: conventional toeic (reading and listening) >= 550;\\nproficient in query languages as sql and nosql\\ngood programming skills: python (required)\\nnice to have: c++, java. scala …\\nexperience with ai frameworks such as keras, pytorch, tensorflow …\\nknowledge of machine learning as decision trees, linear regression, ensemble (random forest, boosting tree), k-means, svm, pca…\\nknowledge of deep learning, neural network, various kinds of network mlp, cnn, lstm, rnn…\\npossession of global certificates of ai (tensorflow developer certificate, google professional machine learning engineer certification ...) or of data engineer (aws, cca, ccp, ibm certified data engineer, google - - professional data engineer …) are a big plus\\ncreative thinking, self-research capability, ability to work in a team, up-to-date knowledge of new technologies\\nbenefits\\nsalary: 1500$ - 2200$ \\nallowances: 1,000,000 vnd per month on lunch and transportation\\naddress current problems related to ai of the company\\npropose new solutions to the company to take full advantage of its massive data\\nmonitor performance, accuracy of ml models based on the use of methods as rmse, rmsea, mae, mse, mape, accuracy, recall, precision, … \\nunlimited utilization of all monkey products\\nopportunities to collaborate with renowned business partners (facebook, coc coc, etc.)\\nchances to work in a well-recognized company which has achieved successes on both national and global scale, namely first place startup in 2016 gist tech-i competition awarded by the american former president barack obama, first place in vietnamese talent competition, top 1 most loved children application on app store and google play\\nfirst-handed experience with top-notch international teaching and learning materials and approaches\\nchances to work closely with excellent vietnamese and american educators and linguists.\\npositive and open-minded environment which is made up of people who are always ready to listen and share\\ncourses fully funded by the company to improve one's competence and skills\\nsalary review every 6 months\\nbonuses on kpi, projects, new ideas, boost-up bonus; on-the-spot reward; rewards for new suggestions of contribution recognition and employee gifts on special occasions\\nequipment and devices provided at work, or allowance for using personal devices\\nnumber of days-off, public and new year holidays, annual leave will be under labor law\\nattractive maternity regime for both male and female employees\\nentitled to social insurance, health insurance, underemployment insurance and other benefits according to the company's policies\\nhealth screening and wellness check-up services at prestigious hospitals\\ndaily tea-break, weekly gather-up, monthly birthday party and annual summer trip\\nother benefits are discussed during the interview  \\ngiới thiệu việc làm này\\n\\n\\n\\n        chia sẻ bài viết\\n        \\n\\n\\n\\n\\n\\n\\nchia sẻ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nsao chép đường dẫn\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\",\n",
       "       '', '',\n",
       "       'yêu cầu ứng viên\\n- tốt nghiệp đại học, cao đẳng chuyên ngành công nghệ thông tin, toán - tin, tin học quản lý hoặc các chuyên ngành có liên quan;- có kinh nghiệm cài đặt, quản trị hệ thống csdl oracle (rac, dataguard, golden gate, odi); ms sql cluster;- có từ 2 năm kinh nghiệm quản trị csdl trở lên;- am hiểu về hệ điều hành linux, unix;- có kinh nghiệm quản trị hệ thống ứng dụng oracle e-business suite (ebs), oracle weblogic, oracle golden gate, ms sql cluster là một lợi thế.\\nquyền lợi\\n- lương cứng từ 15-30 triệu/tháng (net);- lương tháng thứ 13, thưởng các dịp lễ tết, thưởng định kỳ;- làm việc trong môi trường năng động, chuyên nghiệp có nhiều cơ hội thăng tiến;',\n",
       "       '',\n",
       "       'kinh nghiệm\\n\\ntối thiểu 1 năm kinh nghiệm ở vị trí liên quan.\\n\\nyêu cầu bản thân\\n\\nkỹ năng phân tích và viết báo cáo tốt\\nhiểu các nguyên tắc và thực hành chăm sóc khách hàng\\nkỹ năng giao tiếp, giao tiếp và viết lách tốt\\ncó năng lực, tính linh hoạt và sẵn sàng học hỏi\\nkỹ năng tổ chức và quản lý thời gian xuất sắc với khả năng đa nhiệm\\nkhả năng viết lách tốt để làm báo cáo và thuyết trình\\ncó khả năng làm việc hiệu quả dưới áp lực cao.\\ntính sáng tạo, trí tưởng tượng và khả năng áp dụng sáng kiến vào công việc\\nkỹ năng làm việc nhóm, phân tích và giải quyết vấn đề tốt\\nnhận thức liên quan đến kinh doanh và kiến thức tốt về các vấn đề thời sự.\\n\\nhồ sơ ứng tuyển sẽ được tuyệt đối bảo mật. thông tin cá nhân được thu thập chỉ dành cho mục đích tuyển dụng nhân sự. ứng viên trúng tuyển sẽ có mức lương cao cạnh tranh và con đường sự nghiệp vững chắc.\\nứng tuyển\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ncontact\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       "       \"kinh nghiệm cơ bản về chatgpt và các công nghệ ai tổng quát khác\\nthực hiện xử lý phân tích dữ liệu bằng python\\n\\ncó kỹ năng và kiến thức về phát triển mô hình ai thông qua fine-tuning, tiền xử lý dữ liệu và học máy\\nđã từng tiếp xúc với học máy trong nghiên cứu (nhận dạng giọng nói, nhận dạng hình ảnh, xử lý ngôn ngữ tự nhiên, v.v.)\\nchủ động xác định các vấn đề, đề xuất và thực hiện các giải pháp\\ncoi trọng sự hợp tác và giao tiếp trong nhóm, có thể thúc đẩy các dự án một cách suôn sẻ\\ncó trí tưởng tượng và óc sáng tạo linh hoạt, kết hợp các công nghệ và ý tưởng mới một cách tích cực\\nkhả năng đọc/viết/giao tiếp bằng tiếng anh hoặc tiếng nhật. tiếng nhật được ưu tiên\\nchuyên gia có động lực cao và định hướng kinh doanh với thái độ có thể làm được.\\nưu tiên có kinh nghiệm hoặc đam mê trong lĩnh vực liên quan đến ai khác\\n\\n\\nwhy you'll love working here\\n\\n\\nmức lương hấp dẫn\",\n",
       "       'yêu cầu công việc\\n\\n\\ntốt nghiệp đại học hoặc sinh viên năm cuối chuyên ngành kinh tế, kinh doanh, công nghệ thông tin hoặc các chuyên ngành liên quan\\n\\n\\nhiểu biết chung về dữ liệu và phân tích dữ liệu.\\n\\n\\ncó tư tuy logic, định hướng dữ liệu, định hướng chi tiết\\n\\n\\nsử dụng tiếng anh linh hoạt trong nghiên cứu, phân tích thông tin\\n\\n\\nkhả năng giao tiếp và làm việc nhóm\\n\\n\\nưu tiên các ứng viên:\\n\\n\\ncó đam mê về game, chơi nhiều thể loại game, hiểu biết về quy trình làm game\\n\\n\\ncó khả năng sử dụng sql, các tool visualization\\n\\n\\ncó kiến thức về các mô hình về định lượng hoặc kinh tế lượng\\n\\n\\nsẵn sàng học python để xử lý big data từ nhiều nguồn và những công nghệ mới.\\n\\n\\nquyền lợi\\n\\n\\nlương tháng 13, thưởng lễ tết.\\n\\n\\nđược đề xuất, xét thưởng và xét tăng lương định kỳ hàng quý.\\n\\n\\ntham gia các hoạt động tập thể như team bonding, company trip, year end party hàng năm\\n\\n\\nkhám sức khỏe định kỳ hàng năm\\n\\n\\nđược tiếp cận những thách thức để chinh phục, nhiều cơ hội thăng tiến và phát triển.\\n\\n\\nđược làm việc trong môi trường năng động, trẻ trung, thời gian linh động.\\n\\n\\nđược đào tạo những kỹ năng mới phục vụ cho công việc.\\n\\n\\nđược tài trợ các khóa học theo chương trình đào tạo của công ty.\\n\\n\\nmức thu nhập tương xứng với năng lực và trình độ.\\n\\n\\nđược tài trợ tham gia các hoạt động thể thao như bóng đá, bơi lội…\\n\\n\\n📌loại hình công việc: toàn thời gian\\n📌địa điểm làm việc: phú nhuận\\n✨mức lương: 10.000.000₫ -> 20.000.000₫ /tháng\\n💌cv xin gửi về minhdt@imba.co\\ntagged as: data analyst, python, sql',\n",
       "       'experience recruiting world-class talents, come join us.\\nwhat you will do\\n\\n\\n\\nsenior risk analyst responsibilities include monitoring risk of porfolio, focus on reducing negative financial outcomes of digital banking including analyzing requirements, conducting analyses, developing reports, dashboards, data insight recommendations, also track performance and quality control to identify improvements. specifically, you will:\\n\\nunderstand end to end digital lending process includes onboarding, usage, and collection.\\ndevelop risk reports to manage the quality of portfolio and monitor the ratio of non-performing loan, delinquency, and loss rate below the standards of the sbv and ifrs.\\ndevelop ad-hoc reports which focus on actual problems being faced and business impact to notify leaders.\\ndevelop a monitoring report for tracking progress and rules of decision engine.\\nevaluate credit scoring/ fraud score/ income score/ 3rd party data for recommendations of credit strategies.\\nwork with engineering team to implement automated risk strategies.\\nwork closely with the product team to explore data. use data to contribute toward strategic decision-making, and planning.\\npropose optimization of risk policy and initiatives to achieve overall risk target.\\n\\nwhat you need to have\\n\\n\\n\\n\\nproven working experience as a data analyst, or credit risk analytics.\\nhave knowledge of credit products.\\nadept at full task flow from data query and collecting, report writing to presenting findings based on significant amounts of information with attention to detail and accuracy.\\ntechnical expertise regarding data models, database design development, data mining, and segmentation techniques.\\nstrong knowledge of and experience with databases (sql).\\nfamiliar with tools for analyzing datasets (excel, vba, r, python, etc).\\nhave experience with data visualization tools such as powerbi, google data studio, tableau, metabase, qlikview, etc.\\nbs in mathematics, economics, finance, computer science, data science, information management, or statistics.\\nexperience with other self-service data analytics tools, nosql is nice to have.\\nwilling to learn on the job and ready to adapt to changes in requirements.\\n\\nwhat you will get',\n",
       "       'experiences for over 20 years. gameloft creates games for all digital platforms, from mobile to cross-platform titles for pc and consoles. gameloft operates its own established franchises such as asphalt®, dragon mania legends, modern combat and dungeon hunter and also partners with major rights holders including lego®, universal, illumination entertainment, hasbro®, fox digital entertainment, mattel®, lamborghini®, and ferrari®. gameloft distributes its games in over 100 countries and employs 3,600 people worldwide. every month, 55 million unique users can be reached by advertisers in gameloft games with gameloft for brands, a leading b2b offering dedicated to brands and agencies. gameloft is a vivendi company.',\n",
       "       'experience in applying machine learning solutions to business problems\\nresults-oriented with strong analytical and problem-solving skills\\ngood business acumen with a strong ability to solve business problems through data-driven quantitative methodologies\\nthe ability to communicate results clearly to technical and non-technical audiences.\\ndemonstrated ability to research and innovate solutions\\nexperience with python, database management systems, and sql\\nexperience with software design and software development\\nexperience in bank-related products such as unsecured personal loans and credit cards is a plus\\n\\nwhat',\n",
       "       'experience in quality assurance processes and methodologies, enhancing your skills in operational excellence and process improvement.\\nwork closely with experienced professionals who will guide and support you throughout your internship, providing valuable insights and knowledge.\\nexpand your knowledge and understanding of operational quality assurance practices, allowing you to develop a strong foundation for a future career in this field.\\nconnect with professionals in the industry, building valuable relationships and expanding your professional network.\\nreceive regular feedback and performance evaluations, enabling you to assess your strengths and areas for improvement.\\ncollaborate with cross-functional teams, enhancing your teamwork and communication skills in a professional setting.\\nbenefit from a flexible work schedule that accommodates your academic commitments and allows for a healthy work-life balance.',\n",
       "       '',\n",
       "       'experience in delivery of sap analytics solutionexperience in working with or certified sap analytics cloud, sap data warehouse on cloudexperience in working with data warehousing using sap bw or ms sqlexperience in working with data visualization tools such as sap businessobjects (design studio, lumira...), ms power bigood sql skills and python is preferredknowledge of business processes in sap erp (fico, mm, sd...) is a plusgood communication skills and experience with international clientsproactive and flexible to work onsite or offshoreadditional informationdescribe your perks and cultur',\n",
       "       'job requirements1. trình độ học vấn: tốt nghiệp chuyên ngành tài chính, kinh tế, bảo hiểm, quản trị dữ liệu',\n",
       "       '',\n",
       "       'experience:\\n\\nexperience leading cross-team initiatives to identify, define, and track core metrics.\\na coach and mentor with high emotional intelligence: evidenced by humility, tact, compassion, high levels of integrity, and good listening skills.\\ndemonstrated commitment to equity, inclusion, and diversity.\\nexperience leading projects and programs to build and maintain user-facing data products such as dashboards, trusted datasets, and knowledge bases.\\na facilitator with strong collaboration skills and an empowerment approach to open and transparent management.\\n\\nqualities that are important to us:\\n\\nability to explain data and insights clearly to non-specialist audiences and gain their understanding and confidence.\\nempathy towards and commitment to work with the wikimedia affiliates and volunteer communities.\\ndiscretion and competence in handling sensitive or confidential data.\\ncuriosity and critical thinking skills; a lifelong learner who sees situations through multiple lenses.\\nability to link qualitative and quantitative information to make actionable recommendations to the wikimedia foundation and communities.\\ncommitment to the mission of the organization and our values and guiding principles.\\nself-motivated with an ability to navigate through ambiguity and complexity. the wikimedia ecosystem is complex, resources are limited, and our guiding principles are ambitious. we want you to work to find solutions embracing these factors.\\n\\nadditionally, we’d love it if you have:\\n\\nexposure to, and interest in, ethical data management and privacy practices.\\nexperience with large-scale data processing & storage tools (we use hadoop, hive, presto, and spark).\\ncontributed to wikimedia projects or have experience working in other open source projects.\\nexperience with superset or other open source visualization and reporting tools.\\n\\nabout the wikimedia foundation\\nthe wikimedia foundation is the nonprofit organization that operates wikipedia and the other wikimedia free knowledge projects. our vision is a world in which every single human can freely share in the sum of all knowledge. we believe that everyone has the potential to contribute something to our shared knowledge, and that everyone should be able to access that knowledge freely. we host wikipedia and the wikimedia projects, build software experiences for reading, contributing, and sharing wikimedia content, support the volunteer communities and partners who make wikimedia possible, and advocate for policies that enable wikimedia and free knowledge to thrive.',\n",
       "       'experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \\n\\nall locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nhead of search engine optimization (seo) – bangkok based, relocation provided\\napply now\\nbangkok, thailand\\n\\nabout agoda',\n",
       "       '',\n",
       "       'job requirements and qualificationsdoing a bs in computer science/computer engineering/data science. msc level candidate would be a bonushave a good grasp of mathematics especially linear algebra, probability, discrete mathvery familiar with python or c/c++. experience with other languages is also welcomebasic/mediate knowledge of algorithms and data structures is a bonusexperience with machine learning/deep learning frameworks such as scikit-learn, tensorflow, pytorch is a bonusexperience with image processing or natural language processing is a bonusbenefits and perksallowance for 3 months of participationlearn how to make technology productspotential to advance to a full-time position following the successful completion of the internship;access to training programs/ courses and continuous opportunities for personal development;opportunity to work in a professional environmentfree weekly social events and activities at enouvo.an inspiring place to work and a chance to be part of the enouvo family with all of the young, talented and passionate colleaguesabout usenouvo group is a company specializing in providing innovative and technological solutions. after 10 years of operation, enouvo has grown and expanded in many fields such as it, digital product development, agency, coworking space and cafe. we always strive to create the most outstanding products to not only bring value to customers but also contribute to the development of the community.how to applydoes this role sound like a good fit? email us at [email',\n",
       "       'experience with sql, additional experience with programming languages (python, r) is a plus\\nat least 1 year of experience with any visualization tools (power bi, tableau…)\\nstrong proficiency in sql and experience with etl processes and data modeling.\\nexperience with cloud platforms, such as google cloud platform (gcp) or amazon web services (aws).\\nstrong problem-solving skills and ability to work independently and in a team environment.\\nexcellent communication and collaboration skills to work effectively with departments and cross-functional teams.\\nstrong attention to detail and ability to manage multiple projects simultaneously.\\npassion for data and keeping up with the latest trends and technologies in data analytics.\\nprior experience working in a consulting or client-facing role is a plus.',\n",
       "       '', '',\n",
       "       \"kinh nghiệm từ 3 đến 5 năm trong vị trí data analyst.\\n- nắm rõ các thuật ngữ chuyên về digital marketing sẽ là một lợi thế.\\n- am hiểu cách thức vận hành của các nền tảng online: facebook, google,...\\n* kỹ năng:\\n- có kỹ năng phân tích dữ liệu cẩn thận và chính xác\\n- sử dụng thành thạo các công cụ phân tích dữ liệu.\\n- lập kế hoạch công việc đảm bảo sự hiệu quả và tiến độ của công việc.\\n- có kỹ năng tốt trong việc giải quyết vấn đề và có khả năng trình bày và giao tiếp lưu loát tự tin.\\n* thái độ:\\n- tự tin: làm việc với các con số, đồ thị, biểu đồ, thống kê.\\n- tư duy chủ động, trách nhiệm, ham học hỏi & không ngừng phát triển;\\n- sẵn sàng học hỏi và chịu được áp lực\\n\\n\\n\\n\\n\\n\\njob detail\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nposition type\\n\\nfull-time\\n\\n\\n\\n\\n\\n\\ncareer level\\n\\nstaff\\n\\n\\n\\n\\n\\n\\neducation level\\n\\nbachelor's degree\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ngender\\n\\nmale / female\\n\\n\\n\\n\\n\\n\\n\\njob categories\\n\\n\\nadvertising / promotion / pr\\n\\n, \\n\\nmarketing\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ninformation\\n\\n\\n\\n\\n\\n\\n\\n\\nname:\\n\\n\\nms.ly\\n\\n\\n\\n\\n\\n\\n\\n\\n307 a nguyễn trọng tuyển, phường 10\\n\\n, \\n\\nphu nhuan district\\n\\n, \\n\\nho chi minh\\n\\n, \\n\\nviet nam\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n- các ứng viên quan tâm vui lòng gửi hồ sơ trực tuyến qua careerlink, gửi kèm file hoặc trực tiếp đến tại công ty\\n\\n\\n\\n\\n\\n\\napplication language:\\nvietnamese\\n\\n\\n\\n\\n\\n\\n\\n\\nabout company\\n\\n\\n\\n\\n\\n\\n\\n\\ncông ty cổ phần teecom\\n\\n\\n\\n\\nhttp://teecom.vn/\\n\\n\\n\\n\\n25 - 99 employees\\n\\n\\n\\n\\ncontact: ms.ly\\n\\n\\n\\n\\n\\n\\n\\nchính thức thành lập vào tháng 10/2020, teecom là một trong những công ty khởi nghiệp phát triển vượt bậc trong ngành thương mại điện tử.đội ngũ nhân sự trẻ, năng động, dày dặn về kinh nghiệm chuyên môn, dám ước mơ và không ngại thử thách để đưa ra những ý tưởng, sản phẩm thành hiện thực trên thị trường quốc tế.tầm nhìn:xây dựng một hệ sinh thái thương mại điện tử toàn cầu có trị giá 100 triệu đô vào năm 2026.sứ mệnh:kiến tạo một hệ sinh thái cởi mở, sáng tạo và học hỏi nhanh giúp mỗi cá nhân phát triển tối đa tiềm năng, tạo ra các sản phẩm tập trung vào khách hàng, biến các ý tưởng trở nên thành công trên thị trường thương mại điện tử toàn cầu.\\n\\n\\n\\n\\nsee more\\n\\n\\n\\nsee less\\n\\n\\n\\n\\n\\n\\n\\nother jobs from this company\\n\\n|\\n\\nsee all\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ngolang developer\\n\\n\\ncông ty cổ phần teecom\\n\\n\\n\\nho chi minh\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nfull stack technical lead\\n\\n\\ncông ty cổ phần teecom\\n\\n\\n\\nho chi minh\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nnhân viên chăm sóc khách hàng\\n\\n\\ncông ty cổ phần teecom\\n\\n\\n\\nho chi minh\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nmarket research analyst | chuyên viên nghiên cứu thị trường\\n\\n\\ncông ty cổ phần teecom\\n\\n\\n\\nho chi minh\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nsenior it business analyst\\n\\n\\ncông ty cổ phần teecom\\n\\n\\n\\nho chi minh\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ntags\\n\\n\\n\\nmarketing\\nphu nhuan district\\nmarket research staff\\ndata processing\\ndata analyst\\nproduct manager\\n\\n\\n\\n\\nshare\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ncopied\\n\\n\\n\\n\\n\\n\\n\\n\\n\",\n",
       "       '',\n",
       "       'yêu cầu công việc.- được tham gia các chế độ bhxh, bhyt, bhtn theo pháp luật hiện hành.\\ncách thức ứng tuyển\\n\\nhết hạn nộp đơn\\n',\n",
       "       '', '', '', '', '',\n",
       "       'yêu cầu công việc:trình độ cử nhân trở lên chuyên ngành công nghệ thông tin, hệ thống thông tin quản lý, khoa học máy tính hoặc các lĩnh vực có liên quan;\\ntối thiểu 7 năm (chuyên gia)/5 năm (chuyên viên cao cấp)/ 3 năm (chuyên viên chính)/ 2 năm (chuyên viên) kinh nghiệm làm việc;tại các vị trí liên quan trong lĩnh vực tài chính ngân hàng hoặc nhóm ngành công nghệ thông tin;thành thạo sql và các ngôn ngữ lập trình khác (python, r, scala, java, …);\\nam hiểu kĩ thuật etl và có kinh nghiệm thực tế xây dựng datamart;\\nkinh nghiệm về công nghệ big data (hadoop, spark) và kiến thức chuyên sâu về các loại cơ sở dữ liệu khác nhau (sql & nosql database); \\nkinh nghiệm trong kiến trúc xử lý big data trên nền tảng cloud; \\n',\n",
       "       'yêu cầu ứng viên\\n-\\ttốt nghiệp đh chính quy loại khá trở lên chuyên ngành khoa học dữ liệu, khoa học máy tính, cntt, toán học ứng dụng, điện tử viễn thông hoặc liên quan\\n-\\ttrình độ tiếng anh: toeic tối thiểu 550\\n-\\tkiến thức về lập trình, cấu trúc dữ liệu & giải thuật\\n-\\tkiến thức về lập trình lưu trữ, xử lý dữ liệu phân tán, xử lý dữ liệu lớn (hadoop, spark, elastic search…\\n-\\tkiến thức về xây dựng luồng xử lý dữ liệu (batch processing, stream procesing, ...)\\n-\\tkiển thức về các loại csdl (rdbms, graph databases, nosql products, ...)\\n-\\tkỹ năng sử dụng ngôn ngữ lập trình (java, scala, ...), sql\\n-\\tk ỹ năng thành thạo một trong các framework, thư viện lưu trữ, xử lý dữ liệu lớn (hadoop,spark, kafka, zookeeper, ...)\\n-\\tkỹ năng sử dụng một trong các loại csdl (oracle, neo4j, hbase, cassandra, mongodb, ..)\\n\\nquyền lợi\\n- thu nhập cao tương xứng với trình độ. lên tới 50.000.000/tháng-\\tmôi trường làm việc trẻ trung, năng động\\n-\\ttham dự các dự án lớn, ứng dụng các công nghệ hàng đầu\\n-\\ttham dự hội thảo chuyên ngành trên toàn thế giới\\n-\\tlộ trình thăng tiến và phát triển sự nghiệp\\n-\\tthu nhập hấp dẫn tùy theo năng lực của từng cá nhân\\n-\\tchế độ nghỉ mát và khám sức khỏe, đóng bhxh theo quy định của luật lao động.\\n\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 30/06/2023\\n\\n\\n',\n",
       "       '',\n",
       "       'yêu cầu ứng viên\\n● kiến thức:- tốt nghiệp cử nhân chuyên ngành công nghệ thông tin, điện tử viễn thông, tài chính, ngân hàng, kinh tế hoặc tương đương. ưu tiên ứng viên có bằng tốt nghiệp loại giỏi hoặc tốt nghiệp tại nước ngoài- ưu tiên có các chứng chỉ chuyên nghành data engineer, data analytics, data science cho xử lý dữ liệu lớn● kinh nghiệm:- tối thiểu 2 năm kinh nghiệm làm việc trực tiếp tại các công ty, dự án về ds- có kiến thức cơ bản về data mining- có kiến thức về phân tích và visualization dữ liệu- có kiến thức về machine learning, deep machine learning- biết cài đặt trên hadoop eco-sys, aws, gcp,… cùng các tech stack thông dụng như sparkml, jupiternotebook, airflow, vs code với các thuật toán, thư viện thông dụng hiện nay- sử dụng thành thạo python, scala và java là lợi thế- có kinh nghiệm làm việc theo mô hình agile- có kinh nghiệm trong lĩnh vực tài chính ngân hàng- có khả năng đọc viết tiếng anh (cơ bản) nghe nói (nếu có thể).\\nquyền lợi\\n● thu nhập cực hấp dẫn: upto 32m gross ( thỏa thuận mức lương tương xứng với năng lực và kinh nghiệm làm việc)● hỗ trợ kí hợp đồng chính thức, nhận 100% lương và đóng bảo hiểm từ ngày đầu tiên đi làm● thưởng dự án, gói thưởng lễ tết lên đến 14m/year (bonus at tết dương lịch, tết âm lịch, lễ 2/9, quà tết, quà trung thu, sinh nhật công ty, tập đoàn,. )● xét tăng lương cố định hàng năm hoặc 6 tháng/ năm theo đánh giá năng lực● được hưởng bhxh, bhyt, bhtn theo chế độ nhà nước ban hành và tặng thêm gói bhxh sức khỏe “nms care” cho nhân viên● tận hưởng nhiều sự kiện của công ty, từ thi đấu thể thao, tiệc sinh nhật hàng tháng, xây dựng đội ngũ hàng quý đến tiệc năm mới, chuyến đi công ty, du lịch hè, teambuilding, liên hoan, gala định kì gắn kết tình cảm',\n",
       "       '', '', '',\n",
       "       'yêu cầu ứng viên\\n• tốt nghiệp đại học, cao đằng các chuyên ngành: công nghệ thông tin, hệ thống thông tin, dữ liệu, toán tin, thống kê, kinh tế, tài chính – ngân hàng …;• tối thiểu 2 năm kinh nghiệm về kiểm toán, quản trị rủi ro, trong đó tối thiểu 06 tháng 1 năm kinh',\n",
       "       'experience / skills detail\\n\\n\\n\\n- tốt nghiệp trung cấp trở lên\\n- chịu khó và ham học hỏi\\n- có khả năng giải quyết công việc được giao\\n\\n\\n\\n\\n\\n\\njob detail\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nposition type\\n\\nfull-time\\n\\n\\n\\n\\n\\n\\ncareer level\\n\\nstaff\\n\\n\\n\\n\\n\\n\\neducation level\\n\\nassociate degree\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ngender\\n\\nmale / female\\n\\n\\n\\n\\n\\n\\n\\njob categories\\n\\n\\nqa / qc\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ninformation\\n\\n\\n\\n\\n\\n\\n\\n\\nname:\\n\\n\\nphòng hcns\\n\\n\\n\\n\\n\\n\\n\\n\\nphạm ngũ lão, xã xuân dục\\n\\n, \\n\\nmy hao district\\n\\n, \\n\\nhung yen\\n\\n, \\n\\nviet nam\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n- các ứng viên quan tâm vui lòng gửi hồ sơ trực tuyến qua hệ thống careerlink, gửi kèm file hoặc trực tiếp đến tại công ty\\n\\n\\n\\n\\n\\n\\napplication language:\\nvietnamese\\n\\n\\n\\n\\n\\n\\n\\n\\nabout company\\n\\n\\n\\n\\n\\n\\n\\n\\ncông ty tnhh may cao cấp việt hào\\n\\n\\n\\n\\n\\n\\n100 - 499 employees\\n\\n\\n\\n\\ncontact: phòng hcns\\n\\n\\n\\n\\n\\n\\n\\ncông ty tnhh may cao cấp việt hào là một thành viên của tập đoàn rsi đa quốc gia chuyên ngành may, với nhu cầu phát triển thị trường, công ty chúng tôi cần bổ sung nhân sự như sau;\\n\\n\\n\\n\\nsee more\\n\\n\\n\\nsee less\\n\\n\\n\\n\\n\\n\\n\\nother jobs from this company\\n\\n|\\n\\nsee all\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nnhân viên giác sơ đồ\\n\\n\\ncông ty tnhh may cao cấp việt hào\\n\\n\\n\\nhung yen\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nnhân viên qc - kiểm hàng\\n\\n\\ncông ty tnhh may cao cấp việt hào\\n\\n\\n\\nhung yen\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nnhân viên vận hành sản xuất\\n\\n\\ncông ty tnhh may cao cấp việt hào\\n\\n\\n\\nhung yen\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nnhân viên  văn phòng tiếng trung\\n\\n\\ncông ty tnhh may cao cấp việt hào\\n\\n\\n\\nhung yen\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ntags\\n\\n\\n\\nqc\\nsewing\\nstatistics\\nurgent\\nhuyện mỹ hào\\n\\n\\n\\n\\nshare\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ncopied\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       "       '', '', '', '',\n",
       "       'experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \\n\\nall locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ndata architect (bangkok based, relocation provided)\\napply now\\nbangkok, thailand\\n\\nabout agoda',\n",
       "       'experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \\n\\nall locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nsenior dwh/bi developer (bangkok based, relocation provided)\\napply now\\nbangkok, thailand\\n\\nabout agoda',\n",
       "       \"experience in big data technologies with a bachelor’s degree in computer science, information technology, software engineering or equivalent\\nsolid skills in infrastructure troubleshooting, support and practical experience in performance tuning and optimization, bottleneck problem analysis\\nstrong experience with python, sql, apache spark\\nfamiliar with aws cloud  data services (or azure, gcp, v.v.)\\ngood understanding of data structures, data modeling and software architecture.\\nexperience in queues and  stream processing (kafka, flink)\\nexperience scheduler (airflow, aws glue, azure data factory, …)\\nexperience in designing and building etl processes (extractions, data load, aggregation, talend, etc.)\\ntime-series/analytics databases, such as elasticsearch\\ntest driven development methods: tdd, bdd, ddd & testing: component/ integration testing, unit testing\\nexperience in various messaging systems\\nenglish proficiency\\n\\nnice to have\\n\\nskills in search: solr, elk\\nexperience with technologies like spark, kubernetes, docker, jenkins, hive, terraform\\n\\nwhy epam\\n\\nby choosing epam, you're getting a job at one of the most loved workplaces according to newsweek 2021 & 2022\\nemployee ideas are the main driver of our business. we have a very supportive environment where your voice matters\\nyou will be challenged while working side-by-side with the best talent globally. we work with top-notch technologies, constantly seeking new industry trends and best practices\\nwe offer a transparent career path and an individual roadmap to engineer your future & accelerate your journey\\nat epam, you can find vast opportunities for self-development: online courses and libraries, mentoring programs, partial grants of certification, and experience exchange with colleagues around the world. you will learn, contribute, and grow with us\\n\\nlife at epam\\n\\nepam is a leading global provider of digital platform engineering and development services. epam has been named the top it services company on the fortune ‘100 fastest-growing companies’ list (2019-2021)\\nestablished in 2019, epam vietnam has more than 200 employees and is still expanding rapidly. we offer a multicultural environment where our tech talents can proactively develop world-class solutions directly with international clients. we support the sustainable development of our employees through a clear career path and provide a professional working environment and knowledge upgrading with internal learning solutions and external educational resources. epam vietnam has been recognized by the great place to work™ institute as one of vietnam’s best workplaces™ in 2022\\n \\n\\nhow we hire\\n\\nnot sure if you meet all the requirements? no problem. let’s talk anyway and find out more! it takes 1 min of application to start the journey with us. apply now!\\napply and tell us about yourself\\ngo through some standard interviews:\\n                        \\ngeneral interview with a recruiter\\ntechnical interview with our technology experts\\nmanager interview or offer interview with a hiring manager\\n\\n\\nget ready to join the team\\n\\n\\n\\n\\n\\n\\n                apply\\n            \\n\\n                apply\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\napply for\\nsenior data software engineer (python, sql, spark)\\n\\n        \\n        vietnam\\n    \\n\\n\\n\\n\\nthank you for your submission!\\n\\n\\n                    our talent acquisition team will contact you with further details.\\n                    \\n\\n    \\n        \\n            submit again\\n        \\n        \\n    \\n\\n    \\n        \\n            \\n\\n\\n\\n\\n\\n\\noops...\\nsomething went wrong. please try again.\\n\\n    \\n        \\n            submit again\\n        \\n        \\n    \\n\\n    \\n        \\n            \\n\\n\\n\\n\\nit's highly important for us to get your cv. if you are unable to attach a document through your mobile device, please leave us the link where we can find your resume online.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        first name*\\n    \\n\\n\\nfirst name\\n\\n\\n\\n\\n\\n\\n\\n        last name*\\n    \\n\\n\\nlast name\\n\\n\\n\\n\\n\\n\\n\\n        email*\\n    \\n\\n\\nemail\\n\\n\\n\\n\\n\\n\\n\\n\\n        location*\\n        \\n\\n\\nlocation\\n\\n\\n\\n\\n\\n\\n                afghanistan\\n            \\n\\n                albania\\n            \\n\\n                algeria\\n            \\n\\n                american samoa\\n            \\n\\n                andorra\\n            \\n\\n                angola\\n            \\n\\n                anguilla\\n            \\n\\n                antarctica\\n            \\n\\n                antigua\\n            \\n\\n                argentina\\n            \\n\\n                armenia\\n            \\n\\n                aruba\\n            \\n\\n                australia\\n            \\n\\n                austria\\n            \\n\\n                azerbaijan\\n            \\n\\n                bahamas\\n            \\n\\n                bahrain\\n            \\n\\n                bangladesh\\n            \\n\\n                barbados\\n            \\n\\n                belarus\\n            \\n\\n                belgium\\n            \\n\\n                belize\\n            \\n\\n                benin\\n            \\n\\n                bermuda\\n            \\n\\n                bhutan\\n            \\n\\n                bolivia\\n            \\n\\n                bosnia\\n            \\n\\n                botswana\\n            \\n\\n                brazil\\n            \\n\\n                brunei darussalam\\n            \\n\\n                bulgaria\\n            \\n\\n                burkina faso\\n            \\n\\n                burundi\\n            \\n\\n                cambodia\\n            \\n\\n                cameroon\\n            \\n\\n                canada\\n            \\n\\n                cayman islands\\n            \\n\\n                chad\\n            \\n\\n                chile\\n            \\n\\n                china\\n            \\n\\n                colombia\\n            \\n\\n                comoros\\n            \\n\\n                congo\\n            \\n\\n                costa rica\\n            \\n\\n                croatia\\n            \\n\\n                cuba\\n            \\n\\n                cyprus\\n            \\n\\n                czech republic\\n            \\n\\n                democratic republic of the congo\\n            \\n\\n                denmark\\n            \\n\\n                dominica\\n            \\n\\n                dominican republic\\n            \\n\\n                ecuador\\n            \\n\\n                egypt\\n            \\n\\n                el salvador\\n            \\n\\n                england\\n            \\n\\n                equatorial guinea\\n            \\n\\n                eritrea\\n            \\n\\n                estonia\\n            \\n\\n                ethiopia\\n            \\n\\n                fiji\\n            \\n\\n                finland\\n            \\n\\n                france\\n            \\n\\n                gabon\\n            \\n\\n                gambia\\n            \\n\\n                georgia\\n            \\n\\n                germany\\n            \\n\\n                ghana\\n            \\n\\n                greece\\n            \\n\\n                greenland\\n            \\n\\n                grenada\\n            \\n\\n                guadeloupe\\n            \\n\\n                guam\\n            \\n\\n                guatemala\\n            \\n\\n                guinea\\n            \\n\\n                guyana\\n            \\n\\n                haiti\\n            \\n\\n                honduras\\n            \\n\\n                hong kong sar\\n            \\n\\n                hungary\\n            \\n\\n                iceland\\n            \\n\\n                india\\n            \\n\\n                indonesia\\n            \\n\\n                iran\\n            \\n\\n                iraq\\n            \\n\\n                ireland\\n            \\n\\n                israel\\n            \\n\\n                italy\\n            \\n\\n                jamaica\\n            \\n\\n                japan\\n            \\n\\n                jordan\\n            \\n\\n                kazakhstan\\n            \\n\\n                kenya\\n            \\n\\n                korea, north\\n            \\n\\n                korea, south\\n            \\n\\n                kuwait\\n            \\n\\n                kyrgyzstan\\n            \\n\\n                lao democratic republic\\n            \\n\\n                latvia\\n            \\n\\n                lebanon\\n            \\n\\n                liberia\\n            \\n\\n                libya\\n            \\n\\n                liechtenstein\\n            \\n\\n                lithuania\\n            \\n\\n                luxembourg\\n            \\n\\n                macao sar\\n            \\n\\n                macedonia\\n            \\n\\n                madagascar\\n            \\n\\n                malawi\\n            \\n\\n                malaysia\\n            \\n\\n                maldives\\n            \\n\\n                malta\\n            \\n\\n                mexico\\n            \\n\\n                micronesia\\n            \\n\\n                moldova\\n            \\n\\n                monaco\\n            \\n\\n                mongolia\\n            \\n\\n                montenegro\\n            \\n\\n                morocco\\n            \\n\\n                mozambique\\n            \\n\\n                myanmar\\n            \\n\\n                namibia\\n            \\n\\n                nepal\\n            \\n\\n                netherlands\\n            \\n\\n                new zealand\\n            \\n\\n                nicaragua\\n            \\n\\n                niger\\n            \\n\\n                nigeria\\n            \\n\\n                norway\\n            \\n\\n                oman\\n            \\n\\n                pakistan\\n            \\n\\n                palau\\n            \\n\\n                palestine\\n            \\n\\n                panama\\n            \\n\\n                papua new guinea\\n            \\n\\n                paraguay\\n            \\n\\n                peru\\n            \\n\\n                philippines\\n            \\n\\n                poland\\n            \\n\\n                portugal\\n            \\n\\n                puerto rico\\n            \\n\\n                qatar\\n            \\n\\n                romania\\n            \\n\\n                russian federation\\n            \\n\\n                rwanda\\n            \\n\\n                saint lucia\\n            \\n\\n                saint vincent grenadines\\n            \\n\\n                samoa\\n            \\n\\n                san marino\\n            \\n\\n                sao tome and principe\\n            \\n\\n                saudi arabia\\n            \\n\\n                scotland\\n            \\n\\n                senegal\\n            \\n\\n                serbia\\n            \\n\\n                sierra leone\\n            \\n\\n                singapore\\n            \\n\\n                slovakia\\n            \\n\\n                slovenia\\n            \\n\\n                somalia\\n            \\n\\n                south africa\\n            \\n\\n                spain\\n            \\n\\n                sri lanka\\n            \\n\\n                sudan\\n            \\n\\n                suriname\\n            \\n\\n                sweden\\n            \\n\\n                switzerland\\n            \\n\\n                syria\\n            \\n\\n                taiwan\\n            \\n\\n                taiwan, china\\n            \\n\\n                tajikistan\\n            \\n\\n                tanzania\\n            \\n\\n                thailand\\n            \\n\\n                togo\\n            \\n\\n                trinidad and tobago\\n            \\n\\n                tunisia\\n            \\n\\n                türkiye\\n            \\n\\n                turkmenistan\\n            \\n\\n                tuvalu\\n            \\n\\n                uganda\\n            \\n\\n                ukraine\\n            \\n\\n                united arab emirates\\n            \\n\\n                united kingdom\\n            \\n\\n                united states\\n            \\n\\n                uruguay\\n            \\n\\n                uzbekistan\\n            \\n\\n                vatican\\n            \\n\\n                venezuela\\n            \\n\\n                vietnam\\n            \\n\\n                yemen\\n            \\n\\n                zambia\\n            \\n\\n                zimbabwe\\n            \\n\\n\\nlocation\\n\\n\\n\\n\\n\\n\\n        state/province*\\n        \\n\\n\\nstate/province\\n\\n\\n\\n\\n\\nstate/province\\n\\n\\n\\n\\n\\n\\n        city*\\n        \\n\\n\\ncity\\n\\n\\n\\n\\n\\n\\ncity\\n\\n\\n\\n\\n\\n\\n        zip code*\\n        \\n\\n\\nzip code\\n\\n\\n\\n\\n\\nzip code\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        need visa sponsorship?*\\n        \\n\\n\\nneed visa sponsorship?\\n\\n\\n\\n\\nyes\\n            \\nno\\n            \\n\\n\\n\\nneed visa sponsorship?\\n\\n\\n\\n\\n\\n\\n\\nneed visa sponsorship?\\n\\n\\n\\n\\n\\n\\n\\nupload your file\\n\\n\\n\\n\\ndrag & drop your resume or browse files\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ncancel upload\\n\\n\\n\\n\\npath to selected file\\n\\n\\nbrowse...\\n\\n\\nupload your file\\n\\n\\n\\n\\n\\n\\n\\n        copy & paste your cover letter, cv link or message\\n    \\n\\n\\ncopy & paste your cover letter, cv link or message\\n\\n\\n\\n\\n\\n\\n\\n        linkedin summary\\n    \\n\\nedit summary\\n\\n\\n\\nedit summary\\n\\n\\n\\n\\ncancel\\nsave\\n\\n\\n\\n\\n\\nwarning\\nare you sure you want to leave, all modified information will be lost?\\n\\nno\\nyes\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nplease note that by proceeding, you consent to epam processing your personal data as set forth in our\",\n",
       "       'experience and knowledge in creating an excel spreadsheets to identify the npv and irr of a development project;- understanding of the property market throughout vietnam, in particular the development process, construction cost, far and taxation is a benefit;- working closely with and support the investment teams;- researching and developing assumptions required for the development of values such as market growth rates, rents, construction costs, lease rates;- developing opinions and recommendations on potential development opportunities through analysis of various inputs that affect overall value and liquidity of assets;- identifying factors that may materially affect value and liquidity of an asset;- analysing property values relative to market conditions and recent sales data;- conducting scenario analysis (e.g. lease restructuring – buy-outs, renewal vs. relocation scenarios);qualifications- graduated in valuation or real estate;- good understanding of the residential property sector in hcmc;- good understanding of property market principles;- computer literacy with good ms office skills;- minimum 02 years of experience;- good english skills;- be able to conduct site inspections;- high sense of responsibility, trustworthy.additional informationthis is a great opportunity to work under innovative, confident and experienced professionals in contributing the growing business in vietnam. the position requires your enthusiasm, confidence, honesty, dedication and flexibility. the ideal candidate will be oriented and have abilities to work under pressure, and demonstrate capabilities to take over new unfamiliar tasks, also be a centralization of clear communication between the executive and others. you will need to be clear on information, communication, and then plan and schedule all of necessary meetings',\n",
       "       'experience across all touch points. ultimately, our goal is to minimize risk and optimize portfolio performance metrics for the benefit of our customers.responsibilitiesthe ideal candidate will have a passion for utilizing data and analytics to optimize portfolio performance. the successful candidate will be responsible for analyzing large datasets, developing predictive models, and generating actionable insights for credit card portfolio management.\\ndeveloping and implementing credit risk models and analytical tools to assess portfolio performance, credit risk, and profitability.\\nanalyzing and interpreting data to identify trends, patterns, and insights that drive portfolio management decisions.\\nconducting ad-hoc analysis and data mining to support portfolio optimization and strategy development.\\ncollaborating with business stakeholders to understand their needs and requirements, and to develop and implement solutions that meet their needs.\\ncreating and maintaining reports and dashboards that provide insights into portfolio performance and key performance indicators (kpis).\\ndesigning and conducting a/b tests to evaluate the impact of new portfolio strategies and tactics.\\nmaintaining up-to-date knowledge of industry trends, best practices, and regulatory requirements related to credit card portfolio management.\\ncommunicating complex analytical findings and recommendations to non-technical stakeholders, including senior management.\\nmentoring and coaching junior analysts and data scientists on the team.\\npartnering with data engineers and other technical teams to ensure data quality, availability, and scalability.\\nconducting competitive research to stay informed of market trends, customer preferences, and emerging technologies that may impact the credit card portfolio.\\nperform highly complex activities related to financial products, business analysis, and build dashboards for portfolio monitoring.\\nutilize statistical and machine learning techniques to identify patterns and trends in financial data\\ndevelop and implement data-driven investment strategies that optimize portfolio performance\\n\\n\\nyour skills and experience\\n\\nrequirements\\npost graduate degree (masters',\n",
       "       '', '',\n",
       "       'yêu cầu ứng viên\\nđại học các chuyên ngành qtkd, logistics, marketing hoặc các ngành liên quan.có kinh nghiệm tối thiểu 3 năm trở lên.có kinh nghiệm thiết lập và tính toán tính khả thi của dự án: tính dòng tiền, hiệu suất đầu tư như irr, npv…để triển khai dự án một cách hiệu quả nhất. viết báo cáo dự án. có hiểu biết về địa lý địa phương.có khả năng sử dụng các công cụ quản lý dữ liệu.ưu tiên ứng viên có khả năng báo cáo, phân tích sử dụng đa công cụ (excel, power bi tools…)có kỹ năng tổng hợp, phân tích số liệu, data, thông tin, lên báo cáocó kiến thức về tiếng anh tốt, ielts 6.0, tiếng hoa hsk 3 hoặc các chứng chỉ tương đương.yêu cầu tính cẩn thận, chính xác cao và luôn học hỏi, có ý chí cầu tiến trong công việc.\\nquyền lợi\\n● làm việc trong môi trường chuyên nghiệp, năng động và nhiều cơ hội thăng tiến.● được cung cấp đầy đủ phương tiện làm việc: laptop, điện thoại và các công cụ cần thiết phục vụ cho từng dự án.',\n",
       "       \"kinh nghiệm trên 6 tháng ở vị trí kỹ sư dữ liệu.- có kiến thức về cơ sở dữ liệu (sql), hệ thống và lập trình.- có kinh nghiệm về việc sử dụng các công cụ tích hợp dữ liệu etl (ssis, azure data factory, informatica, odi, pentaho,…..).- có\\u202fkinh\\u202fnghiệm\\u202fxây\\u202fdựng\\u202fdata model.- có kinh nghiệm sử dụng ngôn ngữ lập trình (python, r, …), công cụ bi (power bi, ssas, …) là một lợi thế- tư duy logic, khả năng làm việc độc lập và làm việc nhóm hiệu quả.- có khả năng đọc các tài liệu chuyên ngành bằng tiếng anh.- có tinh thần học hỏi và sẵn sàng tiếp thu kiến thức mới- năng động, chăm chỉ, cẩn thận, kiên nhẫn, thân thiện.\\n\\n\\n\\n\\n\\n\\njob detail\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nposition type\\n\\nfull-time\\n\\n\\n\\n\\n\\n\\ncareer level\\n\\ntechnical / engineer\\n\\n\\n\\n\\n\\n\\neducation level\\n\\nbachelor's degree\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ngender\\n\\nmale / female\\n\\n\\n\\n\\n\\n\\n\\nage\\n\\n22 - 30\\n\\n\\n\\n\\n\\n\\n\\n\\n\\njob categories\\n\\n\\nit - software\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ninformation\\n\\n\\n\\n\\n\\n\\n\\n\\nname:\\n\\n\\nphòng hcns\\n\\n\\n\\n\\n\\n\\n\\n\\n62 trần quang khải, tân định\\n\\n, \\n\\ndistrict 1\\n\\n, \\n\\nho chi minh\\n\\n, \\n\\nviet nam\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n- các ứng viên quan tâm vui lòng gửi hồ sơ trực tuyến, gửi kèm file hoặc trực tiếp đến tại công ty \\n\\n\\n\\n\\n\\n\\napplication language:\\nvietnamese\\n\\n\\n\\n\\n\\n\\n\\n\\nabout company\\n\\n\\n\\n\\n\\n\\n\\n\\ncông ty tnhh routine việt nam\\n\\n\\n\\n\\nhttps://routine.vn/\\n\\n\\n\\n\\n100 - 499 employees\\n\\n\\n\\n\\ncontact: phòng hcns\\n\\n\\n\\n\\n\\n\\n\\nroutine\",\n",
       "       'experienced deep learning engineer to join our team for an exciting smart ocr project. as a deep learning engineer, you will play a pivotal role in designing, training, and optimizing neural network models to develop a cutting-edge ocr system.',\n",
       "       '',\n",
       "       'experience requirements\\n8+ years working experience in strategic procurement, costing and analytics fields.working knowledge in upper shoe materials & footwear manufacturing industries are preferred.motivated self-starterexcellent analytical, negotiation and organizational skills.strong bias for results and attention to detailhighly effective communicator with ability to foster relationships at all management levels and cross-culturally.must be fluent in written & spoken english & vietnamesecomputer literate: ms office applications, power point, analytic and procurement platforms. education requirements\\nbachelors of business or analytics fieldplease contact ms. linh hoang at linh.hoang@adecco.com or +tel: +84 28 3636 5811 – ext : 710 for further discussion on the role. contact person\\n\\n',\n",
       "       '',\n",
       "       \"job requirements1.\\tcollege diploma or university degree in the field of computer science.\\n2.\\texpert skill level with 2 to 5 years experience with the following technologies:\\n•\\tazure paas data services\\n•\\tobject oriented analysis and design\\n•\\tci/cd and source control\\n•\\tetl techniques and principles\\n•\\tdata modelling\\n•\\tmaster data management\\n•\\tdata visualization\\n3.\\texperienced in designing and implementing data platform, reporting and analytics solutions in the microsoft azure ecosystem.\\n4.\\tfamiliarity with agile project management and methodologies desired.\\n5.\\table to exercise independent judgement and take action on it.\\n6.\\texcellent analytical and creative problem-solving skills.\\n7.\\texcellent listening, written, and oral communication skills.\\n8.\\tstrong relationship, interpersonal, and team skills.\\n9.\\thighly self-motivated and directed.\\n10.\\texperience working in a team-oriented, collaborative environment.\\n\\nthis role is only open to applicants residing nearshore and offshore. we're currently not processing applicants from lithuania for this role\",\n",
       "       'yêu cầu ứng viên\\n- nắm vững các kiến thức về cơ sở dữ liệu có cấu trúc và phi cấu trúc- có tư duy hệ thống, có khả năng chủ động giải quyết vấn đề- có kinh nghiệm, am hiểu về big data, xử lý tốt data cấu trúc phức tạpưu tiên ứng viên:- có thể làm việc với cường độ và áp lực cao.- tiếng anh chuyển nghành đọc hiểu tốt.\\nquyền lợi\\nmức thu nhập cạnh tranh, upto 25 mils cho vị trí de, thưởng performance năm.bảo hiểm sức khỏe dành cho cbnv, các chương trình team building, happy friday hàng tháng, tháng kỉ niệm thành lập công tythưởng ngày sinh nhật công ty, sinh nhật, các ngày hiếu hỉ của bản thân và gia đìnhlàm việc trong tổ chức xem trọng learning & development với các chương trình học tập\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 30/06/2023\\n\\n\\n',\n",
       "       'job requirements:\\n3 year+ in python, a basic understanding of java.well-grasped understanding of a fundamental data stack, including etl pipelines, workflow orchestrators, and data transformation.basic knowledge of git, *nix; kubernetes is a plus.a good writer and personal information manager. you will be the subject matter expert at a variety of external integrated services. adaptability and a strong sense of quality communication and documentation will be a considerable edge.have an appreciation of sound and evolvable data schema design. in other words, have a great sense of spotting schema design smells.\\nspecial benefits:\\nchance to become an expert in the new trendy domain: ai-driven personalized marketing, personalized customer experience, data analytics, and platform.modern tech & innovative environment.',\n",
       "       '', '',\n",
       "       'experience on big data technologies. a successful history of manipulating, processing and extracting value from large datasets.·',\n",
       "       'qualificationsmust have strong analytical (quantitative as well as qualitative) skills including building models, prior data miningself-starter with the ability to streamline functions and passion to learn and growstrong financial analysis foundation creating forecasts and modelsproficiency with microsoft excel is required; familiarity with sap, finance systemsmust possess excellent communication and presentation skills, and be comfortable interacting with executive-level managementwork and collaborate well with team-mates',\n",
       "       '',\n",
       "       'experience (0-2 years) but has demonstrated excellence in one or several projects: we will prioritize your motivation, ambition and quality of work over your prior experience. if you have never worked before, just share with us some projects you implemented where you demonstrated what we are looking foris comfortable working in english in an international environmentis proficient in excel and google sheet. having prior experience in automating data-oriented process through vba, scripts or any other tool is a plusworking for us means:you are joining a very young and ambitious company: we created the company in january 2019 and have very ambitious fundraising and business targets. we plan to start opening new countries in sea (south east asia) in 12-18 month and will always push to overachieve our high targets and strict deadlinesyou are willing to become the best at what you do in south east asia: we have extremely strong expectations in the quality of work we produce and want to ensure our clients know they are dealing with the best in their fields. as a junior newcomer, this means you want to boost yourself to learn how to become the best at what you do following our teaching, methodology, and paceyou are excited by the idea of writing your own career path: if you expect to know the exact content of your job and career steps, you should look elsewhere. the possibilities to grow in responsibilities and salary with our company will only be limited by your determination, hard work and performanc',\n",
       "       'experience in market research or relevant fields, however, open for fresh graduate. ',\n",
       "       'job requirement·',\n",
       "       \"experience\\n\\n\\nexperience running large scale web scrapes\\nfamiliarity with techniques and tools for crawling, extracting and processing data\\n3-5 years of hands-on experience of writing code, scripts and apis (python, golang)\\nfamiliarity with linux, http, html, javascript and networking\\nexperience with serverless compute components, bigquery, cloud functions, cloud storage\\nexperience with system monitoring/administration tools\\nproficient understanding of code versioning tools, such as git\\nexperience following agile methodology\\nability to dive into technical details and design analytics solutions to meet business needs\\nstrong understanding of data flow and system integrations\\ngood verbal, written communication skills in english\\nexperience or understanding marketing/ ecommerce (metrics) is a plus\\n\\n\\nwhy you'll love working here\\n\\nwhat we offer● excellent and competitive salary package with immediate opportunity to earn incentives.● competitive salary package, performance-based● key internal facing position in a fast-growing international ecommerce company that has strong momentum and strong competitive differentiators (team, technology, regional footprint), this role offers an exciting growth journey and opportunity to co-create our success story.● you will work with a leading team of e-commerce leaders and aspiring movers and shakers to positively shape all ecommerce platforms in the years to come, and will have a broad view on the latest developments in the south east asian ecommerce ecosystem.● ample opportunity for personal and professional development, both on the job and through regular training.● opportunities to work on regional projects with other countries’ offices, in philippines, thailand, singapore, indonesia and malaysiacompany benefit● an attractive salary package with ample opportunities for professional growth.● 2 months probationary period with 100% of gross salary● up to 15 days off per year● working remote from home flexibly● annual health check-up & premium healthcare insurance● social, health, and unemployment insurance based on full salary.● 2 performance review times per year● team building monthly, company trip every year, 13th salary.● on-the-job training and coaching with smart and friendly experts● union and other activities every month (8/3, 20/10, mid-autumn, year-end party, v.v...)● free tea, coffee, snacks for member every day● free parking fee every month\\n\",\n",
       "       '', '',\n",
       "       'experience\\n\\ngraduated from university or higher with a focus on finance, banking, business administration,\\nminimum of 8 years of professional experience in the financial/banking field\\nminimum 5 years business analysis experience.\\nexperience in building and managing financial models\\nproficient in power bi, excel, spss, python…\\n',\n",
       "       'yêu cầu ứng viên\\nsử dụng tốt một trong các phần mềm thống kê/ xây dựng mô hình/ quản lý dữ liệu: spss, sql, oracle, r, python,vvsử dụng tốt excelcó kiến thức về thống kê, kinh tế lượng..ưu tiên ứng viên biết thực hiện/ xây dựng các báo cáo quản trị trong ngành tài chính ngân hàng;ưu tiên ứng viên có kinh nghiệm xây dựng các mô hình bằng phương pháp định lượng (mô hình tài chính/ mô hình rủi ro/ mô hình phân tích, dự báo);thu thập, xử lý nhiều loại dữ liệu từ nhiều nguồn khác nhau;kinh nghiệm tạo báo cáo obi nâng cao, có kiến thức về tableau nâng caocó đức tính cẩn thận, trách nhiệm\\nquyền lợi\\nthu nhập thỏa thuận, tương xứng với năng lựcđược training về các kiến thức và kỹ năng marketingcơ hội trở thành nhân viên chính thức và phát triển dài hạn trong lĩnh vực của tương lai: công nghệ - tài chínhmôi trường năng động, trẻ trung, khuyến khích ý tưởng phá cách, sáng tạocơ hội được học hỏi từ các chuyên gia trong lĩnh vực tài chính, công nghệ, quản trị.\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\nhết hạn nộp đơn\\n\\n\\n',\n",
       "       'job requirement\\n\\njob responsibilities\\n\\n\\n\\n\\n\\nreport this job\\n\\n\\napply this job\\n',\n",
       "       \"experience\\n\\ntechnical attributes:\\n2+ years experience in sql.\\nexperience in legacy database conversion/ data mapping/ performance tuning/ data fixing\\nworked in production environment, manage large and complex volume of data\\ntools: sql server 2012/2014 and visual studio, data integration tool ssis\\nhas strong data analysis skills.\\nunderstand performance tuning, monitoring, indexing strategies\\ncan admin sql servers instances\\nunderstand powershell, agent jobs, performance tuning, backup/recovery.\\nstrong in writing large stored procedures\\n\\nadditional attributes (preferred not required):\\nknowledge and skills in .net frameworks and .net development tools\\nfamiliar with c# language\\ntesting, integrating, writing, troubleshooting and debugging software applications\\nworking knowledge of or experience in erp type system.\\nworking knowledge of or experience in accounting or retail pos systems\\nexperience in agile development methodologies\\nexcellent academic and tertiary qualifications\\n\\n\\nwhy you'll love working here\\n\\nwe are our people, and whilst as a business we make software, as an organization, we make some of the industry’s best!\",\n",
       "       \"experience\\n\\n\\nat least 3-5 years of experience as a data engineer, preferably in the financial services industry with a focus on credit risk.\\nstrong experience with python, pandas, pyspark, airflow, and building etl workflows.\\nthe ideal candidate has strong experience with aws, including s3, iam, and athena.\\nexperience with running containerized workloads on kubernetes\\nworked in an agile environment with continuous delivery\\nstrong sql skills and experience with relational and non-relational databases.\\nknowledge of data modeling, data warehousing, and bi concepts.\\nexcellent problem-solving and communication skills.\\nability to work effectively in a team-oriented environment and collaborate with cross-functional teams.\\n\\n\\nwhy you'll love working here\\n\\nhr benefits\\ncompetitive salary\\nsalary band per level and employee benefits are reviewed once per year\\n13th month salary pro rata depending on the employee’s length of service (within a calender year), paid with the december salary\\nmonthly lunch allowance: 700,000 vnd/employee\\nparking: gft covers the monthly parking fee for employee motorbikes\\nperformance evaluation is once per year, for 2 purposes:\",\n",
       "       \"experienced head of growth to lead our growth strategies across the organization. the ideal candidate will have a proven track record of driving user acquisition, and revenue growth. as the head of growth, you will lead and collaborate with the sales, marketing, and school relations teams to design and execute growth initiatives.\\nresponsibilities:\\ndevelop and implement comprehensive growth strategies, focusing on both the top of the funnel.establish, monitor, and manage key growth metrics, utilizing data to drive strategic direction and operational decision-making.lead and collaborate with the sales team to refine sales strategies, improve conversion rates, and maximize customer lifetime value.guide the marketing team in developing impactful campaigns across various channels to reach target audiences.work with the school relations team to foster partnerships and enhance engagement with schools.work closely with the operation and academic teams to align growth initiatives with service development.identify and pursue new markets and partnership opportunities to expand our user base and increase engagement.monitor and report on the effectiveness of growth strategies to the executive team and the board.\\nqualifications:\\nbachelor's degree in business, marketing, or a related field. an mba or relevant advanced degree is preferred.minimum of 7-10 years of experience in a growth-focused role in a fast-paced, high-growth environment.proven track record of driving user growth and engagement through innovative strategies.strong understanding of growth marketing tools and best practices.excellent analytical and quantitative skills, with a deep understanding of data-driven decision-making.experience leading and collaborating with sales, marketing, and partner relation teams.ability to work cross-functionally with multiple teams to execute growth strategies.exceptional communication and presentation skills\",\n",
       "       '',\n",
       "       'yêu cầu ứng viên\\ntốt nghiệp đại học / cao đẳng hoặc tương đương về khoa học máy tính hoặc kỹ thuật3-5 năm trở lên kinh nghiệm làm việc với các nền tảng cloud, đặc biệt là gcp và có kinh nghiệm với databasehiểu biết về cách thức triển khai giải pháp etl/elt có khả năng mở rộng dữ liệu trên gcphiểu biết về xử lý dữ liệu với python và các nền tảng saashiểu biết về các quy chuẩn về chính sách dữ liệuhiểu biết về hạ tầng cloud (gcp) & onprem: kubernetes, bigquery, airflowhiểu biết về văn hóa devopscó khả năng sử dụng các toolset iaas như terraform, ansible, docker, helm...có khả năng sử dụng và phát triển các toolset về tự động hóa: gitlabcikhả năng quản lý và sắp xếp công việc tốtchủ động, có trách nhiệm, sáng tạo và teamwork tốt',\n",
       "       'experience- good team-leader skills & control, working in high pressure environment.- good microsoft office such as word, excel- team work- good communication.additional informationrecruiter in charge:ms. huong pham ([email',\n",
       "       'experience in the e-commerce industry.\\nwe are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end-to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\\ni. job descriptions\\na - demand planning:\\n\\n develop the deep understanding of demand input factors (seasonality as an example, distributor‘s inventory policy as another example) as well as the effect of demand on the downstream factors (inventory, capacity, lead time, cost...)\\n build the mathematical model for demand forecasting and planning for each of the skus. sensitivity analysis included.\\n in collaboration with sales, finance and operations during the monthly meeting and update/fill out/adjust the demand plan in accordance with the consensus.\\n create a robust planning function to support continuous improvement for the business.\\n provide insights to conduct fact-based portfolio management and to implement a yearly sku portfolio review cycle\\n\\nb – supply planning:\\n\\n manage the inventory status at each node of the supply chain, build the replenishment model based on the demand forecast and inventory policy to decide the stock move or po quality to offer the optimal stock level and purchasing cost (container/pallet utilization as an example).\\n develop the understanding of supplier lead time and capacity/throughput and how fast they can react with change in y4a demand. create supply scenarios to prepare reaction plan for each of the demand/supply variation occurs\\n build monitoring mechanism to tracking actual outcome and demand insights from other departments. lead solutions findings and execution of demand and supply imbalances.\\n\\nc – supply chain analytic:\\n\\n providing analytical, strategic, and operational support across the organization with the primary objective of enhancing our supply chain responsiveness, agility and optimization\\n assisting or leading on-going supply chain projects under the supervision of supply chain manager\\n\\nii. skill and experience\\n\\nwe are looking for supply chain lover so please be ready to show that.\\nboth the theory-driven and data-driven approaches in solving problems.\\nstrong mathematical and analytical skills. hands on experience with applying analytical techniques to solve supply chain problems. fluent one or multiple analytic languages (r, mysql, python, …) is priority.\\npossess excellent verbal and written communication skills as well as presentation skills.\\nintellectual curiosity & honesty.\\nteam player with high ownership.\\ngood at time managing, speed, teamwork, and multitasking.\\nwilling to learn, thrive in a fast-paced environment and have a can-do attitude.\\nat least 2-3 years of experiences in planning, supply chain/business/data analytics or similar roles. retail supply chain, e-commerce experience is priority.\\n\\niii. why you will love joining us?\\nfor you to join\\n\\nfinancial well-being: a competitive salary with 13th month salary, annual performance bonus and a variety of allowances.\\nsalary review: annually or on excellent performance.\\nactivities: company trips, team-building, and other customized monthly bonding events.\\nannual leaves: 16 days off and 01 birthday leave per year.\\nhealthcare: annual health check, insurance according to labor law and extra bao viet insurance package.\\nworking environment: dynamic, friendly environments with working time flexibility (mon-fri) and other perks include snacks, coffee, and healthy food provided daily suited for hardworking, fun, and team collaboration.\\n\\nfor you to grow\\n\\nambition: we are now keeping on with our hyper growth to multicategory, multichannel, multimarket, and expanding into the world largest e-commerce enabler. hence, there will continuously be opportunities to challenge yourself, learn new skills and knowledge.\\nchallenges: your voice can always be heard as we embrace the eagerness of learning and sharing. you can be your own boss and create your own value with the ability to take initiative and make decisions in all aspects of work.\\nchances: be led and coached by experienced and inspirational leaders and participate in various training courses where you can enlarge your knowledge and experience in the e-commerce and supply chain industry.\\n\\nfor you to stay\\n\\npeople: having a headquarter in the us and an operation office in vietnam, our team is young and highly motivated. you will be working with and alongside members having experiences from international corporations or high profile from vietnam that share the same passion and dedication.\\nculture: our working environment is humble, collaborative and 100% healthy. we promote exchange & speak out, you can receive transparent and supportive feedback so you can perform the best.\\ncareer path: provide you a great career path, open to rotating for your better understanding of the company and contribute across many of our functions.\\n\\nand much more, join us and let yourself explore other fantastic things!',\n",
       "       '',\n",
       "       'experienced business intelligence engineer/data analyst to join our team. you will generate insights that will guide product (physical and tech) development and operational excellence and for our customers. data analysis will the core of what we do, and your work will have a direct impact on decision making and strategy for our team. you will gather customer data, mine those data, generate insights, and make recommendations to help senior leaders make key business decisions.\\n\\nmain responsibilities \\ndefine\\n•\\tinterface with internal business teams to gather analytics & decision-making requirements\\n•\\tconduct deep dive analyses of business problems and data issues\\n•\\tanalyze customer and product trends to determine drivers of growth and performance\\n•\\twork closely with stakeholders to translate business needs into analytical needs, including identifying critical metrics and kpis, and deliver actionable insights to relevant decision-makers\\n•\\town the definition, design, and requirements for team’s bi tools and reports\\ndesign\\n•\\tdesign, implement and support a platform that can provide ad-hoc access to large data-sets\\n•\\tidentify and investigate new data sources that can be used to build a holistic view for customer engagement. partner with technology teams to define, extract, transform, and load data from many data sources using sql and other tools\\n•\\tdefine and implement data acquisition and integration logic, selecting appropriate combination of methods and tools within defined technology stack to ensure optimal scalability and performance of the solution\\n•\\tdevelop and maintain databases by defining data schema, acquiring data from primary and secondary sources, and build scripts that will make our data evaluation process more flexible or scalable across data sets\\ndeliver\\n•\\tmodel data and metadata to support ad-hoc and pre-built reporting\\n•\\town the design, implementation, and maintenance of ongoing metrics, reports, analyses, and dashboards, to drive key business decisions.\\n•\\tautomate and simplify self-service or reporting pipelines, including improving etl workflows, automatic alarming, prototyping data science models and performance tuning.\\n•\\tcreate and maintain rich interactive visualizations through data interpretation and analysis integrating various reporting components from multiple data sources\\ndecide\\n•\\tparticipate in strategic and tactical planning discussions and provide data insights. challenge business teams to think differently about how they digest and use the data insights to make informed decisions\\n•\\tproactively analyze data to answer key questions from stakeholders or out of self-initiated curiosity with an eye for what drives business performance, investigating and communicating areas for improvement in efficiency and productivity\\n                                                                                    \\nxem toàn bộ mô tả công việc',\n",
       "       '', '', 'yêu cầu ứng viên\\ntrình độ học vấn· ', '',\n",
       "       'yêu cầu ứng viên\\n+ nam/nữ; tốt nghiệp các trường đại học chuyên ngành cntt hoặc các ngành khác có liên quan+ có từ 6 tháng - 1 năm kinh nghiệm làm việc ở vị trí tương đương+ có kiến thức cơ sở về các thuật toán ai, machine learning+ biết lập trình một trong các ngôn ngữ python, c/c+++ nhanh nhẹn, chủ động và có khả năng làm việc nhóm\\nquyền lợi\\n+ thu nhập 8-20m/tháng, 2-6 tháng xét tăng lương 1 lần',\n",
       "       '', '', '',\n",
       "       'yêu cầu công việc\\ncác công việc khác được giao bởi project manager và group leader.\\n\\n\\nyour skills and experience\\n\\n\\nthành thạo ngôn ngữ python. có từ',\n",
       "       'kinh nghiệm trong lĩnh vực phân tích và trình bày dữ liệu tài chính.\\n• kỹ năng giao tiếp bằng văn bản và bằng lời nói xuất sắc (đặc biệt là bằng tiếng anh), với khả năng truyền đạt rõ ràng thông tin chi tiết về dữ liệu phức tạp cho các bên liên quan phi kỹ thuật.\\n• khả năng làm việc độc lập đã được chứng minh và là một phần của nhóm.\\n• kỹ năng giải quyết vấn đề và tư duy phản biện mạnh mẽ.\\n• kiến thức về sql, python và kho dữ liệu là một lợi thế.\\n• kiến thức về các công cụ báo cáo và trực quan hóa dữ liệu như power point, tableau, powerbi hoặc tương tự là một lợi thế.\\n• có kinh nghiệm tư vấn, tư vấn và nghiên cứu là một lợi thế.\\n• acca/cfa là một lợi thế.\\nchế độ\\n• thu nhập hàng tháng: theo năng lực, có thể thỏa thuận. tháng lương 13.\\n• thưởng năm theo năng lực, thưởng dự án và các mức thưởng khác theo quy chế thu nhập.\\n• các khoản phúc lợi: thưởng lễ, tết, … bằng tiền theo thỏa ước lao động tập thể.\\n• chính sách bhxh, bhyt, bhtn, kpcđ và các phúc lợi khác theo đúng quy định của luật lao động và của công ty.\\n• 14-16 ngày phép/ năm so với trung bình 12 ngày phép/năm trên thị trường.\\n• làm việc trong môi trường năng động, có cơ hội được đào tạo nâng cao nghiệp vụ thường xuyên.\\n• có cơ hội tiếp cận, làm việc trong môi trường tài chính, chứng khoán.\\n• được đào tạo về kỹ năng chuyên môn và kiến thức kinh tế, tài chính, hàng hóa.\\n• trợ cấp internet khi làm việc tại nhà do ảnh hưởng của dịch bệnh covid.\\n• đối với senior: được đóng bảo hiểm y tế của bảo hiểm bưu điện\\n• cơ hội thăng tiến sớm cho cá nhân tiêu biểu.\\n• khung giờ làm việc linh hoạt.\\n• trợ cấp các loại tuỳ theo đối tượng: phụ cấp điện thoại, phụ cấp gửi xe ô tô, trợ cấp kết hôn.\\ngửi cv\\n email liên hệ: talents@fiingroup.vn ',\n",
       "       'experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \\n\\nall locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\npeople analytics manager (bangkok based, relocation provided)\\napply now\\nbangkok, thailand\\n\\nabout agoda',\n",
       "       'experience enabled by our own technology ecosystem and operational infrastructure, we are setting the benchmark in online fashion & lifestyle in our markets, and our vision is to be the #1 online destination for fashion & lifestyle in growth markets.',\n",
       "       'kinh nghiệm. xử lý dữ liệu. trực quan hóa các kết quả phân tích dữ liệu.\\n- giải quyết các vấn đề như phát hiện gian lận, cho điểm tín nhiệm, …\\n- kiểm thử hệ thống. xử lý các vấn đề liên quan đến kiểm thử.\\n- phát triển các công cụ tự động hóa cho kiểm thử, kiểm tra xử lý dữ liệu và các công việc liên quan khác.\\n- tham gia các công việc phân tích dữ liệu kinh nghiệm, lập các báo cáo phân tích tài chính, mô hình hóa sản phẩm theo các yêu cầu nghiệp vụ trên hệ thống phần mềm prophet chuyên biệt.\\n- hỗ trợ các công việc phân tích kỹ thuật nghiệp vụ bảo hiểm nhân thọ, thực hiện các công việc liên quan đến xây dựng các tính năng kỹ thuật của sản phẩm trên hệ thống cntt\\n',\n",
       "       '',\n",
       "       \"experience\\n\\n\\nthe ideal candidate should have a degree in computer science, mathematics, or a related field, with a minimum of 3 years of experience in machine learning and deep learning\\nat least 3 years of experience working as an ai engineer, ai researcher, or data scientist position\\nat least 2 years of experience working on 3d computer vision domains such as 3d object detection, depth estimation, or 3d mesh reconstruction\\nexperience in 3d data processing such as depth information, point cloud, etc.\\nsolid foundation in probability, linear algebra, and space geometry\\ndeep understanding of the multi-view geometry of the camera, a variety of matrix factorization algorithms, linear equation solutions, and spatial coordinate transformations in different coordinate systems\\nexperience in deploying deep learning models onto real environments such as edge devices\\nproficient in frameworks such as pytorch or tensorflow\\nproficient in python. c/c++ is a plus\\ngood logical and critical thinking skills, hard-working and responsible at work\\nable to communicate and work in a team\\n\\n\\nwhy you'll love working here\\n\\n\\ncompetitive salary: up to $2500\\n14 months' salary a year\\nopportunity to receive bonus shares.\\nto fully participate in the regimes prescribed by the state such as social insurance, health insurance, unemployment insurance, and annual leave.\\nbe trained and work directly with experienced experts in the field of ai.\\nhave the opportunity to do challenging things, develop your full potential\\nparticipate in team building sessions, travel 2-3 times/year, and have fun monthly with the company;\\nenjoy full benefits (happiness, birthday...);\\nyoung, comfortable working environment, dynamic startup spirit.\\n\\n\",\n",
       "       '',\n",
       "       'yêu cầu công việc\\n\\n\\nsolid knowledge and experience working with relation databases.\\n\\nstrong knowledge and experience working with python programming language.\\nexperience working with linux/unix, google cloud platform environment.\\nworking knowledge of message queue, stream processing, and highly scalable data storage.\\nexperience working with celery, elasticsearch or flask is a plus.\\nexperience working with git is a plus.\\n\\n\\ntại sao bạn sẽ yêu thích làm việc tại đây\\n\\n\\nopportunity to be onsite in us\\ncompany-sponsored macbook\\nflexible vacation schedule\\nflexible work hours\\noffice happy hours\\na family of exceptional developers\\n\\n',\n",
       "       '',\n",
       "       'yêu cầu công việc\\n\\n\\nuniversity graduate or equivalent\\nfluent in english speaking and writing. good office computer skills and data management.\\ndemonstrated strong ability to manage and analyze and interpret complex problems/data gathered from a variety of sources and, through effective decision-making and planning, delivers superior business solutions.\\nunderstand organizational structure, operating culture, effective work styles, and achieving results in a changing environment.\\n\\n\\n\\njob tags:\\nreplenishment analyst\\nreplenishment analyst\\nanalyst\\nmerchandise\\n',\n",
       "       '', '',\n",
       "       'yêu cầu ứng viên\\ngraduated from a regular university, with priority in it, computer science, information systems,economic informatics, finance – banking, ...- have 2+ years of experience in data warehouse construction.- have good knowledge of database management systems and data modeling.\\nquyền lợi\\nsalary: negotiable (unlimited)- competitive and fair environment, promoting multi-capacity.- salary review: 02 times/year, fixed in april and october every year; sudden increase in salary...- insurance regime: social insurance, health insurance, unemployment insurance fully according to theregulations of the state- annual health check-up- annual vbi health care insurance.- various bonuses: money saving, 13th month bonus, lunar new year bonus, holiday/tet bonus, lastbusiness bonus years, excellent staff, deep knowledge, initiative....- support for parking, laptop, personal computer....- working time: from monday to friday; saturday morning is not required to go to the timekeepingoffice.- participate in activities: events, conferences, seminars on technology... and internal programs set atthe office.- training mode: to participate in internal training programs, certificates according to demand to serveundertaking work.- tourism and vacation activities: 01 time/year. team building: 02 times/year- free tea, coffee, snacks at the office\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 08/06/2023\\n\\n\\n',\n",
       "       '',\n",
       "       'kinh nghiệm làm việc trong lĩnh vực tài chính, ngân hàng tại các tổ chức dịch vụ tài chính liên quan đến xử lý dữ liệu hệ thống, phân tích dữ liệu, lập báo cáo;\\n- tối thiểu 1 năm kinh nghiệm làm việc trong lĩnh vực lập trình vba trên excel: khả năng advance/excellent;\\n- kinh nghiệm lập trình và cấu trúc dữ liệu cơ bản;\\n- kiến thức sql căn bản;\\n- kỹ năng phân tích, quản lý hoạt động và quản lý thời gian tốt; tư duy logic;\\n- kỹ năng tiếng anh cơ bản (ưu tiên).',\n",
       "       '', '', '', '',\n",
       "       \"yêu cầu ứng viên\\n- excellent attention to detail and analytical skills.- strong communication and collaboration skills.- ability to work independently and meet deadlines.\\nquyền lợi\\n12 annual days off a year.salary review once a year.birthday party monthly.gifts on international/national holidays. (women's day, valentines,..)annual health check.social security.\\ncách thức ứng tuyển\\n\\nứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\\n\\n\\n\\nứng tuyển ngay\\n\\nlưu tin\\n\\n\\nhạn nộp hồ sơ: 31/07/2023\\n\\n\\n\",\n",
       "       'yêu cầu ứng viên\\n● kiến thức:- tốt nghiệp cử nhân chuyên ngành công nghệ thông tin, điện tử viễn thông, tài chính, ngân hàng, kinh tế hoặc tương đương. ưu tiên ứng viên có bằng tốt nghiệp loại giỏi hoặc tốt nghiệp tại nước ngoài- ưu tiên có các chứng chỉ chuyên nghành data engineer, data analytics, data science cho xử lý dữ liệu lớn● kinh nghiệm:- tối thiểu 1.5 năm kinh nghiệm làm việc trực tiếp tại các công ty, dự án về de- có kiến thức về kiến trúc vật lý, kiến trúc logic, thành phần cơ bản của hadoop eco-sys: tầng ingesstion, tầng processing, tầng consumtion- có kiến thức và kinh nghiệm sử dụng spark etl with scala, python trên hadoo eco-sys- có kiến thức và kinh nghiệm tối ưu luồng xử lí data: landing zone, working zone, gold zone, các kỹ thuật thiết kế job tối ưu cho dữ liệu lớn, kỹ thuật orchestration luồng job- có kiến thức và kinh nghiệm về các db sau: sql, nosql, graph- có kiến thức và kinh nghiệm flask, fastapi, gunicorn- có kiến thức và kinh nghiệm tableau/ powerbi- có kiến thức và kinh nghiệm unit testing, integration testing, functional testing, a/b testing, ',\n",
       "       'yêu cầu ứng viêntốt nghiệp master ngành computer visionít nhất 2-3 năm kinh nghiệm làm sản phẩm thực tế trong ngành computer visionquen thuộc với pytorch, keras, tensorflowcó kinh nghiệm finetune, tối ưu modeltrung thực, trách nhiệm, có khả năng làm việc độc lập tốt và có tinh thần làm việc nhómquyền lợimức offer upto 3000 usdcontribute vào sản phẩm công nghệ có vision tầm cỡ thế giớiđược quyền quyết định, định hướng công nghệtham gia trực tiếp nghiên cứu, định hướng, phát triển sản phẩmcơ chế đãi ngộ tập trung vào phát triển nhân tài và xây dựng theo concept gia tốc: nhân sự top đầu tăng lương gấp 6 lần nhân sự top dưới.thưởng 4-6 tháng lương 1 năm với nhân sự top đầu.bổ nhiệm ngay khi có chiến công đặc biệt.tham gia đầy đủ các chế độ bhxh, bhyt, bhtn.các gói bảo hiểm ngoài bhxh: bảo hiểm pti, khám sức khỏe định kỳ hàng nămvăn hóa làm việc genz,môi trường làm việc trẻ trung, sáng tạo, dám nghĩ - dám làm, trà đá, bàn tròn, ném đá sếp, áp dụng triệt để văn hóa 6k startup, tsb3c.thực chiến cùng quản lý, chuyên gia từ các tập đoàn lớn: topica, vng, samsung,...du lịch hàng năm, team building, tea break hàng tuầncách thức ứng tuyểnứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.hạn nộp hồ sơ: 08/05/202',\n",
       "       'yêu cầu công việcuniversity degree in finance, accounting or related disciplines\\nhave at least 4 years of experience\\nsystematic thinking\\nexcellent communication, grasping and problem-solving skills\\npreference will be given to candidates who are proficient at power bi, vba, excel at excel\\nhaving experience in building process, work management system such as: oracle, sap, base, 1office is an advantageđịa điểm làm việc35/2 nguyễn văn hưởng, phường thảo điền - quận 2 - thành phố thủ đức, hcm',\n",
       "       'experience in web crawling and/or scraping skills with or without a framework\\n– experience in software development life cycle and developing large scale software systems\\n– proficiency in high level language such as python, java or perl\\n– proficiency in a query language and using sql\\n– experience in programming and working in aws infrastructure\\n– excellent verbal and written communication skills in both vietnamese and english\\n– machine learning research and nlp experience is a great plus\\nrewards:\\n– competitive compensation package\\n– collaborating with talented software engineers\\n– formulate and execute projects that will have a real impact\\n– improve your personal and technical skills\\n',\n",
       "       '', '',\n",
       "       'yêu cầu ứng viên- proven working experience as a data analyst or business data analyst\\n- technical expertise regarding data models, database design development, data mining and segmentation techniques\\n- strong knowledge of and experience with reporting packages (business objects etc), databases (sql etc), programming (xml, javascript, or etl frameworks)\\n- knowledge of statistics and experience using statistical packages for analyzing datasets (excel, spss, sas etc)\\n- strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy- adept at queries, report writing and presenting findings\\n- bs in mathematics, economics, computer science, information management or statisticsquyền lợi- attractive salary from 1,000 - 2,000$\\n- the remuneration mechanism focuses on talent development and builds on the concept of acceleration: the top employees will have the opportunities to increase their salary 6 times more than the underrated employees.\\n- bonus 4-6 months salary per year for top employees.\\n- promoted as soon as there is a special achievement in work.\\n- fully benefits in social insurance, health insurance and unemployment insurance regimes.\\n- extra insurance packages: pti insurance, annual health check per year\\n- genz working culture: young, creative working environment, dare to think - dare to do, dynamic discussion , round table discussion, completely straight discussion with boss, '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "023f89c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_description.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca5be1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Description</th>\n",
       "      <th>Requirements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data-02-06/2121/data.html</td>\n",
       "      <td>mô tả công việc\\n\\n\\nwork on data collection s...</td>\n",
       "      <td>yêu cầu công việc\\n\\n- education level, certif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data-02-06/2860/data.html</td>\n",
       "      <td>responsible for driving strategic planning pro...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data-02-06/2537/data.html</td>\n",
       "      <td>mô tả công việc\\n- tham gia vào các dự án triể...</td>\n",
       "      <td>yêu cầu ứng viên\\n- tốt nghiệp đại học ngành k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data-02-06/2727/data.html</td>\n",
       "      <td>mô tả công việc\\nchịu trách nhiệm trích xuất v...</td>\n",
       "      <td>yêu cầu ứng viên\\n1. trình độ:có kiến thức cơ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data-02-06/860/data.html</td>\n",
       "      <td>descriptionkiotviet wishes to transfer a massi...</td>\n",
       "      <td>experience.what you will do:design the archite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>data-02-06/2989/data.html</td>\n",
       "      <td>mô tả công việc• build financial models to rev...</td>\n",
       "      <td>yêu cầu công việcuniversity degree in finance,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>data-02-06/791/data.html</td>\n",
       "      <td>description \\n\\njob responsibilities (include,...</td>\n",
       "      <td>experience in web crawling and/or scraping ski...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>data-02-06/1499/data.html</td>\n",
       "      <td>responsibilities:\\n\\n\\nyou are an</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>data-02-06/2573/data.html</td>\n",
       "      <td>mô tả công việc\\n\\n                           ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>data-02-06/1898/data.html</td>\n",
       "      <td>mô tả công việc- interpret data, analyze resul...</td>\n",
       "      <td>yêu cầu ứng viên- proven working experience as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Data  \\\n",
       "0    data-02-06/2121/data.html   \n",
       "1    data-02-06/2860/data.html   \n",
       "2    data-02-06/2537/data.html   \n",
       "3    data-02-06/2727/data.html   \n",
       "4     data-02-06/860/data.html   \n",
       "..                         ...   \n",
       "583  data-02-06/2989/data.html   \n",
       "584   data-02-06/791/data.html   \n",
       "585  data-02-06/1499/data.html   \n",
       "586  data-02-06/2573/data.html   \n",
       "587  data-02-06/1898/data.html   \n",
       "\n",
       "                                           Description  \\\n",
       "0    mô tả công việc\\n\\n\\nwork on data collection s...   \n",
       "1    responsible for driving strategic planning pro...   \n",
       "2    mô tả công việc\\n- tham gia vào các dự án triể...   \n",
       "3    mô tả công việc\\nchịu trách nhiệm trích xuất v...   \n",
       "4    descriptionkiotviet wishes to transfer a massi...   \n",
       "..                                                 ...   \n",
       "583  mô tả công việc• build financial models to rev...   \n",
       "584  description \\n\\njob responsibilities (include,...   \n",
       "585                 responsibilities:\\n\\n\\nyou are an    \n",
       "586  mô tả công việc\\n\\n                           ...   \n",
       "587  mô tả công việc- interpret data, analyze resul...   \n",
       "\n",
       "                                          Requirements  \n",
       "0    yêu cầu công việc\\n\\n- education level, certif...  \n",
       "1                                                  NaN  \n",
       "2    yêu cầu ứng viên\\n- tốt nghiệp đại học ngành k...  \n",
       "3    yêu cầu ứng viên\\n1. trình độ:có kiến thức cơ ...  \n",
       "4    experience.what you will do:design the archite...  \n",
       "..                                                 ...  \n",
       "583  yêu cầu công việcuniversity degree in finance,...  \n",
       "584  experience in web crawling and/or scraping ski...  \n",
       "585                                                NaN  \n",
       "586                                                NaN  \n",
       "587  yêu cầu ứng viên- proven working experience as...  \n",
       "\n",
       "[588 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4a09d8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yêu cầu ứng viên\\n1. trình độ:có kiến thức cơ bản về supply chain/ logistics và ngành bán lẻ;nắm được các phương pháp & công cụ thống kê phân tích;tốt nghiệp đại học các chuyên ngành toán thống kê/thống kê kinh tế/ thống kê kinh doanh/kinh tế lượng/ khoa học dữ liệu/ khoa học máy tính/logictics & chuỗi cung ứng/ quản trị kinh doanh2. kinh nghiệm: ưu tiên ứng viên có đam mê phân tích dữ liệu và kinh nghiệm làm việc từ dưới 06 tháng – 01 năm.3. kỹ năng:kỹ năng tư duy logic, có hệ thống, trực quan hóa dữ liệu;kỹ năng excel nâng cao (vba, sql, access);kỹ năng lập kế hoạch và quản lý công việc;kỹ năng giao tiếp tốt và khả năng thuyết trình;kỹ năng giải quyết vấn đề;kỹ năng tổ chức, tổng hợp và phân tích dữ liệu: dashboard (qlik hoặc powerbi hoặc tableau), xử lý & phân tích dữ liệu (alteryx, sql, r hoặc python là một lợi thế).4. thái độ/phẩm chất: nhạy bén, linh hoạt, khéo léo, có trách nhiệm, ham học hỏi, dấn thân.\\nquyền lợi\\nlương thỏa thuận và nhận đúng hạn;thưởng thâm niên, thưởng tháng 13;được hỗ trợ cơm trưa tại công ty;chỗ ở nội trú cho các nhân sự ở xaxem xét tăng lương 1 lần/năm;bhxh, bhyt, bhtn đầy đủ theo luật;tham gia bảo hiểm bảo việt (thời gian làm việc chính thức đủ 8 tháng);nghỉ phép thường niên, lễ, tết theo quy định;tham gia teambuilding, các hoạt động nội bộ và các hoạt động cộng đồng do công ty tổ chức;được đào tạo bài bản về các kiến thức, kỹ năng cho công việc & kỹ năng đời sống (sức khỏe, dinh dưỡng,...);cơ hội thăng tiến công bằng, không giới hạn phòng ban;làm việc với các nhân sự dày dặn kinh nghiệm trong ngành giày chỉ có ở thương hiệu quốc dân “biti\\'s - nâng niu bàn chân việt”;có cơ hội tham gia dự án hạnh phúc happy biti\\'s để hiểu hơn về chính mình, hiểu & kết nối với người khác, kết nối với thiên nhiên;môi trường làm việc được chia sẻ, được lắng nghe và được tôn trọng;được nhận học bổng \"nâng niu tài năng việt\" cho con em có thành tích học tập tốt.\\ncách thức ứng tuyển\\n\\nhết hạn nộp đơn\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Requirements'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c718fd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'excel', 'word', 'analys', 'tableau bi', 'power bi', 'english', 'flink', 'spark', 'data bricks', 'azure', 'sql', 'keras', 'tensorflow', 'scikit learn', 'linux', 'bash script', 'crawing data', 'javascript', 'jetson', 'raspberry', 'asynchronous programming', 'data mining', 'segmentation techniques', 'spring', 'node js', 'vue', 'angular', 'e-commerce', 'data warehouse', 'data pipeline', 'teamwork,independent', 'self study', 'airflow', 'aracle', 'transaction data', 'pytorch', 'visualisation', ' r ', ' r,', ' r.', 'kubeflow', 'vertex', 'reinforcement learning', 'supervised learning', 'c++', 'algorithms', 'oop', 'statistics', 'mathematics', 'google bigquery', 'google bigtable', 'opencv', '1year', '2year', '3year', '4year', '5year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0d388a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excel\n",
      "phân tích\n",
      "sql\n",
      " r\n"
     ]
    }
   ],
   "source": [
    "for key in keyword:\n",
    "    if key in df['Requirements'][3]:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b005ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_keyword(req,keyword):\n",
    "    vn_eng = {'phân tích':'analys', 'thống kê':'statistics', 'năm':'year', 'hướng đối tượng':'oop', 'thuật toán': 'algorithms'}\n",
    "    for key in vn_eng:\n",
    "        req = req.replace(key, vn_eng[key])\n",
    "    tmp = req.find('year')\n",
    "    tmp-=1\n",
    "    while (tmp>0 and (req[tmp]<'0' or req[tmp]>'9' )):\n",
    "        req = req[:tmp] + req[tmp+1:]\n",
    "        tmp-=1\n",
    "    res = []\n",
    "    for key in keyword:\n",
    "        if key in req:\n",
    "            res.append(key)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea60d184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['excel', 'analys', 'sql', ' r ', 'statistics', '1year']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_keyword(df['Requirements'][3],keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb632f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yêu cầu công việc\n",
      "\n",
      "- education level, certification: university degree in computer science, marketing analytics,\n",
      "business, statistics or other related studies; or equivalent work experience\n",
      "- experience:\n",
      "\n",
      "3+ years' experience in similar or equivalent position\n",
      "experience and knowledge of consumer financing industry and collection as a preferred.\n",
      "strong analytical skills with ability to deliver insightful ideas, excited to draw findings from figures.\n",
      "\n",
      "- individual characteristics:\n",
      "\n",
      "good interpersonal, communication and presentation skills.\n",
      "proactive, responsible, attention to detail and a good team player.\n",
      "fluency in written and spoken english\n",
      "\t\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "- tốt nghiệp đại học ngành kinh tế, phân tích dữ liệu, công nghệ thông tin, hệ thống thông tin.- ưu tiên ứng viên có kinh nghiệm làm việc thực tế.- ưu tiên ứng viên có kinh nghiệm đã sử dụng hoặc triển khai các giải pháp bi, excel nâng cao, phân tích tài chính, bsc/kpi- kỹ năng phân tích yêu cầu dữ liệu, tư duy, học hỏi nhanh- có kinh nghiệm xây dựng dashboard, làm việc với tableau bi, power bi.- sử dụng tốt microsoft office word, excel- tiếng anh đọc hiểu bắt buộc, có khả năng giao tiếp cơ bản là một lợi thế\n",
      "yêu cầu ứng viên\n",
      "1. trình độ:có kiến thức cơ bản về supply chain/ logistics và ngành bán lẻ;nắm được các phương pháp & công cụ thống kê phân tích;tốt nghiệp đại học các chuyên ngành toán thống kê/thống kê kinh tế/ thống kê kinh doanh/kinh tế lượng/ khoa học dữ liệu/ khoa học máy tính/logictics & chuỗi cung ứng/ quản trị kinh doanh2. kinh nghiệm: ưu tiên ứng viên có đam mê phân tích dữ liệu và kinh nghiệm làm việc từ dưới 06 tháng – 01 năm.3. kỹ năng:kỹ năng tư duy logic, có hệ thống, trực quan hóa dữ liệu;kỹ năng excel nâng cao (vba, sql, access);kỹ năng lập kế hoạch và quản lý công việc;kỹ năng giao tiếp tốt và khả năng thuyết trình;kỹ năng giải quyết vấn đề;kỹ năng tổ chức, tổng hợp và phân tích dữ liệu: dashboard (qlik hoặc powerbi hoặc tableau), xử lý & phân tích dữ liệu (alteryx, sql, r hoặc python là một lợi thế).4. thái độ/phẩm chất: nhạy bén, linh hoạt, khéo léo, có trách nhiệm, ham học hỏi, dấn thân.\n",
      "quyền lợi\n",
      "lương thỏa thuận và nhận đúng hạn;thưởng thâm niên, thưởng tháng 13;được hỗ trợ cơm trưa tại công ty;chỗ ở nội trú cho các nhân sự ở xaxem xét tăng lương 1 lần/năm;bhxh, bhyt, bhtn đầy đủ theo luật;tham gia bảo hiểm bảo việt (thời gian làm việc chính thức đủ 8 tháng);nghỉ phép thường niên, lễ, tết theo quy định;tham gia teambuilding, các hoạt động nội bộ và các hoạt động cộng đồng do công ty tổ chức;được đào tạo bài bản về các kiến thức, kỹ năng cho công việc & kỹ năng đời sống (sức khỏe, dinh dưỡng,...);cơ hội thăng tiến công bằng, không giới hạn phòng ban;làm việc với các nhân sự dày dặn kinh nghiệm trong ngành giày chỉ có ở thương hiệu quốc dân “biti's - nâng niu bàn chân việt”;có cơ hội tham gia dự án hạnh phúc happy biti's để hiểu hơn về chính mình, hiểu & kết nối với người khác, kết nối với thiên nhiên;môi trường làm việc được chia sẻ, được lắng nghe và được tôn trọng;được nhận học bổng \"nâng niu tài năng việt\" cho con em có thành tích học tập tốt.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "hết hạn nộp đơn\n",
      "\n",
      "experience.what you will do:design the architecture, implement and maintain the data pipelines that are scalable and reliable for kiotviet data platform.design and implement data warehouse, datamarts to meet the need of querying data and perform descriptive and predictive analytics.collect, process, store and analyze our ever-growing customer data.participate in design and implement new generation of our data platform to help push our stakeholders take advantage from data faster.build high-performance, mission critical apis to allow various customer-facing and internal services to query data, perform analytics.brainstorm, discuss with various experts from other departments to develop data products that serve various customer-facing problems and how data will help push our business further.skillsdata structuresdata warehousingbig datarequirementyou must be strong in data structures and algorithms and have a good knowledge in data analysis.deep understanding of data warehouse concepts and practices.you should be experienced building a data warehouse on cloud platform such a google bigquery.possess an in-depth understanding of the data management.you should be experienced in big data processing framework like apache spark.you should be proficient in one or more of the following programming languages: java / scala / python.eager to learn and willing trial and error several times.experienced in manipulating, processing and extracting data from various source systems; working familiarity with relational databases is a plus.experience with cloud platforms such as google cloud platform is a plus.\n",
      "yêu cầu ứng viên\n",
      "tốt nghiệp chuyên ngành liên quan: công nghệ thông tin, điện tử viễn thông, tự động hóa;có tối thiểu 4 năm kinh nghiệm trở lên về lập trình ai trên các thiết bị main board như jetson devices, raspberry pi;có kiến thức về lập trình ai trên các dòng chip arm, hisilicon, rockchip là 1 lợi thế;làm việc thành thạo với các giao thức tcp/ip, mqtt, http,…các mô trình giao tiếp với số lượng lớn client;có kinh nghiệm lập trình driver giao tiếp scanner, các giải pháp vision xử lý ảnh, làm việc với máy xray kiểm soát hàng hoá là một lợi thế;đọc, hiểu tài liệu kỹ thuật tốt;chủ động, sáng tạo, nhiệt tình và có trách nhiệm trong công việc;biết lắng nghe, kiên trì học hỏi, cẩn thận và tỉ mỉ và có khả năng làm việc với cường độ cao;sẵn sàng làm việc over-time khi có yêu cầu;có khả năng làm việc độc lập và làm việc theo nhóm.\n",
      "quyền lợi\n",
      "lương từ junior đến senior: 500$ – 2000$ net (đánh giá tăng lương theo năng lực định kỳ);bảo hiểm sức khỏe cao cấp generali;môi trường làm việc trẻ trung, năng động;làm việc cùng đội ngũ công nghệ giỏi chuyên môn, có cơ hội để phát huy tối đa năng lực của bản thân;liên tục được đào tạo về kiến thức, kỹ năng liên quan đến các lĩnh vực hoạt động của công ty;được cung cấp đầy đủ phương tiện làm việc theo yêu cầu của tính chất công việc;các hoạt động tập thể, giải trí đa dạng (clb bóng đá, game, bi lắc, …); sự kiện team-building hàng năm;được đảm bảo đầy đủ các chế độ phúc lợi theo quy định của pháp luật hiện hành và của công ty;thưởng tết nguyên đán, tết dương lịch, ngày lễ khác và thưởng thành tích nổi bật.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 31/07/2023\n",
      "\n",
      "\n",
      "\n",
      "job requirements:university degree in computer science, engineering and/or a technically oriented field2 years of experience with flink/spark, databricks2 years of experience with azure (dp200 and/or dp201, dp203 certification acts as a plus)passionate about analytics machine learning technology & applications and eager to learnenglish communicationknowledge of big data technologies, such as spark, hadoop/mapreduceknowledge of azure services like storage account, azure databricks etc.good knowledge of sql and excellent coding skillsworking knowledge of various ml/dl applications such as keras, tensorflow, python scikit learn and rself-development, communication, problem-solving skills.open-minded, multi-tasking, teamwork, flexible and interest to learn new things\n",
      "\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "experience with linux os, bash scriptfamiliar with crawling data from the websiteexperienced in sql, and mysql databases.experienced in python/javascript/bash scriptingdata mining or have an interest in data scienceteamwork spirit, responsibility, and good english\n",
      "\n",
      "\n",
      "general information\n",
      "\n",
      "\n",
      "level: junior-middletype of the position: full-time permanent\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "business intelligence developer (bangkok based, relocation provided)\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "job requirements\n",
      "\n",
      "1+ years experience with python asynchronous programming. ( fresher accepted. )\n",
      "\n",
      "advanced experience with sql\n",
      "\n",
      "\n",
      "upper-intermediate\n",
      "nan\n",
      "nan\n",
      "yêu cầu ứng viên- previous experience as a data engineer or in a similar role\n",
      "- technical expertise with data models, data mining, and segmentation techniques\n",
      "- knowledge of programming languages \n",
      "kinh nghiệm tại các vị trí tương đương- thành thạo excel, biết sql là một lợi thế- có kỹ năng tổng hợp và phân tích số liệu- nhanh nhẹn, trung thực, trách nhiệm, cầu tiến - ưu tiên đã từng làm giám sát bán hàng, vận đơn, cửa hàng trưởng, ngành hàng trong các chuỗi bán lẻ lớn\n",
      "địa điểm làm việc\n",
      "bạn có thể lựa chọn làm tại 1 trong các văn phòng- trụ sở chính yody: đường an định, p. việt hòa, tp. hải dương (maps)- với ứng viên tại hà nội, bạn sẽ di chuyển về hải dương làm việc (yody hỗ trợ xe đưa đón hà nội - hải dương hoặc sắp xếp nơi ở miễn phí tại hải dương)\n",
      "quyền lợi:\n",
      "– thu nhập: 15 – 20 triệu (lương + thưởng doanh thu đơn hàng sản phẩm phụ trách)– thưởng cuối năm: 1-2 tháng thu nhập, thưởng theo doanh thu, thưởng các ngày lễ, tết+ cung cấp thiết bị làm việc+ phụ cấp ăn trưa miễn phí tại công ty.+ nghỉ chủ nhật, năm có 12 ngày nghỉ phép+ đóng bảo hiểm khi chính thức theo quy định+ được tổ chức sinh nhật, du lịch 1-2 lần/năm, hưởng các chính sách đãi ngộ đặc biệt từ công ty\n",
      "nan\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "advanced working sql knowledge and experience working with relational databases, query authoring (sql) as well as working familiarity with a variety of databases.experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.strong analytic skills related to working with unstructured datasets.build processes supporting data transformation, data structures,…a successful history of manipulating, processing and extracting value from large disconnected datasets.working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.strong project management and organizational skills.experience supporting and working with cross-functional teams in a dynamic environment.having 2+ years of experience in a data engineer role, who has attained a graduate degree in computer science, statistics, informatics, information systems or another quantitative field. they should also have experience using the following software/tools:experience with big data tools: hadoop, spark, kafka, etc.experience with relational sql and nosql databases, including postgres and mongodbexperience with data pipeline and workflow management tools: azkaban, luigi, airflow, etc.experience with aws cloud services: ec2, emr, rds, redshiftexperience with stream-processing systems: storm, spark-streaming, etc.experience with object-oriented/object function scripting languages: python, java, c++, scala, etc.\n",
      "quyền lợi\n",
      "professional work environment:\n",
      "nan\n",
      "yêu cầu công việc\n",
      "– đang là sinh viên năm 3 hoặc năm cuối chuyên ngành cntt hoặc hiểu biết tương đương, muốn có môi trường học tập và phát triển thực tế.\n",
      "– kỹ năng giao tiếp tốt, cởi mở, thân thiện, làm việc nhóm hiệu quả.\n",
      "– có hiểu biết về các ngôn ngữ / nền tảng sau: spring, spring boot, spring mvc, .net, nodejs, react, vue, angular, go\n",
      "– khả năng nắm bắt, yêu thích nghiên cứu công nghệ mới.\n",
      "\n",
      "experience in the e-commerce industry.\n",
      "we are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end-to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\n",
      "i. job descriptions\n",
      "\n",
      "responsible for industrialization, deployment and functional maintenance of data products/solutions, including digital products, business intelligence, and machine learning use cases.\n",
      "collaborate with other member and user to build data pipelines.\n",
      "responsible for quality checking and testing.\n",
      "collaboratively work to solve research problems.\n",
      "develop new algorithms and computational tools to solve research problems.\n",
      "review research code created by other team members.\n",
      "write technical documentation and reports.\n",
      "continue learning new technologies, introducing existing products, improving product experience, and creating more value.\n",
      "\n",
      "ii. skill and experience\n",
      "\n",
      "at least 1 year experiences in data engineer.\n",
      "demonstrable experience in web application development (building of api driven interfaces).\n",
      "ability to program with python is required.\n",
      "good knowledge in data warehouse, etl, data pipeline.\n",
      "proficiency in sql.\n",
      "exposure to emerging open-source technologies is preferred.\n",
      "good number sense, logical thinking, problem-solving and communication skills.\n",
      "have teamwork skills, work independently and self-study.\n",
      "experience with data pipeline and workflow management tools: airflow, etc.\n",
      "experience with big data tools: spark, kafka, etc.\n",
      "experience with oracle.\n",
      "\n",
      "iii. why you will love joining us?\n",
      "for you to join\n",
      "\n",
      "financial well-being: a competitive salary with 13th month salary, annual performance bonus and a variety of allowances.\n",
      "salary review: annually or on excellent performance.\n",
      "activities: company trips, team-building, and other customized monthly bonding events.\n",
      "annual leaves: 16 days off and 01 birthday leave per year.\n",
      "healthcare: annual health check, insurance according to labor law and extra pti insurance package.\n",
      "working environment: dynamic, friendly environments with working time flexibility (mon-fri), and other perks include snacks, coffee, and healthy food provided daily suited for hardworking, fun, and team collaboration.\n",
      "\n",
      "for you to grow\n",
      "\n",
      "ambition: we are now keeping on with our hyper growth to multicategory, multichannel, multimarket, and expanding into the world largest e-commerce enabler. hence, there will continuously be opportunities to challenge yourself, learn new skills and knowledge.\n",
      "nan\n",
      "experience by exploring offline & online transaction data, customer activity within apps and actual customer insights.\n",
      "maintain rigor in analytical excellence in terms of data analytics, a/b test design, and appropriate statistical tests across the product funnel from acquisition, adoption, retention to monetization.\n",
      "liaise with other analytical chapters such as data science, data engineering, etc, to ensure that initiatives are aligned and data integrity standards are adhered to.\n",
      "analyze our complex and ever-growing data, present insights, and propose strategic options to senior management to drive business decisions.\n",
      "test and validate solutions through proper experimentation process.\n",
      "importantly, using data to identify growth opportunities and problem solve so as to achieve business goals with metrics such as adoption rate, gmv, mau, & cohort retention.\n",
      "\n",
      "you will have the following skills and experience:\n",
      "this role requires a person who is data driven, a growth marketer will create tests and experiments to positively influence customer acquisition, customer conversion, customer retention and customer lifetime value.\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "kinh nghiệm xây dựng ml model và các kỹ thuật liên quan như k-fold cross-validation.\n",
      "có thể xây dựng các mô hình bằng tensorflow hoặc pytorch.\n",
      "có kinh nghiệm với data visualisation bằng bằng biểu đồ sử dụng python, r hoặc một bi dashboard bất kỳ (tableau, powerbi).\n",
      "\n",
      "\n",
      "có kinh nghiệm ứng dụng ml model vào các bài toán thực tế.\n",
      "sử dụng thành thạo một ml platform bất kỳ là một lợi thế (mlflow, kubeflow, azure machine learning, vertex ai).\n",
      "làm việc hiệu quả với các thành viên trong nhóm phát triển sản phẩm và hoàn thành các mục tiêu chung đã được đặt ra trong các giai đoạn cụ thể.\n",
      "yêu cầu ứng viên\n",
      "• trình độ đại học trở lên, học chuyên ngành công nghệ thông tin, hệ thống thông tin hoặc các chuyên ngành liên quan tại các trường đại học công nghệ, đại học công nghiệp, học viện bưu chính viễn thông, đại học bách khoa v,v...• biết sử dụng các công cụ tableau; ngôn ngữ truy vấn sql, python …• có kiến thức cơ bản về các mô hình học máy• có kĩ năng làm việc nhóm và độc lập.• nhanh nhẹn, ham học hỏi, chủ động, thẳng thắn và có tinh thần trách nhiệm cao\n",
      "quyền lợi\n",
      "• nhân viên lương cứng 8 - 12 triệu theo năng lực.• sau khi ký hợp đồng chính thức sẽ được hưởng chế độ thưởng theo quy định công ty.nghỉ phép 12 ngày/năm, nghỉ ốm/nghỉ chế độ thai sản/hiếu hỉ… theo quy định pháp luật lao động, bảo hiểm xã hội• du lịch hàng năm, teambuilding, event.• được tài trợ, tham gia các khóa đào tạo kỹ năng, chuyên môn hàng năm, thi lấy chứng chỉ để phục vụ cho công việc.• review đánh giá công việc 2 lần/ năm;• có khả năng phát triển bản thân, định hướng phát triển công việc lâu dài;• môi trường trẻ, năng động, chuyên nghiệp, được khuyến khích sáng tạo và phát triển các ý tưởng mới, sếp trẻ tâm lý, đồng nghiệp thân thiện, văn hóa trao đổi thẳng thắn, cởi mở trên tinh thần hỗ trợ cùng phát triển;• học hỏi kinh nghiệm trực tiếp từ các senior, chuyên gia giàu kinh nghiệm;\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 07/06/2023\n",
      "\n",
      "\n",
      "\n",
      "experience.\n",
      "what you will do:\n",
      "- design the architecture, implement and maintain the data pipelines that are scalable and reliable for kiotviet data platform.\n",
      "- design and implement data warehouse, datamarts to meet the need of querying data and perform descriptive and predictive analytics.\n",
      "- collect, process, store and analyze our ever-growing customer data.\n",
      "- participate in design and implement new generation of our data platform to help push our stakeholders take advantage from data faster.\n",
      "- build high-performance, mission critical apis to allow various customer-facing and internal services to query data, perform analytics.\n",
      "- brainstorm, discuss with various experts from other departments to develop data products that serve various customer-facing problems and how data will help push our business further.\n",
      "nan\n",
      "kinh nghiệm học tăng cường , học giám sát (reinforcement learning , supervised learning)\n",
      "[lợi thế] kiến thức về ros1/ros2\n",
      "làm việc trong môi trường linux\n",
      "khả năng làm việc nhóm và làm việc độc lập tốt.\n",
      "yêu thích/ mong muốn làm về xe tự lái ở việt nam là một lợi thế\n",
      "\n",
      "quyền lợi\n",
      "\n",
      "\n",
      "lương: trợ cấp (2.000.000 – 4.000.000 vnđ).\n",
      "tham gia các hoạt động học tập, đào tạo trong và ngoài công ty.\n",
      "nghỉ thứ 7, chủ nhật + 12 ngày phép/ năm\n",
      "câu lạc bộ và nhiều hoạt động văn hóa – thể thao – nghệ thuật được công ty tài trợ hoặc hỗ trợ.\n",
      "đảm bảo sức khỏe: khám sức khỏe định kỳ, hỗ trợ mua bảo hiểm sức khỏe chất lượng cao…\n",
      "\n",
      "\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "-có kinh nghiệm tối thiểu 01 năm làm việc trong các tổ chức tín dụng, tài chính hoặc ngân hàng;-có kiến thức nền tảng tốt về hệ quản trị cơ sở dữ liệu và mô hình hóa dữ liệu;-sử dụng thành thạo ít nhất một công cụ bi (power bi, tableau) để trực quan hóa dữ liệu;-cẩn thận, tỉ mỉ, làm việc tốt dưới áp lực;-ưu tiên các ứng viên có kinh nghiệm tham gia triển khai các dự án về báo cáo, dữ liệu tại các công ty tài chính/ngân hàng thương mại;-ưu tiên các ứng viên có hiểu biết về phương pháp agile, đã tham gia trong hoạt động thực tế hoạt động theo mô hình scrum team-ưu tiên các ứng viên đã có kinh nghiệm làm ba, phân tích kinh doanh, mis cho phát triển báo cáo tại các ngân hàng/tổ chức tài chính;-có kỹ năng, tư duy lập trình và sử dụng tốt ít nhất một ngôn ngữ lập trình ứng dụng là một lợi thế;-kỹ năng ngôn ngữ và diễn đạt văn bản tốt; sử dụng thành thạo tiếng việt và có khả năng giao tiếp bằng tiếng anh.\n",
      "quyền lợi\n",
      "quyền lợi• thời gian làm việc: t2-t6, nghỉ t7 và cn• lương hấp dẫn (mức lương & thưởng cạnh tranh)• phụ cấp tăng ca, thưởng dự án, thưởng vượt chỉ tiêu, thưởng tháng lương thứ 13,...• được công ty thực hiện đầy đủ nghĩa vụ về bảo hiểm; thai sản, con nhỏ, cưới hỏi, sinh nhật,...• được tham gia các hoạt động teambuilding, du lịch, các hoạt động thể thao, các hoạt động xây dựng tinh thần đồng đội.• định kỳ xét tăng lương 2 lần/năm hoặc đột xuất theo đánh giá.đặc biệt:• thử việc 100% lương• bảo hiểm sức khoẻ mic, chương trình vay ưu đãi đối với cbnv...• thưởng theo kết quả kinh doanh hàng năm của công ty (thường được thưởng 2 tháng lương) .• được cử tham gia các khóa đào tạo mới, đào tạo nâng cao phù hợp với năng lực và nguyện vọng.• môi trường chuyên nghiệp sử dụng phương pháp scrum và agile vào quản lý phát triển sản phẩm\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 30/06/2023\n",
      "\n",
      "\n",
      "\n",
      "nan\n",
      "nan\n",
      "experience in applying ai/ml/computer vision/ nlp to practical and comprehensive technology solutionsexperience with programming languages such as c++, pythonexperience with one of standard ml frameworks such as pytorch, tensorflow, or kerashands-on knowledge of basic ml/dl algorithms, object-oriented programmingproficient at englishpreferred skillsexperience with innovation acceleratorsbasic knowledge in statistics and mathematics, including probability, linear algebraexperience with ai/ml model deploying on embedded systems/ familiarity with cloud computing environments is a plusgood communication and analytical thinking skillsadditional informationjoin a dynamic english-speaking multi-culture working environmentfurthermore, we also offer you internship allowance during the internship program1 day of birthday leave + 1 day of full-paid leave/ per monthmotivating benefits of trade union activities, team building and company tripopportunity to work in global projects of fast developing company and being a part of the innovation team contributing initiative ideas to the hi-tech worldengage\n",
      "experience amazing learning.\n",
      "\n",
      "job description:\n",
      "\n",
      "•\tdata management – responsible for data gathering, processing, ensuring data structures are adequate and report design and administration as required. \n",
      "•\tcore applications development – responsible to work with relevant departments to define requirements for system integration in the schools. working closely with it team and school leaders in isams development plan;liaising with all stakeholders to develop and present the proposed development plan to school leaders.\n",
      "•\ttraining – planning, coordinating, and conducting core applications specific training for teaching and non-teaching staff for the school to maximise the user experience of the system, as necessary.\n",
      "•\tsupport – being the primary contact with isams support; with it team in maintaining users and user accounts, troubleshooting issues to do with the isams system and the use of it.\n",
      "•\treview – monitoring the effectiveness of the isams implementation and adoption and providing feedback regularly for informed planning.\n",
      "•\tother - comply with regional ict hardware and software procurement process and technology standard. accountable to support the implementation of a disaster recovery plan compliant with regional standards. \n",
      "•\tworking with regional it team and management heads to identify process improvement opportunities, propose system modifications, and devise data governance strategies. \n",
      "•\tmaintains a proficient level of knowledge of the data reporting and collection requirements of school leadership team and other requirements including the schools code of conduct\n",
      "•\tticket and escalation management \n",
      "•\tadhere to school, region, group policies and procedures\n",
      "•\tcoordinate with it team (collaboration with it team on daily operation) \n",
      "•\tdocument knowledgebase, change requests, and project resource.\n",
      "•\tflexible with regard to working hours and available on occasion to work outside of normal hours in response to support demands of the school and regional office. \n",
      "•\tactive participation in new infrastructure initiatives that could help our schools improve efficiencies.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "experience enabled by our own technology ecosystem and operational infrastructure, we are setting the benchmark in online fashion & lifestyle in our markets, and our vision is to be the #1 online destination for fashion & lifestyle in growth markets.\n",
      "nan\n",
      "experience in technology that will help with updates and developments\n",
      "- required availability for off-shift employment and rotational on-call duties\n",
      "                                                                                    \n",
      "read full job descriptions\n",
      "nan\n",
      "experience as a bi developer (industry experience is preferred).\n",
      "+ background in data warehouse design.\n",
      "+ in-depth understanding of database management systems.\n",
      "+ deep knowledge of sql queries,web programming (node js, python is a bonus).\n",
      "+ experience about google bigquery, google bigtable.\n",
      "+ analytical mind with a problem-solving aptitude.\n",
      "qualifications:\n",
      "+ bsc/ba in computer science, engineering or relevant field\n",
      "skills:\n",
      "+ knowledge about database architecture, sql, web programming, linux server.\n",
      "+ ability to take instruction and work to deadlines\n",
      "+ troubleshooting skill, strong logic thinking, solve problems creatively and effectively\n",
      "+ management/leadership\n",
      "+ intermediate english.\n",
      "\n",
      "yêu cầu ứng viên\n",
      "- sử dụng tốt một trong các phần mềm thống kê/ xây dựng mô hình/ quản lý dữ\n",
      "yêu cầu công việc\n",
      "\n",
      "1.tuân thủ đúng các quy định của công ty\n",
      "2. quản lý nhân viên\n",
      "3. triển khai chính xác chương trình, chính sách tới các đối tác hợp tác .\n",
      "4. hoàn thành chỉ tiêu doanh thu được giao.\n",
      "- giới tính: nam, nữ (ưu tiêu nam)\n",
      "- tuổi: < 35\n",
      "\n",
      "experience\n",
      "knowledge/experience in risk management and portfolio management\n",
      "benefitssalary range: up to usd 2,000 gros\n",
      "experience\n",
      "\n",
      "\n",
      "university degree in it or equivalent.\n",
      "proficient with frameworks: pytorch, tensorflow\n",
      "proficient in python, c/c++ programming languages\n",
      "at least 2,5 years of experience working as an ai engineer, ai researcher, or data scientist position.\n",
      "experience working with jetson nvidia devices is a plus.\n",
      "good logical thinking skills, hard working and responsible at work.\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "\n",
      "competitive salary: up to $2500\n",
      "14 months' salary a year\n",
      "opportunity to receive bonus shares.\n",
      "to fully participate in the regimes prescribed by the state such as social insurance, health insurance, unemployment insurance, and annual leave.\n",
      "be trained and work directly with experienced experts in the field of ai.\n",
      "have the opportunity to do challenging things, develop your full potential\n",
      "participate in team building, travel 2-3 times/year.\n",
      "enjoy full benefits (happiness, birthday...);\n",
      "young, comfortable working environment, dynamic startup spirit.\n",
      "\n",
      "\n",
      "yêu cầu ứng viên\n",
      "- có kiến thức về ai/bigdata. kinh nghiệm trên 2 năm- bằng cử nhân hoặc thạc sĩ về khoa học máy tính, kỹ thuật phần mềm hoặc công nghệ thông tin.- hơn 2 năm kinh nghiệm trong các lĩnh vực ai/ml, bigdata.- đã từng thiết kế và triển khai một hệ thống ai hoàn chỉnh từ thu thập dữ liệu đến đào tạo.- kinh nghiệm thực tế trong việc xây dựng, khắc phục sự cố và cung cấp các mô hình ai/ml, bigdata- thành thạo python và các thuật toán tensorflow\n",
      "quyền lợi\n",
      "- lương được xem xét, đánh giá tăng định kỳ một năm 2 lần.- thưởng cuối năm và thưởng các ngày lễ tết.- thời gian làm việc: từ 8h00 - 17h00 (nghỉ trưa 1 tiếng) - từ thứ 2 đến thứ 6\n",
      "experience\n",
      "\n",
      "• strong postgres experience• maintain and modify existing data sets, data loads, documentation, policies, procedures, and other data solutions• create, design, and develop data models for multiple applications• design and implement etl procedures for intake of data from multiple applications in data warehouse• carry out monitoring, tuning, and database performance analysis• design, implement and maintain analytics and business intelligence platform architecture for data warehouse• perform the design and extension of data marts, meta data, and data models• prepare various code designs and ensure efficient implementation of the same• evaluate all codes and ensure the quality of all project deliverables• knowledge of shell scripting is a plus\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "panasonic r&d center vietnam was established in april 2007, is a company specializing in r&d of panasonic group in vietnam with the aim of enhancing r&d activities in the field of digital home appliances, automation, mobility in vietnam, providing r&d services for software solutions in today's hottest fields such as ai, cloud, iot in a chain of r&d centers of worldwide corporations\n",
      "yêu cầu ứng viên\n",
      "• vietnamese nationality.• last year of university/university.• good programming skill in one of languages c/c++/python.• familiar with computer vision/machine learning/deep learning or graphic programming (2d & 3d, opengl, pointcloud, etc)• experiences with common frameworks (opencv, caffe, tensor flow, etc).• software design skill (uml, object oriented design) is a plus\n",
      "quyền lợi\n",
      "1. career path developmentclearly defined long-term multi-career roadmap;unlimited development & training opportunities (language training, technical training, soft-skill training, on-job training, etc.)oversea business trips (japan, china, singapore, us, mexico, eu, etc.)2. work-life balanceflexible working time that supports work-life balance (core time: 9:00-16:00; 5 days from monday - friday/ week)flexible lunch time;additional special holiday3. wellnesswell-protected with 24/7 personal accident and medical care insurance;well-designed annual health check-up program;4. activitiesteam-building activities; birthday party; year-end party; sport day/ family daysummer vacation (trip to famous tourist spots domestic/ overseas,…)5. cash benefitsattractive and competitive salary & bonus package depend on abilities, performance and competenciesdiversified allowance scheme6. physical environmentgrade a office with creative workplace and open space.well-equipped facilities/ devices and professional working platforms. application submission\n",
      "cách thức ứng tuyển\n",
      "\n",
      "hết hạn nộp đơn\n",
      "\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "yêu cầu công việc- chính sách phát triển, thăng tiến có lộ trình theo từng vị trí, từng phòng ban- cơ hội tiếp cận với các công nghệ mới nhất: cloud, big data…môi trường làm việc- tham gia các câu lạc bộ của công ty: clb bóng đá, chạy bộ, yoga, gym…- được trang bị laptop, các thiết bị công nghệ hiện đại trong quá trình làm việc- môi trường làm việc hiện đại, năng động, khuyến khích tối đa sự sáng tạo của nhân viên- văn phòng làm việc hạng a, không gian mở, tiêu chuẩn 5 sao\n",
      "\n",
      "yêu cầu ứng viên\n",
      "requirements- from 2-year experience as a data analyst- fluent in writing & speaking english- familiar with databases & cloud storage (google bigquery, snowflake…)- familiar with visualization tools (tableau, powerbi, looker…)- master of sql and python- having experience in 2 domains (mobile application) and (financial investment) is a great advantage- understand the data needs of different departments (marketing, product, finance…)- understand the scopes of data engineers, data scientists to collaborate and take the lead if needed- have a robust problem-solving mindset. be able to turn a simple question to become a comprehensive data dashboard that detects and solves a business problem- good communication skills. be able to deliver, present and explain the results in an effective way for both technical and non-technical parties\n",
      "quyền lợi\n",
      "benefits- competitive salary with annual salary reviewwork in malaysia: up to 2000 usd with allowanceswork in vietnam: up to 900 usd- an international working environment with friendly, creative colleagues from around the world- an excellent opportunity to grow your career. we encourage you to take the lead, initiate and make decisions- tuition fee sponsorship if you expect to become a data scientist or grow other data skills- enjoy birthday parties and frequent weekend parties and other team-building activities (depending on your work location)\n",
      "cách thức ứng tuyển\n",
      "\n",
      "hết hạn nộp đơn\n",
      "\n",
      "experience in data science and mlops\n",
      "great communication skills\n",
      "desired engineering skills:\n",
      "experience in scripting with sql, spark, r/ python.\n",
      "– possess logical thinking, detail-oriented, strong organizational skills, ability to multi-task and work independently under tight deadlines.\n",
      "– work experience as a data analyst is a plus.\n",
      "– work experience in working with distributed system is a plus.\n",
      "iii. benefits \n",
      "– competitive salary: up to $650/month (junior) or upto $2000/month (senior)\n",
      "(negotiable, and periodically reviewed based on your capacity).\n",
      "– truly cares about you and your experience at ghtk – rewards and promotions are available on special occasions.\n",
      "– attractive insurance package – you will be provided with a package of generali premium health insurance, along with other benefits in accordance with vietnam labour law: health insurance, social insurance,…\n",
      "– special and worthy welfare regimes – there are 12 days off per year, 13th-month salary, yearly kick-off & team-building events with various bonding activities at workplace.\n",
      "– amazing culture – our working environment is young and dynamic with many promotion opportunities, creating a sustainable career path.\n",
      "– opportunity to work with the best – we not only hire talents but also collaborative ones.\n",
      "– get maximum support to master operations knowledge with additional leadership skills to meet the job’s requirements.\n",
      "– be empowered, self-determined, and have enough space for self-development in a typical e-logistics environment.\n",
      "iv. other information\n",
      "– time of work: 9:00 am – 6:30 pm. from monday to friday and alternate saturdays.\n",
      "– address: ghtk building, 8 pham hung street, me tri ward, nam tu liem district, ha noi.\n",
      "v. how to apply\n",
      "– to apply for the data analyst position, please send us your cv to email: talent.acquisition@ghtk.co.\n",
      "– subject: da – your name.\n",
      "job requirements\n",
      "\n",
      "\n",
      "requirements/qualifications(must have): • qualifications in business administration/marketing/computer science. • have passion for data analytics, research or project management. • ability to organize & analyze large amount of data to arrive at actionable insights. • effective spoken and written communication skills (both english and vietnamese) with ability to manage multiple stakeholders’ expectations. • experience in excel & power point is required. • experience writing custom queries in sql or other sql-based languages is a plus. • willing and eager to learn. ability to adapt in a fast-moving environment in cross functional and cross-cultural teams. • strong ownership & self-motivated\n",
      "\n",
      "nan\n",
      "nan\n",
      "kinh nghiệm trong việc xây dựng các dashboard, trực quan hóa báo cáo sử dụng các phần mềm khác nhau như: microsoft power bi, tableau, google data studio, google analytics, …\n",
      "kiến thức về các giải pháp phân tích phổ biến như business intelligence và data warehousing\n",
      "có kinh nghiệm về sql queries để xây dựng bộ dữ liệu (dataset)\n",
      "kĩ năng đọc tài liệu tiếng anh và làm việc nhóm.\n",
      "kĩ năng xử lý vấn đề.\n",
      "\n",
      "chấp nhận sinh viên mới ra trường có nền tảng theo yêu cầu\n",
      "4. quyền lợi\n",
      "\n",
      "mức lương: thoả thuận theo năng lực\n",
      "môi trường làm việc đam mê, năng động, sáng tạo, hoà đồng\n",
      "chế độ đãi ngộ tốt\n",
      "thực hiện chế độ theo quy định nhà nước ngay khi kết thúc 02 tháng thử việc.\n",
      "đóng bhxh theo quy định nhà nước\n",
      "thưởng quý,\n",
      "experience enabled by our own technology ecosystem and operational infrastructure, we are setting the benchmark in online fashion & lifestyle in our markets, and our vision is to be the #1 online destination for fashion & lifestyle in growth markets.\n",
      "nan\n",
      "nan\n",
      "experience in the e-commerce industry.\n",
      "we are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\n",
      "i. job descriptions\n",
      "\n",
      "be responsible for strategizing and performing project management techniques to enhance business performance, works closely with stakeholders to perform business partnering, supporting, coordinating & advising\n",
      "comprehend the company r&r structure and collaborate with relevant teams.\n",
      "define, develop and implement the efficient business processes.\n",
      "follow up kpi tracking, measure & feedback\n",
      "analyze corporate & business situations as well as propose solution recommendations to make improvements;\n",
      "plan, design and implement an overall risk management process, prepare alternative options & action plans to decrease risk factors; propose recommendations to optimize company resources & work efficiency.\n",
      "using data for strategic planning, build up reporting system and management dashboard.\n",
      "\n",
      "ii. skill and experience\n",
      "\n",
      "bachelor‘s degree or above in business, finance, or economics or related fields;\n",
      "experiences in corporate development, business partnering, prioritize in the e-commerce or related industry.\n",
      "a deep understanding of business models, market and industry trends affecting the collaboration and productivity sector;\n",
      "excellent in researching, qualitative & quantitative analytical skills;\n",
      "ability to develop trusted relationships externally and internally;\n",
      "be scrappy and an effective cross-functional collaborator;\n",
      "a self-starter who has worked in a fast-paced, quickly evolving environment with multiple partners;\n",
      "have strong presentation and communication skills and the ability to change complex issues into structured frameworks and concrete plans.\n",
      "\n",
      "key competences\n",
      "\n",
      "have strong communication and interpersonal skills;\n",
      "have the ability to analyze business issues and deliver logical conclusions;\n",
      "familiar with data consolidation, process analysis & strategic planning;\n",
      "problem - solving;\n",
      "conflict resolution;\n",
      "hunger for knowledge & strive for continuous improvement.\n",
      "\n",
      "iii. why you will love joining us?\n",
      "for you to join\n",
      "\n",
      "\n",
      "\n",
      "financial well-being:\n",
      "kinh nghiệm cần thiết- có hơn 3 năm kinh nghiệm phát triển hệ thống- có kinh nghiệm về c ++, python, scala là một điểm cộng- có kinh nghiệm thao tác sql- người có hứng thú với công việc phân tích dữ liệu.\n",
      "ưu tiên- ứng viên có hơn 2 năm kinh nghiệm thiết kế hệ thống cơ bản- ứng viên có kinh nghiệm sử dụng dwh (gcp bigquery, redshift, v.v.)- ứng viên có kinh nghiệm sử dụng các công cụ phân tích tiếp thị đám mây công cộng như aws, gcp và azure- ứng viên có kinh nghiệm sử dụng công cụ kiểu như là bi- ứng viên có kinh nghiệm hỗ trợ khách hàng - ứng viên muốn tự tạo dữ liệu phân tích của riêng mình ngay từ đầu.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job detail\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job code\n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "position type\n",
      "\n",
      "full-time\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "career level\n",
      "\n",
      "technical / engineer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "education level\n",
      "\n",
      "diploma (3 years)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gender\n",
      "\n",
      "male / female\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "age\n",
      "\n",
      "26 - 40\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job categories\n",
      "\n",
      "\n",
      "it - software\n",
      "\n",
      ", \n",
      "\n",
      "interpreter/ translator (japanese)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "information\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "name:\n",
      "\n",
      "\n",
      "careerlink asia co., ltd.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "千葉県千葉市美浜区中瀬２丁目6番地1 wbgマリブイースト21階\n",
      "\n",
      ", \n",
      "\n",
      "\n",
      ", \n",
      "\n",
      "\n",
      ", \n",
      "\n",
      "japan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "application language:\n",
      "japanese\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "careerlink asia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "https://corp.careerlink.asia/\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "25 - 99 employees\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact: careerlink asia co., ltd.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "khách hàng của công ty careerlink là các công ty it\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "see more\n",
      "\n",
      "\n",
      "\n",
      "see less\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "other jobs from this company\n",
      "\n",
      "|\n",
      "\n",
      "see all\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "kỹ sư phát triển và quản lý dự án trên các nền tảng có quy mô lớn như aws, ci / cd, devops\n",
      "\n",
      "\n",
      "careerlink asia\n",
      "\n",
      "\n",
      "\n",
      "japan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nhân viên sale\n",
      "\n",
      "\n",
      "careerlink asia\n",
      "\n",
      "\n",
      "\n",
      "japan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nhân sự quản lý bộ phận\n",
      "\n",
      "\n",
      "careerlink asia\n",
      "\n",
      "\n",
      "\n",
      "japan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nhân viên lập kế hoạch kinh doanh\n",
      "\n",
      "\n",
      "careerlink asia\n",
      "\n",
      "\n",
      "\n",
      "japan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nhân viên bộ phận quản lý\n",
      "\n",
      "\n",
      "careerlink asia\n",
      "\n",
      "\n",
      "\n",
      "japan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tags\n",
      "\n",
      "\n",
      "\n",
      "japanese n2\n",
      "python developer\n",
      "back-end developer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "share\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "copied\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "manager, marketing strategy & analytics (bangkok-based, relocation provided)\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "bachelor's degree in computer science, software or computer engineering, applied math, physics, statistics, or a related field, preferredat least 3 years of hands-on working experience in data/software engineering in a highly scalable production environment2 years of experience developing data warehouses on snowflake platform, requiredgood knowledge of architecting large-scale data infrastructure in the cloud platform good knowledge of big data technologies like hadoop,hive,spark, redshift aws or other real-time streaminggood knowledge of server-side programming languages (preferably python) and golang.devops experience (devops or gitlab) delivering continuous improvementsdata visualization and dashboarding experience (power bi, tableau, etc.) \n",
      "nan\n",
      "kinh nghiệm lập trình với java hoặc python, sử dụng các bộ thư viện về khai phá dữ\n",
      "liệu, học máy, học sâu.\n",
      "– có kinh nghiệm làm việc với môi trường bigdata, các thuật toán phân tán sử dụng spark\n",
      "và mapreduce là một lợi thế.\n",
      "iii. quyền lợi\n",
      "– lương fresher đến senior: 500$ – 2000$\n",
      "job requirement\n",
      "\n",
      "\n",
      "bs/ms/phd in computer science, electrical engineering, or related technical field\n",
      "at least 3+ years of industry experience in developing ml systems\n",
      "strong programming skills in python\n",
      "proficiency manipulating big data with apache spark (pyspark)\n",
      "experience with leading machine learning product development on time-series data (sensor, iot devices, health/fitness tracking, audio, etc.)\n",
      "strong knowledge in software architecture design, debugging, source control management, testing, performance, scaling, and operations.\n",
      "experience and demonstrated capability to handle challenges with vague or abstract problem definition\n",
      "\n",
      "\n",
      "tagged as: apache spark, computer science, python\n",
      "experience\n",
      "\n",
      "\n",
      "etl architecture\n",
      "experiencebachelor’s degree with at least 3 years of related experienceexperience in pharmaceutical industry is preferredwell versed in microsoft excel, powerpoint and power biknowledge in sql server is preferredpossess strong analytical and communication skillsiqvia is a leading global provider of advanced analytics, technology solutions and clinical research services to the life sciences industry. we believe in pushing the boundaries of human science and data science to make the biggest impact possible – to help our customers create a healthier world. learn more at https://jobs.iqvia.com\n",
      "\n",
      "apply now\n",
      "save job\n",
      "remove saved job\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "no recently viewed jobs.  view all opportunities.\n",
      "\n",
      "\n",
      "explore location\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "share this job\n",
      "\n",
      "twitter\n",
      "linkedin\n",
      "facebook\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5 ways to grow your career\n",
      "fulfil your career aspirations at iqvia by unlocking access to these five development resources.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "a warm welcome\n",
      "gawel shares his recruitment experience and the warm welcome he received upon joining iqvia.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "how we work\n",
      "we understand life’s complexities so no matter the role, we strive to find the balance of work flexibility so you can succeed both professionally and personally.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "our benefits\n",
      "our integrated benefits programs are designed to meet individuals’ diverse and changing well-being needs.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan\n",
      "experience: proven practical experience with strong analytical skills and knowledge in the context of cloud. optimization and profound hyperscaler / public cloud knowledge is also helpful.\n",
      "\n",
      "experience for assigned customer segments:\n",
      "- define customer journey (stage/ step/ touchpoints/ related functions) based on internal process. it could be - - \n",
      "- end-to-end journey but usually specific parts of journey.\n",
      "- define the key metrics & questionnaire to measure the success of customer experience based on customer journey (nps, transactional nps, csat, ces, customer complaints, business metrics…).\n",
      "- coordinate with relevant departments to collect and track customer experience metrics across end-to-end journey.\n",
      "- regularly monitor the metrics to identify potential problematic touchpoints.\n",
      "- propose & conduct necessary qualitative & quantitative research to confirm customer journey, identify customer’s expectation, customer pain points, drop rate during detected journey then report key findings.\n",
      "- coordinate with process analyst & business stakeholders to define potential root causes for improvement solution design.\n",
      "- recommend & coordinate in enhancement activities (ux/ui revision, product/process improvement, people training,…).\n",
      "\n",
      "2. drive customer centricity culture activities:\n",
      "organize activities for exco/ head/ employee to experience company product & services.\n",
      "coordinate with hr & related functions to organize activities and contests to promote customer centric culture and mindset within the organization.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "nan\n",
      "yêu cầu công việc:\n",
      " 1/  trình độ học vấn\n",
      "\n",
      "tốt nghiệp từ đại học trở lên chuyên ngành cntt, điện tử viễn thông hoặc các chuyên ngành tương đương\n",
      "\n",
      "2/ kiến thức/ chuyên môn có liên quan\n",
      "\n",
      "hiểu biết về nghiệp vụ ngân hàng là một lợi thế\n",
      "kiến thức và kỹ năng thực tế về thiết kế và truy vấn cơ sở dữ liệu sql server, sql, oracle,...\n",
      "có kiến thức về tiêu chuẩn dữ liệu của các miền dữ liệu trong lĩnh vực ngân hàng như miền dữ liệu khách hàng, sản phẩm tiền gửi, sản phẩm tiền vay…\n",
      "yêu cầu thành thạo ngôn ngữ sql/plsql, sql server\n",
      "\n",
      "3/  các kinh nghiệm liên quan\n",
      "\n",
      "có ít nhất 1 năm kinh nghiệm về phân tích dữ liệu / quản trị dữ liệu / kiểm toán cntt / quản lý siêu dữ liệu.\n",
      "experience and revenue performance by deep segmentation analysis and proactively develop a timely optimisation plan to maximise sellers' success and revenue performance.possess a hybrid user-focused & data-informed mindset. actively conduct in-depth analysis with big amount of data, research market trends and frequently talk to customers to identify sellers' problems/opportunities; while at the same time work closely with relevant teams to deliver appropriate solutions.work closely with product team to develop product roadmap and play an active role in product development process with product team - from users discovery to solutions ideation, results analysis and optimisation.research on new monetisation schemes and regularly carry out experiments to test new premium packages/features to optimise users’ effectiveness as well as spending.work closely with the go to market specialist to maximise adoption of the product offerings from the target segments.responsible for analysis of sales performance and product/ service effectiveness metrics of the business owner segment who is a reliable seller and qualified by the commercial team.prepare weekly, \n",
      "experienced data scientists and machine learning engineers to build/improve large-scale learning applications (e.g., demographic prediction, churn detection, email campaign optimization, user segmentation, recommender systems, ad optimization, etc).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "work closely with the it team to maintain and improve existing data science applications.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "produce comprehensive and clear documentation\n",
      "\n",
      "\n",
      "\n",
      "experience, and creating more value.\n",
      " \n",
      "yêu cầu ứng viên\n",
      "bachelor's degree in computer science or a related field.4+ years of experience in backend development or data engineering, etl development, or a similar role.experience working with microservice architecture.proficiency one of langue in .net, java, or python for data processing and scripting.experience working with relational databases, such as one of the database types: postgresql, mysql, oracle, or ms sql server.knowledge of working with document databases, such as one the database types: elasticsearch, redis, mongodb, or apache solr.familiarity with data warehousing concepts and cloud-based data storage solutions (e.g., aws, gcp, azure).strong problem-solving skills, attention to detail, and the ability to work independently and as part of a team.excellent communication and collaboration skills, especially in agile culture environment.﻿nice to have:\n",
      "experience (3+ years) in business intelligence, data analysis, or a related role, with a track record of successful team leadership.\n",
      "strong knowledge of tableau and able to develop insightful dashboards and reports that drive business decision making and outcomes;\n",
      "intermediate to advanced database, t-sql, data modelling, etl (ssis, azure data factory …) skills;\n",
      "intermediate powerpoint;\n",
      "experience in python, c#, vba is a plus\n",
      "understand data models, database design development, data mining and segmentation techniques.\n",
      "\n",
      "what we offer: we treat people fairly and with dignity, keeping a healthy perspective about life and work and fostering a positive and enjoyable work environment with appealing benefits as below:\n",
      "\n",
      "a competitive monthly salary based on your ability\n",
      "13th month tet bonus & bi-annual performance bonus\n",
      "annual salary review\n",
      "attractive employee awards: employee of year, semi-annual outstanding employee\n",
      "social insurance and healthcare insurance upon vietnam labor code\n",
      "pti insurance package, and annual health check\n",
      "an english-speaking environment\n",
      "an open culture that spurs creativity, innovation, and inclusivity\n",
      "a variety of training courses for your career development\n",
      "diverse activities to foster relationships, including company trips, year-end party, employees’ birthdays\n",
      "an open-space office, a cafeteria, and a range of modern equipment\n",
      "other allowance from referrals and special occasions (weddings, seniority, and new-born baby)\n",
      "\n",
      "work location: our office is located at 9th floor, ree tower, 9 doan van bo, ward 13, district 4\n",
      "working hours\n",
      "working hours can be decided flexibly, however, for the 1st several months it is:\n",
      "mon – fri: 3pm – 6pm (office) & 9pm – 2am (wfh)\n",
      "afterwards, fully remote or shifts like 7pm – 4am or 9pm – 6am can be considered.\n",
      "nan\n",
      "kinh nghiệm 1 năm\n",
      "job requirementbachelor’s degree or above in data science, computer science, information technology,\n",
      "job requirements:involved in the full cycle of data science product development + deployment, with strong presence in the project.substantial tech experience in all tech aspects of data science work, eda, modelling, testing, bau monitoring.experience with fmcgexperience working with/managing 3rd partiesworking with partners from tech product/platform (ms azure, gcp etc)research for new methodology (from application point of view), writing white papers, product evaluationunilever is an organisation committed to equity, inclusion and diversity to drive our business results and create a better future, every day, for our diverse employees, global consumers, partners, and communities. we believe a diverse workforce allows us to match our growth ambitions and drive inclusion across the business. at unilever we are interested in every individual bringing their ‘whole self’ to work and this includes you! thus if you require any support or access requirements, we encourage you to advise us at the time of your application so that we can support you through your recruitment journey.\n",
      "nan\n",
      "nan\n",
      "experience in edw bi development, including microsoft sql server reporting services (ssrs) and integration services (ssis).experience in building self-serve reporting, including parameterized reports with drill-down capabilitiesthe environment consists of microsoft sql server databases (versions 2012, 2014 and 2016).experience with t-sql is required (writing optimizing stored procedures, packages and queries).ability to work independently and good team playergood english communication skillhandle multiple assignmentadditional information\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "yêu cầu công việc\n",
      "\n",
      "knowledge and experience:\n",
      "bachelor’s degree in computer science or equivalent with a minimum of\n",
      "kinh nghiệm hơn 04 năm về chuyên môn phân tích hoạt động kinh doanh. ưu tiên ứng viên có kinh nghiệm làm việc trong mô hình chuỗi nhà hàng f&b, chuỗi cửa hàng bán lẻ retails, fmcg, …;\n",
      "tổ chức & phân tích dữ liệu tốt. sử dụng tốt các công cụ về dữ liệu và phân tích dữ liệu (power bi, power query, data studio, …);\n",
      "có kỹ năng thực hiện phân tích và tổ chức các báo cáo về tài chính, kết quả hoạt động kinh doanh chính xác và có thể đưa ra các nhìn nhận, đánh giá và góp ý hiệu quả;\n",
      "tính cách trung thực, ý thức bảo mật thông tin số liệu tốt;\n",
      "tư duy tốt về kinh doanh và nắm bắt tốt xu hướng kinh doanh của ngành/ thị trường;\n",
      "thái độ tích cực và có tinh thần đồng đội tốt. tinh thần trách nhiệm cao và chịu được áp lực công việc.\n",
      "\n",
      "phúc lợi\n",
      "\n",
      "lương thỏa thuận theo năng lực;\n",
      "thời gian làm việc: thứ 2 - thứ 6, 8h30 - 17h30;\n",
      "công ty cung cấp đầy đủ trang thiết bị làm việc cần thiết như desktop / laptop;\n",
      "lương tháng 13 + thưởng theo kết quả hoạt động kinh doanh;\n",
      "giảm giá trên tổng hóa đơn khi dùng bữa tại các nhà hàng thuộc hệ thống của golden gate;\n",
      "môi trường trẻ trung, năng động. nhiều cơ hội phát triển;\n",
      "công ty thường xuyên có các hoạt động: du lịch hằng năm, team building, tiệc cuối năm.\n",
      "\n",
      "job requirementprofessional skills:good communication, understanding customer psychology;ability to work under pressure and finish on time;proficient in ms word, excel, powerpoint;proficient in sql or python is a great advantage;planning & strategy skills,\n",
      "nan\n",
      "nan\n",
      "experience\n",
      "good knowledge of at least one of the programming languages: java or c++\n",
      "strong understanding of algorithms and data structures\n",
      "good understanding of software-hardware performance\n",
      "strong knowledge and experience of software system design\n",
      "ability to understand data - thus, data analytical skills, designing systems based on understanding of data, experience with big data systems\n",
      "\n",
      "preferred qualifications:\n",
      "\n",
      "deep enough understanding of problems from business and product/user perspective; ability to adjust technical solution based on this\n",
      "ability to present things to top management in a clear and concise manner\n",
      "basic understanding of machine learning\n",
      "strong team player with ability to grow capacity of the team via development of team members\n",
      "ability to work smoothly with other stakeholders - product managers, project managers\n",
      "business oriented mindset\n",
      "\n",
      "soft skills:\n",
      "\n",
      "able to analytical thinking and result-orientation\n",
      "good english skills\n",
      "creative thinker and proactive problem solver\n",
      "good communication in both verbal and written\n",
      "well understanding of organizational structure and culture\n",
      "good organizational and time management skills;\n",
      "ability to be adapt quickly to changes\n",
      "\n",
      "---\n",
      "further information will be discussed in the interview!interested candidates, please\n",
      "job requirementmust-have:high proficiency in data management, data analysis and predictive modeling in pythonmachine learning / deep learning work experienceexperience integrating ml models into production systemsgreat-to-have:education or experience in physics or mechanical engineeringnice-to-have:ml ops (aws, k8s, helm)education: master’s degree or higher in computer science, computer engineering, physics or other science/engineering disciplineswhat's on offerawesome colleagueswe will match exceptional talent with exceptional compensation (salary and equity)\n",
      "nan\n",
      "kinh nghiệm chuyên môn, kĩ năng của các thành viên; tư vấn và hỗ trợ kịp thời cho các thành viên khi có vướng mắc hoặc phương án xử lý tối ưu trong nhóm;\n",
      "7. khác\n",
      "- đưa ra các đề xuất nhằm nâng cao hiệu quả công việc. thực hiện các công việc khác theo sự phân công của trưởng phòng.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "yêu cầu công việc\n",
      "\n",
      "trình độ đại học trở lên chuyên ngành toán – tin, công nghệ thông tin, hệ thống thông tin kinh tế\n",
      "có ít nhất 1 năm kinh nghiệm trong ngành cntt, phân tích dữ liệu\n",
      "có khả năng truy vấn, truy xuất dữ liệu (sql, oracle)\n",
      "kỹ năng báo cáo, phân tích sử dụng đa công cụ (excel, tableau, power bi,…)\n",
      "\n",
      "có khả năng phân tích dữ liệu bằng các ngôn ngữ python, r,..)\n",
      "\n",
      "có kiến thức tốt về toán logic, toán thống kê, quản trị kho dữ liệu\n",
      "có kỹ năng làm việc nhóm và giải quyết vấn đề\n",
      "kỹ năng quản lý tổ chức và quản lý công việc\n",
      "kỹ năng quản lý nhân sự\n",
      "kỹ năng đánh giá, phân tích\n",
      "\n",
      "\n",
      "job requirements:\n",
      "b.sc. engineering, computer science, data science, or related majors.solid experience in data analytics specializing in customer data use-cases for a b2c business model: retail, banking, fintech, services, f&b…experiences with supporting business stakeholders with their data-driven marketing/product/cx optimization projects are an advantage\n",
      "experience on the engagement & loyalty mobile app, optimizing analytics efficiency and cost, and optimizing individual department operation\n",
      "work closely with other departments and stakeholders, including ceo, business, product, finance, marketing, tech, and senior management, to ensure that data-related goals and initiatives are aligned with the organization’s overall strategy\n",
      "\n",
      "strategy & analytics:\n",
      "\n",
      "lead the data analytics and data warehousing departments in strategy development with regard to the collection, manipulation, and analysis of data for various business functions/departments such as marketing, sales, and operations, among others\n",
      "endeavor to create new data-driven approaches for the purpose of generating business insights through data analytics, information visualization, and addressing unanswered business issues in a proactive manner.lead the team in building data governance framework to provide trusted data across functions\n",
      "in-charge of strategic products including: customer segmentation, personalization engine, anti-fraud engine etc.\n",
      "keeping up with industry trends and best practices, applying new technologies and techniques to enhance the organization’s data strategy\n",
      "\n",
      "data management:\n",
      "oversee and participate in data management activities, including:\n",
      "\n",
      "define, build, and manage the organization’s data architecture, including data models, data flows, data integration patterns, data pipelines, data processing, data warehouses, data marts…\n",
      "collect and centralize data from various sources, including internal systems, external partners, and third-party providers.\n",
      "ensure data privacy and security with appropriate policies and security measures.\n",
      "ensure data quality and accuracy with appropriate data quality checks and controls are in place.\n",
      "manage data throughout its lifecycle, from creation to retirement, to optimize its value and minimize risks.\n",
      "\n",
      "\n",
      "nan\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "• trình độ đại học trở lên, học chuyên ngành công nghệ thông tin, hệ thống thông tin hoặc các chuyên ngành liên quan tại các trường đại học công nghệ, đại học công nghiệp, học viện bưu chính viễn thông, đại học bách khoa v,v...• có kinh nghiệm sử dụng ngôn ngữ lập trình python• có kinh nghiệm sử dụng sql• có hiểu biết về elasticsearch, mongodb là một lợi thế• có hiểu biết về airflow, spark là một lợi thế• có kĩ năng làm việc nhóm và độc lập.• nhanh nhẹn, có khả năng tự học tốt và có tinh thần trách nhiệm cao.\n",
      "quyền lợi\n",
      "• nhân viên lương cứng 7 - 12 triệu theo năng lực.• sau khi ký hợp đồng chính thức sẽ được hưởng chế độ thưởng theo quy định công ty.nghỉ phép 12 ngày/năm, nghỉ ốm/nghỉ chế độ thai sản/hiếu hỉ… theo quy định pháp luật lao động, bảo hiểm xã hội• du lịch hàng năm, teambuilding, event.• được tài trợ, tham gia các khóa đào tạo kỹ năng, chuyên môn hàng năm, thi lấy chứng chỉ để phục vụ cho công việc.• review đánh giá công việc 2 lần/ năm;• có khả năng phát triển bản thân, định hướng phát triển công việc lâu dài;• môi trường trẻ, năng động, chuyên nghiệp, được khuyến khích sáng tạo và phát triển các ý tưởng mới, sếp trẻ tâm lý, đồng nghiệp thân thiện, văn hóa trao đổi thẳng thắn, cởi mở trên tinh thần hỗ trợ cùng phát triển;• học hỏi kinh nghiệm trực tiếp từ các senior, chuyên gia giàu kinh nghiệm;\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 07/06/2023\n",
      "\n",
      "\n",
      "\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "kinh nghiệm tại vị trí tương đương hoặc kế toán/kiểm toán / have 1 or 2 years of experience in similar position or accounting/auditing.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job detail\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "position type\n",
      "\n",
      "full-time\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "career level\n",
      "\n",
      "staff\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "education level\n",
      "\n",
      "bachelor's degree\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gender\n",
      "\n",
      "male / female\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job categories\n",
      "\n",
      "\n",
      "accounting / audit\n",
      "\n",
      ", \n",
      "\n",
      "finance / investment\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "information\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "name:\n",
      "\n",
      "\n",
      "hcns\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "18 đại lộ bình dương, vĩnh phú\n",
      "\n",
      ", \n",
      "\n",
      "thuan an city\n",
      "\n",
      ", \n",
      "\n",
      "binh duong\n",
      "\n",
      ", \n",
      "\n",
      "viet nam\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- các ứng viên quan tâm vui lòng gửi hồ sơ trực tuyến, gửi kèm file hoặc trực tiếp đến tại công ty.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "application language:\n",
      "vietnamese\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "công ty cổ phần bệnh viện đa khoa quốc tế hạnh phúc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "http://www.hanhphuchospital.com\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "500 - 999 employees\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact: hcns\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bệnh viện quốc tế hạnh phúc cung cấp các tiện nghi và dịch vụ y tế toàn diện trong lĩnh vực chăm sóc sức khỏe với trọng tâm là ngành sản-phụ khoa và nhi khoa.\n",
      "phương châm của hạnh phúc là \"đón mừng cuộc sống\" phản ánh chính xác tinh thần các dịch vụ mà chúng tôi cung cấp.\n",
      "chúng tôi đang tìm kiếm các cá nhân năng động để cùng chia sẻ hoài bão và là một phần của hạnh phúc.\n",
      "gia nhập với chúng tôi, các bạn sẽ có được:\n",
      "- môi trường làm việc thử thách, năng động, chuyên nghiệp\n",
      "- đào tạo phù hợp với yêu cầu công tác\n",
      "- thu nhập hấp dẫn tương xứng với khả năng làm việc\n",
      "- công việc ổn định và cơ hội thăng tiến trong nghề nghiệp\n",
      "- có xe đưa đón nhân viên từ tp hồ chí minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "see more\n",
      "\n",
      "\n",
      "\n",
      "see less\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "other jobs from this company\n",
      "\n",
      "|\n",
      "\n",
      "see all\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[hcm] finance analyst\n",
      "\n",
      "\n",
      "công ty cổ phần bệnh viện đa khoa quốc tế hạnh phúc\n",
      "\n",
      "\n",
      "\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "chuyên viên pháp lý cao cấp\n",
      "\n",
      "\n",
      "công ty cổ phần bệnh viện đa khoa quốc tế hạnh phúc\n",
      "\n",
      "\n",
      "\n",
      "binh duong\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "work location\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "18 đại lộ bình dương, vĩnh phú, thuan an city, binh duong\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tags\n",
      "\n",
      "\n",
      "\n",
      "thuan an town\n",
      "finance\n",
      "phân tích tài chính\n",
      "finance analyst\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "share\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "copied\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan\n",
      "experienced engineering manager to join the data engineering team. at the wikimedia foundation, we operate the world’s largest collaborative project: a top ten website, reaching a billion people globally every month, while incorporating the values of privacy, transparency and community that are so important to our users.\n",
      "working closely with other technology and product teams, as well as our community of contributors and readers, you will help deliver the next generation of data usage, analysis and access across all wikimedia projects.\n",
      "this role is responsible for key data engineering initiatives spanning our work in product analytics, machine learning and search.\n",
      "nan\n",
      "yêu cầu công việc\n",
      "\n",
      "\n",
      "at least 2+ years using linux os, bash script\n",
      "familiar with\n",
      "yêu cầu ứng viên\n",
      "6 months experience using awsexperience designing and building web environments on aws, which includes working with services like (ec2, s3, route53, lambda, cloudwatch,…)experience building and maintaining cloud-native applicationsa solid background in linux/unix and windows server system administrationexperience using devops tools in a cloud environment, such as ansible, artifactory, docker, github, jenkins, kubernetes, maven, and sonar qubeexperience using monitoring solutions like cloudwatch, zabbix, grafanaan understanding of writing infrastructure-as-code (iac), using tools like cloudformation or terraformknowledge of one or more of the most-used programming languages like python, bash shell, power shell\n",
      "quyền lợi\n",
      "highly competitive salary and bonus, plus several additional benefitsearnings up to 13 months salary/year (including salary and bonus)consider periodic salary increasesopportunity to work on challenging projectsjoin insurance according to vietnamese labor law (social insurance, health insurance, unemployment insurance)\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 24/06/2023\n",
      "\n",
      "\n",
      "\n",
      "qualificationsbachelor’s degree in accounting/finance/business informaticsat least 4 years in same or similar roleacquire strong analytical (quantitative as well as qualitative) skills including building models, prior data miningfamiliar with microsoft excel, power bi, sap and all other financial systemsself-starter with the ability to streamline functions and passion to learn and growmust possess excellent communication and presentation skills in english and vietnamese, and be comfortable interacting with executive-level managementwork and collaborate well with team-matesadditional informationwhy\n",
      "nan\n",
      "nan\n",
      "experience in the e-commerce industry.we are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end-to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.mô tả công việccoordinate, analyze daily, weekly and monthly reports on operational activities for the management team (excel, power bi..)assist in analyzing cost related reports & find opportunities to minimize/exploit costs;monthly analyze p&l and follow-up actual results in comparison with budget/targetother tasks as assigned by direct managers.\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "experience\n",
      "\n",
      "qualifications/experience:\n",
      "5+ years’ experience as a data analyst or business intelligence analyst.\n",
      "proficient use of microsoft sql.\n",
      "proficient use of power bi.\n",
      "perfect english skills.\n",
      "have a good understanding of the data warehouse\n",
      "excellent presentation and data visualization skills.\n",
      "excellent communication skills.\n",
      "degree in data science / data analysis / mathematics is a plus.\n",
      "knowledge about the process of a production company is a plus.\n",
      "has worked with an investment company is a plus\n",
      "worked in us market or used to study in us is a plus\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "analyst/senior analyst (flights team, bangkok-based, relocation provided)\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "nan\n",
      "experience as a cost accountant, cost analyst, accountant or similar role\n",
      "experience in modern data platforms, its components and their purpose in the overall ecosystem and architecture\n",
      "apply your knowledge and experience to engineer data from its raw elements from source systems into a useable format for business to derive insights\n",
      "apply your experience in modern data modelling techniques\n",
      "apply the right mindset, attitude and willingness to learn, grow not only one self, but also help grow others.\n",
      "nan\n",
      "nan\n",
      "yêu cầu công việc\n",
      "\n",
      "trình độ học vấn: tốt nghiệp đai học chuyên ngành công nghệ thông tin, khoa học máy tính…\n",
      "kinh nghiệm:\n",
      "• ít nhất 1 năm kinh nghiệm ở vị trí tương đương\n",
      "• có kỹ năng viết sql, pl/sql\n",
      "• có kiến thức cơ bản về hệ quản trị cơ sở dữ liệu: oracle, sql server, my sql…\n",
      "• nắm vững kiến thức về: data warehouse, oracle database, bigdata... thành thạo pl/sql và các công cụ tích hợp dữ liệu elt\n",
      "• có khả năng đọc hiểu tài liệu tiếng anh chuyên ngành\n",
      "\n",
      "experience in work/internship/project is preferred\n",
      "detail-oriented\n",
      "\n",
      "** following will be plus points:\n",
      "\n",
      "experience with linux\n",
      "solid programming skills in python or c++\n",
      "benefitssalary range: up to usd 3,500 gros\n",
      "nan\n",
      "nan\n",
      "experience in developing ml systems\n",
      "strong programming skills in python\n",
      "proficiency in manipulating big data with apache spark (pyspark)\n",
      "experience with leading machine learning product development on time-series data (sensor, iot devices, health/fitness tracking, audio, etc.)\n",
      "strong knowledge of software architecture design, debugging, source control management, \n",
      "yêu cầu ứng viên\n",
      "- sinh viên năm 3, năm 4 khối ngành kinh tế hoặc cntt\n",
      "- tuy duy tốt, nhanh nhạy về số liệu\n",
      "- có khả năng đọc hiểu và phân tích dữ liệu, đưa ra kết luận và giải pháp thông qua các báo cáo\n",
      "- có khả năng làm việc độc lập và trong nhóm, cẩn thận và chính xác trong công việc.\n",
      "- có khả năng giao tiếp tốt, đưa ra ý kiến và thuyết phục được người khác.\n",
      "- có kinh nghiệm làm việc với game là một lợi thế.\n",
      "quyền lợi\n",
      "- hỗ trợ lương thực tập 4.000.000 vnđ/ tháng tùy theo năng lực\n",
      "- thời gian thực tập 2 - 4 tháng - tùy vào năng lực của ứng viên\n",
      "- cam kết cơ hội trở thành nhân viên chính thức sau 2 - 4 tháng thực tập nếu đáp ứng đủ tiêu chí\n",
      "- môi trường làm việc vô cùng thoải mái, sáng tạo, năng động.\n",
      "- được hỗ trợ dấu thực tập nếu ứng viên cần\n",
      "- được tham gia các dự án đang chạy của công ty\n",
      "- được cầm tay chỉ việc, đào tạo kỹ năng và kinh nghiệm làm việc thực tế\n",
      "- hưởng đầy đủ các trợ cấp khác như đi lại, gửi xe như 1 nhân viên chính thức\n",
      "- ăn uống miễn phí đồ ăn, thức uống trong văn phòng\n",
      "- thưởng liên tục: tết âm, tết dương, 8/3, 30/4-1/5, 1/6, trung thu, giữa năm, 2/9, 20/10, giáng sinh.\n",
      "- thời gian làm việc: 7h/ngày (sáng: 9:00 - 12:00, chiều: 13:00 - 17:30, nghỉ giữa chiều 15:00 - 15:30)\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 30/06/2023\n",
      "\n",
      "\n",
      "\n",
      "yêu cầu ứng viêntốt nghiệp đại học trở lên chuyên ngành tài chính, kiểm toán, kinh tế,…có ít nhất 2 năm kinh nghiệm làm công việc tương tự tại hoặc làm cho các công ty kiểm toán (big4).đã học hoặc hoàn thành các chứng chỉ về lĩnh vực tài chính, kiểm toán như: acca, cpa, cfa là lợi thế.tiếng anh giao tiếp khá, nắm được tiếng anh chuyên ngành.nhanh nhẹn, chăm chỉ, tinh thần trách nhiệm cao trong công việc.\n",
      "nan\n",
      "yêu cầu công việc…;- lương tháng 13 bằng từ 1-3 tháng lương thỏa thuận.thưởng:- thưởng định kỳ theo kết quả kinh doanh chung của tập đoàn theo quý và theo năm;- thưởng đột xuất theo chương trình chung của tập đoàn;- thưởng đột xuất theo thành tích đặc biệt và hoặc các sáng kiến cải tiến trong công việc.chế độ đãi ngộ khác:- được hưởng đầy đủ các chế độ phúc lợi cơ bản theo quy định của nhà nước ngay sau kết thúc thời gian thử việc bao gồm bhxh, bhyt, bhtn, chế độ khám sức khỏe định kỳ...;- được hưởng đầy đủ các chế độ phúc lợi động viên cho bản thân và người thân theo quy định chung của tập đoàn như chế độ thăm hỏi; mừng các ngày lễ trong năm; mừng ngày thành lập tập đoàn; hiếu - hỉ…;- được hưởng đầy đủ các chế độ phúc lợi nâng cao (dành cho cấp quản lý) như: mừng danh hiệu quản lý cuối năm, bảo hiểm sức khỏe cho bản thân và người thân; chăm sóc sức khỏe (tập thể thao, tập gym…); hỗ trợ đi lại; hỗ trợ mua sắm và sử dụng dịch vụ ưu đãi;- được tham gia các hoạt động ngoại khóa, văn hóa đoàn thể hấp dẫn dành cho cbnv;- môi trường làm việc chuyên nghiệp, nhân văn, văn hóa và thân thiện.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 30/06/2023\n",
      "\n",
      "\n",
      "\n",
      "experience (stored procedures, function, trigger…) and understanding of data warehousing and data modeling;\n",
      "experienced with business intelligence tools such as microsoft bi stack (e.g., ssis, ssrs, and ssas, azure data warehouse), tableau;\n",
      "intermediate c# or other programming languages;\n",
      "advanced knowledge of data systems and the ability to transform and shape large usable data sets.\n",
      "\n",
      "work behavior\n",
      "\n",
      "ability to lead, plan and manage in an entrepreneurial, team-oriented environment;\n",
      "highly organized with strong project management skills, and drive to meet organizational objectives; ability to manage multiple projects on interrelated timelines;\n",
      "strong written and verbal communication skills;\n",
      "demonstrate experience in getting things done in dynamic, entrepreneurial environment;\n",
      "demonstrate a high attention-to-detail in the analysis and reporting of data.\n",
      "\n",
      "what we offer: we treat people fairly and with dignity, keeping a healthy perspective about life and work and fostering a positive and enjoyable work environment with appealing benefits as below:\n",
      "\n",
      "a competitive monthly salary based on your ability\n",
      "13th month tet bonus & bi-annual performance bonus\n",
      "annual salary review\n",
      "attractive employee awards: employee of year, semi-annual outstanding employee\n",
      "social insurance and healthcare insurance upon vietnam labor code\n",
      "pvi insurance package, and annual health check\n",
      "an english-speaking environment\n",
      "an open culture that spurs creativity, innovation, and inclusivity\n",
      "a variety of training courses for your career development\n",
      "diverse activities to foster relationships, including company trips, year-end party, employees’ birthdays\n",
      "an open-space office, a cafeteria, and a range of modern equipment\n",
      "other allowance from referrals and special occasions (weddings, seniority, and new-born baby)\n",
      "\n",
      "work location\n",
      "ree tower, 9 doan van bo street, ward 13, district 4, hcmc\n",
      "working hours\n",
      "mon – fri: 3pm – 6pm (office) & 9pm – 2am (wfh)\n",
      "nan\n",
      "nan\n",
      "yêu cầu công việc- tốt nghiệp đại học các ngành về phân tích thông tin, toán, khoa học máy tính, thống kê.- có ít nhất 01 năm kinh nghiệm trong lĩnh vực data analyst hoặc business analyst- kỹ năng phân tích tốt.- có tư duy logic có hệ thống, có kỹ năng giải quyết vấn đề, làm việc có tổ chức và tư duy dựa trên dữ liệu- yêu thích tìm hiểu các kỹ thuật khai thác dữ liệu mới cũng như tìm hiểu các điểm nổi bật của dữ liệu- thành thạo ngôn ngữ lập trình phân tích dữ liệu: sql hoặc r hoặc python.quyền lợi- thu nhập từ 25trđ/tháng trở lên- thưởng tháng lương 13 cùng chế độ phúc lợi hấp dẫn- hưởng đầy đủ các chế độ theo luật lao động: nghỉ lễ tết, nghỉ phép, bhxh- tăng lương định kỳ hàng năm và theo hiệu quả công việc- tham gia bảo hiểm sức khỏe- ưu đãi mua hàng nội bộthông tin liên hệ công ty:ms giang– phòng hành chính nhân sựđịa chỉ: tầng 17, tòa nhà 319 bqp, số 63 lê văn lương, phường trung hòa, cầu giấy, hà nội.email: hanhchinhnhansu@elmich.vnsđt:0931.569.633\n",
      "nan\n",
      "experienced data scientist to:\n",
      "\n",
      "build ekyc components (face recognition, ocr, object detection, fraud detection), using state-of-the-art methods\n",
      "develop ml models and provide solutions for acquisition, verification, validation, and fraud detection of user data\n",
      "\n",
      "requirements\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bs or ms in computer science or related fields\n",
      "2+ years of experience in data science and mlops\n",
      "must be proficient in software design and software development.\n",
      "must be proficient in python, scripting language. experience with other programming languages (c++, java, javascript ...) is a plus\n",
      "must be proficient in linux system, version control system (git), virtualization and sw packaging tool (docker)\n",
      "great communication skills\n",
      "desired skills:\n",
      "\n",
      "\n",
      "\n",
      "experience with ml framework: tensorflow, pytorch, mxnet, onnx.\n",
      "experience with managing data science and computer vision toolkit, such as jupyterhub, opencv... is a plus\n",
      "experience with working with databases and query language is a plus.\n",
      "familiar with mlops concept and toolkit is a plus\n",
      "basic understanding of machine learning techniques and algorithms\n",
      "bs/ms in computer science with focus on machine learning is a plus\n",
      "\n",
      "\n",
      "what we offer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "competitive compensation package, including 13th-month salary and performance bonuses\n",
      "comprehensive health care coverage for you and your dependents\n",
      "generous leave policies, including annual leave, sick leave, and flexible work hours\n",
      "convenient central district 1 office location, next to a future metro station\n",
      "onsite lunch with multiple options, including vegetarian\n",
      "grab for work allowance and fully equipped workstations\n",
      "fun and engaging team building activities, sponsored sports clubs, and happy hour every thursday\n",
      "unlimited free coffee, tea, snacks, and fruit to keep you energized\n",
      "an opportunity to make a social impact by helping to democratize credit access in emerging markets.\n",
      "\n",
      "about us\n",
      "\n",
      "\n",
      "\n",
      "we are an ai fintech company specialized in assessing credit profiles of consumers in emerging markets combining pioneering ai with large alternative data sources. in 2020 we reached our ambitious milestone of credit profiling 1 billion consumers spanning 4 countries - vietnam, indonesia, india & the philippines - and building a platform for the wider industry and the financial services industry, in particular, to provide the \"un & under\" served access to credit. at the core of this initiative has been our strict and unwavering adherence to the norms of consumer data privacy and consumer data rights.\n",
      "but we're not satisfied as we embark on the next leg of our journey to deliver 100 million credit lines to consumers in the markets where we operate. although this goal is ambitious, we truly believe that by harnessing the power of ai & big data we can deliver financial access at an unprecedented scale.\n",
      "as a firm, we're audacious problem-solvers motivated by our impact on society. we deeply espouse the values of ownership - of our actions and initiatives, integrity in all we do, and agility in execution.\n",
      "we place great importance on doing what is right, what is best, and what is innovative. if you are smart, driven, and want to make a difference in the world with the most advance and fascinating technology, come join our team. we can satisfy your desire to explore new territory and give you the runway to really make an impact.\n",
      "experience and user interface design.\n",
      "stay up-to-date with the latest industry trends, technologies, and best practices related to self-service bi and saas solutions.\n",
      "\n",
      "experience range: from 3 years\n",
      "job location: hanoi, hcmc\n",
      "duty & responsibilities:\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tthis is a development project. as a hadoop big data engineer, you will operate and monitor scalable and resilient data platform based on hadoop ecosystem to address the business requirements: \n",
      "– engineer reliable data pipelines for sourcing, processing, transforming, enriching and storing data in different ways, using data platform infrastructure effectively\n",
      "– ingest and transform data sets from a variety of data sources\n",
      "– focus on ingesting, storing, processing, and analyzing large datasets\n",
      "– create scalable, high-performance web services for tracking data\n",
      "– using java (spring boot framework) for development tasks\n",
      "\n",
      "requirements: \n",
      "\t\t\t\t\t\t\t\t\t\t\tmust have requirements:\n",
      "– must have 3+ years of experience at a similar role\n",
      "– having hands on experience in hadoop ecosystem (on-prem) including spark, hdfs, mapreduce, yarn, …\n",
      "– good in programming language python.\n",
      "– experience in monitoring large-scale data processing job (batch-processing, stream processing)\n",
      "– having a background of software developing on java spring boot\n",
      "good to have:\n",
      "– experience with hadoop distributions such as cloudera, hortonworks, comparison and feasibility\n",
      "– experience with data warehouse and data management: data quality, data integration\n",
      "– experience in etl, sql and nosql database\n",
      "– experience with sre, patching & automation: kubernetes or docker & containerization\n",
      "– experience working with big data in a cloud environment\n",
      "– experience in data api\n",
      "– good to have architecture knowledge or experience\n",
      "preferred language for application: english\n",
      "\n",
      "nan\n",
      "nan\n",
      "yêu cầu công việc\n",
      "\n",
      "individual skills\n",
      "good communication skill and business understanding with abilities to drive cross-functional team\n",
      "proactive problem solver, eye for detail, process driven\n",
      "agile trained, can elicit user stories, draw process diagrams\n",
      "data modelling experience\n",
      "good understanding of data management - data lineage, meta data, data quality, data governance\n",
      "analytics experience\n",
      "1.5+ years experience in similar role, experience in distribution / last mile delivery/ fulfillment services is preferable\n",
      "sql and data analysis\n",
      "strong analytical skills with the ability to collect, organize, analyze, model, and interpret data\n",
      "experience with an etl framework like airflow, nifi\n",
      "proficient in visualization tools: power bi, tableau, superset, data studio ect.\n",
      "experience with python\n",
      "\n",
      "\n",
      "tại sao bạn sẽ yêu thích làm việc tại đây\n",
      "\n",
      "benefit\n",
      "nan\n",
      "yêu cầu công việc\n",
      "1. bằng cấp/chứng chỉ:\n",
      "experience in the e-commerce industry.\n",
      "we are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\n",
      "i. job descriptions\n",
      "\n",
      "develop and deliver action-oriented, insightful analytics presentations that provide consultative directions to key stakeholders;\n",
      "consolidate data from multiple sources including sales, supply chain, operations, marketing, and source databases to create integrated views that can be used to drive decision making;\n",
      "leverage bi tools and other software applications to develop data models, conduct data analyzing and visualizing in dashboards and reports\n",
      "work with/or build several large and complex databases.\n",
      "\n",
      "ii. skill and experience\n",
      "\n",
      "at least 3-5 years’ experience in business intelligence or relevant role;\n",
      "bachelor’s degree and above in statistics, business, data analytics, and other related fields;\n",
      "strong in sql skills;\n",
      "having knowledge in design data warehouse architecture;\n",
      "have experience in using python is a big plus;\n",
      "ability to demonstrate a high level of verbal and written (both english and vietnamese) to coordinate with internal stakeholders across departments;\n",
      "be opened minded, think out of the box and willing to do attitude;\n",
      "experience in business intelligence in e-commerce/fintech companies is a plus;\n",
      "having knowledge in finance, logistics, operation or marketing is a plus;\n",
      "entrepreneurial spirit and start-up mindset.\n",
      "\n",
      "iii. why you will love joining us?\n",
      "for you to join\n",
      "\n",
      "\n",
      "\n",
      "financial well-being:\n",
      "yêu cầu công việc\n",
      "\n",
      "kiến thức cần có:\n",
      "\n",
      "hệ điều hành: ubuntu server, window server\n",
      "ngôn ngữ lập trình: python, java\n",
      "cơ sở dữ liệu: on-premes: oracle, postgres, mysql (nosql is a plus)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "học vấn: tốt nghiệp đh trở lên 1 trong số các chuyên ngành: computer science, engineering, mathematics hoặc các chuyên ngành có liên quan\n",
      "kiến thức tốt về: datawarehousing, cấu trúc dữ liệu và giải thuật, etl, elt\n",
      "có các kinh nghiệm làm việc sau đây là lợi thế:\n",
      "\n",
      "có kinh nghiệm trong việc thiết kế và xây dựng data models, quy trình etl và elt dữ liệu từ nguồn về dwh, tối ưu hóa luồng dữ liệu\n",
      "kinh nghiệm làm việc theo mô hình agile và scrum\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan\n",
      "yêu cầu công việc\n",
      "\n",
      "-\n",
      "nan\n",
      "job requirementsrequired qualifications:1-2 years of working experience as a data scientist or similar role in an it company, university, or research institute;highly analytical with a heavy emphasis on data mining and data visualization (problem formulation, analytical ability, synthesis);experience using statistical computer languages (r, python, slq, etc.) to manipulate data and draw insights from large data sets;experience with statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications;experience with common data machine learning frameworks (tensorflow, scikit-learn, nlp, etc);preferred qualifications:bsc/ba in computer science, engineering, or relevant field; a graduate degree in data science or other quantitative fields is preferred;experience in adverts & advertising network, online marketing;strong communication skills (good english communication skill is a plus);excellent teamwork mindset that can foster teamwork spirit among other members;demonstrating a willingness to learn.\n",
      "quyền lợi\n",
      "hiring processphone screening > home test > onsite interviews > offering.\n",
      "experiences\n",
      "\n",
      "either full-time or part-time (minimum 25hs/week but more hours is welcomed).\n",
      "must have a laptop with minimum requirements: 8gb ram, ssd and i3.\n",
      "must have a basic understanding of python, oop (object oriented programming) and database.\n",
      "good logical thinking in programming.\n",
      "show your senior your progress (like test or demo).\n",
      "\n",
      "\n",
      "3. why you’ll love working here\n",
      "\n",
      "will provide support during your job (can discuss more details during the interview).\n",
      "potentially become an official employee with the company benefits.\n",
      "free coffee, tea and cakes.\n",
      "we have these clubs for you to join: football, table football, music, english, media and more.\n",
      "get advices for career development.\n",
      "\n",
      "working hours: morning: 8h30 – 12h00; afternoon: 13h00 – 17h30. (monday to friday).\n",
      "kinh nghiệm làm data analyst - phân tích dữ liệu tại một công ty công nghệ.- có kinh nghiệm sử dụng toán học, công cụ trực quan hóa dữ liệu, phân tích kinh doanh và công nghệ chuyển đổi khối lượng lớn dữ liệu phức tạp thành giải pháp.- kỹ năng excel và phân tích dữ liệu tốt bao gồm khả năng sử dụng các công cụ bi.- kỹ năng sử dụng các công cụ visualize để chuyển hóa dữ liệu thành biểu đồ, báo cáo.- kiến thức hoặc kinh nghiệm làm việc về phát triển cơ sở dữ liệu sql.- kỹ năng giải quyết vấn đề và tư duy hoàn thành mục tiêu- có kỹ năng phân tích sắc bén, khả năng thu thập, tổ chức, phân tích và phổ biến lượng lớn thông tin một cách chi tiết và chính xác.- có niềm đam mê với dữ liệu.- cẩn thận, kiên nhẫn, chịu khó, ham học hỏi, có tinh thần trách nhiệm.* ngoài ra:- khả năng code cơ bản để xử lý các mô hình dự báo (predictive models) là lợi thế.- kinh nghiệm với google analytics là một lợi thế.- thành thạo tiếng anh và nghiên cứu tài liệu tiếng anh là một điểm cộng lớn. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job detail\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "position type\n",
      "\n",
      "full-time\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "career level\n",
      "\n",
      "staff\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "education level\n",
      "\n",
      "bachelor's degree\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gender\n",
      "\n",
      "male / female\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job categories\n",
      "\n",
      "\n",
      "it - software\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "information\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "name:\n",
      "\n",
      "\n",
      "phòng nhân sự\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fhome building - 16 ly thuong kiet,  thach thang\n",
      "\n",
      ", \n",
      "\n",
      "hai chau district\n",
      "\n",
      ", \n",
      "\n",
      "da nang\n",
      "\n",
      ", \n",
      "\n",
      "viet nam\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- các ứng viên quan tâm vui lòng gửi hồ sơ trực tuyến, gửi kèm file hoặc trực tiếp đến tại công ty \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "application language:\n",
      "vietnamese\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "công ty cổ phần nal solutions\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "https://nals.vn/\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100 - 499 employees\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact: phòng nhân sự\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nal solutions is a vietnam - japan joint venture software technology company under nal holding. at nals, we bring technology solutions and develop diverse and high-tech products encompassing website development, mobile apps, ai & big data, iot ar/vr.\n",
      "with a board of experienced and skilled technical engineers, a dynamic, enthusiastic, and proactive working environment will always bring quality products and receive certitude from customers. regardless of project type or industry, nals consistently strives to provide comprehensive support from consulting to system development and deliver a great customer experience.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "see more\n",
      "\n",
      "\n",
      "\n",
      "see less\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "other jobs from this company\n",
      "\n",
      "|\n",
      "\n",
      "see all\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python django developer\n",
      "\n",
      "\n",
      "công ty cổ phần nal solutions\n",
      "\n",
      "\n",
      "\n",
      "da nang\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "java developer\n",
      "\n",
      "\n",
      "công ty cổ phần nal solutions\n",
      "\n",
      "\n",
      "\n",
      "da nang\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "php developer\n",
      "\n",
      "\n",
      "công ty cổ phần nal solutions\n",
      "\n",
      "\n",
      "\n",
      "da nang\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "technical leader\n",
      "\n",
      "\n",
      "công ty cổ phần nal solutions\n",
      "\n",
      "\n",
      "\n",
      "da nang\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "process quality assurance (good at japanese)\n",
      "\n",
      "\n",
      "công ty cổ phần nal solutions\n",
      "\n",
      "\n",
      "\n",
      "da nang\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "work location\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fhome building - 16 ly thuong kiet,  thach thang, hai chau district, da nang\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tags\n",
      "\n",
      "\n",
      "\n",
      "hai chau district\n",
      "software\n",
      "it\n",
      "data analyst\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "share\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "copied\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "experience in developing ai solutions in a professional setting.\n",
      "experience requirements\n",
      "• bachelor’s degree in economics, business administration, banking & financeknowledge & skills• at least 03 year experiences of working in insurance/ finance/ banking or equivalent position• must be good knowledge in access, sql & vba. programming language c# (visual studio) is plus• be able to work independently and under pressure to meet the deadline committed in company level• be able to work with details and good analytical skills to deal with large of amount of complex data.• have good english skill (especially speaking and business writing)• possess good communication, problem solving and stakeholder management skills• be careful and responsible.﻿please click the apply button or contact ms tien ngo at +84 359 341 711 or\n",
      "yêu cầu ứng viên\n",
      "sv năm cuối các ngành có liên quan đến data sciencequen thuộc với linux oskiến thức tốt về data mining, data science / machine learninghiểu biết về databases chẳng hạn sql / mysqlkinh nghiệm sử dụng python, pandas, numpy, matplot, sklearn, pyspark or\n",
      "yêu cầu ứng viên\n",
      "- kinh nghiệm: mới ra trường, \n",
      "experience\n",
      "\n",
      "\n",
      "bachelor degree in computer science or software engineering\n",
      "specializing in data science or a higher degree is a big plus.\n",
      "at least 02-year-experience in building data platforms and pipelines for analytics.\n",
      "excellence at least 2 programming languages like sql, python, java, scala\n",
      "experience with hadoop, spark\n",
      "experience with cloud services (aws, gcp, azure)\n",
      "\n",
      "experience with different database/data warehouse systems: mongodb, postgresql, bigquery, etc\n",
      "experience with data pipeline and workflow management tools: airflow, cloud composer, dbt, airbyte\n",
      "knowledge of data viz tools like metabase, tableau, looker, etc\n",
      "knowledge of streaming process platform is a plus\n",
      "exposure to emerging open source technologies.\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "benefit\n",
      "competitive salary, 13th-month pay & performance bonus\n",
      "monthly allowance (transportation)\n",
      "annual health check-ups.\n",
      "join training courses and tech sharing\n",
      "open communication with senior engineer & technical leader\n",
      "challenging working environment with attractive domain as logistics\n",
      "comfortable private working area for tech team\n",
      "teambuilding + outing trip\n",
      "our culture\n",
      "we collect, analyze and integrate data into every corner of the enterprise. data team is the backbone of our company. just like the “on-demand delivery” segment, our data team provides \"on-demand technologies\" to serve our fast-changing business needs and evolving market.\n",
      "our data team has the power to try many up-to-date solutions, tools, and technologies such as cloud services, big data distributed systems, machine learning models…\n",
      "currently, we have created different data positions to solve a variety of problems that are fun, challenging, and meaningful.\n",
      "\n",
      "\n",
      "job requirementsat least 3 years of experience in software development.hands-on experience with java, spring, and spring boot is required.having a good understanding of messaging brokers is required.good experience working with typescript and angular.good experience working with web services (restful, soap).good knowledge of git workflow and jenkins is a big plus.passionate about software development.good background in software development processes and best practices.good command of english.effective communication both verbally and non-verbally.positive thinking and attitude in every situation.candidates are vietnamese people.work places : ho chi minh, da nang.benefits and incentivesattractive and high – competitive salarypremium healthcare insurance, annual health check up in the prestige and quality hospitalsannual performance review with high bonus and salary increaseonsite opportunities in the silicon valley and others13th month salaryvietnamese public holiday and special holiday bonuses, personal occasions allowances (birthday, newborn baby, marriage, bereavement, sickness,…)overtime payment\n",
      "experienceexperience in office 365 usage and internet browsers.have interests in the position of sales admin/business intelligence/data analyst.ready to learn working with crm and sales financial systems.fluency in microsoft office, especially in excel and bi tools (power bi practice is an advantage).english fluency in speaking and writing.what we offer:working time: mond-fri, flexible working time, wfh is applicable.allowance for full-time internship:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "experience in a fast-paced startup environment.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model good leadership behaviour by engaging in peer to peer feedback and code reviews to foster a healthy, collaborative engineering culture as measured by scrum team health checks.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "use unit test and agile practices to deliver features continuously to production, measured by feedback and daily releases going smoothly.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "embrace a fast paced environment and have a keen interest in data / machine learning tech.\n",
      "\n",
      "\n",
      "\n",
      "nan\n",
      "nan\n",
      "yêu cầu công việc\n",
      "\n",
      "\n",
      "from 2-year experience as a data analyst\n",
      "fluent in writing & speaking english\n",
      "master of sql and python\n",
      "familiar with databases & cloud storage (google bigquery, snowflake…)\n",
      "familiar with visualization tools (tableau, powerbi, looker…)\n",
      "having experience in 2 domains (mobile application) and (financial investment) is a great advantage\n",
      "understand the data needs of different departments (marketing, product, finance…)\n",
      "understand the scopes of data engineers, data scientists to collaborate and take the lead if needed\n",
      "have a robust problem-solving mindset. be able to turn a simple question to become a comprehensive data dashboard that detects and solves a business problem\n",
      "good communication skills. be able to deliver, present and explain the results in an effective way for both technical and non-technical parties\n",
      "\n",
      "\n",
      "tại sao bạn sẽ yêu thích làm việc tại đây\n",
      "\n",
      "\n",
      "competitive salary with annual salary reviewwork in malaysia: up to 2000 usd with allowanceswork in vietnam: up to 900 usd\n",
      "\n",
      "an international working environment with friendly, creative colleagues from around the world\n",
      "an excellent opportunity to grow your career. we encourage you to take the lead, initiate and make decisions\n",
      "tuition fee sponsorship if you expect to become a data scientist or grow other data skills\n",
      "enjoy birthday parties and frequent weekend parties and other team-building activities (depending on your work location)\n",
      "\n",
      "\n",
      "yêu cầu công việc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "• proven work experience as a personal assistant/secretary/administrator\n",
      "• knowledge of office management systems and procedures\n",
      "• ms office and english proficiency\n",
      "• outstanding organizational and time management skills\n",
      "• ability to multi-task and prioritize daily workload\n",
      "• excellent verbal and written communications skills\n",
      "• proactive, flexible, and self-motivated\n",
      "• problem-solving skills and can work under high pressure\n",
      "\n",
      "\n",
      "\n",
      "experience. we like to get to know our candidates, challenge them, and be able to give them proper feedback as quickly as possible. here's what our recruitment process looks like:\n",
      "nan\n",
      "job requirements:qualifications:• university/ college degree with marketing/ business majorexperience:• at least 5 years’ experience in market research (2 years' working experience for a market research agency is preferable) and minimum 1 year of working as a ci/ market research manager.job capabilities & behaviors requirements:• execution excellence: take full ownership to resolve difficulties, challenges and deliver the project objectives efficiently with highest standard of quality• working together: work well with different types of people including external research vendors and internal stakeholders; proactively contribute thoughts, ideas in meetings, cross-functional projects• strategic thinking: think a big picture and use good judgment to find hows to approach/ implement one issue/ challenge thoroughly and efficiently• great data analytic skill (i.e either qualitative or quantitative data points)• be a great communicator, both spoken and written english communication\n",
      "\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "strategic partnerships – salesforce developer (bangkok- based, relocation provided)\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "nan\n",
      "nan\n",
      "yêu cầu ứng viên- tư duy logic, khả năng sắp xếp, phân tích, giải quyết vấn đề tốt\n",
      "- có khả năng làm việc độc lập, đồng thời có kỹ năng làm việc nhóm\n",
      "- là người chủ động, trách nhiệm, ham học hỏi, tinh thần tích cực\n",
      "- chịu được áp lực tốt trong công việc và sẵn sàng làm ngoài giờ\n",
      "- ưu tiên có kinh nghiệm phân tích dữ liệu hoặc truyền thông/marketing tối thiểu 6 tháng và sử\n",
      "nan\n",
      "nan\n",
      "experience across all touchpoints. ultimately, our goal is to minimize risk and optimize portfolio performance metrics for the benefit of our customers.\n",
      "responsibilities\n",
      "\n",
      "\n",
      "\n",
      "the ideal candidate will have a passion for utilizing data and analytics to optimize portfolio performance. the successful candidate will be responsible for analyzing large datasets, developing predictive models, and generating actionable insights for credit card portfolio management.\n",
      "\n",
      "developing and implementing credit risk models and analytical tools to assess portfolio performance, credit risk, and profitability.\n",
      "analyzing and interpreting data to identify trends, patterns, and insights that drive portfolio management decisions.\n",
      "conducting ad-hoc analysis and data mining to support portfolio optimization and strategy development.\n",
      "collaborating with business stakeholders to understand their needs and requirements, and to develop and implement solutions that meet their needs.\n",
      "creating and maintaining reports and dashboards that provide insights into portfolio performance and key performance indicators (kpis).\n",
      "designing and conducting a/b tests to evaluate the impact of new portfolio strategies and tactics.\n",
      "maintaining up-to-date knowledge of industry trends, best practices, and regulatory requirements related to credit card portfolio management.\n",
      "communicating complex analytical findings and recommendations to non-technical stakeholders, including senior management.\n",
      "mentoring and coaching junior analysts and data scientists on the team.\n",
      "partnering with data engineers and other technical teams to ensure data quality, availability, and scalability.\n",
      "conducting competitive research to stay informed of market trends, customer preferences, and emerging technologies that may impact the credit card portfolio.\n",
      "perform highly complex activities related to financial products, business analysis, and build dashboards for portfolio monitoring.\n",
      "utilize statistical and machine learning techniques to identify patterns and trends in financial data\n",
      "develop and implement data-driven investment strategies that optimize portfolio performance\n",
      "\n",
      "requirements\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "sinh viên năm 3,4,5 hoặc đã tốt nghiệp trong vòng 06 tháng chuyên ngành cntt hoặc tương đương các trường đại học/ cao đẳng. có thể tham gia parttime (20h/tuần).thời gian thực tập: 3- 6 thángcó đam mê và nắm chắc các kiến thức cơ bản lập trìnhcó đam mê tìm hiểu các công nghệ mới, phát triển các sản phẩm mớikhả năng tư duy tốt, chủ động trong công việc, có tinh thần trách nhiệm cao để hoàn thành công việc được giaocó khả năng làm việc teamwork cũng như làm việc độc lập\n",
      "quyền lợi\n",
      "được sự hướng dẫn, dìu dắt từ những người có kinh nghiệm nhiều năm, kỹ năng tốt.được tham gia vào dự án thực tế, quy trình làm việc chuyên nghiệp.có lương hỗ trợ: 2m/tháng\n",
      "yêu cầu công việc\n",
      "\n",
      "yêu cầu công việc\n",
      "\n",
      "tốt nghiệp đại học hoặc cao hơn chuyên nghành toán, thống kê, kinh tế, ngân hàng, tài chính, khoa học máy tính, kỹ thuật phần mềm…\n",
      "tối thiểu 5 năm làm việc trong lĩnh vực phân tích dữ liệu, mô hình học máy, học sâu. ưu tiên các ứng viên có kinh nghiệm tại ngân hàng\n",
      "có hiểu biết sâu sắc và có kinh nghiệm làm việc với các mô hình thống kê, dự báo, các thuật toán học máy, các kỹ thuật phân tích nâng cao\n",
      "thành thạo sql, excel và\n",
      "experience in data engineering, data warehousing, and data streamingstrong experience with sql database.experience with python programing language.experience with\n",
      "experience\n",
      "\n",
      "\n",
      "5+ years relevant work experience with large amounts of data\n",
      "education background in machine learning, statistics, math, data science, computer science or other closely related area\n",
      "strong machine learning/statistics background with hands-on experience in academia and/or industry, sourcing, cleaning, manipulating and analyzing large volumes of data\n",
      "experience with open-source machine learning libraries such as numpy, pandas, scikit-learn, distributed/parallel big data processing architecture (e.g., hadoop, spark, mllib) and deep learning framework (e.g., tensorflow, pytorch)\n",
      "understand the business domain (fintech, adtech knowledge is a plus)\n",
      "can plan, prioritize and troubleshoot\n",
      "experience with recommendation systems is a plus\n",
      "experience with data science models in finance domain or crm (e.g., credit scoring, clv, churn, etc) is a plus.\n",
      "nan\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "• advanced data analytics (azure data factory, data bricks, data lake, hd insights)• sql migration / modernization experience• azure sql database (standalone, elastic pool, serverless, managed instance, hyperscale)• azure synapse analytics• nosql: azure cosmos db, mongodb, cassandra• azure blob storage, azure data lake store• power bi and analysis services• machine learning services/cognitive services• 2+ years’ experience working with bi technologies and tools like microsoft power bi, tableau.• 2 years of experience with azure (da-100 certification acts as a plus)• 3+ years’ using programming languages such as java, dax, mdx, sql, python.• 2+ years’ bi related experience using etl, data warehousing management, data mining, report designer, or development; ability to write complex sql queries against a variety of data sources.• 3+ years’ heterogeneous database management systems like ms sql, oracle, mysql, sap etc. and working knowledge with various data sources like flat files (csv, delimited), web api, xml.• proven ability to build consensus between teams with differing architecture and design viewpoints and perspectives.• good understanding of data and query optimization, query profiling, and query performance monitoring tools and techniques.• experience implementing solutions on multiple hardware platforms and operating systems.• must be self-motivated, responsible, conscientious, and detail oriented. proven ability to follow priorities and timelines.• must have strong analytical and problem-solving skills.• english communication.\n",
      "quyền lợi\n",
      "- 13th month salary, social insurance- opportunity to work on new technologies and tools- opportunity to work with multicultural environment and travel.- performance review and adjust salary twice a year- very attractive remuneration package- a flat hierarchy and a culture of collaboration across all disciplines- modern workplace\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 30/06/2023\n",
      "\n",
      "\n",
      "\n",
      "nan\n",
      "experience in deep learning and machine learning in the area of computer vision\n",
      "experience in building and optimizing microservices, data pipelines, and data sets\n",
      "experience working with cloud infrastructure such as aws, azure or gcp\n",
      "proficient in python programming language\n",
      "knowledge of react js advantageous, but not mandatory\n",
      "experience in restful api service development and familiarity with http / tcp\n",
      "experience in parallel and concurrent computation preferred\n",
      "familiarity with devops container techniques including docker and kubernetes preferred\n",
      "\n",
      "\n",
      "\n",
      "application form\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "upload maximum 1.5mb\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "submit \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "kinh nghiệm\n",
      "\n",
      "kỹ năng giao tiếp, đàm phán và giao tiếp mạnh mẽ, để liên lạc với đồng nghiệp, khách hàng\n",
      "khả năng làm việc với cơ sở dữ liệu và nguồn tài nguyên cntt, khả năng sử dụng phần mềm báo cáo quản trị để thu thập và quản lý thông tin\n",
      "tối thiểu 2 năm kinh nghiệm tại vị trí tương tự\n",
      "tiếng anh thành thạo (cả nói và viết)\n",
      "\n",
      "tính cách\n",
      "\n",
      "chú ý đến chi tiết và hướng đến kết quả\n",
      "kỹ năng viết báo cáo và phân tích mạnh mẽ\n",
      "hiểu các nguyên tắc và thực hành chăm sóc khách hàng\n",
      "kỹ năng giao tiếp, giao tiếp và viết lách tuyệt vời\n",
      "thúc đẩy, năng lực, linh hoạt và sẵn sàng học hỏi\n",
      "kỹ năng tổ chức và quản lý thời gian tuyệt vời với khả năng đa tác vụ\n",
      "khả năng viết báo cáo và thuyết trình tốt\n",
      "khả năng làm việc hiệu quả dưới áp lực\n",
      "sáng tạo, trí tưởng tượng và khả năng sử dụng sáng kiến\n",
      "kỹ năng làm việc nhóm, phân tích và giải quyết vấn đề tốt\n",
      "nhận thức tốt về các hoạt độngkinh doanh và kiến thức tốt về các vấn đề hiện tại\n",
      "\n",
      "để sắp xếp phỏng vấn cùng savills, hãy gửi cv của bạn đến chúng tôi và cho biết vì sao bạn tin tưởng rằng mình sẽ phù hợp với vị trí ứng tuyển.\n",
      "bên cạnh những thông báo tuyển dụng cụ thể, savills việt nam rất chào đón những cá nhân xuất sắc, những người tin rằng mình sẽ thành công tại savills và trên thị trường bất động sản.\n",
      "để ứng tuyển vào các vị trí tuyển dụng của savills, vui lòng email bản cv của bạn đến địa chỉ  careers-hcmc@savills.com.vn\n",
      "ứng tuyển\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "yêu cầu công việc\n",
      "\n",
      "các yêu cầu về bằng cấp/chứng chỉtốt nghiệp loại khá trở lên chuyên ngành ngân hàng hoặc cntt hoặc các lĩnh vực có liên quanyêu cầu về kinh nghiệm/kiến thức\n",
      "có ít nhất 4 năm kinh nghiệm trong việc xây dựng chỉ số phân tích dữ liệu và thực hiện báo cáo.\n",
      "có 3 - 5 năm kinh nghiệm thực tiễn về\n",
      "experience range: from 3 years\n",
      "job location: hanoi, hcmc\n",
      "duty & responsibilities:\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tas a hadoop big data engineer, you will operate and monitor scalable and resilient data platform based on hadoop ecosystem to address the business requirements:  \n",
      "development tasks (30%)\n",
      "– engineer reliable data pipelines for sourcing, processing, transforming, enriching and storing data in different ways, using data platform infrastructure effectively\n",
      "– ingest and transform data sets from a variety of data sources\n",
      "– focus on ingesting, storing, processing, and analyzing large datasets\n",
      "– create scalable, high-performance web services for tracking data \n",
      "supporting tasks (70%) \n",
      "– provide high operational excellence guaranteeing high availability and platform stability.\n",
      "– technical analysis, trouble shooting and fixing the production incidents, problem tickets and changes\n",
      "– take ownership of (data processing/batch jobs) applications from a support & maintenance perspective\n",
      "– work on small enhancements (analysis, build/test, deployment/release support) \n",
      "\n",
      "requirements: \n",
      "\t\t\t\t\t\t\t\t\t\t\tmust have requirements:\n",
      "– must have 3+ years of experience at a similar role\n",
      "– having hands on experience in hadoop ecosystem (on-prem) including spark, hdfs, mapreduce, yarn, …\n",
      "– good in programming language python\n",
      "– experience in monitoring large-scale data processing job (batch-processing, stream processing)\n",
      "– understanding of sla and meeting timelines for support activities \n",
      "good to have: \n",
      "– experience with hadoop distributions such as cloudera, hortonworks, comparison and feasibility\n",
      "– experience with data warehouse and data management: data quality, data integration\n",
      "– experience in etl, sql and nosql database\n",
      "– experience with sre, patching & automation: kubernetes or docker & containerization\n",
      "– experience working with big data in a cloud environment\n",
      "– experience in backend development using java\n",
      "– experience in data api\n",
      "– good to have architecture knowledge or experience \n",
      "preferred language for application: english\n",
      "\n",
      "experience in one or more areas of ai, such as machine learning, computer vision, image processing, natural language processinggood understanding of the latest research and technologies in artificial intelligence;experience in programming languages such as python, r, matlab, c++, java;hands-on experience with one or more deep learning frameworks (tensorflow, caffe, theano, pytorch);technical hands-on experience in system integration;communicate technical concepts effectively to non-technical audience;strong communication and documentation skills, adaptable and a team player.additional informationwhy bosch?because we don't just follow trends, we create them.because together we turn ideas into reality, working every day to make the world of tomorrow a better place. do you have high standards when it comes to your job? so do we. at bosch, you will discover more than just work.benefits and career opportunitiesworking in one of the best places to work in vietnamjoin a dynamic and fast growing global company (english-speaking environment)13th-month salary bonus + attractive performance bonus (you'll love it!) + annual performance appraisal100% monthly basic salary and mandatory social insurances in 2-month probationonsite opportunities: short-term and long-term assignments15++ days of annual leave + 1 day of birthday leavepremium health insurance for employee and 02 family membersflexible working timelunch and parking allowancevarious training on hot-trend technologies/ foreign language (english/chinese/japanese) and soft-skillsfitness & sport activities: football, badminton, yoga, aerobicfree in-house entertainment facilities and snackjoin in various team building, company trip, year-end party, tech talks and a lot of charity event\n",
      "nan\n",
      "experienced analysts.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "experience\n",
      "\n",
      "requirements\n",
      "possession of a solid problem-solving mindset with the support of tools and technologies.\n",
      "minimum three years of working experience in data engineering or jvm-based backend development.\n",
      "efficient coding skills in sql, python, java/scala, and bash scripting.\n",
      "comfortable working with modern data technologies, including spark, airflow, and kafka.\n",
      "good understanding of different types of common data formats and data storage technologies.\n",
      "nan\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "trình độ học vấn: cao đẳng trở lên chuyên ngành quản trị kinh doanh hoặc các chuyên ngành kinh tế.có ít nhất 6 tháng - 1 năm kinh nghiệm làm việc liên quan đến xử lý, thống kê dữ liệu.sử dụng thành thạo công cụ excel.cẩn thận, chi tiết, chủ động trong công việc, tư duy hệ thống và chịu được áp lực cao.kỹ năng làm việc độc lập.kỹ năng giải quyết vấn đề.kỹ năng giao tiếp và làm việc nhóm.\n",
      "quyền lợi\n",
      "làm việc trong môi trường vui vẻ, cởi mở, tôn trọng lẫn nhau.được đào tạo, tạo điều kiện học hỏi, khẳng định bản thân và thăng tiến.tham gia các hoạt động teambuilding.hưởng các chế độ khác theo quy định của nhà nước.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 09/06/2023\n",
      "\n",
      "\n",
      "\n",
      "kinh nghiệm trong việc làm báo cáo phân tích hiệu quả kinh doanh, phân tích dữ liệu hoặc làm ở vị trí tương tự- có kiến thức về phương pháp luận phân tích dữ liệu toán thống kê và phân tích định lượng. kiến thức chung về hoạt động quản trị kinh doanh, mô hình kinh doanh, kinh tế- giao tiếp tự tin, có tư duy logic, kỹ năng giải quyết vấn đề - tư duy phản biện tốt\n",
      "\n",
      "địa điểm làm việc\n",
      "- trụ sở yody: đường an định, phường việt hoà, tp hải dương- văn phòng hà nội: 90 nguyễn tuân, thanh xuân, hà nội- ứng viên có thể làm việc tại hà nội, 1 tuần về hải dương 2 ngày- có xe đưa đón hà nội - hải dương hoặc sắp xếp nơi ở miễn phí tại hải dương (nếu làm việc cố định tại hải dương)\n",
      "\n",
      "quyền lợi\n",
      "+ thu nhập 20-35 tr/tháng+ thưởng cuối năm: 1 - 3 tháng thu nhập, thưởng theo doanh thu, thưởng các ngày lễ, tết+ nghỉ chủ nhật, năm có 12 ngày nghỉ phép+ đóng bảo hiểm khi chính thức theo quy định+ phụ cấp ăn trưa miễn phí tại công ty+ cung cấp máy tính/thiết bị làm việc+ được tổ chức sinh nhật, du lịch 1-2 lần/năm, hưởng các chính sách đãi ngộ đặc biệt từ công ty+ hỗ trợ xe đưa đón hà nội - hải dương, chỗ ở miễn phí tại hải dương\n",
      "\n",
      "kết nối với yody\n",
      "- hotline/zalo - ms quyên 0344 367 752- email:\n",
      "nan\n",
      "nan\n",
      "experience\n",
      "2+ years of experience in relevant role\n",
      "proficientwith some of the modern relational databases such as oracle, db2, and sql server\n",
      "hand-on experiences on designing and developing etl solution by using ssis or other etl tools\n",
      "strong in writing t-sql, pl/sql\n",
      "good understanding of data modelling, processing and warehouse techniques\n",
      "skilled at optimizing large complicated sql statements\n",
      "capable of troubleshooting common database issues\n",
      "knowledge at reporting development with microsoft ssis and ssrs\n",
      "analytical thinking\n",
      "good interpersonal and communication skills\n",
      "time management and planning skill\n",
      "\n",
      "equal opportunity\n",
      "nan\n",
      "nan\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "senior analyst (supply analytics team, bangkok-based, relocation provided)\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "job requirements:qualifications \n",
      "job requirements qualificationsdegree in business, mathematics, statistics, engineering, computer science, or other quantitative disciplineexperience min 2-3 years of solid experience in business intelligence/ business analyticsknowledge and skill ability to interpret data and translate them into actionable insightsknowledge of statistical and predictive modeling concepts, machine learning approaches, clustering and classification techniques/ recommendation and optimization algorithms is preferredskilled in sql and excelfamiliarity with one of the programming language r/python is a plusinherently curious about data with a strong desire to keep up to date with the latest developments in analytics and machine learningattention to detailscritical thinkingcan-do attitudedecent communication skills\n",
      "\n",
      "experience in the field of business intelligence within the fast-paced environment of zalopay. we are seeking someone who is eager to learn, detail-oriented, and passionate about using data to drive marketing strategies and business growth.main responsibilities:1. analytics & insights (40%)use sql and other query language (training will be provided) to retrieve data for analysis/planning.help identify and analyze trends, patterns, and insights through retrieved data.use excel and other visualization tool (training will be provided) to visualize data for communicating between stakeholdershelp the team with developing reports, dashboards, and visualizations to track key performance indicators (kpis) and campaign effectiveness.2. campaign operations (40%)help with documentation for campaign.help setup and organize meeting between cross-functional teams for campaign discussionnote taking between meetings and providing meeting recap afterward.work closely with cross-functional teams to understand business requirements and provide data-backed recommendations.3. planning & forecast (20%)retrieve and utilize historical data to help with campaign planning and forecast.assist the team in forming planning & forecast model to meet target kpis.\n",
      "\n",
      "nan\n",
      "nan\n",
      "yêu cầu công việc:trình độ cử nhân trở lên, ưu tiên chuyên ngành tài chính, ngân hàng, kinh tế, kế toán, công nghệ thông tin, tin học;\n",
      "tối thiểu 7 năm (chuyên gia)/ 5 năm (chuyên viên cao cấp)/ 3 năm (chuyên viên chính)/ 2 năm (chuyên viên)/ưu tiên có (nhân viên) kinh nghiệm làm việc trong lĩnh vực tài chính, ngân hàng tại các tổ chức dịch vụ tài chính liên quan đến xử lý dữ liệu hệ thống, phân tích dữ liệu, lập báo cáo;\n",
      "tối thiểu 1 năm kinh nghiệm làm việc trong lĩnh vực lập trình vba trên excel: khả năng advance/excellent;\n",
      "kinh nghiệm lập trình và cấu trúc dữ liệu cơ bản;\n",
      "kiến thức sql căn bản;\n",
      "kỹ năng phân tích, quản lý hoạt động và quản lý thời gian tốt; tư duy logic;\n",
      "kỹ năng tiếng anh cơ bản (ưu tiên). \n",
      "\n",
      "\n",
      "\n",
      "chia sẻ công việc này\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tfacebook\n",
      "\t\t\t\t\t\n",
      "\n",
      "\t\t\t\t\t\tlinkedin\n",
      "\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "experience in the relevant technologiesbachelor degree in it/ computer science or relevant backgroundexperience in the hadoop ecosystem and its components: hdfs, yarn, mapreduce, apache spark (python/scala), apache sqoop, apache impala, apache avro, apache flume, apache kafkapreferred: having certificate cca175 – spark and hadoop developerdesigned and developed etl processexperienced in unix with scripting experience is preferredshould have strong knowledge on concepts of data warehousing models, data ingestion patterns, data quality and data governanceexperience on the hadoop systems with good understanding and knowledge of hadoop clustergood at english communication skillsadditional informationwhy bosch?because we don't just follow trends, we create them.because together we turn ideas into reality, working every day to make the world of tomorrow a better place. do you have high standards when it comes to your job? so do we. at bosch, you will discover more than just work.benefits and career opportunitiesworking in one of the best places to work in vietnamjoin a dynamic and fast growing global company (english-speaking environment)13th-month salary bonus + attractive performance bonus (you'll love it!) + annual performance appraisal100% monthly basic salary and mandatory social insurances in 2-month probationonsite opportunities: short-term and long-term assignments15++ days of annual leave + 1 day of birthday leavepremium health insurance for employee and 02 family membersflexible working timelunch and parking allowancevarious training on hot-trend technologies/ foreign language (english/chinese/japanese) and soft-skillsfitness & sport activities: football, badminton, yoga, aerobicfree in-house entertainment facilities and snackjoin in various team building, company trip, year-end party, tech talks and a lot of charity event\n",
      "nan\n",
      "experience\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "kinh nghiệm >1 năm trong việc xây dựng csdl (biết xây dựng trên ms sql là một lợi thế)\n",
      "có kinh nghiệm >1 năm trong xây dựng gói trích xuất dữ liệu (etl/ elt, biết xây dựng trên ms sql là một lợi thế)\n",
      "có kinh nghiệm về sql queries, stored procedures, and functions\n",
      "có kinh nghiệm về xây dựng ssis package\n",
      "kinh nghiệm trong xây dựng reports and dashboards dùng ssrs hoặc các phân mềm khác (lợi thế)\n",
      "có khả năng điều chỉnh và cải thiện hiệu suất hoạt động của hệ thống (indexing, analyzing query execution plans) (lợi thế)\n",
      "kĩ năng làm việc nhóm\n",
      "kĩ năng xử lý vấn đề\n",
      "\n",
      "1-2 năm kinh nghiệm trong lĩnh vực\n",
      "4. quyền lợi:\n",
      "\n",
      "mức lương: thoả thuận theo năng lực\n",
      "môi trường làm việc đam mê, năng động, sáng tạo, hoà đồng\n",
      "chế độ đãi ngộ tốt\n",
      "thực hiện chế độ theo quy định nhà nước ngay khi kết thúc 02 tháng thử việc.\n",
      "đóng bhxh theo quy định nhà nước\n",
      "thưởng quý,\n",
      "nan\n",
      "experience in cpg sales, trade marketing, retailer - key account, merchandising.bachelor's degreeknowledge of sales processes in cpg companies, customers, modern and traditional markets.good knowledge of nielsen iq products, services and data preferreddigital knowledge, salesforceexcellent business english and vietnamese, both verbal and writtenproven sales acumenexcellent problem solving skills, solution oriented and good analytical skillvery good client-facing and communication/presentation skillsfinancial understanding (eg. p&l, ebitda) and how this relates to business successstrong collaboration and networking skillsadditional informationabout niqniq, the world’s leading consumer intelligence company, reveals new pathways to growth for retailers and consumer goods manufacturers. with operations in more than 100 countries, niq delivers the most complete and clear understanding of consumer buying behavior through an advanced business intelligence platform with integrated predictive analytics. niq delivers the full view.\n",
      "experience- utilise our unique partnership with google and your knowledge of ga360 to implement, optimise and analyse performance for our clients- be highly proficient in javascript and sql- have strong communication and presentation skills, including training experience- join a high growth, values-driven company- enjoy flexible/remote working, with the ability to collaborate irl with teams in sydney, wollongong, or brisbane. for the right candidate we will consider other locations, including melbourne.what you will do with usreporting to the head of martech, you will play a key role within xpon technologies as one of our data analytics specialists, where you will liaise with clients, set the strategy, and drive the implementation of their ga 360.you will work closely with our clients to understand their business needs and requirements, and translate these into functional technical solutions across ga 360 and gtm implementations.you will be focused on working with our team to provide the best possible outcomes for our clients, and will:- understand and translate complex business requirements into a functional technical architecture that can be implemented and activated by clients.- implement and manage the delivery of solutions by working collaboratively with google gmp teams, internal teams, and delivery partners.- develop and maintain product knowledge about core competencies of google technologies, and other industry technology solutions.- document the current state of the client's technology and outline systems enhancements needed. serve as technical leader for xpon technologies' clients, with regards to programmatic advertising, analytics, measurement, attribution and marketing activation strategies.- develop deep business partnerships and trusted relationships with both partners and decision-makers at the c-suite level.- conduct effective and efficient troubleshooting, testing and qa analytics implementations.- be involved in weekly one on ones with actions to drive performance.- compile marketing reports and roi analysis.- contribute to strategy documentation and scoping for clients.a day of in the life of this role could include:- conducting discovery/audits to determine the foundation of a client's current set up.- establishing client side stakeholders/owners.- establishing architecture requirements for ga 360.- implementing technical gtm/ga solutions.- briefing internal teams on the solution.- working closely with the client and internal build team to deliver the required insights.- working to establish the right data foundations.- post implementation conducting monthly hygiene checks for ways to improve the data set.- providing ga & gtm training to client teams. \n",
      "yêu cầu ứng viên\n",
      "tốt nghiệp đại học trở lên chuyên ngành: thống kê kinh tế- xã hội, tài chính.giao tiếp tốt .có khả năng diễn đạt, thuyết trìnhcó tinh thần trách nhiệm,cẩn thận, trung thực, nhiệt tình trong công việcưu tiên những ứng viên có thành tích học tập giỏi, xuất sắc (chưa có kinh nghiệm sẽ được đào tạo, tư vấn và chia sẻ về nghiệp vụ, kiến thức chuyên môn và kỹ năng mềm).\n",
      "quyền lợi\n",
      "mức lương thỏa thuận theo năng lực,kết quả làm việc.làm việc trong môi trường nghiên cứu, hiện đại, chuyên nghiệp, năng động, bình đẳng, phát huy tối đa khả năng chủ động và sáng tạo;được trang bị đầy đủ trang thiết bị phục vụ công việc;được đóng các chế độ bhyt, bhxh, theo quy định của nhà nước;hưởng các chính sách khen thưởng, phúc lợi theo quy định của công ty.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 07/06/2023\n",
      "\n",
      "\n",
      "\n",
      "kinh nghiệm trong xây dựng data modeling và xây dựng logical data model (ldm), physical data model (pdm).\n",
      "có nền tảng kiến thức / kinh nghiệm làm việc với mdm tools and implementation\n",
      "có nền tảng kiến thức/ kinh nghiệm làm việc với mdm integration patterns (near realtime, batch)\n",
      "xây dựng báo có dùng ssrs\n",
      "có khả năng lập trình, cấu hình và triển khai trên các nền tảng công nghệ của microsoft.\n",
      "có kĩ năng thực hiện test cases/ automation test là một lợi thế\n",
      "\n",
      "chấp nhận sinh viên mới ra trường có nền tảng theo yêu cầu\n",
      "4. quyền lợi:\n",
      "\n",
      "mức lương: thoả thuận theo năng lực\n",
      "môi trường làm việc đam mê, năng động, sáng tạo, hoà đồng\n",
      "chế độ đãi ngộ tốt\n",
      "thực hiện chế độ theo quy định nhà nước ngay khi kết thúc 02 tháng thử việc.\n",
      "đóng bhxh theo quy định nhà nước\n",
      "thưởng quý,\n",
      "yêu cầu công việc\n",
      "\n",
      "\n",
      "đại học chuyên ngành kinh tế, qtkd, tài chính, marketing;\n",
      "có khả năng phân tích số liệu và thuyết trình;\n",
      "có hiểu biết về nghiên cứu thị trường;\n",
      "có kinh nghiệm làm việc ở vị trí tương đương tối thiểu 3 năm, ưu tiên trong ngành hàng fmcg;\n",
      "tiếng anh và các công cụ microsoft office thành thạo; công cụ phân tích số liệu\n",
      "\n",
      "tổ chức, sắp xếp công việc khoa học; khả năng chịu\n",
      "nan\n",
      "nan\n",
      "job requirements\n",
      "\n",
      "at least 6-8 years of experience related field.\n",
      "skills in strategic planning, logical thinking, problem solving, analytics\n",
      "management skill (better to have)\n",
      "advanced knowledge and mindset of digital marketing\n",
      "trendy & entertainment\n",
      "production knowledge\n",
      "solid experience with sns digital marketing\n",
      "excellence in communication skill\n",
      "outstanding presentation skills.\n",
      "\n",
      "\n",
      "benefits \n",
      "\n",
      "salary: negotiable \n",
      "international, challenging, and friendly working environment\n",
      "salary for 13th month\n",
      "full of social welfare under vietnamese labor law (insurance, annual leave, etc.)\n",
      "annual travel, team building activities, and periodic health check\n",
      "12 annual leave days and 3 paid summer holidays\n",
      "training: trained in soft and technical skills\n",
      "\n",
      "\n",
      "apply online or feel free to contact me directly for more information about this opportunity. due to the high volume of applicants, we regret to inform that only shortlisted candidates will be notified. thank you for your understanding.\n",
      "\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "experienced researchers in machine learning, expert systems, or artificial\n",
      "– intelligence to apply such technologies toward the development of an expert system that can help research worldwide financial markets. candidates need not have prior knowledge of financial markets, as the new hire will work closely with our highly accomplished quantitative researchers in the financial markets \n",
      "we offer outstanding career opportunities, which include:\n",
      "– competitive financial rewards, relative to performance and position\n",
      "– friendly and collegial working environment\n",
      "– opportunity for promotion and career advancement\n",
      "– opportunity to work with a team of highly accomplished experts in the financial markets to develop a industry frontier machine learning system.\n",
      "job qualifications:\n",
      "– ph.d. or m.s. degree from a top university in machine learning, expert systems, or artificial intelligence\n",
      "– machine learning related working experience at top tier companies.\n",
      "– have on-hand machine learning experience in resolving realistic large scale machine learning projects.\n",
      "– industrial experiences in expert system, game theory, mcts, deep learning related projects are a big plus.\n",
      "– proficient in c++ or python programming; knowledge of database is plus; knowledge of parallel computation is plus.\n",
      "– experience with time-series data analysis is a plus.\n",
      "– have a research scientist mind-set, i.e., be a deep thinker, creative, persevering, smart, a self-starter, etc.\n",
      "– possess good english language skills\n",
      "– have a strong interest in learning about worldwide financial markets\n",
      "– have a strong work ethic\n",
      "position based in hanoi, vietnam.\n",
      "\n",
      "nan\n",
      "yêu cầu công việc\n",
      "\n",
      "\n",
      "strong problem solving skills with an emphasis on product development.\n",
      "experience working with search engines: elasticsearch, sorl.\n",
      "experience working with machine learning operations (mlops)\n",
      "experience working with and creating data architectures and designing data warehouse\n",
      "experience working with sql / nosql database\n",
      "experience visualizing/presenting data for stakeholders using: ggplot, powerpoint, powerbi, metabase, etc. periscope,\n",
      "excellent written and verbal communication skills for coordinating across teams.\n",
      "a drive to learn and master new technologies and techniques.\n",
      "\n",
      "\n",
      "tại sao bạn sẽ yêu thích làm việc tại đây\n",
      "\n",
      "\n",
      "fastest growing fintech startup with state-of-the-arts technology\n",
      "top notch engineering team\n",
      "competitive salary with regular review and advancement\n",
      "opportunity to take charge of your own works and directly contribute to company products\n",
      "small, young and close-knit team. we move fast, work hard and play hard.\n",
      "\n",
      "\n",
      "nan\n",
      "experience will be an advantage.good at english communication.opportunity to working in an international team and global projects.additional informationcommitted 13-month bonus and collaborative yearly performance bonus.15-day annual leave + birthday leave and will be added 1 more every 3 years.meal & parking allowances (60.000 vnd/day).premium insurance (pvi) for employee and 2 family members.overseas training programs and working onsite opportunity.good benefits of trade union activities, team building and company trip.global career path and transparent performance review system.loyalty bonus and day off for your long-service award every 5, 10, 15... year.opportunity to work in global projects of fast developing company being a part of innovation team contributing initiative ideas to the hi-tech world.engage in our diverse training programs which surely help strengthen both your personal and professional skills\n",
      "yêu cầu ứng viên\n",
      "- bachelor’s degree in engineering, computer science (or equivalent experience)\n",
      "- at least 6 months of relevant experience as a data analysis\n",
      "- 3+ years of experience working as business analyst\n",
      "- in-depth knowledge of car domain is nice to have.\n",
      "- extensive experience working with data analytics and related technologies.\n",
      "- demonstrable experience and skills with ms excel and ms powerpoint\n",
      "- thorough knowledge of the relevant business units\n",
      "- basic knowledge of data management issues\n",
      "- significant data quality and metadata management expertise\n",
      "- some familiarity with product and project management is desirable.\n",
      "- nice to have prior fintech experience.\n",
      "- in-depth knowledge of sql (complex join, subqueries, unions,e.g…) and powerbi is nice to have\n",
      "- excellent understanding of business architecture ideas and how they're used.\n",
      "- excellent written english communication skills\n",
      "- ability to move fast and be efficient, making decisions on objective data evidence.\n",
      "- ability to work independently.\n",
      "quyền lợi\n",
      "- salary up to 1800$\n",
      "- health-care insurance tic\n",
      "- working hour: 8h00-17h30 or 8h30 - 18h00 mon - fri\n",
      "- salary package 14-16 months/ year\n",
      "- performance review at least 1/ year\n",
      "- team building, yep\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 10/06/2023\n",
      "\n",
      "\n",
      "\n",
      "experiences\n",
      " \n",
      "\n",
      "at least 02 years of working experience in banking data processing or related fields in mis, \n",
      "data warehouse\n",
      "\n",
      " \n",
      "5.\n",
      "nan\n",
      "yêu cầu công việc\n",
      "\n",
      "\n",
      "tốt nghiệp đại học, chuyên ngành toán, thống kê, ngân hàng, kinh tế, quản trị kinh doanh là một lợi thế\n",
      "tối thiểu 1 năm kinh nghiệm lĩnh vực liên quan\n",
      "thành thạo tiếng anh và việt\n",
      "kỹ năng phân tích và tư duy logic\n",
      "sử dụng thành thạo các công cụ báo cáo (sql/ python)\n",
      "\n",
      "\n",
      "nan\n",
      "experience:    strong technical experience of 7-12 years working with data projects preferably in cloud (aws, google, azure) and with at least 3 end-to-end production implementations in cloud hands-on experience of over 5 years in working with python, pyspark and its associated common packages to load and transform data hand-on experience of over 5 years working in cloud technologies like s3, glue, lambda, dynamodb or similar technologies  understanding and exposure of over 4 years in managing end-to-end data pipeline process and procedures experience of over 5 years in managing and driving conversations with business teams strong understanding and implementation experience of agile methodologies strong exposure and experience of over 5 years in code promotion process following devops processes in cloud self-motivated and comes with a can-do attitude with experience working in fast paced environment experience managing a team of data engineers and resolving technical issues faced by them    preferred experience:  demonstrates experience in translating high level business capability requirements into executable technical solutions broad experience of projects involving one/more of relevant data analytics technology areas viz big data engineering, data warehousing, data integration, data quality, data modelling, visualization, analytics prior experience in creating data models for building data pipelines across various layers of a data lake on cloud and on-prem setup.  prior experience working and co-ordinating directly with customer and multiple vendors across multiple locations for project delivery.required technical and professional expertiseas abovepreferred technical and professional expertiseas abov\n",
      "yêu cầu ứng viên\n",
      "sinh viên từ năm 2 chuyên ngành công nghệ thông tin, điện tử viễn thông, khoa học máy tính, toán tin ứng dụng và các chuyên ngành liên quan.có kinh nghiệm lập trình python/ đã làm các bài tập project liên quan đến pythonđã làm một số project cá nhân yêu cầu kỹ năng từ một trong số các ngôn ngữ lập trình hướng đối tượngbiết sử dụng docker, git là một lợi thế.tiếng anh giao tiếp cơ bản (kỹ năng nghe nói tương đương ielts 6.5 trở lên)\n",
      "quyền lợi\n",
      "hỗ trợ cơ bản up to 5.000.000 vnd/tháng, cùng thêm các phụ phí phát sinh trong quá trình làm việc như ăn trưa, gửi xe, kinh phí chạy thí nghiệmđược làm việc trực tiếp cùng mentor nước ngoài giàu kinh nghiệmđược cung cấp laptop cá nhâncó lộ trình thăng tiến lên nhân viên chính thức rõ ràngmôi trường làm việc cởi mở và năng động, khuyến khích trao đổi ý tưởng ở mọi cấp. bạn được chủ động làm việc, sáng tạo theo cách riêngcó hỗ trợ chứng nhận thực tập tốt nghiệp\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 30/06/2023\n",
      "\n",
      "\n",
      "\n",
      "yêu cầu ứng viên\n",
      "● kiến thức:- tốt nghiệp cử nhân chuyên ngành công nghệ thông tin, điện tử viễn thông, tài chính, ngân hàng, kinh tế hoặc tương đương. ưu tiên ứng viên có bằng tốt nghiệp loại giỏi hoặc tốt nghiệp tại nước ngoài- ưu tiên có các chứng chỉ chuyên nghành data engineer, data analytics, data science cho xử lý dữ liệu lớn● kinh nghiệm:- tối thiểu 2 năm kinh nghiệm làm việc trực tiếp tại các công ty, dự án về ds- có kiến thức cơ bản về data mining- có kiến thức về phân tích và visualization dữ liệu- có kiến thức về machine learning, deep machine learning- biết cài đặt trên hadoop eco-sys, aws, gcp,… cùng các tech stack thông dụng như sparkml, jupiternotebook, airflow, vs code với các thuật toán, thư viện thông dụng hiện nay- sử dụng thành thạo python, scala và java là lợi thế- có kinh nghiệm làm việc theo mô hình agile- có kinh nghiệm trong lĩnh vực tài chính ngân hàng- có khả năng đọc viết tiếng anh (cơ bản) nghe nói (nếu có thể).\n",
      "quyền lợi\n",
      "● thu nhập cực hấp dẫn: upto 32m gross ( thỏa thuận mức lương tương xứng với năng lực và kinh nghiệm làm việc)● hỗ trợ kí hợp đồng chính thức, nhận 100% lương và đóng bảo hiểm từ ngày đầu tiên đi làm● thưởng dự án, gói thưởng lễ tết lên đến 14m/year (bonus at tết dương lịch, tết âm lịch, lễ 2/9, quà tết, quà trung thu, sinh nhật công ty, tập đoàn,. )● xét tăng lương cố định hàng năm hoặc 6 tháng/ năm theo đánh giá năng lực● được hưởng bhxh, bhyt, bhtn theo chế độ nhà nước ban hành và tặng thêm gói bhxh sức khỏe “nms care” cho nhân viên● tận hưởng nhiều sự kiện của công ty, từ thi đấu thể thao, tiệc sinh nhật hàng tháng, xây dựng đội ngũ hàng quý đến tiệc năm mới, chuyến đi công ty, du lịch hè, teambuilding, liên hoan, gala định kì gắn kết tình cảm\n",
      "experience requirements\n",
      "5-7+ years of professional experience in data analysis, visualization, and deep-dive ad-hoc analysis.industry experience in fmcg/nutrition/pharma/consulting is advantageous.strong background in business intelligence, data analytics, and visualization, including dwh and bi tools.proficient in data extraction, aggregation, transformation, and modeling.advanced skills in sql, r, python, sas, and other relevant tools for working with databases.familiarity with machine learning models, supervised and unsupervised learning, and artificial intelligence.competency in bi technologies like integration services, sql server, mongodb, analysis services, automl, power bi, and qlik. education requirements\n",
      "bachelor's degree in a relevant field is required (e.g., data science, computer science, statistics, business analytics).please click the\n",
      "yêu cầu ứng viên\n",
      "đam mê và tham vọng trở thành tên tuổi trong lĩnh vực quantitative finance (những tỷ phú công nghệ)+ nắm vững kiến thức toán từ lớp 1 đến lớp 12+ biết ít nhất 1 ngôn ngữ lập trình hướng đối tượng+ đọc hiểu các tài liệu tiếng anh+ \n",
      "nan\n",
      "kinh nghiệm đọc hiểu, xử lý số liệu (ưu tiên biết corebanking (t24) và bi –tool),\n",
      "experience is one of the core components of fun games that are played for decades and remembered forever. \n",
      "we are looking for a data analyst with a passion for helping millions of players to enjoy our games in a trouble-free way. in this role you will be coordinating our external analysts with their data needs as well as our internal needs for your brains. the ideal candidate is someone with a strong analytical mindset and interest in analysing player behavior. someone always on the lookout for new ways to help us serve players better and improve overall player experience with new ideas and approaches.\n",
      "responsibilities\n",
      "\n",
      "support the player experience team and external analysts with their data needs\n",
      "define what data should be collected and what types of analysis that data enables\n",
      "proactively provide actionable insights and shed light on previously unexplored aspects of player experience\n",
      "together with the rest of the team, develop vision and strategy for continuous improvement of support quality\n",
      "work side by side with subcontractors, external partners and internal tech teams\n",
      "\n",
      "requirements\n",
      "\n",
      "experience in a data analyst, manager or scientist role, interpreting and visualizing data to provide actionable insight and conclusions on player behavior\n",
      "expert knowledge of sql\n",
      "coding skills with r or python, and sql at a proficient level and some experience with bi tools like qliksenser or tableau\n",
      "fluent in the data science workflow, applying statistics, understanding biases\n",
      "great communication skills, both written and spoken, especially for non-technical audience\n",
      "skills to work with a team but also work autonomously\n",
      "proactive drive to improve our games and yourself, to\n",
      "yêu cầu ứng viên\n",
      "• bằng đại học các ngành liên quan: khoa học máy tính, kỹ thuật, vật lý, toán, tài chính, kinh tế...\n",
      "nan\n",
      "experience required.\n",
      "university graduate.\n",
      "proficiency in excel’s advanced features is an advantage.\n",
      "ability to search for information, update content trends on social networks, forums and n\n",
      "honesty, carefulness, hard work.\n",
      "high sense of responsibility.\n",
      "\n",
      "\n",
      "kinh nghiệm từ 1,5 năm làm việc về các hệ thống big data,</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-weight: 400; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">nắm vững kiến thức cơ bản về khoa học dữ liệu, giải thuật, có tư duy lập trình hướng đối tượng và cơ sở dữ liệu.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 10pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 12pt 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">kiến thức về </span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">data-warehouse</span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">, xử lý dữ liệu phân tán, xử lý dữ liệu lớn (</span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">hadoop, spark,</span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\"> …)&nbsp;</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 10pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">kiến thức về xây dựng luồng xử lý dữ liệu (batch processing, stream processing...), và các công cụ quản lý workflow (luigi, airflow…)</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">kiến thức và kinh nghiệm xây dựng hệ thống chuyên sâu về dữ liệu với kiến trúc lambda/kappa/data lake</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">có kinh nghiệm làm việc về các hệ thống big data, data-warehouse, bi, sử dụng các mã nguồn mở như hadoop ecosystem, spark, hive, kudu, kafka, hbase, cassandra;</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 10pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">khả năng lập trình chuyên sâu&nbsp; </span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">java, scala, python</span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">...</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">lập trình thông thạo spark, spark-streaming;</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt; padding: 0pt 0pt 12pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">kỹ năng sử dụng một trong các loại csdl </span><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">(rdbms, graph databases, nosql, ...)</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.8; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">tư duy tốt, có khả năng nghiên cứu, đánh giá và cập nhật công nghệ mới.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: &quot;noto sans&quot;, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.2; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">tiếng anh đọc hiểu tài liệu kỹ thuật.</span></p></li></ul><p dir=\"ltr\" style=\"line-height: 1.5; margin-left: -0.1pt; text-indent: -0.1pt; text-align: justify; margin-top: 14pt; margin-bottom: 0pt; padding: 0pt 0pt 14pt 0.1pt;\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; text-decoration-line: underline; text-decoration-skip-ink: none; vertical-align: baseline; white-space: pre-wrap;\">lý do để đồng hành với elcom</span></p><p dir=\"ltr\" style=\"line-height: 1.5; margin-left: -0.1pt; text-indent: -0.1pt; text-align: justify; margin-top: 0pt; margin-bottom: 14pt; padding: 0pt 0pt 0pt 0.1pt;\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">môi trường chuyên nghiệp, cởi mở, trao quyền và đề cao sự sáng tạo:</span></p><ul style=\"margin-bottom: 0px; padding-inline-start: 48px;\"><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 14pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">được mentor bởi đội ngũ quản lý, manager dày dặn kinh nghiệm, hỗ trợ sát sao, nhiệt tình.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 14pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">tham gia vào những dự án lớn, ứng dụng các công nghệ hàng đầu.</span></p></li></ul><p dir=\"ltr\" style=\"line-height: 1.5; margin-left: -0.1pt; text-indent: -0.1pt; text-align: justify; margin-top: 14pt; margin-bottom: 14pt; padding: 0pt 0pt 0pt 0.1pt;\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">tập trung hỗ trợ sự phát triển cá nhân:</span></p><ul style=\"margin-bottom: 0px; padding-inline-start: 48px;\"><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 14pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">được tư vấn, đồng hành và hỗ trợ phát triển sự nghiệp cùng với hệ thống career path (phát triển theo hướng chuyên gia hoặc hướng quản lý).</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 14pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">chính sách hỗ trợ các hoạt động học tập, phát triển bản thân</span></p></li></ul><p dir=\"ltr\" style=\"line-height: 1.5; margin-left: -0.1pt; text-indent: -0.1pt; text-align: justify; margin-top: 14pt; margin-bottom: 14pt; padding: 0pt 0pt 0pt 0.1pt;\"><span style=\"font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">quan tâm đặc biệt tới nhân viên:</span></p><ul style=\"margin-bottom: 0px; padding-inline-start: 48px;\"><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 14pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">văn phòng làm việc hiện đại với không gian mở; môi trường trẻ trung, năng động, sáng tạo và phát triển.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">gói đãi ngộ cạnh tranh với mức thu nhập hấp dẫn </span><span style=\"font-size: 11pt; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">(up to 1300 usd)</span><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\"> cùng chính sách nâng lương linh hoạt( 2 lần/ năm).</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">chính sách </span><span style=\"font-size: 11pt; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">thưởng hấp dẫn trực tiếp từ lợi nhuận công ty,</span><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\"> 6 khoản thưởng cho các ngày lễ khác trong năm. </span><span style=\"font-size: 11pt; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">gói thu nhập lên tới 14, 15 tháng lương/ năm.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">chăm sóc sức khỏe toàn diện với gói </span><span style=\"font-size: 11pt; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">bảo hiểm sức khỏe elcom care</span><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\"> do pti cung cấp được thiết kế riêng cho cbnv.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">khám sức khỏe thường niên tại bệnh viện hàng đầu cả nước.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">được hưởng toàn bộ các quyền lợi theo luật lao động ban hành về chế độ tham gia bảo hiểm xã hội, nghỉ lễ, nghỉ phép năm.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">bữa trưa </span><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">được phục vụ miễn phí tại văn phòng</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">các hoạt động văn hóa, giải trí phong phú:</span><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">du lịch, teambuilding, ngày hội sinh nhật công ty tại các địa điểm du lịch, resort cao cấp.</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">ngoài ra, bạn sẽ được tham gia nhiều hoạt động thú vị như: office happy hours, team outings, tham gia các câu lạc bộ cực cool như clb thể thao (zumba, bóng bàn, bóng đá, cầu lông), chơi bi-a, âm nhạc,…</span></p></li><li dir=\"ltr\" style=\"list-style-type: disc; font-size: 11pt; font-family: calibri, sans-serif; color: rgb(0, 0, 0); background-color: transparent; font-weight: 700; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre; margin-left: -0.1pt;\" aria-level=\"1\"><p dir=\"ltr\" style=\"line-height: 1.5; text-align: justify; margin-top: 0pt; margin-bottom: 14pt;\" role=\"presentation\"><span style=\"font-size: 11pt; background-color: transparent; font-variant-numeric: normal; font-variant-east-asian: normal; font-variant-alternates: normal; vertical-align: baseline; white-space: pre-wrap;\">thời gian làm việc: thứ 2 đến thứ 6.</span></p></li></ul></span>\n",
      "                                                    \n",
      "experience requirements\n",
      "• 5+ years experience in a developer role• advanced working sql knowledge and experience working with relational databases, query authoring (sql) as well as working familiarity with a variety of databases.• experience with data warehousing architecture and data modeling• experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.• experienced in manipulating, processing and extracting data from various source systems.• experienced in implementing concepts such as slowly changing dimension (scd type) and change data capture (cdc) functionality in both an oltp (relational modeling) and olap (dimensional modeling) environments.• able to work independently with minimum supervision.• experience with testing methodologies with the stated major development language(s)/technology education requirements\n",
      "• bachelor’s degree in computer science, engineering, mathematics, or a related technical discipline. contact person\n",
      "\n",
      "\n",
      "experience in data analysis and reporting servicesgood knowledge in data transformation (etl) and processing solutions and sql database.experience with python programing language and reporting tools (bi, tableau, etc)experience in database performance monitoring and tuningknowledge of data modeling and data relationship analysis for the large\n",
      "experiences in analytics and computer vision but any other field of ai will be considered too.\n",
      "\n",
      "\n",
      "\n",
      "what you will do:\n",
      "\n",
      "- getting involved in data science project from its inception to its delivery\n",
      "\n",
      "- researching our clients’ problem and dataset to assess the potential added value of data science and analytics solutions\n",
      "\n",
      "- selecting, acquiring and integrating client data for analysis\n",
      "\n",
      "- developing data hypotheses and methods and evaluating analytics and/or models\n",
      "\n",
      "- advising clients on the effectiveness of specific techniques based on project findings and comprehensive research\n",
      "\n",
      "- when required, working alongside engineers to implement data pipeline to provide data solution to clients’ problem\n",
      "\n",
      "- programming language for data science: python\n",
      "\n",
      "- cloud environment: aws, microsoft azure, google cloud platform\n",
      "\n",
      "\n",
      "\n",
      "- have strong experience/knowledge related to analysis/computer vision/other ml/ai fields\n",
      "\n",
      "- have good problem-solving skills\n",
      "\n",
      "- have hands on experience in industries as data scientist and/or r&d researcher\n",
      "\n",
      "- be proficient in at least one programming language, preferably python.\n",
      "\n",
      "- have experience/knowledge of working on the cloud (aws or azure or gcp etc)\n",
      "\n",
      "- have experiences/knowledge of databases\n",
      "\n",
      "- have experiences/knowledge of dnn, machine learning\n",
      "\n",
      "- have sufficient background in mathematics, statistics\n",
      "\n",
      "- have experience working on ai related projects\n",
      "\n",
      "- (senior) have deep understanding of a knowledge domain / industry vertical\n",
      "\n",
      "- (senior) must have experiences with leading projects and teams\n",
      "\n",
      "- be fluent in english\n",
      "\n",
      "- have a great ambition and ability to study the most leading-edge research by yourself and apply them to your own development.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "job requirements:\n",
      "\n",
      "nan\n",
      "experience >• language skills: english - intermediate level (good english communication both verbal and written.)• educational background: bachelor degree in marketing, business, or related.• experience: - at least 2 years experience in marketing position, strong experience in market research, data analysis- experience in power bi and dax queries is plus.- knowledge of marketing principal and digital marketing.＜preferable experience＞- experience in electrical products will be plus                                    \n",
      "\n",
      "\n",
      "yêu cầu ứng viên\n",
      "proven experience as a machine learning engineer or similar role\n",
      "understanding of data structures, data modeling and software architecture\n",
      "deep knowledge of math, probability, statistics and algorithms\n",
      "ability to write robust code in python, java and r\n",
      "familiarity with machine learning frameworks (like keras or pytorch) and libraries (like scikit-learn)\n",
      "excellent communication skillsability to work in a team\n",
      "outstanding analytical and problem-solving skills\n",
      "bsc in computer science, mathematics or similar field; master’s degree is a plus\n",
      "quyền lợi\n",
      "● package: 13, 14 salary month + project bonus ● extra package: 16 mil /employee/year (bonus at: tet, new year, your birthday, cmc corp’s birthday, 2/9 and tet’s gift, middle-autumn gift, …) ● salary review 2 times/year or on excellent performance. ● opportunity to approach newest technology trends; development of your career within an international company ● building large-scale & global software products for our clients. ● onsite opportunities: short-term and long-term assignments in us, europe, asia. ● paid annual leave: 12 days ● company’s labor policy completely pursuant to vietnamese labor legislation plus other benefits offered by the company (pti care premium, company trip, holiday, sum-up, etc) ● exciting leisure: sport and art events (football club, family day, happy hour,…) ● working time: 8h/day (from monday to friday) , flexible working time (check in: 7h30-9h00 ; check out: 16h30-18h00\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 17/06/2023\n",
      "\n",
      "\n",
      "\n",
      "nan\n",
      "experience in the relevant technologiesexperience in the hadoop ecosystem and its components: hdfs, yarn, mapreduce, apache spark (python/scala), apache sqoop, apache impala, apache avro, apache flume, apache kafkapreferred: having certificate cca175 – spark and hadoop developerdesigned and developed etl processexperienced in unix with scripting experience is preferredshould have strong knowledge on concepts of data warehousing models, data ingestion patterns, data quality and data governanceexperience on the hadoop systems with good understanding and knowledge of hadoop clustergood at english communication skillsadditional information\n",
      "experience in data analytics, cost/pricing/promotional analysis, accounts payable review, retail buying/procurement, internal auditing, freight/logistics/supply chain, business intelligence….\n",
      "working time: monday- friday, 08:00 – 17:00\n",
      "kinh nghiệm khoảng 03 năm trở lên về chuyên môn phân tích tài chính doanh nghiệp / phân tích kết quả hoạt động kinh doanh, ....;\n",
      "ưu tiên ứng viên có kinh nghiệm làm việc trong mô hình chuỗi nhà hàng f&b, chuỗi cửa hàng bán lẻ retails, fmcg, …;\n",
      "kỹ năng tổng hợp & phân tích dữ liệu tốt. thành thạo excel và các công cụ tổng, phân tích và trình bày dữ liệu như power bi - sql, power query, data studio, …ưu tiên ứng viên có kinh nghiệm làm việc với hệ thống sap / bravo / oracle;\n",
      "có kỹ năng thực hiện phân tích và tổ chức các báo cáo về tài chính, kết quả hoạt động kinh doanh chính xác và có thể đưa ra các nhìn nhận, đánh giá và góp ý hiệu quả;\n",
      "tính cách trung thực, ý thức bảo mật thông tin số liệu tốt;\n",
      "tư duy tốt về kinh doanh và nắm bắt tốt xu hướng kinh doanh của ngành/ thị trường;\n",
      "thái độ tích cực và có tinh thần đồng đội tốt. tinh thần trách nhiệm cao và chịu được áp lực công việc.\n",
      "\n",
      "phúc lợi\n",
      "\n",
      "địa điểm làm việc: lầu 7 - gigamall phạm văn đồng, 242 phạm văn đồng, hiệp bình chánh, thủ đức, tp hồ chí minh\n",
      "lương thỏa thuận theo năng lực;\n",
      "thời gian làm việc: thứ 2 - thứ 6, 8h30 - 17h30;\n",
      "công ty cung cấp đầy đủ trang thiết bị làm việc cần thiết như desktop / laptop;\n",
      "đảm bảo đầy đủ chế độ phúc lợi theo quy định của luật như: đóng bảo hiểm full 100% lương, bảo hiểm tai nạn 24/7, ... ngoài ra còn có gói bảo hiểm sức khỏe cá nhân (đối với các vị trí từ level supervisor trở lên);\n",
      "lương tháng 13 + thưởng theo kết quả hoạt động kinh doanh;\n",
      "giảm giá trên tổng hóa đơn khi dùng bữa tại các nhà hàng thuộc hệ thống của golden gate;\n",
      "môi trường trẻ trung, năng động. nhiều cơ hội phát triển;\n",
      "công ty thường xuyên có các hoạt động: du lịch hằng năm, team building, tiệc cuối năm.\n",
      "\n",
      "experience\n",
      "\n",
      "what we are looking for:\n",
      "bachelor’s degree in mis, information technology, computer science, or other quantitative major. an understanding of basic accounting/finance is a plus;\n",
      "significant data management and analysis experience;\n",
      "strong knowledge of tableau and able to develop insightful dashboards and reports that drive business decision making and outcomes;\n",
      "intermediate to advanced database and transact sql skills;\n",
      "intermediate powerpoint;\n",
      "experience in python, c#, vba, and ssis packages is a plus;\n",
      "understand data models, database design development, data mining and segmentation techniques.\n",
      "work behavior\n",
      "ability to lead, plan and manage in an entrepreneurial, team-oriented environment;\n",
      "highly organized with strong project management skills, and drive to meet organizational objectives; ability to manage multiple projects on interrelated timelines;\n",
      "strong written and verbal communication skills;\n",
      "demonstrate experience in getting things done in dynamic, entrepreneurial environment;\n",
      "demonstrate a high attention-to-detail in the analysis and reporting of data.\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "we treat people fairly and with dignity, keeping a healthy perspective about life and work and fostering a positive and enjoyable work environment with appealing benefits as below:\n",
      "a competitive monthly salary based on your ability\n",
      "13th month tet bonus & bi-annual performance bonus\n",
      "annual salary review\n",
      "attractive employee awards: employee of year, semi-annual outstanding employee\n",
      "social insurance and healthcare insurance upon vietnam labor code\n",
      "pvi insurance package, and annual health check\n",
      "an english-speaking environment\n",
      "an open culture that spurs creativity, innovation, and inclusivity\n",
      "a variety of training courses for your career development\n",
      "diverse activities to foster relationships, including company trips, year-end party, employees’ birthdays\n",
      "an open-space office, a cafeteria, and a range of modern equipment\n",
      "other allowance from referrals and special occasions (weddings, seniority, and new-born baby)\n",
      "\n",
      "\n",
      "job requirement• bachelor’s degree or higher in accounting or finance.• at least 03 years of experience at the same position in fmcg/ mnc/ manufacturing companies.• knowledge of accepted local accounting practices and principles.• knowledge of applicable laws, codes and regulations.• attention to detail and accuracy, adaptive to change.• strong data analysis skills (ms power bi, sql, etc.) is a plus.• strong communication, teamwork skills, planning and organizing skills.• good judgment and problem solving skills.\n",
      "yêu cầu công việc\n",
      "\n",
      "đam mê các lĩnh vực mô hình tài chính, quản trị hiệu quả tài chính, phân tích kinh doanh\n",
      "có kiến thức về phương pháp luận phân tích dữ liệu toán thống kê và phân tích định lượng.\n",
      "có kiến thức chung về hoạt động quản trị kinh doanh, mô hình kinh doanh\n",
      "có am hiểu chuyên sâu về mô hình giá/phí của các sản phẩm trong dịch vụ ngân hàng.\n",
      "kỹ năng phân tích, kỹ năng lập kế hoạch, thống kê tổng hợp số liệu, tư duy kinh doanh\n",
      "có khả năng diễn giải dữ liệu, kết quả, báo cáo phân tích bằng ngôn ngữ kinh doanh\n",
      "có kỹ năng làm việc và giao tiếp với các bên liên quan, có tư duy logic, kỹ năng giải quyết vấn đề\n",
      "có khả năng tự định hướng và tính tự tổ chức cao\n",
      "khả năng giao tiếp và hoạt động chuyên nghiệp với tất cả các cấp nhân sự và các phòng ban khác trong toàn tổ chức.\n",
      "quen thuộc với nhiều khái niệm, thực hành của lĩnh vực này.\n",
      "tư duy phản biện: có thể xử lý dữ liệu theo cách để đưa ra các đề xuất cần có tư duy phản biện.\n",
      "tốt nghiệp đại học trở lên với chuyên ngành tập trung vào tài chính, ngân hàng, quản trị kinh doanh,\n",
      "8 năm kinh nghiệm chuyên môn trong lĩnh vực tài chính/ngân hàng\n",
      "kinh nghiệm phân tích kinh doanh tối thiểu 5 năm.\n",
      "có kinh nghiệm liên quan đến xây dựng và quản trị mô hình tài chính\n",
      "thành thạo power bi, excel, spss, python…\n",
      "\n",
      "job requirements\n",
      "\n",
      "\n",
      "•\t3+ yoe in analytics, project management, strategy and/or tech consulting, or other related fields. experience in e-commerce is a plus.•\tsharp critical thinking, strong analytical and numerical skills. good communication skills•\teager to work in a fast-paced and ambiguous environment•\tsolid knowlegde of sql and other programming language. hands-on experience in data extraction, cleaning, preparation, and dashboard development•\thighly energetic and self-motivated. willingness to learn attitude with ability to work under pressure•\tbachelor’s or master's degree in relevant field of study.\n",
      "\n",
      "experience and contribute to the development of business applications using microsoft powerapps. you will work closely with the development team and under the guidance of experienced professionals to learn and apply powerapps development techniques, best practices, and design principles. this internship will provide you with valuable exposure to low-code development, business process automation, and the power platform.\n",
      "responsibilities:\n",
      "\n",
      " application development: collaborate with the development team to design and develop powerapps solutions, including canvas apps and model-driven apps, following established development practices and guidelines.\n",
      " requirement understanding: assist in gathering and documenting business requirements by engaging with stakeholders and end users to ensure clear understanding of application needs.\n",
      " user interface design: contribute to the creation of user-friendly and visually appealing user interfaces, considering usability and accessibility standards.\n",
      " data integration: assist in integrating powerapps with various data sources, such as sharepoint, sql databases, excel, and external apis, under the guidance of senior developers.\n",
      " testing and quality assurance: support the testing efforts by conducting functional testing, identifying bugs or issues, and participating in debugging and troubleshooting activities.\n",
      " documentation and reporting: contribute to the documentation of technical specifications, user guides, and other relevant materials to ensure knowledge sharing and support future maintenance.\n",
      " learning and skill development: actively participate in training sessions, workshops, and knowledge-sharing activities to enhance your powerapps development skills and stay up-to-date with industry trends.\n",
      " collaboration and communication: collaborate with team members, actively participate in meetings, and communicate progress, challenges, and ideas effectively.\n",
      "\n",
      "requirements:\n",
      "education/knowledge:\n",
      "\n",
      " education: currently pursuing a degree in computer science, information technology, or a related field. familiarity with low-code development platforms and a strong interest in business process automation is preferred.\n",
      " technical skills: basic understanding of microsoft powerapps, power platform, or related technologies.\n",
      "\n",
      "personalities/skills:\n",
      "\n",
      "have a good analytical thinking.\n",
      "have the ability to work well independently and in teams.\n",
      "good in communication skills.\n",
      "strong ability to manage time.\n",
      "nan\n",
      "experience\n",
      "\n",
      "\n",
      "experience in relational database design and implementation (ms sql is a plus).\n",
      "basic knowledge of transaction locking, sql server broker.\n",
      "strong analytical skills and be able to show initiative and take a proactive approach to your work.\n",
      "good english skills.\n",
      "years of experience: 03\n",
      "prefer candidates who have a passion for long-term engagement.\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "\n",
      "attractive salary plus 13th-month salary.\n",
      "high bonus and incentive-based on performance, seniority.\n",
      "work in a dynamic environment alongside team members who are talented and passionate about what they do.\n",
      "in-house health club: gym, swimming pool, soccer field, volleyball court, and entertainment area.\n",
      "annual health check.\n",
      "personal accident & health insurance.\n",
      "social – health – insurance paid fully.\n",
      "team building events are fully sponsored by the company.\n",
      "complimentary duty meals, snacks & beverages.\n",
      "outstanding annual company trip.\n",
      "long-term service award.\n",
      "quarterly and yearly incentive awards for best-performing employees.\n",
      "\n",
      "\n",
      "yêu cầu công việc:\n",
      "- tốt nghiệp đại học trở lên về các chuyên ngành: bảo hiểm, toán học, kinh tế, quản trị hoặc các chuyên ngành liên quan;\n",
      "- ít nhất 03 năm kinh nghiệm làm việc ở vị trí tương đương tại các công ty bảo hiểm nhân thọ;\n",
      "- ưu tiên các ứng viên đã thi soa;\n",
      "- tiếng anh tốt 4 kỹ năng;\n",
      "- thời gian làm việc: thứ 2 - thứ 6 từ 08:30 - 17:30\n",
      "- địa điểm làm việc: \n",
      "experience of progressively responsible experience in a directly related area, during which both professional and management capabilities have been clearly demonstrated (managed at least 15 people).\n",
      "- statistics\n",
      "- sas knowledge\n",
      "- financial services experience \n",
      "\n",
      "kinh nghiệm tại vị trí tương đương\n",
      "có kiến thức về nghiên cứu và phân tích thị trường\n",
      "có kinh nghiệm về thu thập dữ liệu, quản lý hệ thống dữ liệu\n",
      "sử dụng tiếng anh thành thạo và ưu tiên ứng viên biết thêm ngôn ngữ khác\n",
      "tối thiểu đạt điểm b- ở các bài test bằng tiếng anh và kỹ năng viết báo cáo bằng tiếng anh tốt\n",
      "\n",
      "ứng tuyển\n",
      "để sắp xếp phỏng vấn cùng savills, hãy gửi cv của bạn đến chúng tôi và cho biết vì sao bạn tin tưởng rằng mình sẽ phù hợp với vị trí ứng tuyển.\n",
      "bên cạnh những thông báo tuyển dụng cụ thể, savills việt nam rất chào đón những cá nhân xuất sắc, những người tin rằng mình sẽ thành công tại savills và trên thị trường bất động sản.\n",
      "để ứng tuyển vào các vị trí tuyển dụng của savills, vui lòng email bản cv của bạn đến địa chỉ careers@savills.com.vn\n",
      "ứng tuyển vị trí này\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "              lưu tuyết \n",
      "              hạnh\n",
      "            \n",
      "\n",
      "\n",
      "quản lý cấp caobộ phận hành chính & nhân sựhanoi\n",
      "\n",
      "+84 24 7301 9888\n",
      "\n",
      "\n",
      "liên hệ ngay\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "yêu cầu ứng viên\n",
      "university degree in computer science or information technology, finance, banking or related majorfemale; experience in sql, powerbi is compulsorystrong analytical thinking and ability to learn quickly with can do attitudeadvanced excel skill with knowledge in power query, power pivots- preferably working in financial & banking institution.\n",
      "quyền lợi\n",
      "• làm việc giờ hành chính từ t2-t6 (nghỉ t7 & cn)• thu nhập ổn định• được đóng bhxh và bhyt theo quy định của nhà nước• chế độ phúc lợi về sức khỏe, du lịch hàng năm• chương trình đào tạo nghiệp vụ dành riêng cho nhân viên• lộ trình thăng tiến rõ ràng• các phúc lợi khác theo quy định của ngân hàng.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 01/07/2023\n",
      "\n",
      "\n",
      "\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "experience: 2-3 years experienced in data analytics. experience in retail industry, f&b and fmcg is a plus.\n",
      "\n",
      "skill:\n",
      "experience in running campaigns on various search platforms such as google, search engines and onsite search tools of ecommerce platforms.familiar with agency environment (3+ years) - experienced in serving top fmcg clients - can handle working under pressure and leads junior membersstrong in search performance & search concept (user intention - keywords exploration| bidding| mapping - negative exclusion - technical set up) - proven record in seo-sem, onsite search (marketplace) or related fieldspay attention to details, comfortable working with data on daily basisknow how to use super metric, google studio & advance in excel (macro, advance formula, etc.) is a plus hands-on experience with seo/sem, google analytics sense of ownership and pride in your performance and its impact on a company’s successteamwork, time-management, and data analyst skillsknowledge on data visualization tool (google studio, tableau, power bi, power point) is a plusknowledge on other paid ads: cpas, programmatic, messenger, tiktok shop is a plusadditional informationan off-beat perspective and the courage to look at challenges.responsible and dedicated.a cheerful, humble individual who is very willing to learn every day, easy to manage and highly collaborative.someone who is honest, responsible, down to earth, hardworking, and passionate\n",
      "nan\n",
      "experiences in power bi developmentat least 1-2 year of experience working with data warehouse systems: ms sql, oracle sql, …at least 1-2 year of experiences in machine learning / ai developmenthave python programming\n",
      "yêu cầu ứng viên\n",
      "học vấn, kinh nghiệm:tốt nghiệp cao đẳng, đại học, ưu tiên chuyên ngành it.\n",
      "có từ 2 đến 4 năm kinh nghiệm trong phân tích dữ liệu hoặc vai trò liên quan trong các ngành hàng bán lẻ.\n",
      "có kinh nghiệm tạo báo cáo, trang tổng quan và bản trình bày.\n",
      "có kinh nghiệm với phân tích dữ liệu và các công cụ bi như tableau, qlikview, spark, powerbi.\n",
      "có kinh nghiệm sử dụng toán học, công cụ trực quan hóa dữ liệu, phân tích kinh doanh và công nghệ chuyển đổi khối lượng lớn dữ liệu phức tạp thành giải pháp.\n",
      "job requirementmust have:bsc/m.sc. from a leading university in computer science, engineering, or a related disciplineexperience developing scalable and robust softwareexperience building distributed or data-intensive systemsexperience programming production systems in python and c++knowledge of parallelization, threading, multiprocessing, etc.familiar with workflow scheduling (e.g. airflow)experience working in linux environmentsstrong communication skills; ability to express complex concepts in simple termsnice to have:experience in deploying machine learning frameworks in productionexperience with kubernetes and kafkawork with leading cloud technologies (such as aws, and gcp)experience with sql databases (mysql, postgresql)familiar with deep learning frameworks (pytorch)\n",
      "yêu cầu ứng viên:có ít nhất 01 năm kinh nghiệm ở các vị trí tương đương trong các công ty về logistics, ecommerce,…có tư duy phân tích và tối ưu vận hànhcẩn thận, tỉ mỉ trong công việc, tính chính xác caokỹ năng trung bình về sql/ google sheetskỹ năng trình bày, truyền đạt thông tin tốtkhả năng nhìn nhận tổng thể bức tranh toàn cảnh\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "experience.pintu is looking for a quant trader/researcher who will lead and execute proprietary market-making operations for our exchange. the position reports directly to cfo. the quant trader/researcher will work closely with the engineering, risk management, and treasury ops team.job description : develop proprietary market-making (”mm”) operations for pintu exchange: develop in-house quantitative trading & risk management strategies/models for mm at pintu exchange that supports mm goal priorities. collaborate with engineering, risk management, and treasury ops teams to orchestrate the implementation of semi/fully-automated quantitative trading strategies.   build & manage a team of mm quantitative researcher/trader(s), including task allocation & mentorship. quant strategies monitoring & improvement : continuously monitor model parameters and back-test existing in-house mm strategies to meet the mm goal priorities research & identify new quantitative trading strategies that meets mm goal priorities   imm goal priorities: supports the improvement of pintu exchange liquidity; satisfies internal risk parameters; improves mm’s risk-adjusted returns requirements: 5+ past professional quantitative research/trading experience in global/ regional mm firms. ideally has a minimum of 3 years in crypto and 2 years in trade-fi quant research/trading experience. good understanding of market structures in both crypto (cex & dex) and financial markets (e.g. fx). past academic background in either in comp-sci, statistics, financial engineering/operation research, or mathematics. extensive experience in programming languages such as python/r/etc, or similar applicable programming languages. excellent understanding of high frequency trading (”hft”) strategies (a must) and/or algo-trading (plus). excellent communication, leadership, & interpersonal skills. had experience in managing a team. cfa & frm is a plus. timezone: max 3 time zones away from jkt/sg (or willing to relocate to singapore/bali/jakarta). \n",
      "experience in the e-commerce industry.\n",
      "we are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\n",
      "i. job descriptions\n",
      "data mart & data warehouse\n",
      "\n",
      "collaborate with the data engineer and data analyst team to build up, centralize data and improve the quality control process from multiple sources.\n",
      "manage the data collection process to be adaptable to the company’s continuous expansion, more advance analytic.\n",
      "\n",
      "data analysis and reporting\n",
      "\n",
      "assisting line manager by preparing management reports and ad-hoc analysis.\n",
      "automate ar, ap report and forecast payment schedule.\n",
      "deepdive and control payment from system of amazon, walmart ensuring timing, accuracy and completeness of cash collection. build up dashboard to get things control more efficiently.\n",
      "build up tools to optimize financing fee for cashflow.\n",
      "automate operational p&l and cashflow. connect with key metrics from s&op to give a full picture of fluctuation and figure out the root causes.\n",
      "together with finance build up automate report/dashboard for evaluating performance of portfolio by various perspectives.\n",
      "build up report/dashboard integrating key metrics relate to finance and s&op to give greater visibility of the relationships between resources, capabilities, and results.\n",
      "\n",
      "ii. skill and experience\n",
      "\n",
      "bachelor‘s degree in business, finance, or other analytical disciplines.\n",
      "minimum 02 years working experience in data analyst/business analyst/business intelligence. have experience in finance/fintech is an advantage\n",
      "proficiency in excel & sql is required. knowing python or r is an advantage.\n",
      "knowledgeable of statistics such as regression, normal distribution, etc\n",
      "impressive data visualization (not limited to tableau tools, google data studio, power bi, superset, etc.)\n",
      "\n",
      "iii. why you will love joining us?\n",
      "for you to join\n",
      "\n",
      "\n",
      "\n",
      "financial well-being:\n",
      "kinh nghiệm làm việc ở vị trí nhân sự, kế toán hoặc các công việc tương đương - yêu thích làm việc với các con số. - thái độ làm việc tích cực, trung thực, nhanh nhẹn, nhiệt tình và tinh thần trách nhiệm cao\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job detail\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "position type\n",
      "\n",
      "full-time\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "career level\n",
      "\n",
      "staff\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "education level\n",
      "\n",
      "bachelor's degree\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gender\n",
      "\n",
      "female\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "age\n",
      "\n",
      "25 - 33\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job categories\n",
      "\n",
      "\n",
      "clerical / administrative\n",
      "\n",
      ", \n",
      "\n",
      "human resources\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "information\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "name:\n",
      "\n",
      "\n",
      "phòng nhân sự\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lầu 19, cao ốc flemington, 182 lê đại hành, p.15\n",
      "\n",
      ", \n",
      "\n",
      "district 11\n",
      "\n",
      ", \n",
      "\n",
      "ho chi minh\n",
      "\n",
      ", \n",
      "\n",
      "viet nam\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- các ứng viên quan tâm có thể nộp hồ sơ trực tuyến, đính kèm file qua email hoặc trực tiếp đến tại công ty\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "application language:\n",
      "vietnamese\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "công ty tnhh điều hòa gree (việt nam)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "https://www.gree.com.vn\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "25 - 99 employees\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact: phòng nhân sự\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "được thành lập vào năm 1991, từ một xưởng sản xuất nhỏ hiện tại gree đã phát triển thành là một tập đoàn hàng đầu thế giới về điều hòa không khí. gree là thương hiệu điều hòa số 1 thế giới năm 2015 do tập đoàn nghiên cứu thị trường euromonitor international bình chọn. năm 2015 gree đạt doanh số 25 tỷ usd, tốc độ tăng trưởng đạt 38% so với cùng kỳ năm trước và năm 2020 được xếp hạng 246 trong danh sách 2000 công ty lớn nhất theo bình chọn và thống kê của tạp chí forbes.\n",
      "mỗi năm gree cung cấp ra thị trường thế giới 60 triệu bộ điều hòa dân dụng và 5,5 triệu bộ điều hòa thương mại, chiếm 1/3 sản lượng điều hòa thế giới, có nghĩa là cứ 3 bộ điều hòa bán ra trên thế giới thì có 1 bộ điều hòa do gree sản xuất. bên cạnh đó gree còn sở hữu hơn 14000 bằng sáng chế kỹ thuật, trong đó có hơn 5000 bằng sáng chế phát minh trong ngành điều hòa thế giới. điển hình trong đó là công nghệ g10 inverter, đây là công nghệ inverter tiên tiến nhất trên thế giới hiện nay giúp tiết kiệm 60% điện năng tiêu thụ, hoạt động ổn định và độ ồn cực thấp. công nghệ điều hòa thương mại sử dụng năng lượng mặt trời, công nghệ chiller ly tâm quang điện công suất tối đa 2000 hp. đồng thời gree cũng sở hữu nhiều môi chất lạnh thân thiện môi trường như: r410a; r290; r134; r407.\n",
      "về gree việt nam, công ty đã chính thức có mặt tại việt nam năm 2013 và đang có những bước tiến mạnh mẽ trên thị trường. trong khoảng thời gian từ 2013 đến 2015 gree đã đạt tốc độ tăng trưởng cao nhất thị trường với con số lên đến 65%. định hướng sắp tới của gree việt nam sẽ tiếp tục cung cấp đến khách hàng những sản phẩm chất lượng với nhiều tính năng vượt trội, tiết kiệm điện năng và thân thiện với môi trường. bên cạnh đó là những dịch vụ hậu mãi hấp dẫn đúng với phương châm luôn đặt sự hài lòng của khách hàng lên hàng đầu từ trước đến nay của gree.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "see more\n",
      "\n",
      "\n",
      "\n",
      "see less\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "other jobs from this company\n",
      "\n",
      "|\n",
      "\n",
      "see all\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "trợ lý kinh doanh (tiếng trung)\n",
      "\n",
      "\n",
      "công ty tnhh điều hòa gree (việt nam)\n",
      "\n",
      "\n",
      "\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[hcm] phó giám đốc hành chính nhân sự\n",
      "\n",
      "\n",
      "công ty tnhh điều hòa gree (việt nam)\n",
      "\n",
      "\n",
      "\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[hn] nhân viên tài xế\n",
      "\n",
      "\n",
      "công ty tnhh điều hòa gree (việt nam)\n",
      "\n",
      "\n",
      "\n",
      "ha noi\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[hồ chí minh] chuyên viên hành chính lễ tân - tiếng hoa cơ bản\n",
      "\n",
      "\n",
      "công ty tnhh điều hòa gree (việt nam)\n",
      "\n",
      "\n",
      "\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[hcm] chuyên viên xuất nhập khẩu - thời vụ\n",
      "\n",
      "\n",
      "công ty tnhh điều hòa gree (việt nam)\n",
      "\n",
      "\n",
      "\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "photos\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "work location\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lầu 19, cao ốc flemington, 182 lê đại hành, p.15, district 11, ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tags\n",
      "\n",
      "\n",
      "\n",
      "chinese\n",
      "office worker\n",
      "district 11\n",
      "recruitment\n",
      "human resource\n",
      "kpi\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "share\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "copied\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "yêu cầu ứng viên\n",
      "yêu cầu > 1 năm kinh nghiệm ở các vị trí data engineer hoặc big data engineer hoặc data scientist;ưu tiên hiểu biết 1 trong các hệ thống như hadoop eco system (on premise), spark, hive, kafka, cassandra, neo4j, elastic search…thành thạo 1 trong các ngôn ngữ lập trình: python, sql, pl/sql, java, .net, scala,…có kinh nghiệm với 1 trong các hệ thống csdl như sql server, oracle, hbase, cassandra, clickhouse, mongodb, maria db, redis,...kỹ năng làm việc nhóm và làm việc độc lập tốtcó khả năng làm việc dưới môi trường áp lực.\n",
      "quyền lợi\n",
      "rank lương không giới hạnmức lương cạnh tranh, 13 tháng lươngđược đào tạo bài bản, lộ trình thăng tiến rõ ràngcung cấp laptop/ pcnghỉ thứ 7, chủ nhật, 12 ngày phép/ nămcompany trip, team buildinghappy hours hàng tháng, free snacks, hoa quả, đồ uốngtổ chức sinh nhật, team lunch, …làm việc với khách hàng khối ngân hàng, công việc ổn định và lâu dài\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 22/06/2023\n",
      "\n",
      "\n",
      "\n",
      "nan\n",
      "nan\n",
      "yêu cầu công việc\n",
      "\n",
      "technical requirements:\n",
      "understanding ms power platform (power apps, power automate)\n",
      "report building and data visualization\n",
      "knowing background in database analytics and data mining\n",
      "knowing the program power platform \n",
      "nan\n",
      "kinh nghiệm\n",
      "\n",
      "tối thiểu 2 - 3 năm kinh nghiệm ở vị trí tương tự\n",
      "kỹ năng giao tiếp, đàm phán và giao tiếp mạnh mẽ, để liên lạc với đồng nghiệp, khách hàng\n",
      "khả năng làm việc với các tài nguyên cntt như cơ sở dữ liệu và bảng tính để thu thập và quản lý thông tin\n",
      "\n",
      "tính cách\n",
      "\n",
      "hiểu biết sâu sắc về nghiên cứu thị trường và phân tích thị trường\n",
      "phải hiểu các nguyên tắc và thực hành chăm sóc khách hàng\n",
      "chú ý đến chi tiết và hướng đến kết quả\n",
      "mô hình định tính và định lượng mạnh\n",
      "kỹ năng viết báo cáo và phân tích mạnh mẽ\n",
      "kiểm soát độ chính xác / chất lượng\n",
      "thúc đẩy tăng trưởng trong một môi trường chuyển tiếp\n",
      "kỹ năng giao tiếp, giao tiếp, thuyết trình và viết lách tuyệt vời\n",
      "thúc đẩy, năng lực, linh hoạt và sẵn sàng học hỏi\n",
      "kỹ năng tổ chức và quản lý thời gian tuyệt vời với khả năng đa tác vụ\n",
      "khả năng làm việc hiệu quả dưới áp lực\n",
      "sáng tạo, trí tưởng tượng và khả năng sử dụng sáng kiến\n",
      "kỹ năng làm việc nhóm, phân tích và giải quyết vấn đề tốt\n",
      "nhận thức liên quan đến kinh doanh và kiến thức tốt về các vấn đề hiện tại\n",
      "\n",
      "để sắp xếp phỏng vấn cùng savills, hãy gửi cv của bạn đến chúng tôi và cho biết vì sao bạn tin tưởng rằng mình sẽ phù hợp với vị trí ứng tuyển.\n",
      "bên cạnh những thông báo tuyển dụng cụ thể, savills việt nam rất chào đón những cá nhân xuất sắc, những người tin rằng mình sẽ thành công tại savills và trên thị trường bất động sản.\n",
      "để ứng tuyển vào các vị trí tuyển dụng của savills, vui lòng email bản cv của bạn đến địa chỉ careers-hcmc@savills.com.vn\n",
      "ứng tuyển\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan\n",
      "yêu cầu công việc\n",
      "\n",
      "• tốt nghiệp đại học trở lên các khối trường kinh tế, tài chính, ngân hàng...\n",
      "• có kỹ năng tổng hợp, phân tích số liệu, thông tin, lên báo cáo;\n",
      "• có khả năng làm việc độc lập;\n",
      "• có kỹ năng về phân tích định lượng, tư duy logic, giải quyết vấn đề\n",
      "• sử dụng thành thạo tin học văn phòng (word, excel…); sql; vba...\n",
      "\n",
      "\n",
      "job tags:\n",
      "chuyên viên kế hoạch\n",
      "nhân viên kế hoạch\n",
      "planning specialist\n",
      "nhân viên kế hoạch thư ký\n",
      "planning staff\n",
      "strategic planning executive\n",
      "strategic planning staff\n",
      "chuyên viên phân tích kinh doanh\n",
      "chuyên viên phân tích kinh doanh\n",
      "\n",
      "nan\n",
      "experience\n",
      "\n",
      "- bachelor degree in it/ computer science or relevant background.- have at least 5 year of experience in the relevant technologies.- expertise in implementation of modern data warehouse and lakehouse solutions, data quality and metadata management.- strong experience with azure synapse analytics, dedicated and serverless sql pools, adls gen2, azure data factory, databricks, stream analytics.- extensive etl/elt experience with azure data movement and transformation capabilities (azure synapse pipelines, azure data flow).- excellent working knowledge on sql/tsql.- deep knowledge of azure synapse data pipeline orchestration and computation framework azure synapse with spark pools.- strong experience on data modelling of dimensional, temporal, slowly changing dimensions and full/incremental/delta data loading processes.- familiarity with data visualization techniques using power bi cloud, tableau is a plus.- microsoft azure data engineer associate (dp-203) preferred.- good at english communication skills.\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "why bosch?because we don't just follow trends, we create them.because together we turn ideas into reality, working every day to make the world of tomorrow a better place. do you have high standards when it comes to your job? so do we. at bosch, you will discover more than just work.benefits and career opportunities\n",
      "working in one of the best places to work in vietnam\n",
      "join a dynamic and fast growing global company (english-speaking environment)\n",
      "\n",
      "13th-month salary bonus + attractive performance bonus (you'll love it!) + annual performance appraisal\n",
      "\n",
      "100% monthly basic salary and mandatory social insurances in 2-month probation\n",
      "\n",
      "onsite opportunities: short-term and long-term assignments\n",
      "\n",
      "15++ days of annual leave + 1 day of birthday leave\n",
      "premium health insurance for employee and 02 family members\n",
      "\n",
      "flexible working time\n",
      "lunch and parking allowance\n",
      "various training on hot-trend technologies/ foreign language (english/chinese/japanese) and soft-skills\n",
      "\n",
      "fitness & sport activities: football, badminton, yoga, aerobic\n",
      "free in-house entertainment facilities and snack\n",
      "join in various team building, company trip, year-end party, tech talks and a lot of charity events\n",
      "\n",
      "\n",
      "nan\n",
      "experience.\n",
      "collaborating closely with various teams, including game designers, developers, ua, and product managers, to comprehend game objectives and offer data-driven recommendations.\n",
      "creating and maintaining comprehensive dashboards, reports, and visualizations to effectively communicate key performance indicators to stakeholders.\n",
      "identifying potential areas of growth and optimization through the analysis of player behavior, in-game economy, and content performance.\n",
      "designing and implementing a/b tests to evaluate the effectiveness of proposed changes and support informed decision-making.\n",
      "continuously monitoring and analyzing game performance to ensure product goals are met and to inform future development strategies.\n",
      "staying current with industry trends, tools, and best practices in gaming analytics to drive ongoing improvement within the team.\n",
      "\n",
      "\n",
      "your skills and experience\n",
      "\n",
      "\n",
      "bachelor's or master's degree in computer science, statistics, mathematics, or a related field.\n",
      "a minimum of 2 years of experience in data analytics, preferably within the gaming industry.\n",
      "proficiency in sql and experience handling large datasets and complex data structures.\n",
      "familiarity with data visualization tools (e.g., looker studio, power bi) and a strong ability to present data effectively.\n",
      "proficient in statistical analysis and data modeling techniques.\n",
      "experience with a/b testing and experimental design principles.\n",
      "exceptional problem-solving skills and a keen eye for detail.\n",
      "excellent communication and teamwork abilities, with the capacity to work well in a dynamic, team-focused environment.\n",
      "a passion for gaming and a deep understanding of game mechanics and player behavior.\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "\n",
      "great facility to work. you will have a macbook and extra high definition screens\n",
      "remote work 12 days / annual leave 12 days / sick leave 2 days\n",
      "premium health insurance package for you and your relatives\n",
      "annual health check-up at the premium clinic\n",
      "development opportunity: sponsorship for all training courses includes business english...\n",
      "interesting workout activities: gym/fitness, yoga, kick-boxing, football after work\n",
      "with regular discussions, you will have a lot of opportunities to learn from experts in their fields\n",
      "13th-month salary + annual bonus + project bonus\n",
      "twice yearly performance review and one-time salary review per year\n",
      "reward & recognition in mobile platform\n",
      "international opportunity to expose and grow\n",
      "professional, creative working environment and talented teams, equal-opportunities & agile culture\n",
      "at least one abroad travel every year. we often send our elites to international conferences like gdc, wwdc, google i/o... to update the latest technology\n",
      "1-2 annual luxury company trip, team building\n",
      "free food & drinks, kitchen at work, playstation & billiards corner\n",
      "friday evening party, happy hours, team activities, and awesome parties\n",
      "the remaining annual leave will be transferred to the next working year\n",
      "additional allowance, gifts for birthdays, giving-birth, weddings, illness, mid-autumn festival, lunar new year, 1/1, 1/5, 1/6…\n",
      "paternity leave policy offers more than 10 days of paid leave, not including days-off according to vietnam labor law regulations\n",
      "free parking\n",
      "\n",
      "\n",
      "nan\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "- tốt nghiệp đại học trở lên các chuyên ngành công nghệ thông tin hoặc các ngành có liên quan.- tiếng anh: khả năng giao tiếp; đọc hiểu tài liệu kỹ thuật.có ít nhất một trong các nhóm kỹ năng sau:- nắm vững kiến thức về database (oracle, sql, server), thành thạo pl/sql và các công cụ tích hợp dữ liệu elt.- có kinh nghiệm tối thiểu 1 năm làm việc với các công cụ bi (obiee/oas)- có kinh nghiệm tối thiều 1 năm phân tích dữ liệu, sử dụng các ngôn ngữ r, python,... sử dụng công cụ sas.có các kinh nghiệm sau là lợi thế:- có các chứng chỉ công nghệ liên quan đến hệ thống mis/dw như: oracle,bi, data analytics .- có kinh nghiệm sử dụng công cụ etl: datastage, ssis, odi, informatica,.. \n",
      "yêu cầu ứng viên\n",
      "- tốt nghiệp đại học trở lên chuyên ngành liên quan đến digital marketing, market research, toán, khoa học máy tính, quản trị thông tin, công nghệ thông tin, thống kê,....- có kỹ năng đọc và viết tiếng anh tốt- biết và code cơ bản r, python- sử dụng thành thạo công cụ phổ biến như: google data studio, sql server, powerbi, tableau, sas…- có kỹ năng sử dụng các công cụ visualize để chuyển hóa dữ liệu thành graphics; kỹ năng chuyển hóa dữ liệu thành actionable insight- có kỹ năng phân tích sắc bén, khả năng thu thập, tổ chức, phân tích và phổ biến lớn thông tin một cách chi tiết và chính xác- có kỹ năng lập kế hoạch, kiểm soát việc thực hiện kế hoạch- có ít nhất 03 năm kinh nghiệm trong lĩnh vực phân tích dữ liệu- kỹ năng áp dụng kỹ thuật trực quan hóa và khám phá dữ liệu hiện đại để cung cấp thông tin chi tiết hữu ích\n",
      "quyền lợi\n",
      "- được hưởng đầy đủ các chế độ phúc lợi xã hội như: bhyt, bhxh, bh thất nghiệp và nghỉ mát hàng năm;- mức lương thỏa thuận đảm bảo xứng đáng với sự đóng góp của mỗi người. cơ chế lương thưởng linh hoạt và khuyến khích sự phát triển của mỗi cá nhân.- môi trường làm việc chuyên nghiệp, sáng tạo, được đào tạo nâng cao kĩ năng trong quá trình làm việc, có nhiều cơ hội khẳng định bản thân và thăng tiến trong nghề nghiệp.- thời gian làm việc: 8h30 - 17h30 các ngày từ thứ 2 đến thứ 6 trong tuần;- nghỉ thứ 7, chủ nhật và các ngày lễ khác, phép năm theo quy định của luật lao động.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 30/06/2023\n",
      "\n",
      "\n",
      "\n",
      "experience in online education.about usfluentu is an online education company that helps people learn languages with real-world videos, including movie trailers, music videos, news and inspiring talks. we have a website, ios app (usually among the top 50 grossing ios education apps), and android app. founded in 2011, we’re a profitable, stable company with long-term focus, and we’re proudly self-funded. and we've been remote/distributed since day one.we get 5 million visitors per month on our blogs, 100,000+ people on our email list, and many more receiving web and mobile notifications.this is a unique opportunity to play a pivotal role on our business intelligence strategy, which is still in the early stages. we've worked with a reputable consultancy until now, and you'll be our first dedicated hire focused specifically on bi data engineering, empowered to build a program from the foundation up.job descriptionas our first analytics engineer, you will be responsible for:working in an agile/kanban style methodology while balancing long-term data modeling & infrastructure planninginterpreting & executing analytics feature requests from senior stakeholdersplanning & documenting work to be done, with regular feedback to stakeholders to minimize unnecessary workmaintaining & improving the entire data pipeline from start to finish, from extracting data from saas api's to configuring display options/creating charts for end users in looker, eg:using data-extractor-as-a-service tools such as stitch to extract data on a scheduled basis & oversee automated loading behaviorcreating & maintaining proprietary extraction tools, such as bash scripts on google cloud instancesmanaging the dbt etl pipelineacting as looker admin (development, security & administration)using software engineering best-practices (such as version control, component-based software/architecture, dry code etc).implementing testing frameworks & subjecting all work to qayou would work closely with the founder of fluentu and our other leadership.how we workwe’re a 100% distributed/remote team. here’s a little bit more about how we work:almost all of our communication is text-based (mostly via asana) and we value clear communication, among other things.most things are not urgent. we take pride in having a calm work environment.we also have a flat collaborative environment.we make decisions based on logic/reason.we believe in getting things done and continuous improvement.qualificationsour ideal candidate:can work in a fast-paced environment and be responsive to new requirementsis terrific at written communicationcan explain technical concepts to a non-technical audienceunderstands basic principles around content marketingis comfortable managing their own time and workflow independentlycan juggle multiple projects & work streams concurrentlyhas most or all of the following technical skills:experience working collaboratively using githas strong sql skills (we use bigquery standard sql)understands data modelling concepts, à la kimball dimensional modellingexceptional understanding of data manipulation (ie joins, data granularity, referential integrity, uniqueness/primary/foreign keys etc)some knowledge of sql database performancelooker, dbt & google cloud knowledge (can be easily learned if you possess the above skills)ideally linux/cloud architecture & python skills but these are not mandatory.has a deep interest in language learning or online education.is able to work a minimum of 25+ hours per week (pay is hourly) and is looking for something long-term.how to applyplease click here and fill out the form.\n",
      "\n",
      "\n",
      "experience. we stand for benchmark-setting customer service, delivery options, returns policies, and curation of brands.the data squadour data team knows our customers and their shopping habits better than they do. have you ever noticed suggested items when shopping online? or maybe a matching item for something you have just added to your bag? that’s our team!\n",
      "experience etc.)\n",
      "nan\n",
      "job requirementph.d. or m.s. degree from a leading university in a quantitative or highly analytical field (e.g.\n",
      "experience in cybersecurity incident handling and experience in security operation center in banking/finance.\n",
      "knowledge of security policy and technical standard development, multi-tiered trust zone structures, and complex edr, xdr management systems.\n",
      "experience with splunk and other similar tools/platforms.\n",
      "experience in improving and automating reports.\n",
      "programming or scripting experience with python or others.\n",
      "strong verbal and writing english skills\n",
      "attention to detail and task completeness\n",
      "a self-starter who can work unsupervised and delivery on their commitments\n",
      "strong interpersonal and communication skills with the ability to lead and work as part of a team\n",
      "knowledge with iso 27000 series, nist scf…\n",
      "\n",
      "yêu cầu ứng viên\n",
      "tốt nghiệp chính quy loại khá trở lên chuyên ngành khoa học máy tính, cntt, toán học ứng dụng, điện tử; ..trình độ tiếng anh toeic 650 trở lên hoặc tương đươngkinh nghiệm 1 năm trở lên với vai trò ai engineer hoặc tương đươngưu tiên: đã tham gia xây dựng, triển khai >= 2 sản phẩm, giải pháp ai\n",
      "quyền lợi\n",
      "chế độ lương thưởng hấp dẫn với lương tháng 13đánh giá hiệu suất: 2 lần/nămcơ hội thăng tiến và thu nhập phù hợp tùy vào chuyên môn hoặc khả năng quản lý.được học hỏi: sds tạo điều kiện cho mọi người rèn luyện ở mọi lúc mọi nơi, đồng hành và thúc đẩy phát triển cá nhân từ đồng nghiệp và quản lý giàu kinh nghiệmđược thử sức trong một môi trường làm việc trẻ trung, cởi mở với chính sách đãi ngộ tốtdu lịch hằng năm với địa điểm hấp dẫn, thường xuyên tổ chức các hoạt động team building gắn kết cộng đồng, các hoạt động vui chơi giải trí cho nhân viên.tham gia chương trình hàng tháng, các buổi liên hoan, sinh nhật hàng tháng, tiệc noel, tất niên,…được tham gia bhxh, bhyt, bhtn, chế độ nghỉ phép \n",
      "nan\n",
      "job requirements:\n",
      "\n",
      "bachelor’s degree in marketing, economics, business administration, or related fields.\n",
      "at least 1 year experience in a research/insight role or related position.\n",
      "having experience in social listening is an advantage.\n",
      "working at an agency is a plus.\n",
      "be enthusiastic about social media empowerment and its possibilities to build strong brand propositions.\n",
      "be convenient for analyzing a variety of data types (number, text, image…) analysis.\n",
      "good at analytical and report writing skills.\n",
      "trend catching.\n",
      "willingness to analyze data points for large databases.\n",
      "strong interpersonal, negotiation and communication skills for liaising with colleagues, customers..\n",
      "english proficiency, especially in developing reports.\n",
      "proficient in office informatics, especially excel and powerpoint.\n",
      "\n",
      "why you’ll love working here: \n",
      "\n",
      "young, dynamic environment and freedom to creative.\n",
      "transparency and honesty are the 2 factors from our core value.\n",
      "trust with customer and commitment through standard quality products and solutions.\n",
      "human oriented.\n",
      "\n",
      "benefits include: \n",
      "\n",
      "100% salary during probation.\n",
      "working monday – friday.\n",
      "company trip, team-building and other social activities.\n",
      "work from home policy\n",
      "salary bonus, performance review\n",
      "gifts on holidays, birthday\n",
      "13th-month salary\n",
      "training-on-the-job\n",
      "\n",
      "contact info:\n",
      "\n",
      "email: recruitment@kompa.ai\n",
      "facebook: kompa life\n",
      "\n",
      "kinh nghiệm về data streaming (kafka/ storm/ samza/ aws kinesis...)- có kinh nghiệm sử dụng message queue (rabbitmq / google pubsub/ aws sns/ active mq)\n",
      "nan\n",
      "experience in data/software engineering in a highly scalable production environment\n",
      "2 years of experience developing data warehouses on snowflake platform, required\n",
      "good knowledge of architecting large-scale data infrastructure in the cloud platform good knowledge of big data technologies like hadoop,hive,spark, redshift aws or other real-time streaming\n",
      "good knowledge of server-side programming languages (preferably python) and golang.\n",
      "devops experience (devops or gitlab) delivering continuous improvements\n",
      "data visualization and dashboarding experience (power bi, tableau, etc.)\n",
      "experience working in unix/linux; familiar with bash scripting\n",
      "– the candidate must have knowledge of computer systems, object oriented design, data structures and algorithms and familiarity with at least one major programming language (perl, python, java, c++), experience with relational databases (mysql)\n",
      "– bachelor’s degree required; degree in computer science/electrical engineering or\n",
      "related field preferred\n",
      "– strong written and verbal communication skills\n",
      "– excellent analytical skills and a passion for solving problems\n",
      "– be detail oriented and capable of multitasking and delivering in fast-paced work environment\n",
      "\n",
      "yêu cầu ứng viên\n",
      "học vấn: tốt nghiệp đại học các chuyên ngành: qtkd/ kinh tế/ toán tin ứng dụng/toán thống kê/ tài chính hoặc các ngành có liên quan.kinh nghiệm từ 1-3 năm tại vị trí tương đương ngành hàng bán lẻ, chuỗi siêu thị, fmcg ...kỹ năng cần thiết: phân tích dữ liệu (excel, power bi, ...)kỹ năng trình bày báo cáo, thuyết trìnhtư duy logic\n",
      "quyền lợi\n",
      "lương cạnh tranh, lương tháng 13++, thưởng cuối năm.phụ cấp cơm 50.000/ngàythời gian làm việc: từ 8h-17h00, t2-t6phụ cấp ngoại ngữ hấp dẫn, lên đến 3.000.000/tháng (anh, hàn)chế độ bhxh, bhyt, bhtn trên tổng thu nhập; bảo hiểm tai nạn 24h; bảo hiểm chăm sóc sức khỏe.môi trường làm việc năng động, có nhiều cơ hội đào tạo và thăng tiến.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "hết hạn nộp đơn\n",
      "\n",
      "experience in power bi developmenthands-on experience in sql query in sql serverhands-on experience in sql server integration services (ssis)hands-on experience in  sql server reporting services (ssrs)good at unit testing and integration test strategieswilling to support team members/others on db-related tasksgood english communication skillsmust be able to multi-task and deal with changing prioritiesadditional informationwhy bosch?because we don't just follow trends, we create them.because together we turn ideas into reality, working every day to make the world of tomorrow a better place. do you have high standards when it comes to your job? so do we. at bosch, you will discover more than just work.benefits and career opportunitiesworking in one of the best places to work in vietnamjoin a dynamic and fast growing global company (english-speaking environment)13th-month salary bonus + attractive performance bonus (you'll love it!) + annual performance appraisal100% monthly basic salary and mandatory social insurances in 2-month probationonsite opportunities: short-term and long-term assignments15++ days of annual leave + 1 day of birthday leavepremium health insurance for employee and 02 family membersflexible working timelunch and parking allowancevarious training on hot-trend technologies/ foreign language (english/chinese/japanese) and soft-skillsfitness & sport activities: football, badminton, yoga, aerobicfree in-house entertainment facilities and snackjoin in various team building, company trip, year-end party, tech talks and a lot of charity event\n",
      "nan\n",
      "nan\n",
      "kinh nghiệm\n",
      "\n",
      "ít nhất 5 năm kinh nghiệm trong mảng phân tích số liệu (bi).\n",
      "ít nhất 2 năm kinh nghiệm quản lý đội ngũ phân tích số liệu có từ 3 chuyên viên trở lên.\n",
      "\n",
      "3. kỹ năng, yêu cầu khác\n",
      "\n",
      "am hiểu sản phẩm, dịch vụ ngành ngân hàng.\n",
      "kỹ năng phân tích và giải quyết vấn đề tốt.\n",
      "kỹ năng giao tiếp, thuyết trình, thuyết phục và quản lý dự án tốt.\n",
      "quen thuộc với cơ sở dữ liệu (sử dụng ngôn ngữ sql), hiểu được mô hình dữ liệu và các liên hệ. có thể làm việc được với các kỹ sư dữ liệu và chuyên viên phân tích dữ liệu để xây dựng các bảng dữ liệu, các data marts cần cho công việc của bộ phận.\n",
      "có kỹ năng xây dựng dashboard bằng các công cụ như power bi, data studio ….\n",
      "quen thuộc với python và các công cụ để hỗ trợ xử lý dữ liệu lớn.\n",
      "\n",
      "nan\n",
      "experience in relevant domain (crm, big data, business intelligence, analytics reporting).\n",
      "experience with etl, data management, transformation, and modelling•experience with cloud technologies•required knowledge in sql, c#, .net.\n",
      "experience with reporting service like ssrs.\n",
      "knowledge and experience in end-to-end project delivery, hybrid / agile delivery methodologies•previous experience as a data engineer or in a similar role.\n",
      "technical expertise with data models, data mining, and segmentation techniques.\n",
      "knowledge of programming languages •hands-on experience with sql database design.\n",
      "great numerical and analytical skills•degree in computer science, it, or similar field•data engineering certification will be plus•good communication skill.\n",
      "\n",
      "qualification\n",
      "\n",
      "bachelors or masters in it or computer science.\n",
      "master or equivalent.\n",
      "\n",
      "soft skills\n",
      "\n",
      "excellent written and verbalcommunication skills.\n",
      "capacity to manage high stress situations.\n",
      "ability to multi-task and manage various project elements simultaneously.\n",
      "leadership skills•big picture thinking and vision.\n",
      "attention to detail•conflict resolution skills.\n",
      "\n",
      "to apply for an interview with savills, please send your cv (with your photo attached) and a clear summary of why you believe you have a strong fit with savills. further to specific advertised vacancies, savills vietnam encourages applications from talented individuals who feel they have what it takes to succeed at savills and in the real estate market.\n",
      "for career opportunities, please email your cv and cover letter to careers-hcmc@savills.com.vn\n",
      "apply now\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "experience in developing machine learning/data science applicationstrong experience in computer visionstrong programming skills in python, javascriptgood foundation in math and algorithmshave knowledge of neural networksexperience in using ml frameworks such as tensorflow/ keras/ pytorchadditional informationperks you'll enjoy\n",
      "nan\n",
      "kinh nghiệm sẽ thỏa thuận dựa trên năng lực, đảm bảo mức cạnh tranh so với thị trường.\n",
      "- hưởng từ 13-16 tháng lương/năm, chưa tính các khoản thưởng khác.\n",
      "- được tham gia vào các dự án lớn đang đang triển khai tại các cơ quan nhà nước, các tập đoàn, \n",
      "nan\n",
      "yêu cầu công việc\n",
      "\n",
      "• bachelor degree in supply chain management, business analytics, business administration\n",
      "• more than 2\n",
      "nan\n",
      "nan\n",
      "experienced leadership team, owning more than 40% of our equity, have delivered industry-leading investment returns for shareholders.job descriptionfollow line manager to lead the team conducting the valuation for residential & commercial real estate properties.build, maintain, expanse and enhance client relationships in order to achieve the business plan for valuation & advisory team.responsible for administering, managing and controlling the operation of the team to achieve the business performance as well as to ensure compliance of valuation standards (both international and vietnam), vietnam laws. ensuring that all policies and procedures are adhered to so that consistent and standard practice is achieved across the colliers group.recruit, supervising, training, developing staff on valuation and client requirements as well as assessing staff performance. leading and training the team in valuation approach (income approach; market approach, cost approach), carry out feasibility study and market research, highest and best use report for real estate development consulting.design and implement databases for ease of reference of up-to-date market information and establish systems to ensure that those databases are accurate and up to date at all times.prepare as required market weekly and monthly reports and other studies, documents as instructed by the line manager.at all times to be aware of activity within the marketplace relevant to your field of operation and be mindful of developing such information received into business opportunities for the company.various other job related tasks as assigned by the bod.qualificationsbachelor's degree in finance, economics or related fieldmof license or mrics is in a must.5+ years of property valuation consulting experience.in-depth knowledge of valuation approaches: cost, market, and income approach; experience in financial modelling, real estate project feasibility study.strong analytical and problem-solving skills, as well as strong team building, interpersonal and communication skills (both written and oral).presentation skill is required.ability to work independently, exercising good initiative and judgementproficiency with microsoft excel, word, and powerpoint.flexibility for travel to conduct the sites inspection and market research\n",
      "experience as a developer\n",
      "    knowledge of oracle / pro c / pl-sql\n",
      "    good command of french is a plus\n",
      "    experience with network programing, unit environment and good knowledge of the voip network is a plus.\n",
      "\n",
      "personality requirements\n",
      "\n",
      "- hard working, responsible, creative, strong interpersonal and communication skills.\n",
      "\n",
      "- ability of working independent and teamwork\n",
      "\n",
      "\t                \t                    we offer: \n",
      "\t                \t            \n",
      "successful candidate will come in one of the european subsidiaries for 3 months internal training to our methods and product.\n",
      "opportunity to work with international company, high reputation clients on the financial, commercial financial fields: silicon valley bank, bnp parisbas, societe generale, ge capital, ups capital kbc, barclays, bbva, france telecom orange, etc.\n",
      "salary range: attractive, or negotiable depending your expertise and experience.\n",
      "social and health insurance: according to the current government regulations competitive remuneration package including performance driven benefits:soft skill training, 13th month salary, project bonus, loyalty program (3% of your total annual income), key person package (yearly bonus, monthly telephone fee, health insurance for your dependents), additional health care program - generali, annual health examination, lunch allowance (840,000 vnd/month), activities: company trip, football, volleyball ...\n",
      "trainings and continuous investment into your professional development\n",
      "friendly work environment with international working standards\n",
      "                                                send your cv by clicking \n",
      "                            \n",
      "                                here. apply now!\n",
      "                            we are eager to meet you!\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "senior business intelligence analyst (bangkok based, relocation provided)\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "- tốt nghiệp đại học, cao đẳng về chuyên ngành kinh doanh, công nghệ thông tin, toán học hoặc các chuyên ngành liên quan khác.- có kinh nghiệm làm việc trong ngành phân tích dữ liệu là một lợi thế. hoặc bạn sẽ phải chấp nhận làm thực tập sinh hoặc nhân viên học việc tại các doanh nghiệp.- có khả năng sử dụng các công cụ, phần mềm phân tích dữ liệu- có khả năng code cơ bản với các ngôn ngữ lập trình như sql, python để xử lý mô hình dự báo.- có kỹ năng phân tích sắc bén, khả năng thu thập, tổ chức, phân tích và phổ biến lượng lớn thông tin một cách chi tiết và chính xác- kỹ năng lập kế hoạch, kiểm soát việc thực hiện kế hoạch.- cẩn thận, kiên nhẫn, chịu khó, ham học hỏi, có tinh thần trách nhiệm\n",
      "quyền lợi\n",
      "'- mức lương: \n",
      "nan\n",
      "job requirement:minimum 4 years experience in it, data analyzing, building system for employee information management.familiar with power bi, sql, excelbachelor/ college degree in hr, business administration, it or related field.good communication in english and presentation skills.high pressure ability\n",
      "\n",
      "experience on machine learning, deep learning, statistics\n",
      "skillful in using excel, powerpoint and word as the primary working tools\n",
      "\n",
      "3/ skills\n",
      "\n",
      "quick and flexible learning skills to adapt to new things and work on multiple tasks\n",
      "skill of communication, human relations, building relationships with stakeholders.\n",
      "identification and problem-solving skills\n",
      "critical thinking skills\n",
      "teamwork skill\n",
      "presentation and negotiation skills\n",
      "analysis and conflict management skills\n",
      "coordinating personnel and work skills\n",
      "building relationships with customers skills\n",
      "\n",
      "4/ relevant experiences\n",
      "\n",
      "+3 years of experience in advanced analytics/ machine learning/ deep learning\n",
      "having a broad knowledge of business related to advanced analysis\n",
      "\n",
      "5/ personal characteristic\n",
      "\n",
      "high sense of responsibility, honest, careful, accurate and sensitive in work\n",
      "creativity and creating team spirit\n",
      "be proactive and enthusiastic in work\n",
      "confident, creative, dynamic\n",
      "high customer service spirit\n",
      "have the spirit of cooperation and support each other\n",
      "\n",
      "experience in sales, management, customer service, finance, administration, or related field;have business knowledge, grasp the psychology and behavior of customers;data-driven decision-making;programming (python, sql) and data science knowledge is a plus;strong verbal and written communication skills;analytical mind for problem-solving;actively innovative attitude; well-ordered method of working.benefitssalary range: up to 25m/month;competitive salary and benefits (macbook & pvi insurance);13th salary & performance pay;on-job training about programming languages (python, sql) and tools/ platforms (metabase, integromat, hubspot, data studio, zendesk, coda);working 5 days/week;yearly performance review;regular team building events, happy hour,...;sharp, motivated creative and supportive colleagues in a fun office environment;address: rivera park tower, 7/28 thanh thai street, 10 ward, ho chi minh city\n",
      "yêu cầu ứng viên\n",
      "sinh viên năm 2, năm 3, ưu tiên các bạn yêu thích ngành marketing, digital marketing, market research.\n",
      "- yêu thích công việc trên máy tính, làm việc với con số và chữ, có khả năng tìm kiếm trên google, am hiểu internet, các mạng xã hội.\n",
      "- yêu cầu tính cách: cẩn thận, kiên nhẫn, chịu khó, ham học hỏi, có tinh thần trách nhiệm và tự giác\n",
      "- yêu cầu kỹ năng: microsoft office (word, excel, powerpoint), spss,…\n",
      "- thời gian làm việc: full-time/part-time\n",
      "trong cv yêu cầu ghi rõ về kinh nghiệm làm việc và quá trình học tập của bản thân.\n",
      "quyền lợi\n",
      "- được huấn luyện chi tiết các kĩ năng thu thập và phân tích dữ liệu, cơ hội cập nhật thông tin và xu hướng thị trường\n",
      "- theo đuổi định hướng chuyên sâu ngành marketing, digital marketing hoặc market research\n",
      "- được làm việc trong môi trường chuyên nghiệp, vui vẻ và hòa đồng.\n",
      "\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 17/06/2023\n",
      "\n",
      "\n",
      "\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "yêu cầu công việc\n",
      "\n",
      "có kiến thức về phương pháp luận phân tích dữ liệu toán thống kê và phân tích định lượng.\n",
      "có kiến thức chung về hoạt động quản trị kinh doanh, mô hình kinh doanh\n",
      "có am hiểu chuyên sâu về mô hình giá/phí của các sản phẩm trong dịch vụ ngân hàng.\n",
      "kỹ năng phân tích, kỹ năng lập kế hoạch, thống kê tổng hợp số liệu, tư duy kinh doanh\n",
      "có khả năng diễn giải dữ liệu, kết quả, báo cáo phân tích bằng ngôn ngữ kinh doanh\n",
      "có kỹ năng làm việc và giao tiếp với các bên liên quan, có tư duy logic, kỹ năng giải quyết vấn đề\n",
      "có khả năng tự định hướng và tính tự tổ chức cao\n",
      "tư duy phản biện: có thể xử lý dữ liệu theo cách để đưa ra các đề xuất cần có tư duy phản biện.\n",
      "tốt nghiệp đại học trở lên với chuyên ngành tập trung vào tài chính, ngân hàng, quản trị kinh doanh,\n",
      "có ít nhất 2 năm kinh nghiệm chuyên môn trong lĩnh vực tài chính/ngân hàng\n",
      "kinh nghiệm phân tích kinh doanh tối thiểu 1 năm.\n",
      "có kinh nghiệm liên quan đến xây dựng và quản trị mô hình tài chính\n",
      "thành thạo power bi, excel, spss, python…\n",
      "\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "experience working in the solution architect position\n",
      "\n",
      "\t\tstrong knowledge about tech-stacks:\n",
      "\n",
      "\n",
      "\n",
      "fullstack: django / mysql / jquery / bootstrap / docker\n",
      "\n",
      "se: c++, python\n",
      "\n",
      "cloud: aws (ec2, api gateway, lamda, vpc, …)\n",
      "\n",
      "\n",
      "\n",
      "\t\tproven experience in developing strategic system architecture plans\n",
      "\n",
      "\t\texperience in designing vms (video management system), cloud systems\n",
      "\n",
      "\t\tstrong knowledge of software evaluation principles and practices\n",
      "\n",
      "\t\tsolid understanding of information processing fundamentals and best practices\n",
      "\n",
      "\t\texcellent written and verbal communication skills\n",
      "\n",
      "\t\texperience conducting technology, trends, standards and products research\n",
      "\n",
      "\t\tsolid track record in prioritizing and executing tasks when under extreme pressure\n",
      "\n",
      "\t\texperience providing guidance and leadership to novice systems engineers\n",
      "\n",
      "\t\tproven experience identifying, analyzing and resolving system problems\n",
      "\n",
      "\t\tbusiness english\n",
      "\n",
      "\n",
      "\t\n",
      "yêu cầu công việc\n",
      "\n",
      "• university graduate major: economics/ management/banking/ finance\n",
      "• at least 3 years in banking industry, in which at least 1 year working in operations of a bank.\n",
      "• having knowledge & experience at planning/ performance management/ analytics role in financial service is an advantage.\n",
      "• good understanding of data modelling and prediction.\n",
      "• strong critical & analytical thinking\n",
      "• logical & assertive communication\n",
      "• influencing skill\n",
      "• curiosity, agility, high adaptability to vuca contexts & demanding stakeholders\n",
      "• passionate, proactive, self-motivated\n",
      "benefits\n",
      "• attractive income, competitive salary and bonus according to ability\n",
      "• bonus on holidays and new year (according to banking policy from time to time)\n",
      "get preferential loans according to the bank's policy from time to time\n",
      "• attractive leave mode according to job rank\n",
      "• compulsory insurance according to labor law & vpbank care insurance for employees depending on rank and working time\n",
      "• participate in training courses depending on the training framework for each position\n",
      "• working time: monday - friday & saturday morning (two saturday mornings/month off)\n",
      "• dynamic, friendly working environment with many opportunities for training, learning and development; participate in many interesting cultural activities (sports event, talents, teambuilding activities...)\n",
      "\n",
      "\n",
      "job tags:\n",
      "head of performance management - hanoi - ta\n",
      "head of performance management operation division - hanoi - ta\n",
      "\n",
      "experience in the e-commerce industry.\n",
      "we are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end-to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\n",
      "\n",
      "i. job descriptions\n",
      "\n",
      "•\tbe responsible for strategic analysis and recommendations directly for board of directors. be actively involved in and provide an input into the strategic planning process for a company’s business that currently operated in usa and is expanding to international markets.\n",
      "•\tbe accountable for monthly strategic reports which using wide range of data to provide meaningful insight and assists in business strategy at the highest level.\n",
      "•\tresponsible for the detail of management dashboard metric and data analysis.\n",
      "•\tconduct project management in a wide range of insightful and strategic research for the senior leadership team gain a deeper understanding of existing and new markets (including detailed market sizing and market share analysis), as well as enhance knowledge of key competitors in each of our markets.\n",
      "•\tresponsible for identifying not only key business opportunities but also potential risks, putting forward recommendations and presenting the conclusions to the leadership team for consideration\n",
      "•\tclosely work with internal stakeholders in different departments to clarify and suggest any improvement in processes, business strategy and risk managements.\n",
      "•\treview internal business operation, consolidating reports and challenging the financial indicators, market sizing assumptions, business opportunities, product qualities, saving, customers review and others business aspects from different departments.\n",
      "•\tleverage insights to evaluate organizational operation health, identify potential business issues, and potential growth. connecting all the dots from internal to external data to assist corporate development senior manager and strategy director to define segment’s future short, medium and long-term strategy.\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "nan\n",
      "experience in budget controlling, forecasting, and budgeting. a candidate who used to work in big 4 firms is preferable.good knowledge in ifrs, vas and tax laws/regulations.ms. office (word, excel, power-point), data knowledge and process, sql or power bi skill is an advantage.strong written and spoken english language skills, including the ability to structure communications clearly, confidently, and logically.hard-working, honest, and self-responsibility. able to work under high pressure\n",
      "experience in it and 5+ year of\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      " completion of a degree or diploma in computer science, information technology, engineering or a related discipline. english proficiency is required at least three years of hands-on experience, preferably in big data infrastructure experienced with data-lake, data warehouse, data mart have experience with a programming language (python / go / javascript) for data processing and analysis. experience designing sql tables, indexing, tuning queries, and optimizations across different functional environments\n",
      "experience range: from 3 years\n",
      "job location: hcmc\n",
      "duty & responsibilities:\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tyou will be responsible for building and running the data processing pipeline on google cloud platform \n",
      "– work with implementation teams from concept to operations, providing deep technical expertise for successfully deploying large scale data solutions in the enterprise, using modern data/analytics technologies on gcp\n",
      "– design pipelines and architectures for data processing\n",
      "– implement methods for devops automation of all parts of the build data pipelines to deploy from development to production\n",
      "– formulate business problems as technical data problems while ensuring key business drivers are captured in collaboration with product management\n",
      "– extract, load, transform, clean and validate data\n",
      "– supporting and debugging data pipelines \n",
      "\n",
      "requirements: \n",
      "\t\t\t\t\t\t\t\t\t\t\tmust-have requirements\n",
      "– at least 4 years of experience working as a data engineer\n",
      "– good development experience in data warehouse platform\n",
      "– experience with data staging, data transformation and change data management\n",
      "– good experience in advanced sql\n",
      "– good python skills\n",
      "– experience in a cloud datawarehouse platform (can be any but big query is mostly preferred)\n",
      "– good command of english communication\n",
      "good-to-have requirements\n",
      "– experience with gcp\n",
      "– relative experience in containerization: docker and kubernetes\n",
      "– relative experience in declarative ci/cd or devops\n",
      "– relative experience in infrastructure as a code (iaac) (i.e., terraform, cloud build)\n",
      "– experience with automated testing (ideally robot framework)\n",
      "– relative experience in data management: data governance, data architecture, data modelling, data quality, data integration\n",
      "preferred language for application: english\n",
      "\n",
      "nan\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "at least 3 years experience in administration or financial service sectorgood computer skill (especially in ms excel, power bi know-how, word, power point, data analysis), life insurance or accounting is preferable, basic english.bachelor degree (full-time university degree with majors in economics / insurance / business administration / marketing / banking / finance / accounting).good communicate skill, strong interpersonal and customer service skill.carefulness\n",
      "quyền lợi\n",
      "chế độ bảo hiểmdu lịchphụ cấpđồng phụcchế độ thưởngchăm sóc sức khỏeđào tạotăng lươngnghỉ phép năm\n",
      "cách thức ứng tuyển\n",
      "\n",
      "hết hạn nộp đơn\n",
      "\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "tối thiểu 2 kinh nghiệm trong vai trò data engineerkiến thức về lập trình, cấu trúc dữ liệu & giải thuật tốtlập trình thành thạo một trong những ngôn ngữ như python, javathành thạo các ngôn ngữ xử lý dữ liệu như sql, nosql, mongodb, big querykiến thức về lập trình lưu trữ, xử lý dữ liệu phân tán, xử lý dữ liệu lớn (hadoop, spark, elastic search…)kiến thức về xây dựng luồng xử lý dữ liệu (batch processing, stream procesing, ...)khả năng học hỏi và thích ứng nhanh với công nghệ mới.là người tỉ mỉ, năng động và có trách nhiệmbiết quản lý thời gian, có kỹ năng phân tích và giải quyết vấn đềkhả năng làm việc độc lập & làm việc nhómkỹ năng giao tiếp tốt\n",
      "quyền lợi\n",
      "1. mức lương: up to 40.000.000đ2. thời gian, địa điểm làm việctừ thứ hai đến thứ sáu hàng tuần và thứ bảy cách tuần.sáng: \n",
      "yêu cầu công việc\n",
      "bắt buộc\n",
      "– kinh nghiệm làm việc tối thiểu 2 năm trong lĩnh vực data\n",
      "– thành thạo truy vấn sql và các ngôn ngữ tương tự (oracle, mysql, postgresql…)\n",
      "– sử dụng thành thạo bi tools (power bi là điểm cộng) và r/python\n",
      "điểm cộng\n",
      "– có kinh nghiệm triển khai các mô hình phân tích định lượng vào thực tế là lợi thế\n",
      "– ứng viên có kinh nghiệm làm việc trong ngành tài chính nói chung và công ty chứng khoán nói riêng.\n",
      "\n",
      "experience as a financial analyst, financial analyst, financial planning, analysis, modeling, or in a similar position. knowledge of the e-commerce market is preferable.\n",
      "strong critical thinking, analytical thinking, systematic problem-solving skills. \n",
      "high proficiency with the use of ms office, especially excel (intermediate and above). knowing about bi tool is an advantage\n",
      "ability to learn new concepts and tasks quickly, detail-oriented and able to perform in a high-pressure environment.\n",
      "good communication in english spoken & written skills.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "benefits\n",
      "\n",
      "at crossian, our people are the key to our success. we believe in creating an attractive total compensation package (tcp) that not only retains employees but allows them to excel in their profession. these include:\n",
      "competitive gross salary (14-30 million vnđ depending on what you bring to the table)\n",
      "full salary during probation\n",
      "20 days work-from-home & 12 days of paid annual leave\n",
      "global health insurance package for yourself and direct family members\n",
      "guaranteed 13th month salary\n",
      "quarterly bonus & year-end bonus as part of our profit sharing program\n",
      "a pantry & a crossian cafe stocked with goodies, ready to serve\n",
      "lots of other company benefits including 5* annual company trip, budget for frequent team building activities and other monthly / quarterly / annual company events\n",
      "general company t&d program + dedicated t&d budget for managers\n",
      "experienced                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    share\n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mangtas is looking for a data analyst to join our team in our remote office. the data analyst is responsible for managing our master data set and developing respective reports/visualizations.the ideal person for this position has an exceptional eye for detail, expertise as a data analyst, and a solid understanding of popular data analysis tools. he/she will work closely with product owners across various lines of business to understand the objectives of the organization and prioritize any requirements.responsibilities:\n",
      "qualification: bachelor of information technology, computer science or related field eg. business, economic and trading.certificate in da/ba/bigood understanding of etl good knowledge of application & database design and development skills.competencies & skillsgood communication in english (speaking, listening and writing)good collaboration high responsibility, reliability, flexibility and service mind.\n",
      "\n",
      "experience. experience in big4 audit firms and/or logistics industry is preferable.\n",
      "highly analytical and ability to analyze large data sets to extract actionable insights to provide creative recommendations to management and business partners.\n",
      "highly proficiency in excel is a must, knowledge of sql is a plus.\n",
      "highly curious, logical, self-motivated, independent, proactive, and result oriented.\n",
      "ability to work cross-functionally, to thrive in a dynamic and fast-paced environment, and to manage and prioritize multiple projects with tight deadlines.\n",
      "demonstrate strong leadership skills, with exceptional interpersonal and communication skills (both written and verbal) to influence other leaders in finance and business.\n",
      "fluent in english.\n",
      "\n",
      "\n",
      "apply now\n",
      "\n",
      "experiences\n",
      "must have:\n",
      "\n",
      "up to 2-3 years of experience as a data engineer or software engineer.\n",
      "working experience with 1 or more languages / frameworks (java, scala, python).\n",
      "strong interest to learn and develop skills in analyzing and implementing data pipelines for structured and unstructured data.\n",
      "good at multi-threading, atomic operations, computation framework: spark (dataframe, sql,…), distributed storage, distributed computing.\n",
      "experience with aws (ec2, s3, lambda, rds, emr, redshift, glue) is an added advantage.\n",
      "experience with rdbms (postgresql) and nosql (dynamo) databases is an advantage.\n",
      "experience with big data tools (hadoop, spark, kafka) is an added advantage.\n",
      "experience with etl tools (airflow, airbyte, talend) is an added advantage.\n",
      "understand designs of resilience, fault-tolerance, high availability, and high scalability, …\n",
      "tools: ci/cd, gitlab,…\n",
      "good at communication & team working.\n",
      "being open-minded, willing to learn new things.\n",
      "\n",
      "bonus points:\n",
      "\n",
      "cloud experience (aws, gcp, etc), aws is a plus.\n",
      "experience in performance tuning/optimizing big data programs.\n",
      "having knowledge of distributed query engines: presto, hive,…\n",
      "\n",
      "\n",
      "3. why you’ll love working here\n",
      "\n",
      "income = net salary + benefit + performance bonus (>14 months salary).\n",
      "review salary twice per year base on your performance and output.\n",
      "health check once per year.\n",
      "health insurance pvi care if you work here more than one year.\n",
      "enjoy all of our company policies: insurance, vacation, public holiday, party, birthday and more.\n",
      "free coffee, tea and cakes.\n",
      "we have these clubs for you to join: football, table football, music, english, media and more.\n",
      "have a chance to involved and learn from our senior.\n",
      "have our senior to review your works, instruct you during the project using scrum.\n",
      "get advices for career development.\n",
      "\n",
      "working hours: 8h30 am -12h00 pm & 1h00 pm – 5h30 pm. (monday to friday)\n",
      "nan\n",
      "job requirementsjob benefitapply/  refe\n",
      "nan\n",
      "kinh nghiệm về công nghệ lưu trữ và xử lý dữ liệu lớn, lập trình;\n",
      "có khả năng thiết kế và triển khai các mô hình dữ liệu đa chiều, thiết kế pipeline và triển khai các công cụ etl.\n",
      "có kinh nghiệm\n",
      "tư duy tổng thể tốt và có khả năng triển khai chi tiết.\n",
      "ưu tiên:\n",
      "\n",
      "\n",
      "ứng viên có kinh nghiệm trong mảng tài chính, chứng khoán.\n",
      "ứng viên có kinh nghiệm làm việc với azure hoặc aws.\n",
      "có kinh nghiệm xử lý etl dữ liệu với ssis và ssas là một lợi thế.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " quyền lợi: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thời gian làm việc 5 ngày/tuần (từ thứ hai đến thứ sáu).\n",
      "cơ hội thăng tiến, phát triển nghề nghiệp công bằng.\n",
      "thu nhập hấp dẫn, cạnh tranh.\n",
      "được hưởng chế độ bhxh, bhyt, bhtn, bảo hiểm sức khỏe theo quy định của công ty.\n",
      "được tham gia các chương trình đào tạo, huấn luyện của công ty.\n",
      "môi trường làm việc chuyên nghiệp, thân thiện, năng động.\n",
      "mức lương: thỏa thuận\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " hồ sơ yêu cầu: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bản thông tin ứng viên theo mẫu của mbs.\n",
      "các mẫu thông tin ứng viên/cv khác không theo mẫu mbs là hồ sơ không hợp lệ.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " thời hạn nhận hồ sơ:  phỏng vấn cuốn chiếu ngay khi nhận được hồ sơ đến khi tuyển được ứng viên phù hợp\n",
      "nơi nhận hồ sơ: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nộp bản thông tin ứng viên theo mẫu của mbs theo hình thức sau:\n",
      "\n",
      "nộp hồ sơ online trên website tuyển dụng/gửi qua email:\n",
      "nan\n",
      "experience in the e-commerce industry.\n",
      "we are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end-to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\n",
      "i. job descriptions\n",
      "1. supply chain expansion, optimization & process standardization: \n",
      "\n",
      "detect and realize cost - cash - service level optimization opportunities by fine-tuning supply chain configurations and driving for smooth applications: incoterms, lead time, moq, multi-sourcing, port of loading, forms of loading, etc., at product, market and seasonality levels.\n",
      "work on ongoing supply chain development projects, that strongly bond with the hyper growth across product selections, channels, platforms, sources (supply-based) and markets (demand-based) of the company. \n",
      "develop product pricing strategy with sales, marketing and sourcing teams to optimize physical flow and financial flow;\n",
      "involve in supply & demand planning for multinational markets;\n",
      "head to the automation, standardization and scalability of all the expansion projects.\n",
      "\n",
      "2. data analysis, interpretation and visualization: \n",
      "\n",
      "perform operational analytics in various but strongly connected fields: pricing, demand forecast, inventory, sales, etc. with the highest curiosity and eagerness for value creation.\n",
      "collaborate with cross-functional teams to form effective hypotheses based on business needs.\n",
      "test hypotheses; examine the results; do scenario, sensitivity, etc. analyses to spot out growth opportunities.\n",
      "build interactive trackers, creative visualizations as well as concrete management reports to govern project outcomes and support bias-for-action decision-making.\n",
      "conduct deep-dive / root cause analyses for long-term fixes.\n",
      "\n",
      "3. project management: \n",
      "\n",
      "initiate, set up plans and timelines; coordinate and follow up with cross-functional departments to drive the projects.\n",
      "actively communicate the objectives & progress to the stakeholders based on aligned success metrics, deep-dive on arising issues and take reaction plans to ensure high-quality deliverables at a timely manner\n",
      "\n",
      "ii. skill and experience\n",
      "\n",
      "bachelor degree and above in supply chain, business or data analytics.\n",
      "1 year of experience in supply chain/business/data analytics. retail supply chain and/or e-commerce experience is highly valued. fresher with excellent analytical and academic background is also welcome.\n",
      "advanced ms office is compulsory. be fluent in at least one query/code language (r, mysql & python are preferred).\n",
      "great attention to detail, strong analytical and data story-telling sense with a “continuous improvement” mindset.\n",
      "good command of spoken & written english and vietnamese is a must.\n",
      "good at time management, teamwork, and multitasking. have strong ownership and responsibility for deliverables.\n",
      "willing to learn, thrive in a fast-paced environment and have a can-do attitude\n",
      "experience working under linux environment, familiar with vi or emacs for editing files\n",
      "– interested in applying technology to real world situation, comfortable working in fast paced work environment, detail oriented and capable performing tasks under time pressure\n",
      "– experience with programming in c/c++, familiar with common algorithms and data structures (binary tree, sorting, etc), object oriented programming and design patterns. familiarity with compilers, debuggers under linux (gcc, g++, gdb).\n",
      "– experience with scripting languages, such as perl, python, and shell scripting\n",
      "– knowledge of basic statistics/probability, familiar with concepts such as correlation, standard deviation and how to compute\n",
      "– familiarity with databases (such as mysql)\n",
      "position based in hanoi, vietnam.\n",
      "\n",
      "experience in a similar role \n",
      "graduate degree in computer science, statistics, informatics, information systems, or another quantitative field\n",
      "experience building and optimizing ‘big data’ data pipelines, architectures, and data sets.\n",
      "experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.\n",
      "experience supporting and working with cross-functional teams in a dynamic environment.\n",
      "advanced working sql knowledge and experience working with relational databases, query authoring (sql) as well as working familiarity with a variety of databases.\n",
      "strong analytic skills related to working with unstructured datasets.\n",
      "build processes supporting data transformation, data structures, metadata, dependency, and workload management.\n",
      "a successful history of manipulating, processing, and extracting value from large, disconnected datasets.\n",
      "working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores\n",
      "\n",
      "\n",
      "nan\n",
      "experience, you will be curious about the payments industry, results-driven and client-centric. as a candidate you should have both technical and business acumen:degree (masters or ph.d. would be an advantage) in quantitative field such as statistics, mathematics, operational research, computer science, economics, or engineering or equivalent experienceminimum 8 years of analytical expertise in applying statistical solutions to business problemshands on experience with one or\n",
      "nan\n",
      "kinh nghiệm.\n",
      "experience in data processingstrong quality & detail orientationsolid problem solvingability to work well in a fast-face environmentable to work effectively within team and stakeholder (cs/oo/io_delivery team)logical thinking, strong analytical and problem-solving skillsgood communication skillsadditional informationabout nielseniqnielseniq is a global measurement and data analytics company providing the most complete and trusted view of consumers and markets in 90 countries covering 90% of the world’s population. focusing on consumer-packaged goods manufacturers and fmcg and retailers, we enable customers to defy what’s possible. how? we combine unparalleled datasets, pioneering\n",
      "experience level:1+ years (expertise in database development)qualifications:bachelor degree in it/ computer sciencehands-on experience in oracle database developmenthands on experience in development using sql, pl/sqlgood english communication skillsbe flexible/ comfortable if working in shiftadditional informationjob location:hcmc: etown 2, 364 cong hoa, ward 13, tan binh dist., hcmchanoi: 29 lieu giai, ngoc khanh, ba dinh dist., hanoiso... why bosch?\n",
      "because - together - we turn the ideas into reality, working every day to make the world of tomorrow a better place.as a boschler, you will have a chance to:work in one of the best places to work in vietnamjoin a dynamic and fast growing global company (english-speaking environment)get 13th-month salary bonus + attractive performance bonus (you'll love it!) + annual performance appraisal100% monthly basic salary and mandatory social insurances in 2-month probationonsite opportunities: short-term and long-term assignments15++ days of annual leave + 1 day of birthday leavepremium health insurance for employee and 02 family membersflexible working timelunch and parking allowancegood benefits of company activitiesopportunity to work in global projects of fast developing company and being a part of innovation team contributing initiative ideas to the hi-tech world.engage in our diverse training programs which surely help strengthen both your personal\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "trình độ & kinh nghiệm- người có bằng cấp về kinh doanh, tài chính, kế toán, luật hoặc các ngành học liên quan khác.- có từ 1 năm kinh nghiệm về quản lý ngân sách hoặc các vị trí liên quan.\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "kinh nghiệm làm việc tại các vị trí liên quan trong lĩnh vực tài chính ngân hàng hoặc nhóm ngành công nghệ thông tin;\n",
      "am hiểu về khai thác dữ liệu (data mining), lập mô hình thống kê, phân tích dữ liệu số và hoạt động kinh doanh;\n",
      "thành thạo các công cụ báo cáo bi như tableau, qlikview & powerbi;\n",
      "kỹ năng trình bày và thuyết trình tốt;\n",
      "kỹ năng phân tích và đọc hiểu báo cáo tốt;\n",
      "\n",
      "nan\n",
      "nan\n",
      "yêu cầu công việc\n",
      "– nam/nữ, tuổi từ 25 – 35\n",
      "– tốt nghiệp đại học chuyên ngành kiểm toán, tài chính, …\n",
      "– tối thiểu 3 năm kinh nghiệm kế toán/ tài chính\n",
      "– kỹ năng thiết lập, trình bày báo cáo; phân tích đánh giá dữ liệu; xây dựng aop-kpi và quản trị giá thành (công ty sản xuất)\n",
      "– ưu tiên đã từng tham gia triển khai sap/ sử dụng sap\n",
      "\n",
      "nan\n",
      "nan\n",
      "qualifications● tốt nghiệp cao đẳng trở lên các ngành lên quan tới toán thống kê, quản lý dữ liệu, it...● có hiểu biết về các phương pháp và công cụ phân tích dữ liệu / quản lý dữ liệu● sử dụng tốt các công cụ thống kê như excel, spss, sas...● tư duy logic và có khả năng trình bày báo cáo rõ ràng, rành mạch, dễ hiểu.additional informationrecruiter in charge: ms. minh minh - [email\n",
      "yêu cầu công việc\n",
      "\n",
      "\n",
      "tốt nghiệp\n",
      "experience, and data accuracy.\n",
      "your skills and experience\n",
      "we at parcel perform believe in innovation, energy and resourcefulness for everything we do. we will not stop delivering an outstanding product that we can be proud of and need you to help us inform the world. you need to feel the same way about our offering and bring along the following things:\n",
      "\n",
      "at least 5 years of working as a data engineer\n",
      "solid foundation in python and at least another language in the jvm family\n",
      "deep knowledge of sql database design\n",
      "experience with distributed systems, high volume databases, and etl pipelines\n",
      "familiarity with big data analysis\n",
      "exposure to a wide range of nosql solutions\n",
      "excellent critical thinking, organizational and communication skills\n",
      "strong ownership and good collaboration skills to work in a team\n",
      "good english communication\n",
      "\n",
      "why you'll love working here\n",
      "we at parcel perform are dedicated to being a platform for growth for all our team members, regardless of function and location.\n",
      "\n",
      "the opportunity to work in a fast-growing, super exciting and innovative business that will revolutionize the e-commerce logistics industry. you will be the needle of success on the growth of a global product that will become a key platform behind successful e-commerce logistics worldwide.\n",
      "the ability to continuously learn and develop in an international setting with you being a critical driver behind the success of us achieving our mission.\n",
      "an environment where everybody never stops growing and focuses on succeeding - we continuously work with you on your strengths and weaknesses across many important dimensions and look at ways for you to address them and further your development\n",
      "your entry ticket into being part of the parcel perform journey, where you will work with and alongside people from around the world that share the same passion and dedication.\n",
      "\n",
      "who are we at parcel perform!\n",
      "parcel perform is the leading delivery experience platform. it enables modern e-commerce enterprises to create unique end-to-end customer journeys and optimize logistics operations with powerful data integrations, parcel tracking, delivery notifications and logistics performance reports in real-time.\n",
      "parcel perform's scalable saas platform executes more than 100m parcel updates daily and integrates with 800+ carriers. the data-first company is pioneering innovative ml / ai use cases in e-commerce logistics including its 'date of arrival' prediction engine. parcel perform is the partner of choice for top brands, marketplaces and carriers across all major verticals globally.\n",
      " \n",
      "job requirements\n",
      "university degree, ideally in a relevant degree such as data analyst or similar;minimum of 1 year of proven experience in a relevant position;proficient in english communicationdemonstrated ability to create and analyze quality reportsadvanced knowledge in real time management analysis with strong decision making skillscontent moderation familiarity is a plusexcellent data analysis skills with strong logical thinking mindset; ability to organize and analyze data in a structured mannerintermediate knowledge in performing root cause analysis.highly proficient in using ms excelimpeccable attention to detail.\n",
      "what benefits you will get\n",
      "1. salary and benefits\n",
      "attractive salary and benefits (competitive basic salary, lunch allowance, 13th salary, additional bonus, profit sharing) and annual salary review.100% compulsory insurance covered by the company after the probation.premium healthcare and mental health care service for you, 100% covered by the company.extra bonus per personal events (wedding, funeral, hospitalization, newborn baby) and a very cute baby box for staff who are going to welcome a new baby angel to the world.annual health check, annual flu vaccination.fantastic internal events.summer vacation (paid days off and bonus).paid leave (12 days/year).\n",
      "2. working environment\n",
      "5 shifts per week, night shifts included (equivalent to 40 working hours/ week).international, fun and professional working environmentstanding desks if you like, modern hardware, no dress code, free drinks (coffee, tea, etc.)english working environmentinternal english class fully sponsored by the company with a native teacher during working time.training and career development opportunities.\n",
      "all interested candidates are welcome to apply. please send your resume expressing your interest to us. kindly note that only shortlisted candidates will be contacted by our hr team.\n",
      "experienced\n",
      "nan\n",
      "yêu cầu công việc\n",
      "\n",
      "1.tuân thủ đúng các quy định của công ty\n",
      "2. quản lý nhân viên\n",
      "3. triển khai chính xác chương trình, chính sách tới các đối tác hợp tác .\n",
      "4. hoàn thành chỉ tiêu doanh thu được giao.\n",
      "- giới tính: nam, nữ (ưu tiêu nam)\n",
      "- tuổi: < 35\n",
      "\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "sinh viên đã tốt nghiệp chuyên ngành cntt, đtvt, đktđ các trường đại học.\n",
      "experience working with large financial datasets and time-series data\n",
      "nan\n",
      "yêu cầu công việc- được tham gia các chế độ bhxh, bhyt, bhtn theo pháp luật hiện hành- các chế độ phúc lợi khác theo quy định của công ty như nghỉ mát hàng năm, sinh nhật, thăm hỏi ốm đau, hiếu, hỉ. \n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 03/06/2023\n",
      "\n",
      "\n",
      "\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "- kinh nghiệm: kinh nghiệm từ 01 năm lĩnh vực lập trình machine vision(đối với ứng viên mới ra trường/ chưa có kinh nghiệm: công ty có đào tạo tại cơ sở hà nội từ 03-06 tháng, có lương)- học vấn: tốt nghiệp các trường kỹ thuật ( bách khoa, công nghiệp, học viện kỹ thuật quân sự, giao thông vận tải và các trường kỹ thuật khác)\n",
      "nan\n",
      "experience working on large-scale data projects in a fast-paced environment.\n",
      "responsibilities\n",
      "qualifications\n",
      "what we offer\n",
      "additional inf\n",
      "experience in data analytics working closely with business functions.\n",
      "- knowledge of statistical and predictive modeling concepts, machine learning approaches, clustering and classification techniques/ recommendation and optimization algorithms is preferred.\n",
      "- proficient in microsoft excel, sql and visualization tools. power bi experience is a plus.\n",
      "- experience with python/ r programming is a plus.\n",
      "- experience in the retail/ fnb industry is highly desirable but not mandatory.\n",
      "- attention to details.\n",
      "- critical thinking.\n",
      "- can-do attitude.\n",
      "- decent communication skills.\n",
      "nan\n",
      "nan\n",
      "experience, and creating more value\n",
      "nan\n",
      "nan\n",
      "job requirements:\n",
      "1 year+ in python, a basic understanding of java.basic knowledge of git, *nix; kubernetes is a plus.a hungry learner and a good writer. you will be the subject matter expert at a variety of external integrated services. adaptability and a strong sense of quality communication and documentation will be great edges.have an appreciation of sound and evolvable data schema design. on the opposite side, having a solid sense and ability to detect schema design smells.\n",
      "special benefits:\n",
      "be trained with data engineering experts and specialists.being a part of the incredible team building\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "head of paid search (bangkok based, relocation provided)\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "yêu cầu công việc\n",
      "1. bằng cấp/chứng chỉ:\n",
      "experience, technical and design capabilities, manufacturing know-how, supply chain insights and global product management expertise to enable success for the world’s leading brands. we are driven by a common purpose to make a positive impact for each other, our communities, and the environment.\n",
      "job description\n",
      " job summary  responsible to serve as the customer interface for the demand plan and shipment information, develop feasible operational plan and maintain ownership over the execution of the operational plan, achieve the objective of customer satisfaction, minimize jabil liability and continuously improve the performance of the planning metrics.  essential duties and responsibilities  · work with bu and customer to develop a collaborative demand plan through properly executing the demand management process  · create a master schedule through resource analysis including material sizing and capacity sizing  · load master schedule into the jabil erp system.  · create and maintain a feasible production plan and closely work with operation team to achieve successful execution of the plan.  · develop revenue forecast and closely monitor the actual performance and drive for immediate corrective action and recovery plan in case there is potential miss to the revenue target.  · monitor planning metrics and drive for continuous improvement  · comply and follow all procedures within the company security policy and the rules of the road  · may perform other duties and responsibilities as assigned  management & supervisory responsibilities  · typically reports to management . direct supervisor job title(s) typically include: planning supervisor, planning manager.  · job is not directly responsible for managing other employees (e.g., hiring/termination and/or pay decisions, performance management).  please do not change any wording in this section. only include who the direct supervisor is.  job qualifications  knowledge requirements  · thorough knowledge of erp/mrp  · 1 to 2 years materials related experiences  · advanced pc skills including knowledge of jabil's software packages  · ability to read and interpret documents such as safety rules, operating and maintenance instructions, and procedure manuals.  · ability to write routine reports and correspondence.  · ability to speak effectively before groups of customers or employees of organization, strong communication skills.  · ability to apply common sense understanding to carry out instructions furnished in written, oral, or diagram form.  · ability to deal with problems involving several concrete variables in standardized situations.  · ability to calculate figures and amounts such as discounts, interest, commissions, proportions, percentages, area, circumference, and volume.  · ability to apply concepts of basic algebra and geometry.  · strong proficiency in determining logistics requirements to enable company’s business goals and objectives with ability to devise and implement strategy to achieve targets.  · proficient verbal and written english skill  education & experience requirements  bachelor’s degree required.  or an equivalent combination of education, training, or experience. \n",
      "\n",
      "jabil, including its subsidiaries, is an equal opportunity employer and considers qualified applicants for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identify, age, disability, genetic information, veteran status, or any other characteristic protected by law.\n",
      "\n",
      "\n",
      "                        be aware of fraud: when applying for a job at jabil you will be contacted via correspondence through our official job portal with a jabil.com e-mail address; direct phone call from a member of the jabil team; or direct e-mail with a jabil.com e-mail address. jabil does not request payments for interviews or at any other point during the hiring process. jabil will not ask for your personal identifying information such as a social security number, birth certificate, financial institution, driver’s license number or passport information over the phone or via e-mail. if you believe you are a victim of identity theft, contact your local police department. any scam job listings should be reported to whatever website it was posted in.\n",
      "                    \n",
      "accessibility accommodation\n",
      "if you are a qualified individual with a disability, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access\n",
      "nan\n",
      "experience\n",
      "\n",
      "\n",
      "nan\n",
      "nan\n",
      "experience.\n",
      "2 type for this positions:\n",
      "\n",
      "full - time job, definite term contract (1 - 3 years)\n",
      "full - time job, permanent contract\n",
      "experience in team leadership and management\n",
      "proven experience in project management\n",
      "minimum of 3 years of experience in a similar role\n",
      "\n",
      "\n",
      "yêu cầu ứng viên\n",
      "tốt nghiệp chuyên ngành các khối ngành về hệ thống thông tin,…có chứng chỉ về phân tích dữ liệu: power bi.tiếng anh giao tiếp với khách hàng mức khá tốt.khả năng làm việc độc lập và đảm nhận vai trò lãnh đạo trong nhóm.khả năng giao tiếp hiệu quả để thiết lập mối quan hệ làm việc với khách hàng.có khả năng phân tích, lập mô hình dữ liệu trong môi trường hoặc tập dữ liệu lớn.ưu tiên có sự hiểu về biết về lĩnh vực dầu khíthành thạo phân tích, triển khai báo cáo trên power bi và các công cụ etl & dwh khác (sap bw, azure, sql, power query,...)có kinh nghiệm làm việc với r và python, power apps, power automate,..có kinh nghiệm làm việc với các công cụ và công nghệ quản lý dữ liệu chủ (mdm)kỹ năng tư duy phân tích và khái niệm nâng cao.\n",
      "quyền lợi\n",
      "lương cứng thỏa thuận theo kinh nghiệm và năng lực.có lương tháng thứ 13, thưởng lễ tết, thưởng theo kết quả kinh doanh của công ty (gói thu nhập năm 14-16 tháng/năm)\n",
      "kinh nghiệm làm việc với java, csdl nosql.\n",
      "– là lợi thế nếu:\n",
      "+ có kinh nghiệm làm việc với ít nhất một trong các khung nền tảng sau, ví dụ: kubeflow, mlflow,\n",
      "aws sagemaker, google ai platform, azure machine learning, datarobot, mlflow.\n",
      "+ có kinh nghiệm huấn luyện và triển khai các mô hình học máy/trí tuệ nhân tạo.\n",
      "iii. quyền lợi\n",
      "– lương fresher đến senior: 500$ – 2000$ (đánh giá tăng lương theo năng lực định kỳ);\n",
      "– bảo hiểm sức khỏe cao cấp generali;\n",
      "– môi trường làm việc trẻ trung, năng động, thời gian làm việc linh hoạt;\n",
      "– làm việc cùng đội ngũ công nghệ giỏi chuyên môn, có cơ hội để phát huy tối đa năng lực của bản thân;\n",
      "– liên tục được đào tạo về kiến thức, kỹ năng liên quan đến các lĩnh vực hoạt động của công ty;\n",
      "– được cung cấp đầy đủ phương tiện làm việc theo yêu cầu của tính chất công việc;\n",
      "– các hoạt động tập thể, giải trí đa dạng (clb bóng đá, game, bi lắc, …); sự kiện team-building hàng năm;\n",
      "– được đảm bảo đầy đủ các chế độ phúc lợi theo quy định của pháp luật hiện hành và của công ty;\n",
      "– thưởng tết nguyên đán, tết dương lịch, ngày lễ khác và thưởng thành tích nổi bật.\n",
      "iv. thông tin khác\n",
      "– thời gian làm việc: 9:00 – 18:30; thứ hai – thứ sáu và hai ngày thứ bảy trong tháng luân\n",
      "phiên\n",
      "– địa chỉ: toà nhà ghtk, đường phạm hùng, phường mễ trì, quận nam từ liêm, hà nội.\n",
      "v. cách thức ứng tuyển\n",
      "để ứng tuyển vị trí ai/mlops, vui lòng gửi cv & cover letter về email: talent.acquisition@ghtk.co\n",
      "tiêu đề: ai/mlops_họ tên.\n",
      "nan\n",
      "experience.able to work independently under remote supervision by expatessential skillsbachelor’s degree and academic excellence from quantitative field.msc level in engineering, operations, statistics, physics, mathematics or equivalent technical field.microsoft office (intermediate)fluent english competency (toeic 700 or above)benefits13th month salaryinternal healthcare plan16 days annual leavecareer data analyst data scientistdata analystmodec management servicesthe job was closedappl\n",
      "nan\n",
      "kinh nghiệm phát triển etl hoặc báo cáo như: sql, datastage, tableau, powerbi, python..\n",
      "– có kinh nghiệm tham gia một trong các loại hình dự án data analytics, business inteligence, data warehouse, data lake, bigdata…\n",
      "– ưu tiên các ứng viên có hiểu biết về giải pháp data của ibm như cloud pak for data, singlestore\n",
      "– có khả năng giao tiếp & đọc hiểu tài liệu kỹ thuật tiếng anh.\n",
      "– kỹ năng ứng xử, giao tiếp, thuyết trình tốt\n",
      "– kỹ năng giải quyết vấn đề và làm việc theo nhóm\n",
      "– có khả năng làm việc độc lập, chủ động, trách nhiệm, nhiệt tình trong công việc.\n",
      "yêu cầu khác\n",
      "– sức khỏe, tính tuân thủ kỷ luật;\n",
      "– có khả năng học hỏi và làm việc trong môi trường chịu áp lực cao.\n",
      "\n",
      "\n",
      "\n",
      "benefit\n",
      "\n",
      "– thưởng kpi hàng tháng 20% lương.\n",
      "– thưởng nhân viên xuất sắc tháng.\n",
      "– thưởng các dịp lễ\n",
      "– thưởng tháng lương thứ 13: chuyển tự động vào cuối tháng 12 hàng năm.\n",
      "– thưởng dự án.\n",
      "– bảo hiểm sức khỏe 24/7.\n",
      "\n",
      "\n",
      "nan\n",
      "experience at the same position for multinational companies\n",
      "- advanced ms excel including experience modeling transactions, word, power point, familiarity with applications used for business.\n",
      "- good communication in english. \n",
      "\n",
      "experience is fine\n",
      "good linguistic competence in english: conventional toeic (reading and listening) >= 550;\n",
      "proficient in query languages as sql and nosql\n",
      "good programming skills: python (required)\n",
      "nice to have: c++, java. scala …\n",
      "experience with ai frameworks such as keras, pytorch, tensorflow …\n",
      "knowledge of machine learning as decision trees, linear regression, ensemble (random forest, boosting tree), k-means, svm, pca…\n",
      "knowledge of deep learning, neural network, various kinds of network mlp, cnn, lstm, rnn…\n",
      "possession of global certificates of ai (tensorflow developer certificate, google professional machine learning engineer certification ...) or of data engineer (aws, cca, ccp, ibm certified data engineer, google - - professional data engineer …) are a big plus\n",
      "creative thinking, self-research capability, ability to work in a team, up-to-date knowledge of new technologies\n",
      "benefits\n",
      "salary: 1500$ - 2200$ \n",
      "allowances: 1,000,000 vnd per month on lunch and transportation\n",
      "address current problems related to ai of the company\n",
      "propose new solutions to the company to take full advantage of its massive data\n",
      "monitor performance, accuracy of ml models based on the use of methods as rmse, rmsea, mae, mse, mape, accuracy, recall, precision, … \n",
      "unlimited utilization of all monkey products\n",
      "opportunities to collaborate with renowned business partners (facebook, coc coc, etc.)\n",
      "chances to work in a well-recognized company which has achieved successes on both national and global scale, namely first place startup in 2016 gist tech-i competition awarded by the american former president barack obama, first place in vietnamese talent competition, top 1 most loved children application on app store and google play\n",
      "first-handed experience with top-notch international teaching and learning materials and approaches\n",
      "chances to work closely with excellent vietnamese and american educators and linguists.\n",
      "positive and open-minded environment which is made up of people who are always ready to listen and share\n",
      "courses fully funded by the company to improve one's competence and skills\n",
      "salary review every 6 months\n",
      "bonuses on kpi, projects, new ideas, boost-up bonus; on-the-spot reward; rewards for new suggestions of contribution recognition and employee gifts on special occasions\n",
      "equipment and devices provided at work, or allowance for using personal devices\n",
      "number of days-off, public and new year holidays, annual leave will be under labor law\n",
      "attractive maternity regime for both male and female employees\n",
      "entitled to social insurance, health insurance, underemployment insurance and other benefits according to the company's policies\n",
      "health screening and wellness check-up services at prestigious hospitals\n",
      "daily tea-break, weekly gather-up, monthly birthday party and annual summer trip\n",
      "other benefits are discussed during the interview  \n",
      "giới thiệu việc làm này\n",
      "\n",
      "\n",
      "\n",
      "        chia sẻ bài viết\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "chia sẻ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sao chép đường dẫn\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "- tốt nghiệp đại học, cao đẳng chuyên ngành công nghệ thông tin, toán - tin, tin học quản lý hoặc các chuyên ngành có liên quan;- có kinh nghiệm cài đặt, quản trị hệ thống csdl oracle (rac, dataguard, golden gate, odi); ms sql cluster;- có từ 2 năm kinh nghiệm quản trị csdl trở lên;- am hiểu về hệ điều hành linux, unix;- có kinh nghiệm quản trị hệ thống ứng dụng oracle e-business suite (ebs), oracle weblogic, oracle golden gate, ms sql cluster là một lợi thế.\n",
      "quyền lợi\n",
      "- lương cứng từ 15-30 triệu/tháng (net);- lương tháng thứ 13, thưởng các dịp lễ tết, thưởng định kỳ;- làm việc trong môi trường năng động, chuyên nghiệp có nhiều cơ hội thăng tiến;\n",
      "nan\n",
      "kinh nghiệm\n",
      "\n",
      "tối thiểu 1 năm kinh nghiệm ở vị trí liên quan.\n",
      "\n",
      "yêu cầu bản thân\n",
      "\n",
      "kỹ năng phân tích và viết báo cáo tốt\n",
      "hiểu các nguyên tắc và thực hành chăm sóc khách hàng\n",
      "kỹ năng giao tiếp, giao tiếp và viết lách tốt\n",
      "có năng lực, tính linh hoạt và sẵn sàng học hỏi\n",
      "kỹ năng tổ chức và quản lý thời gian xuất sắc với khả năng đa nhiệm\n",
      "khả năng viết lách tốt để làm báo cáo và thuyết trình\n",
      "có khả năng làm việc hiệu quả dưới áp lực cao.\n",
      "tính sáng tạo, trí tưởng tượng và khả năng áp dụng sáng kiến vào công việc\n",
      "kỹ năng làm việc nhóm, phân tích và giải quyết vấn đề tốt\n",
      "nhận thức liên quan đến kinh doanh và kiến thức tốt về các vấn đề thời sự.\n",
      "\n",
      "hồ sơ ứng tuyển sẽ được tuyệt đối bảo mật. thông tin cá nhân được thu thập chỉ dành cho mục đích tuyển dụng nhân sự. ứng viên trúng tuyển sẽ có mức lương cao cạnh tranh và con đường sự nghiệp vững chắc.\n",
      "ứng tuyển\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "kinh nghiệm cơ bản về chatgpt và các công nghệ ai tổng quát khác\n",
      "thực hiện xử lý phân tích dữ liệu bằng python\n",
      "\n",
      "có kỹ năng và kiến thức về phát triển mô hình ai thông qua fine-tuning, tiền xử lý dữ liệu và học máy\n",
      "đã từng tiếp xúc với học máy trong nghiên cứu (nhận dạng giọng nói, nhận dạng hình ảnh, xử lý ngôn ngữ tự nhiên, v.v.)\n",
      "chủ động xác định các vấn đề, đề xuất và thực hiện các giải pháp\n",
      "coi trọng sự hợp tác và giao tiếp trong nhóm, có thể thúc đẩy các dự án một cách suôn sẻ\n",
      "có trí tưởng tượng và óc sáng tạo linh hoạt, kết hợp các công nghệ và ý tưởng mới một cách tích cực\n",
      "khả năng đọc/viết/giao tiếp bằng tiếng anh hoặc tiếng nhật. tiếng nhật được ưu tiên\n",
      "chuyên gia có động lực cao và định hướng kinh doanh với thái độ có thể làm được.\n",
      "ưu tiên có kinh nghiệm hoặc đam mê trong lĩnh vực liên quan đến ai khác\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "\n",
      "mức lương hấp dẫn\n",
      "yêu cầu công việc\n",
      "\n",
      "\n",
      "tốt nghiệp đại học hoặc sinh viên năm cuối chuyên ngành kinh tế, kinh doanh, công nghệ thông tin hoặc các chuyên ngành liên quan\n",
      "\n",
      "\n",
      "hiểu biết chung về dữ liệu và phân tích dữ liệu.\n",
      "\n",
      "\n",
      "có tư tuy logic, định hướng dữ liệu, định hướng chi tiết\n",
      "\n",
      "\n",
      "sử dụng tiếng anh linh hoạt trong nghiên cứu, phân tích thông tin\n",
      "\n",
      "\n",
      "khả năng giao tiếp và làm việc nhóm\n",
      "\n",
      "\n",
      "ưu tiên các ứng viên:\n",
      "\n",
      "\n",
      "có đam mê về game, chơi nhiều thể loại game, hiểu biết về quy trình làm game\n",
      "\n",
      "\n",
      "có khả năng sử dụng sql, các tool visualization\n",
      "\n",
      "\n",
      "có kiến thức về các mô hình về định lượng hoặc kinh tế lượng\n",
      "\n",
      "\n",
      "sẵn sàng học python để xử lý big data từ nhiều nguồn và những công nghệ mới.\n",
      "\n",
      "\n",
      "quyền lợi\n",
      "\n",
      "\n",
      "lương tháng 13, thưởng lễ tết.\n",
      "\n",
      "\n",
      "được đề xuất, xét thưởng và xét tăng lương định kỳ hàng quý.\n",
      "\n",
      "\n",
      "tham gia các hoạt động tập thể như team bonding, company trip, year end party hàng năm\n",
      "\n",
      "\n",
      "khám sức khỏe định kỳ hàng năm\n",
      "\n",
      "\n",
      "được tiếp cận những thách thức để chinh phục, nhiều cơ hội thăng tiến và phát triển.\n",
      "\n",
      "\n",
      "được làm việc trong môi trường năng động, trẻ trung, thời gian linh động.\n",
      "\n",
      "\n",
      "được đào tạo những kỹ năng mới phục vụ cho công việc.\n",
      "\n",
      "\n",
      "được tài trợ các khóa học theo chương trình đào tạo của công ty.\n",
      "\n",
      "\n",
      "mức thu nhập tương xứng với năng lực và trình độ.\n",
      "\n",
      "\n",
      "được tài trợ tham gia các hoạt động thể thao như bóng đá, bơi lội…\n",
      "\n",
      "\n",
      "📌loại hình công việc: toàn thời gian\n",
      "📌địa điểm làm việc: phú nhuận\n",
      "✨mức lương: 10.000.000₫ -> 20.000.000₫ /tháng\n",
      "💌cv xin gửi về minhdt@imba.co\n",
      "tagged as: data analyst, python, sql\n",
      "experience recruiting world-class talents, come join us.\n",
      "what you will do\n",
      "\n",
      "\n",
      "\n",
      "senior risk analyst responsibilities include monitoring risk of porfolio, focus on reducing negative financial outcomes of digital banking including analyzing requirements, conducting analyses, developing reports, dashboards, data insight recommendations, also track performance and quality control to identify improvements. specifically, you will:\n",
      "\n",
      "understand end to end digital lending process includes onboarding, usage, and collection.\n",
      "develop risk reports to manage the quality of portfolio and monitor the ratio of non-performing loan, delinquency, and loss rate below the standards of the sbv and ifrs.\n",
      "develop ad-hoc reports which focus on actual problems being faced and business impact to notify leaders.\n",
      "develop a monitoring report for tracking progress and rules of decision engine.\n",
      "evaluate credit scoring/ fraud score/ income score/ 3rd party data for recommendations of credit strategies.\n",
      "work with engineering team to implement automated risk strategies.\n",
      "work closely with the product team to explore data. use data to contribute toward strategic decision-making, and planning.\n",
      "propose optimization of risk policy and initiatives to achieve overall risk target.\n",
      "\n",
      "what you need to have\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "proven working experience as a data analyst, or credit risk analytics.\n",
      "have knowledge of credit products.\n",
      "adept at full task flow from data query and collecting, report writing to presenting findings based on significant amounts of information with attention to detail and accuracy.\n",
      "technical expertise regarding data models, database design development, data mining, and segmentation techniques.\n",
      "strong knowledge of and experience with databases (sql).\n",
      "familiar with tools for analyzing datasets (excel, vba, r, python, etc).\n",
      "have experience with data visualization tools such as powerbi, google data studio, tableau, metabase, qlikview, etc.\n",
      "bs in mathematics, economics, finance, computer science, data science, information management, or statistics.\n",
      "experience with other self-service data analytics tools, nosql is nice to have.\n",
      "willing to learn on the job and ready to adapt to changes in requirements.\n",
      "\n",
      "what you will get\n",
      "experiences for over 20 years. gameloft creates games for all digital platforms, from mobile to cross-platform titles for pc and consoles. gameloft operates its own established franchises such as asphalt®, dragon mania legends, modern combat and dungeon hunter and also partners with major rights holders including lego®, universal, illumination entertainment, hasbro®, fox digital entertainment, mattel®, lamborghini®, and ferrari®. gameloft distributes its games in over 100 countries and employs 3,600 people worldwide. every month, 55 million unique users can be reached by advertisers in gameloft games with gameloft for brands, a leading b2b offering dedicated to brands and agencies. gameloft is a vivendi company.\n",
      "experience in applying machine learning solutions to business problems\n",
      "results-oriented with strong analytical and problem-solving skills\n",
      "good business acumen with a strong ability to solve business problems through data-driven quantitative methodologies\n",
      "the ability to communicate results clearly to technical and non-technical audiences.\n",
      "demonstrated ability to research and innovate solutions\n",
      "experience with python, database management systems, and sql\n",
      "experience with software design and software development\n",
      "experience in bank-related products such as unsecured personal loans and credit cards is a plus\n",
      "\n",
      "what\n",
      "experience in quality assurance processes and methodologies, enhancing your skills in operational excellence and process improvement.\n",
      "work closely with experienced professionals who will guide and support you throughout your internship, providing valuable insights and knowledge.\n",
      "expand your knowledge and understanding of operational quality assurance practices, allowing you to develop a strong foundation for a future career in this field.\n",
      "connect with professionals in the industry, building valuable relationships and expanding your professional network.\n",
      "receive regular feedback and performance evaluations, enabling you to assess your strengths and areas for improvement.\n",
      "collaborate with cross-functional teams, enhancing your teamwork and communication skills in a professional setting.\n",
      "benefit from a flexible work schedule that accommodates your academic commitments and allows for a healthy work-life balance.\n",
      "nan\n",
      "experience in delivery of sap analytics solutionexperience in working with or certified sap analytics cloud, sap data warehouse on cloudexperience in working with data warehousing using sap bw or ms sqlexperience in working with data visualization tools such as sap businessobjects (design studio, lumira...), ms power bigood sql skills and python is preferredknowledge of business processes in sap erp (fico, mm, sd...) is a plusgood communication skills and experience with international clientsproactive and flexible to work onsite or offshoreadditional informationdescribe your perks and cultur\n",
      "job requirements1. trình độ học vấn: tốt nghiệp chuyên ngành tài chính, kinh tế, bảo hiểm, quản trị dữ liệu\n",
      "nan\n",
      "experience:\n",
      "\n",
      "experience leading cross-team initiatives to identify, define, and track core metrics.\n",
      "a coach and mentor with high emotional intelligence: evidenced by humility, tact, compassion, high levels of integrity, and good listening skills.\n",
      "demonstrated commitment to equity, inclusion, and diversity.\n",
      "experience leading projects and programs to build and maintain user-facing data products such as dashboards, trusted datasets, and knowledge bases.\n",
      "a facilitator with strong collaboration skills and an empowerment approach to open and transparent management.\n",
      "\n",
      "qualities that are important to us:\n",
      "\n",
      "ability to explain data and insights clearly to non-specialist audiences and gain their understanding and confidence.\n",
      "empathy towards and commitment to work with the wikimedia affiliates and volunteer communities.\n",
      "discretion and competence in handling sensitive or confidential data.\n",
      "curiosity and critical thinking skills; a lifelong learner who sees situations through multiple lenses.\n",
      "ability to link qualitative and quantitative information to make actionable recommendations to the wikimedia foundation and communities.\n",
      "commitment to the mission of the organization and our values and guiding principles.\n",
      "self-motivated with an ability to navigate through ambiguity and complexity. the wikimedia ecosystem is complex, resources are limited, and our guiding principles are ambitious. we want you to work to find solutions embracing these factors.\n",
      "\n",
      "additionally, we’d love it if you have:\n",
      "\n",
      "exposure to, and interest in, ethical data management and privacy practices.\n",
      "experience with large-scale data processing & storage tools (we use hadoop, hive, presto, and spark).\n",
      "contributed to wikimedia projects or have experience working in other open source projects.\n",
      "experience with superset or other open source visualization and reporting tools.\n",
      "\n",
      "about the wikimedia foundation\n",
      "the wikimedia foundation is the nonprofit organization that operates wikipedia and the other wikimedia free knowledge projects. our vision is a world in which every single human can freely share in the sum of all knowledge. we believe that everyone has the potential to contribute something to our shared knowledge, and that everyone should be able to access that knowledge freely. we host wikipedia and the wikimedia projects, build software experiences for reading, contributing, and sharing wikimedia content, support the volunteer communities and partners who make wikimedia possible, and advocate for policies that enable wikimedia and free knowledge to thrive.\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "head of search engine optimization (seo) – bangkok based, relocation provided\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "nan\n",
      "job requirements and qualificationsdoing a bs in computer science/computer engineering/data science. msc level candidate would be a bonushave a good grasp of mathematics especially linear algebra, probability, discrete mathvery familiar with python or c/c++. experience with other languages is also welcomebasic/mediate knowledge of algorithms and data structures is a bonusexperience with machine learning/deep learning frameworks such as scikit-learn, tensorflow, pytorch is a bonusexperience with image processing or natural language processing is a bonusbenefits and perksallowance for 3 months of participationlearn how to make technology productspotential to advance to a full-time position following the successful completion of the internship;access to training programs/ courses and continuous opportunities for personal development;opportunity to work in a professional environmentfree weekly social events and activities at enouvo.an inspiring place to work and a chance to be part of the enouvo family with all of the young, talented and passionate colleaguesabout usenouvo group is a company specializing in providing innovative and technological solutions. after 10 years of operation, enouvo has grown and expanded in many fields such as it, digital product development, agency, coworking space and cafe. we always strive to create the most outstanding products to not only bring value to customers but also contribute to the development of the community.how to applydoes this role sound like a good fit? email us at [email\n",
      "experience with sql, additional experience with programming languages (python, r) is a plus\n",
      "at least 1 year of experience with any visualization tools (power bi, tableau…)\n",
      "strong proficiency in sql and experience with etl processes and data modeling.\n",
      "experience with cloud platforms, such as google cloud platform (gcp) or amazon web services (aws).\n",
      "strong problem-solving skills and ability to work independently and in a team environment.\n",
      "excellent communication and collaboration skills to work effectively with departments and cross-functional teams.\n",
      "strong attention to detail and ability to manage multiple projects simultaneously.\n",
      "passion for data and keeping up with the latest trends and technologies in data analytics.\n",
      "prior experience working in a consulting or client-facing role is a plus.\n",
      "nan\n",
      "nan\n",
      "kinh nghiệm từ 3 đến 5 năm trong vị trí data analyst.\n",
      "- nắm rõ các thuật ngữ chuyên về digital marketing sẽ là một lợi thế.\n",
      "- am hiểu cách thức vận hành của các nền tảng online: facebook, google,...\n",
      "* kỹ năng:\n",
      "- có kỹ năng phân tích dữ liệu cẩn thận và chính xác\n",
      "- sử dụng thành thạo các công cụ phân tích dữ liệu.\n",
      "- lập kế hoạch công việc đảm bảo sự hiệu quả và tiến độ của công việc.\n",
      "- có kỹ năng tốt trong việc giải quyết vấn đề và có khả năng trình bày và giao tiếp lưu loát tự tin.\n",
      "* thái độ:\n",
      "- tự tin: làm việc với các con số, đồ thị, biểu đồ, thống kê.\n",
      "- tư duy chủ động, trách nhiệm, ham học hỏi & không ngừng phát triển;\n",
      "- sẵn sàng học hỏi và chịu được áp lực\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job detail\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "position type\n",
      "\n",
      "full-time\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "career level\n",
      "\n",
      "staff\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "education level\n",
      "\n",
      "bachelor's degree\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gender\n",
      "\n",
      "male / female\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job categories\n",
      "\n",
      "\n",
      "advertising / promotion / pr\n",
      "\n",
      ", \n",
      "\n",
      "marketing\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "information\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "name:\n",
      "\n",
      "\n",
      "ms.ly\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "307 a nguyễn trọng tuyển, phường 10\n",
      "\n",
      ", \n",
      "\n",
      "phu nhuan district\n",
      "\n",
      ", \n",
      "\n",
      "ho chi minh\n",
      "\n",
      ", \n",
      "\n",
      "viet nam\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- các ứng viên quan tâm vui lòng gửi hồ sơ trực tuyến qua careerlink, gửi kèm file hoặc trực tiếp đến tại công ty\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "application language:\n",
      "vietnamese\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "công ty cổ phần teecom\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "http://teecom.vn/\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "25 - 99 employees\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact: ms.ly\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "chính thức thành lập vào tháng 10/2020, teecom là một trong những công ty khởi nghiệp phát triển vượt bậc trong ngành thương mại điện tử.đội ngũ nhân sự trẻ, năng động, dày dặn về kinh nghiệm chuyên môn, dám ước mơ và không ngại thử thách để đưa ra những ý tưởng, sản phẩm thành hiện thực trên thị trường quốc tế.tầm nhìn:xây dựng một hệ sinh thái thương mại điện tử toàn cầu có trị giá 100 triệu đô vào năm 2026.sứ mệnh:kiến tạo một hệ sinh thái cởi mở, sáng tạo và học hỏi nhanh giúp mỗi cá nhân phát triển tối đa tiềm năng, tạo ra các sản phẩm tập trung vào khách hàng, biến các ý tưởng trở nên thành công trên thị trường thương mại điện tử toàn cầu.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "see more\n",
      "\n",
      "\n",
      "\n",
      "see less\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "other jobs from this company\n",
      "\n",
      "|\n",
      "\n",
      "see all\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "golang developer\n",
      "\n",
      "\n",
      "công ty cổ phần teecom\n",
      "\n",
      "\n",
      "\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "full stack technical lead\n",
      "\n",
      "\n",
      "công ty cổ phần teecom\n",
      "\n",
      "\n",
      "\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nhân viên chăm sóc khách hàng\n",
      "\n",
      "\n",
      "công ty cổ phần teecom\n",
      "\n",
      "\n",
      "\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "market research analyst | chuyên viên nghiên cứu thị trường\n",
      "\n",
      "\n",
      "công ty cổ phần teecom\n",
      "\n",
      "\n",
      "\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "senior it business analyst\n",
      "\n",
      "\n",
      "công ty cổ phần teecom\n",
      "\n",
      "\n",
      "\n",
      "ho chi minh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tags\n",
      "\n",
      "\n",
      "\n",
      "marketing\n",
      "phu nhuan district\n",
      "market research staff\n",
      "data processing\n",
      "data analyst\n",
      "product manager\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "share\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "copied\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan\n",
      "yêu cầu công việc.- được tham gia các chế độ bhxh, bhyt, bhtn theo pháp luật hiện hành.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "hết hạn nộp đơn\n",
      "\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "yêu cầu công việc:trình độ cử nhân trở lên chuyên ngành công nghệ thông tin, hệ thống thông tin quản lý, khoa học máy tính hoặc các lĩnh vực có liên quan;\n",
      "tối thiểu 7 năm (chuyên gia)/5 năm (chuyên viên cao cấp)/ 3 năm (chuyên viên chính)/ 2 năm (chuyên viên) kinh nghiệm làm việc;tại các vị trí liên quan trong lĩnh vực tài chính ngân hàng hoặc nhóm ngành công nghệ thông tin;thành thạo sql và các ngôn ngữ lập trình khác (python, r, scala, java, …);\n",
      "am hiểu kĩ thuật etl và có kinh nghiệm thực tế xây dựng datamart;\n",
      "kinh nghiệm về công nghệ big data (hadoop, spark) và kiến thức chuyên sâu về các loại cơ sở dữ liệu khác nhau (sql & nosql database); \n",
      "kinh nghiệm trong kiến trúc xử lý big data trên nền tảng cloud; \n",
      "\n",
      "yêu cầu ứng viên\n",
      "-\ttốt nghiệp đh chính quy loại khá trở lên chuyên ngành khoa học dữ liệu, khoa học máy tính, cntt, toán học ứng dụng, điện tử viễn thông hoặc liên quan\n",
      "-\ttrình độ tiếng anh: toeic tối thiểu 550\n",
      "-\tkiến thức về lập trình, cấu trúc dữ liệu & giải thuật\n",
      "-\tkiến thức về lập trình lưu trữ, xử lý dữ liệu phân tán, xử lý dữ liệu lớn (hadoop, spark, elastic search…\n",
      "-\tkiến thức về xây dựng luồng xử lý dữ liệu (batch processing, stream procesing, ...)\n",
      "-\tkiển thức về các loại csdl (rdbms, graph databases, nosql products, ...)\n",
      "-\tkỹ năng sử dụng ngôn ngữ lập trình (java, scala, ...), sql\n",
      "-\tk ỹ năng thành thạo một trong các framework, thư viện lưu trữ, xử lý dữ liệu lớn (hadoop,spark, kafka, zookeeper, ...)\n",
      "-\tkỹ năng sử dụng một trong các loại csdl (oracle, neo4j, hbase, cassandra, mongodb, ..)\n",
      "\n",
      "quyền lợi\n",
      "- thu nhập cao tương xứng với trình độ. lên tới 50.000.000/tháng-\tmôi trường làm việc trẻ trung, năng động\n",
      "-\ttham dự các dự án lớn, ứng dụng các công nghệ hàng đầu\n",
      "-\ttham dự hội thảo chuyên ngành trên toàn thế giới\n",
      "-\tlộ trình thăng tiến và phát triển sự nghiệp\n",
      "-\tthu nhập hấp dẫn tùy theo năng lực của từng cá nhân\n",
      "-\tchế độ nghỉ mát và khám sức khỏe, đóng bhxh theo quy định của luật lao động.\n",
      "\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 30/06/2023\n",
      "\n",
      "\n",
      "\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "● kiến thức:- tốt nghiệp cử nhân chuyên ngành công nghệ thông tin, điện tử viễn thông, tài chính, ngân hàng, kinh tế hoặc tương đương. ưu tiên ứng viên có bằng tốt nghiệp loại giỏi hoặc tốt nghiệp tại nước ngoài- ưu tiên có các chứng chỉ chuyên nghành data engineer, data analytics, data science cho xử lý dữ liệu lớn● kinh nghiệm:- tối thiểu 2 năm kinh nghiệm làm việc trực tiếp tại các công ty, dự án về ds- có kiến thức cơ bản về data mining- có kiến thức về phân tích và visualization dữ liệu- có kiến thức về machine learning, deep machine learning- biết cài đặt trên hadoop eco-sys, aws, gcp,… cùng các tech stack thông dụng như sparkml, jupiternotebook, airflow, vs code với các thuật toán, thư viện thông dụng hiện nay- sử dụng thành thạo python, scala và java là lợi thế- có kinh nghiệm làm việc theo mô hình agile- có kinh nghiệm trong lĩnh vực tài chính ngân hàng- có khả năng đọc viết tiếng anh (cơ bản) nghe nói (nếu có thể).\n",
      "quyền lợi\n",
      "● thu nhập cực hấp dẫn: upto 32m gross ( thỏa thuận mức lương tương xứng với năng lực và kinh nghiệm làm việc)● hỗ trợ kí hợp đồng chính thức, nhận 100% lương và đóng bảo hiểm từ ngày đầu tiên đi làm● thưởng dự án, gói thưởng lễ tết lên đến 14m/year (bonus at tết dương lịch, tết âm lịch, lễ 2/9, quà tết, quà trung thu, sinh nhật công ty, tập đoàn,. )● xét tăng lương cố định hàng năm hoặc 6 tháng/ năm theo đánh giá năng lực● được hưởng bhxh, bhyt, bhtn theo chế độ nhà nước ban hành và tặng thêm gói bhxh sức khỏe “nms care” cho nhân viên● tận hưởng nhiều sự kiện của công ty, từ thi đấu thể thao, tiệc sinh nhật hàng tháng, xây dựng đội ngũ hàng quý đến tiệc năm mới, chuyến đi công ty, du lịch hè, teambuilding, liên hoan, gala định kì gắn kết tình cảm\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "• tốt nghiệp đại học, cao đằng các chuyên ngành: công nghệ thông tin, hệ thống thông tin, dữ liệu, toán tin, thống kê, kinh tế, tài chính – ngân hàng …;• tối thiểu 2 năm kinh nghiệm về kiểm toán, quản trị rủi ro, trong đó tối thiểu 06 tháng 1 năm kinh\n",
      "experience / skills detail\n",
      "\n",
      "\n",
      "\n",
      "- tốt nghiệp trung cấp trở lên\n",
      "- chịu khó và ham học hỏi\n",
      "- có khả năng giải quyết công việc được giao\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job detail\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "position type\n",
      "\n",
      "full-time\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "career level\n",
      "\n",
      "staff\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "education level\n",
      "\n",
      "associate degree\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gender\n",
      "\n",
      "male / female\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job categories\n",
      "\n",
      "\n",
      "qa / qc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "information\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "name:\n",
      "\n",
      "\n",
      "phòng hcns\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "phạm ngũ lão, xã xuân dục\n",
      "\n",
      ", \n",
      "\n",
      "my hao district\n",
      "\n",
      ", \n",
      "\n",
      "hung yen\n",
      "\n",
      ", \n",
      "\n",
      "viet nam\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- các ứng viên quan tâm vui lòng gửi hồ sơ trực tuyến qua hệ thống careerlink, gửi kèm file hoặc trực tiếp đến tại công ty\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "application language:\n",
      "vietnamese\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "công ty tnhh may cao cấp việt hào\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100 - 499 employees\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact: phòng hcns\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "công ty tnhh may cao cấp việt hào là một thành viên của tập đoàn rsi đa quốc gia chuyên ngành may, với nhu cầu phát triển thị trường, công ty chúng tôi cần bổ sung nhân sự như sau;\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "see more\n",
      "\n",
      "\n",
      "\n",
      "see less\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "other jobs from this company\n",
      "\n",
      "|\n",
      "\n",
      "see all\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nhân viên giác sơ đồ\n",
      "\n",
      "\n",
      "công ty tnhh may cao cấp việt hào\n",
      "\n",
      "\n",
      "\n",
      "hung yen\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nhân viên qc - kiểm hàng\n",
      "\n",
      "\n",
      "công ty tnhh may cao cấp việt hào\n",
      "\n",
      "\n",
      "\n",
      "hung yen\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nhân viên vận hành sản xuất\n",
      "\n",
      "\n",
      "công ty tnhh may cao cấp việt hào\n",
      "\n",
      "\n",
      "\n",
      "hung yen\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nhân viên  văn phòng tiếng trung\n",
      "\n",
      "\n",
      "công ty tnhh may cao cấp việt hào\n",
      "\n",
      "\n",
      "\n",
      "hung yen\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tags\n",
      "\n",
      "\n",
      "\n",
      "qc\n",
      "sewing\n",
      "statistics\n",
      "urgent\n",
      "huyện mỹ hào\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "share\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "copied\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "data architect (bangkok based, relocation provided)\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "senior dwh/bi developer (bangkok based, relocation provided)\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "experience in big data technologies with a bachelor’s degree in computer science, information technology, software engineering or equivalent\n",
      "solid skills in infrastructure troubleshooting, support and practical experience in performance tuning and optimization, bottleneck problem analysis\n",
      "strong experience with python, sql, apache spark\n",
      "familiar with aws cloud  data services (or azure, gcp, v.v.)\n",
      "good understanding of data structures, data modeling and software architecture.\n",
      "experience in queues and  stream processing (kafka, flink)\n",
      "experience scheduler (airflow, aws glue, azure data factory, …)\n",
      "experience in designing and building etl processes (extractions, data load, aggregation, talend, etc.)\n",
      "time-series/analytics databases, such as elasticsearch\n",
      "test driven development methods: tdd, bdd, ddd & testing: component/ integration testing, unit testing\n",
      "experience in various messaging systems\n",
      "english proficiency\n",
      "\n",
      "nice to have\n",
      "\n",
      "skills in search: solr, elk\n",
      "experience with technologies like spark, kubernetes, docker, jenkins, hive, terraform\n",
      "\n",
      "why epam\n",
      "\n",
      "by choosing epam, you're getting a job at one of the most loved workplaces according to newsweek 2021 & 2022\n",
      "employee ideas are the main driver of our business. we have a very supportive environment where your voice matters\n",
      "you will be challenged while working side-by-side with the best talent globally. we work with top-notch technologies, constantly seeking new industry trends and best practices\n",
      "we offer a transparent career path and an individual roadmap to engineer your future & accelerate your journey\n",
      "at epam, you can find vast opportunities for self-development: online courses and libraries, mentoring programs, partial grants of certification, and experience exchange with colleagues around the world. you will learn, contribute, and grow with us\n",
      "\n",
      "life at epam\n",
      "\n",
      "epam is a leading global provider of digital platform engineering and development services. epam has been named the top it services company on the fortune ‘100 fastest-growing companies’ list (2019-2021)\n",
      "established in 2019, epam vietnam has more than 200 employees and is still expanding rapidly. we offer a multicultural environment where our tech talents can proactively develop world-class solutions directly with international clients. we support the sustainable development of our employees through a clear career path and provide a professional working environment and knowledge upgrading with internal learning solutions and external educational resources. epam vietnam has been recognized by the great place to work™ institute as one of vietnam’s best workplaces™ in 2022\n",
      " \n",
      "\n",
      "how we hire\n",
      "\n",
      "not sure if you meet all the requirements? no problem. let’s talk anyway and find out more! it takes 1 min of application to start the journey with us. apply now!\n",
      "apply and tell us about yourself\n",
      "go through some standard interviews:\n",
      "                        \n",
      "general interview with a recruiter\n",
      "technical interview with our technology experts\n",
      "manager interview or offer interview with a hiring manager\n",
      "\n",
      "\n",
      "get ready to join the team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                apply\n",
      "            \n",
      "\n",
      "                apply\n",
      "            \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "apply for\n",
      "senior data software engineer (python, sql, spark)\n",
      "\n",
      "        \n",
      "        vietnam\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thank you for your submission!\n",
      "\n",
      "\n",
      "                    our talent acquisition team will contact you with further details.\n",
      "                    \n",
      "\n",
      "    \n",
      "        \n",
      "            submit again\n",
      "        \n",
      "        \n",
      "    \n",
      "\n",
      "    \n",
      "        \n",
      "            \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "oops...\n",
      "something went wrong. please try again.\n",
      "\n",
      "    \n",
      "        \n",
      "            submit again\n",
      "        \n",
      "        \n",
      "    \n",
      "\n",
      "    \n",
      "        \n",
      "            \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "it's highly important for us to get your cv. if you are unable to attach a document through your mobile device, please leave us the link where we can find your resume online.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        first name*\n",
      "    \n",
      "\n",
      "\n",
      "first name\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        last name*\n",
      "    \n",
      "\n",
      "\n",
      "last name\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        email*\n",
      "    \n",
      "\n",
      "\n",
      "email\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        location*\n",
      "        \n",
      "\n",
      "\n",
      "location\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                afghanistan\n",
      "            \n",
      "\n",
      "                albania\n",
      "            \n",
      "\n",
      "                algeria\n",
      "            \n",
      "\n",
      "                american samoa\n",
      "            \n",
      "\n",
      "                andorra\n",
      "            \n",
      "\n",
      "                angola\n",
      "            \n",
      "\n",
      "                anguilla\n",
      "            \n",
      "\n",
      "                antarctica\n",
      "            \n",
      "\n",
      "                antigua\n",
      "            \n",
      "\n",
      "                argentina\n",
      "            \n",
      "\n",
      "                armenia\n",
      "            \n",
      "\n",
      "                aruba\n",
      "            \n",
      "\n",
      "                australia\n",
      "            \n",
      "\n",
      "                austria\n",
      "            \n",
      "\n",
      "                azerbaijan\n",
      "            \n",
      "\n",
      "                bahamas\n",
      "            \n",
      "\n",
      "                bahrain\n",
      "            \n",
      "\n",
      "                bangladesh\n",
      "            \n",
      "\n",
      "                barbados\n",
      "            \n",
      "\n",
      "                belarus\n",
      "            \n",
      "\n",
      "                belgium\n",
      "            \n",
      "\n",
      "                belize\n",
      "            \n",
      "\n",
      "                benin\n",
      "            \n",
      "\n",
      "                bermuda\n",
      "            \n",
      "\n",
      "                bhutan\n",
      "            \n",
      "\n",
      "                bolivia\n",
      "            \n",
      "\n",
      "                bosnia\n",
      "            \n",
      "\n",
      "                botswana\n",
      "            \n",
      "\n",
      "                brazil\n",
      "            \n",
      "\n",
      "                brunei darussalam\n",
      "            \n",
      "\n",
      "                bulgaria\n",
      "            \n",
      "\n",
      "                burkina faso\n",
      "            \n",
      "\n",
      "                burundi\n",
      "            \n",
      "\n",
      "                cambodia\n",
      "            \n",
      "\n",
      "                cameroon\n",
      "            \n",
      "\n",
      "                canada\n",
      "            \n",
      "\n",
      "                cayman islands\n",
      "            \n",
      "\n",
      "                chad\n",
      "            \n",
      "\n",
      "                chile\n",
      "            \n",
      "\n",
      "                china\n",
      "            \n",
      "\n",
      "                colombia\n",
      "            \n",
      "\n",
      "                comoros\n",
      "            \n",
      "\n",
      "                congo\n",
      "            \n",
      "\n",
      "                costa rica\n",
      "            \n",
      "\n",
      "                croatia\n",
      "            \n",
      "\n",
      "                cuba\n",
      "            \n",
      "\n",
      "                cyprus\n",
      "            \n",
      "\n",
      "                czech republic\n",
      "            \n",
      "\n",
      "                democratic republic of the congo\n",
      "            \n",
      "\n",
      "                denmark\n",
      "            \n",
      "\n",
      "                dominica\n",
      "            \n",
      "\n",
      "                dominican republic\n",
      "            \n",
      "\n",
      "                ecuador\n",
      "            \n",
      "\n",
      "                egypt\n",
      "            \n",
      "\n",
      "                el salvador\n",
      "            \n",
      "\n",
      "                england\n",
      "            \n",
      "\n",
      "                equatorial guinea\n",
      "            \n",
      "\n",
      "                eritrea\n",
      "            \n",
      "\n",
      "                estonia\n",
      "            \n",
      "\n",
      "                ethiopia\n",
      "            \n",
      "\n",
      "                fiji\n",
      "            \n",
      "\n",
      "                finland\n",
      "            \n",
      "\n",
      "                france\n",
      "            \n",
      "\n",
      "                gabon\n",
      "            \n",
      "\n",
      "                gambia\n",
      "            \n",
      "\n",
      "                georgia\n",
      "            \n",
      "\n",
      "                germany\n",
      "            \n",
      "\n",
      "                ghana\n",
      "            \n",
      "\n",
      "                greece\n",
      "            \n",
      "\n",
      "                greenland\n",
      "            \n",
      "\n",
      "                grenada\n",
      "            \n",
      "\n",
      "                guadeloupe\n",
      "            \n",
      "\n",
      "                guam\n",
      "            \n",
      "\n",
      "                guatemala\n",
      "            \n",
      "\n",
      "                guinea\n",
      "            \n",
      "\n",
      "                guyana\n",
      "            \n",
      "\n",
      "                haiti\n",
      "            \n",
      "\n",
      "                honduras\n",
      "            \n",
      "\n",
      "                hong kong sar\n",
      "            \n",
      "\n",
      "                hungary\n",
      "            \n",
      "\n",
      "                iceland\n",
      "            \n",
      "\n",
      "                india\n",
      "            \n",
      "\n",
      "                indonesia\n",
      "            \n",
      "\n",
      "                iran\n",
      "            \n",
      "\n",
      "                iraq\n",
      "            \n",
      "\n",
      "                ireland\n",
      "            \n",
      "\n",
      "                israel\n",
      "            \n",
      "\n",
      "                italy\n",
      "            \n",
      "\n",
      "                jamaica\n",
      "            \n",
      "\n",
      "                japan\n",
      "            \n",
      "\n",
      "                jordan\n",
      "            \n",
      "\n",
      "                kazakhstan\n",
      "            \n",
      "\n",
      "                kenya\n",
      "            \n",
      "\n",
      "                korea, north\n",
      "            \n",
      "\n",
      "                korea, south\n",
      "            \n",
      "\n",
      "                kuwait\n",
      "            \n",
      "\n",
      "                kyrgyzstan\n",
      "            \n",
      "\n",
      "                lao democratic republic\n",
      "            \n",
      "\n",
      "                latvia\n",
      "            \n",
      "\n",
      "                lebanon\n",
      "            \n",
      "\n",
      "                liberia\n",
      "            \n",
      "\n",
      "                libya\n",
      "            \n",
      "\n",
      "                liechtenstein\n",
      "            \n",
      "\n",
      "                lithuania\n",
      "            \n",
      "\n",
      "                luxembourg\n",
      "            \n",
      "\n",
      "                macao sar\n",
      "            \n",
      "\n",
      "                macedonia\n",
      "            \n",
      "\n",
      "                madagascar\n",
      "            \n",
      "\n",
      "                malawi\n",
      "            \n",
      "\n",
      "                malaysia\n",
      "            \n",
      "\n",
      "                maldives\n",
      "            \n",
      "\n",
      "                malta\n",
      "            \n",
      "\n",
      "                mexico\n",
      "            \n",
      "\n",
      "                micronesia\n",
      "            \n",
      "\n",
      "                moldova\n",
      "            \n",
      "\n",
      "                monaco\n",
      "            \n",
      "\n",
      "                mongolia\n",
      "            \n",
      "\n",
      "                montenegro\n",
      "            \n",
      "\n",
      "                morocco\n",
      "            \n",
      "\n",
      "                mozambique\n",
      "            \n",
      "\n",
      "                myanmar\n",
      "            \n",
      "\n",
      "                namibia\n",
      "            \n",
      "\n",
      "                nepal\n",
      "            \n",
      "\n",
      "                netherlands\n",
      "            \n",
      "\n",
      "                new zealand\n",
      "            \n",
      "\n",
      "                nicaragua\n",
      "            \n",
      "\n",
      "                niger\n",
      "            \n",
      "\n",
      "                nigeria\n",
      "            \n",
      "\n",
      "                norway\n",
      "            \n",
      "\n",
      "                oman\n",
      "            \n",
      "\n",
      "                pakistan\n",
      "            \n",
      "\n",
      "                palau\n",
      "            \n",
      "\n",
      "                palestine\n",
      "            \n",
      "\n",
      "                panama\n",
      "            \n",
      "\n",
      "                papua new guinea\n",
      "            \n",
      "\n",
      "                paraguay\n",
      "            \n",
      "\n",
      "                peru\n",
      "            \n",
      "\n",
      "                philippines\n",
      "            \n",
      "\n",
      "                poland\n",
      "            \n",
      "\n",
      "                portugal\n",
      "            \n",
      "\n",
      "                puerto rico\n",
      "            \n",
      "\n",
      "                qatar\n",
      "            \n",
      "\n",
      "                romania\n",
      "            \n",
      "\n",
      "                russian federation\n",
      "            \n",
      "\n",
      "                rwanda\n",
      "            \n",
      "\n",
      "                saint lucia\n",
      "            \n",
      "\n",
      "                saint vincent grenadines\n",
      "            \n",
      "\n",
      "                samoa\n",
      "            \n",
      "\n",
      "                san marino\n",
      "            \n",
      "\n",
      "                sao tome and principe\n",
      "            \n",
      "\n",
      "                saudi arabia\n",
      "            \n",
      "\n",
      "                scotland\n",
      "            \n",
      "\n",
      "                senegal\n",
      "            \n",
      "\n",
      "                serbia\n",
      "            \n",
      "\n",
      "                sierra leone\n",
      "            \n",
      "\n",
      "                singapore\n",
      "            \n",
      "\n",
      "                slovakia\n",
      "            \n",
      "\n",
      "                slovenia\n",
      "            \n",
      "\n",
      "                somalia\n",
      "            \n",
      "\n",
      "                south africa\n",
      "            \n",
      "\n",
      "                spain\n",
      "            \n",
      "\n",
      "                sri lanka\n",
      "            \n",
      "\n",
      "                sudan\n",
      "            \n",
      "\n",
      "                suriname\n",
      "            \n",
      "\n",
      "                sweden\n",
      "            \n",
      "\n",
      "                switzerland\n",
      "            \n",
      "\n",
      "                syria\n",
      "            \n",
      "\n",
      "                taiwan\n",
      "            \n",
      "\n",
      "                taiwan, china\n",
      "            \n",
      "\n",
      "                tajikistan\n",
      "            \n",
      "\n",
      "                tanzania\n",
      "            \n",
      "\n",
      "                thailand\n",
      "            \n",
      "\n",
      "                togo\n",
      "            \n",
      "\n",
      "                trinidad and tobago\n",
      "            \n",
      "\n",
      "                tunisia\n",
      "            \n",
      "\n",
      "                türkiye\n",
      "            \n",
      "\n",
      "                turkmenistan\n",
      "            \n",
      "\n",
      "                tuvalu\n",
      "            \n",
      "\n",
      "                uganda\n",
      "            \n",
      "\n",
      "                ukraine\n",
      "            \n",
      "\n",
      "                united arab emirates\n",
      "            \n",
      "\n",
      "                united kingdom\n",
      "            \n",
      "\n",
      "                united states\n",
      "            \n",
      "\n",
      "                uruguay\n",
      "            \n",
      "\n",
      "                uzbekistan\n",
      "            \n",
      "\n",
      "                vatican\n",
      "            \n",
      "\n",
      "                venezuela\n",
      "            \n",
      "\n",
      "                vietnam\n",
      "            \n",
      "\n",
      "                yemen\n",
      "            \n",
      "\n",
      "                zambia\n",
      "            \n",
      "\n",
      "                zimbabwe\n",
      "            \n",
      "\n",
      "\n",
      "location\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        state/province*\n",
      "        \n",
      "\n",
      "\n",
      "state/province\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "state/province\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        city*\n",
      "        \n",
      "\n",
      "\n",
      "city\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "city\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        zip code*\n",
      "        \n",
      "\n",
      "\n",
      "zip code\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "zip code\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        need visa sponsorship?*\n",
      "        \n",
      "\n",
      "\n",
      "need visa sponsorship?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "yes\n",
      "            \n",
      "no\n",
      "            \n",
      "\n",
      "\n",
      "\n",
      "need visa sponsorship?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "need visa sponsorship?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "upload your file\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "drag & drop your resume or browse files\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cancel upload\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "path to selected file\n",
      "\n",
      "\n",
      "browse...\n",
      "\n",
      "\n",
      "upload your file\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        copy & paste your cover letter, cv link or message\n",
      "    \n",
      "\n",
      "\n",
      "copy & paste your cover letter, cv link or message\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        linkedin summary\n",
      "    \n",
      "\n",
      "edit summary\n",
      "\n",
      "\n",
      "\n",
      "edit summary\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cancel\n",
      "save\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "warning\n",
      "are you sure you want to leave, all modified information will be lost?\n",
      "\n",
      "no\n",
      "yes\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "please note that by proceeding, you consent to epam processing your personal data as set forth in our\n",
      "experience and knowledge in creating an excel spreadsheets to identify the npv and irr of a development project;- understanding of the property market throughout vietnam, in particular the development process, construction cost, far and taxation is a benefit;- working closely with and support the investment teams;- researching and developing assumptions required for the development of values such as market growth rates, rents, construction costs, lease rates;- developing opinions and recommendations on potential development opportunities through analysis of various inputs that affect overall value and liquidity of assets;- identifying factors that may materially affect value and liquidity of an asset;- analysing property values relative to market conditions and recent sales data;- conducting scenario analysis (e.g. lease restructuring – buy-outs, renewal vs. relocation scenarios);qualifications- graduated in valuation or real estate;- good understanding of the residential property sector in hcmc;- good understanding of property market principles;- computer literacy with good ms office skills;- minimum 02 years of experience;- good english skills;- be able to conduct site inspections;- high sense of responsibility, trustworthy.additional informationthis is a great opportunity to work under innovative, confident and experienced professionals in contributing the growing business in vietnam. the position requires your enthusiasm, confidence, honesty, dedication and flexibility. the ideal candidate will be oriented and have abilities to work under pressure, and demonstrate capabilities to take over new unfamiliar tasks, also be a centralization of clear communication between the executive and others. you will need to be clear on information, communication, and then plan and schedule all of necessary meetings\n",
      "experience across all touch points. ultimately, our goal is to minimize risk and optimize portfolio performance metrics for the benefit of our customers.responsibilitiesthe ideal candidate will have a passion for utilizing data and analytics to optimize portfolio performance. the successful candidate will be responsible for analyzing large datasets, developing predictive models, and generating actionable insights for credit card portfolio management.\n",
      "developing and implementing credit risk models and analytical tools to assess portfolio performance, credit risk, and profitability.\n",
      "analyzing and interpreting data to identify trends, patterns, and insights that drive portfolio management decisions.\n",
      "conducting ad-hoc analysis and data mining to support portfolio optimization and strategy development.\n",
      "collaborating with business stakeholders to understand their needs and requirements, and to develop and implement solutions that meet their needs.\n",
      "creating and maintaining reports and dashboards that provide insights into portfolio performance and key performance indicators (kpis).\n",
      "designing and conducting a/b tests to evaluate the impact of new portfolio strategies and tactics.\n",
      "maintaining up-to-date knowledge of industry trends, best practices, and regulatory requirements related to credit card portfolio management.\n",
      "communicating complex analytical findings and recommendations to non-technical stakeholders, including senior management.\n",
      "mentoring and coaching junior analysts and data scientists on the team.\n",
      "partnering with data engineers and other technical teams to ensure data quality, availability, and scalability.\n",
      "conducting competitive research to stay informed of market trends, customer preferences, and emerging technologies that may impact the credit card portfolio.\n",
      "perform highly complex activities related to financial products, business analysis, and build dashboards for portfolio monitoring.\n",
      "utilize statistical and machine learning techniques to identify patterns and trends in financial data\n",
      "develop and implement data-driven investment strategies that optimize portfolio performance\n",
      "\n",
      "\n",
      "your skills and experience\n",
      "\n",
      "requirements\n",
      "post graduate degree (masters\n",
      "nan\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "đại học các chuyên ngành qtkd, logistics, marketing hoặc các ngành liên quan.có kinh nghiệm tối thiểu 3 năm trở lên.có kinh nghiệm thiết lập và tính toán tính khả thi của dự án: tính dòng tiền, hiệu suất đầu tư như irr, npv…để triển khai dự án một cách hiệu quả nhất. viết báo cáo dự án. có hiểu biết về địa lý địa phương.có khả năng sử dụng các công cụ quản lý dữ liệu.ưu tiên ứng viên có khả năng báo cáo, phân tích sử dụng đa công cụ (excel, power bi tools…)có kỹ năng tổng hợp, phân tích số liệu, data, thông tin, lên báo cáocó kiến thức về tiếng anh tốt, ielts 6.0, tiếng hoa hsk 3 hoặc các chứng chỉ tương đương.yêu cầu tính cẩn thận, chính xác cao và luôn học hỏi, có ý chí cầu tiến trong công việc.\n",
      "quyền lợi\n",
      "● làm việc trong môi trường chuyên nghiệp, năng động và nhiều cơ hội thăng tiến.● được cung cấp đầy đủ phương tiện làm việc: laptop, điện thoại và các công cụ cần thiết phục vụ cho từng dự án.\n",
      "kinh nghiệm trên 6 tháng ở vị trí kỹ sư dữ liệu.- có kiến thức về cơ sở dữ liệu (sql), hệ thống và lập trình.- có kinh nghiệm về việc sử dụng các công cụ tích hợp dữ liệu etl (ssis, azure data factory, informatica, odi, pentaho,…..).- có kinh nghiệm xây dựng data model.- có kinh nghiệm sử dụng ngôn ngữ lập trình (python, r, …), công cụ bi (power bi, ssas, …) là một lợi thế- tư duy logic, khả năng làm việc độc lập và làm việc nhóm hiệu quả.- có khả năng đọc các tài liệu chuyên ngành bằng tiếng anh.- có tinh thần học hỏi và sẵn sàng tiếp thu kiến thức mới- năng động, chăm chỉ, cẩn thận, kiên nhẫn, thân thiện.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job detail\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "position type\n",
      "\n",
      "full-time\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "career level\n",
      "\n",
      "technical / engineer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "education level\n",
      "\n",
      "bachelor's degree\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gender\n",
      "\n",
      "male / female\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "age\n",
      "\n",
      "22 - 30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "job categories\n",
      "\n",
      "\n",
      "it - software\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "information\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "name:\n",
      "\n",
      "\n",
      "phòng hcns\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "62 trần quang khải, tân định\n",
      "\n",
      ", \n",
      "\n",
      "district 1\n",
      "\n",
      ", \n",
      "\n",
      "ho chi minh\n",
      "\n",
      ", \n",
      "\n",
      "viet nam\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- các ứng viên quan tâm vui lòng gửi hồ sơ trực tuyến, gửi kèm file hoặc trực tiếp đến tại công ty \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "application language:\n",
      "vietnamese\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "about company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "công ty tnhh routine việt nam\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "https://routine.vn/\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100 - 499 employees\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "contact: phòng hcns\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "routine\n",
      "experienced deep learning engineer to join our team for an exciting smart ocr project. as a deep learning engineer, you will play a pivotal role in designing, training, and optimizing neural network models to develop a cutting-edge ocr system.\n",
      "nan\n",
      "experience requirements\n",
      "8+ years working experience in strategic procurement, costing and analytics fields.working knowledge in upper shoe materials & footwear manufacturing industries are preferred.motivated self-starterexcellent analytical, negotiation and organizational skills.strong bias for results and attention to detailhighly effective communicator with ability to foster relationships at all management levels and cross-culturally.must be fluent in written & spoken english & vietnamesecomputer literate: ms office applications, power point, analytic and procurement platforms. education requirements\n",
      "bachelors of business or analytics fieldplease contact ms. linh hoang at linh.hoang@adecco.com or +tel: +84 28 3636 5811 – ext : 710 for further discussion on the role. contact person\n",
      "\n",
      "\n",
      "nan\n",
      "job requirements1.\tcollege diploma or university degree in the field of computer science.\n",
      "2.\texpert skill level with 2 to 5 years experience with the following technologies:\n",
      "•\tazure paas data services\n",
      "•\tobject oriented analysis and design\n",
      "•\tci/cd and source control\n",
      "•\tetl techniques and principles\n",
      "•\tdata modelling\n",
      "•\tmaster data management\n",
      "•\tdata visualization\n",
      "3.\texperienced in designing and implementing data platform, reporting and analytics solutions in the microsoft azure ecosystem.\n",
      "4.\tfamiliarity with agile project management and methodologies desired.\n",
      "5.\table to exercise independent judgement and take action on it.\n",
      "6.\texcellent analytical and creative problem-solving skills.\n",
      "7.\texcellent listening, written, and oral communication skills.\n",
      "8.\tstrong relationship, interpersonal, and team skills.\n",
      "9.\thighly self-motivated and directed.\n",
      "10.\texperience working in a team-oriented, collaborative environment.\n",
      "\n",
      "this role is only open to applicants residing nearshore and offshore. we're currently not processing applicants from lithuania for this role\n",
      "yêu cầu ứng viên\n",
      "- nắm vững các kiến thức về cơ sở dữ liệu có cấu trúc và phi cấu trúc- có tư duy hệ thống, có khả năng chủ động giải quyết vấn đề- có kinh nghiệm, am hiểu về big data, xử lý tốt data cấu trúc phức tạpưu tiên ứng viên:- có thể làm việc với cường độ và áp lực cao.- tiếng anh chuyển nghành đọc hiểu tốt.\n",
      "quyền lợi\n",
      "mức thu nhập cạnh tranh, upto 25 mils cho vị trí de, thưởng performance năm.bảo hiểm sức khỏe dành cho cbnv, các chương trình team building, happy friday hàng tháng, tháng kỉ niệm thành lập công tythưởng ngày sinh nhật công ty, sinh nhật, các ngày hiếu hỉ của bản thân và gia đìnhlàm việc trong tổ chức xem trọng learning & development với các chương trình học tập\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 30/06/2023\n",
      "\n",
      "\n",
      "\n",
      "job requirements:\n",
      "3 year+ in python, a basic understanding of java.well-grasped understanding of a fundamental data stack, including etl pipelines, workflow orchestrators, and data transformation.basic knowledge of git, *nix; kubernetes is a plus.a good writer and personal information manager. you will be the subject matter expert at a variety of external integrated services. adaptability and a strong sense of quality communication and documentation will be a considerable edge.have an appreciation of sound and evolvable data schema design. in other words, have a great sense of spotting schema design smells.\n",
      "special benefits:\n",
      "chance to become an expert in the new trendy domain: ai-driven personalized marketing, personalized customer experience, data analytics, and platform.modern tech & innovative environment.\n",
      "nan\n",
      "nan\n",
      "experience on big data technologies. a successful history of manipulating, processing and extracting value from large datasets.·\n",
      "qualificationsmust have strong analytical (quantitative as well as qualitative) skills including building models, prior data miningself-starter with the ability to streamline functions and passion to learn and growstrong financial analysis foundation creating forecasts and modelsproficiency with microsoft excel is required; familiarity with sap, finance systemsmust possess excellent communication and presentation skills, and be comfortable interacting with executive-level managementwork and collaborate well with team-mates\n",
      "nan\n",
      "experience (0-2 years) but has demonstrated excellence in one or several projects: we will prioritize your motivation, ambition and quality of work over your prior experience. if you have never worked before, just share with us some projects you implemented where you demonstrated what we are looking foris comfortable working in english in an international environmentis proficient in excel and google sheet. having prior experience in automating data-oriented process through vba, scripts or any other tool is a plusworking for us means:you are joining a very young and ambitious company: we created the company in january 2019 and have very ambitious fundraising and business targets. we plan to start opening new countries in sea (south east asia) in 12-18 month and will always push to overachieve our high targets and strict deadlinesyou are willing to become the best at what you do in south east asia: we have extremely strong expectations in the quality of work we produce and want to ensure our clients know they are dealing with the best in their fields. as a junior newcomer, this means you want to boost yourself to learn how to become the best at what you do following our teaching, methodology, and paceyou are excited by the idea of writing your own career path: if you expect to know the exact content of your job and career steps, you should look elsewhere. the possibilities to grow in responsibilities and salary with our company will only be limited by your determination, hard work and performanc\n",
      "experience in market research or relevant fields, however, open for fresh graduate. \n",
      "job requirement·\n",
      "experience\n",
      "\n",
      "\n",
      "experience running large scale web scrapes\n",
      "familiarity with techniques and tools for crawling, extracting and processing data\n",
      "3-5 years of hands-on experience of writing code, scripts and apis (python, golang)\n",
      "familiarity with linux, http, html, javascript and networking\n",
      "experience with serverless compute components, bigquery, cloud functions, cloud storage\n",
      "experience with system monitoring/administration tools\n",
      "proficient understanding of code versioning tools, such as git\n",
      "experience following agile methodology\n",
      "ability to dive into technical details and design analytics solutions to meet business needs\n",
      "strong understanding of data flow and system integrations\n",
      "good verbal, written communication skills in english\n",
      "experience or understanding marketing/ ecommerce (metrics) is a plus\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "what we offer● excellent and competitive salary package with immediate opportunity to earn incentives.● competitive salary package, performance-based● key internal facing position in a fast-growing international ecommerce company that has strong momentum and strong competitive differentiators (team, technology, regional footprint), this role offers an exciting growth journey and opportunity to co-create our success story.● you will work with a leading team of e-commerce leaders and aspiring movers and shakers to positively shape all ecommerce platforms in the years to come, and will have a broad view on the latest developments in the south east asian ecommerce ecosystem.● ample opportunity for personal and professional development, both on the job and through regular training.● opportunities to work on regional projects with other countries’ offices, in philippines, thailand, singapore, indonesia and malaysiacompany benefit● an attractive salary package with ample opportunities for professional growth.● 2 months probationary period with 100% of gross salary● up to 15 days off per year● working remote from home flexibly● annual health check-up & premium healthcare insurance● social, health, and unemployment insurance based on full salary.● 2 performance review times per year● team building monthly, company trip every year, 13th salary.● on-the-job training and coaching with smart and friendly experts● union and other activities every month (8/3, 20/10, mid-autumn, year-end party, v.v...)● free tea, coffee, snacks for member every day● free parking fee every month\n",
      "\n",
      "nan\n",
      "nan\n",
      "experience\n",
      "\n",
      "graduated from university or higher with a focus on finance, banking, business administration,\n",
      "minimum of 8 years of professional experience in the financial/banking field\n",
      "minimum 5 years business analysis experience.\n",
      "experience in building and managing financial models\n",
      "proficient in power bi, excel, spss, python…\n",
      "\n",
      "yêu cầu ứng viên\n",
      "sử dụng tốt một trong các phần mềm thống kê/ xây dựng mô hình/ quản lý dữ liệu: spss, sql, oracle, r, python,vvsử dụng tốt excelcó kiến thức về thống kê, kinh tế lượng..ưu tiên ứng viên biết thực hiện/ xây dựng các báo cáo quản trị trong ngành tài chính ngân hàng;ưu tiên ứng viên có kinh nghiệm xây dựng các mô hình bằng phương pháp định lượng (mô hình tài chính/ mô hình rủi ro/ mô hình phân tích, dự báo);thu thập, xử lý nhiều loại dữ liệu từ nhiều nguồn khác nhau;kinh nghiệm tạo báo cáo obi nâng cao, có kiến thức về tableau nâng caocó đức tính cẩn thận, trách nhiệm\n",
      "quyền lợi\n",
      "thu nhập thỏa thuận, tương xứng với năng lựcđược training về các kiến thức và kỹ năng marketingcơ hội trở thành nhân viên chính thức và phát triển dài hạn trong lĩnh vực của tương lai: công nghệ - tài chínhmôi trường năng động, trẻ trung, khuyến khích ý tưởng phá cách, sáng tạocơ hội được học hỏi từ các chuyên gia trong lĩnh vực tài chính, công nghệ, quản trị.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "hết hạn nộp đơn\n",
      "\n",
      "\n",
      "\n",
      "job requirement\n",
      "\n",
      "job responsibilities\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "report this job\n",
      "\n",
      "\n",
      "apply this job\n",
      "\n",
      "experience\n",
      "\n",
      "technical attributes:\n",
      "2+ years experience in sql.\n",
      "experience in legacy database conversion/ data mapping/ performance tuning/ data fixing\n",
      "worked in production environment, manage large and complex volume of data\n",
      "tools: sql server 2012/2014 and visual studio, data integration tool ssis\n",
      "has strong data analysis skills.\n",
      "understand performance tuning, monitoring, indexing strategies\n",
      "can admin sql servers instances\n",
      "understand powershell, agent jobs, performance tuning, backup/recovery.\n",
      "strong in writing large stored procedures\n",
      "\n",
      "additional attributes (preferred not required):\n",
      "knowledge and skills in .net frameworks and .net development tools\n",
      "familiar with c# language\n",
      "testing, integrating, writing, troubleshooting and debugging software applications\n",
      "working knowledge of or experience in erp type system.\n",
      "working knowledge of or experience in accounting or retail pos systems\n",
      "experience in agile development methodologies\n",
      "excellent academic and tertiary qualifications\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "we are our people, and whilst as a business we make software, as an organization, we make some of the industry’s best!\n",
      "experience\n",
      "\n",
      "\n",
      "at least 3-5 years of experience as a data engineer, preferably in the financial services industry with a focus on credit risk.\n",
      "strong experience with python, pandas, pyspark, airflow, and building etl workflows.\n",
      "the ideal candidate has strong experience with aws, including s3, iam, and athena.\n",
      "experience with running containerized workloads on kubernetes\n",
      "worked in an agile environment with continuous delivery\n",
      "strong sql skills and experience with relational and non-relational databases.\n",
      "knowledge of data modeling, data warehousing, and bi concepts.\n",
      "excellent problem-solving and communication skills.\n",
      "ability to work effectively in a team-oriented environment and collaborate with cross-functional teams.\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "hr benefits\n",
      "competitive salary\n",
      "salary band per level and employee benefits are reviewed once per year\n",
      "13th month salary pro rata depending on the employee’s length of service (within a calender year), paid with the december salary\n",
      "monthly lunch allowance: 700,000 vnd/employee\n",
      "parking: gft covers the monthly parking fee for employee motorbikes\n",
      "performance evaluation is once per year, for 2 purposes:\n",
      "experienced head of growth to lead our growth strategies across the organization. the ideal candidate will have a proven track record of driving user acquisition, and revenue growth. as the head of growth, you will lead and collaborate with the sales, marketing, and school relations teams to design and execute growth initiatives.\n",
      "responsibilities:\n",
      "develop and implement comprehensive growth strategies, focusing on both the top of the funnel.establish, monitor, and manage key growth metrics, utilizing data to drive strategic direction and operational decision-making.lead and collaborate with the sales team to refine sales strategies, improve conversion rates, and maximize customer lifetime value.guide the marketing team in developing impactful campaigns across various channels to reach target audiences.work with the school relations team to foster partnerships and enhance engagement with schools.work closely with the operation and academic teams to align growth initiatives with service development.identify and pursue new markets and partnership opportunities to expand our user base and increase engagement.monitor and report on the effectiveness of growth strategies to the executive team and the board.\n",
      "qualifications:\n",
      "bachelor's degree in business, marketing, or a related field. an mba or relevant advanced degree is preferred.minimum of 7-10 years of experience in a growth-focused role in a fast-paced, high-growth environment.proven track record of driving user growth and engagement through innovative strategies.strong understanding of growth marketing tools and best practices.excellent analytical and quantitative skills, with a deep understanding of data-driven decision-making.experience leading and collaborating with sales, marketing, and partner relation teams.ability to work cross-functionally with multiple teams to execute growth strategies.exceptional communication and presentation skills\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "tốt nghiệp đại học / cao đẳng hoặc tương đương về khoa học máy tính hoặc kỹ thuật3-5 năm trở lên kinh nghiệm làm việc với các nền tảng cloud, đặc biệt là gcp và có kinh nghiệm với databasehiểu biết về cách thức triển khai giải pháp etl/elt có khả năng mở rộng dữ liệu trên gcphiểu biết về xử lý dữ liệu với python và các nền tảng saashiểu biết về các quy chuẩn về chính sách dữ liệuhiểu biết về hạ tầng cloud (gcp) & onprem: kubernetes, bigquery, airflowhiểu biết về văn hóa devopscó khả năng sử dụng các toolset iaas như terraform, ansible, docker, helm...có khả năng sử dụng và phát triển các toolset về tự động hóa: gitlabcikhả năng quản lý và sắp xếp công việc tốtchủ động, có trách nhiệm, sáng tạo và teamwork tốt\n",
      "experience- good team-leader skills & control, working in high pressure environment.- good microsoft office such as word, excel- team work- good communication.additional informationrecruiter in charge:ms. huong pham ([email\n",
      "experience in the e-commerce industry.\n",
      "we are on an ambitious journey to dominate not only amazon‘s sporting goods market but also to enter new e-commerce markets from many regions like canada, europe, japan. besides, home sporting goods, furniture, outdoor and gardening are also great opportunities that we desire to occupy and create significant values. with our steady knowledge in e-commerce, yes4all started to provide end-to-end ecommerce-enabler service in order to help vietnamese and global manufacturers or struggling sellers bring their products to the us & international markets.\n",
      "i. job descriptions\n",
      "a - demand planning:\n",
      "\n",
      " develop the deep understanding of demand input factors (seasonality as an example, distributor‘s inventory policy as another example) as well as the effect of demand on the downstream factors (inventory, capacity, lead time, cost...)\n",
      " build the mathematical model for demand forecasting and planning for each of the skus. sensitivity analysis included.\n",
      " in collaboration with sales, finance and operations during the monthly meeting and update/fill out/adjust the demand plan in accordance with the consensus.\n",
      " create a robust planning function to support continuous improvement for the business.\n",
      " provide insights to conduct fact-based portfolio management and to implement a yearly sku portfolio review cycle\n",
      "\n",
      "b – supply planning:\n",
      "\n",
      " manage the inventory status at each node of the supply chain, build the replenishment model based on the demand forecast and inventory policy to decide the stock move or po quality to offer the optimal stock level and purchasing cost (container/pallet utilization as an example).\n",
      " develop the understanding of supplier lead time and capacity/throughput and how fast they can react with change in y4a demand. create supply scenarios to prepare reaction plan for each of the demand/supply variation occurs\n",
      " build monitoring mechanism to tracking actual outcome and demand insights from other departments. lead solutions findings and execution of demand and supply imbalances.\n",
      "\n",
      "c – supply chain analytic:\n",
      "\n",
      " providing analytical, strategic, and operational support across the organization with the primary objective of enhancing our supply chain responsiveness, agility and optimization\n",
      " assisting or leading on-going supply chain projects under the supervision of supply chain manager\n",
      "\n",
      "ii. skill and experience\n",
      "\n",
      "we are looking for supply chain lover so please be ready to show that.\n",
      "both the theory-driven and data-driven approaches in solving problems.\n",
      "strong mathematical and analytical skills. hands on experience with applying analytical techniques to solve supply chain problems. fluent one or multiple analytic languages (r, mysql, python, …) is priority.\n",
      "possess excellent verbal and written communication skills as well as presentation skills.\n",
      "intellectual curiosity & honesty.\n",
      "team player with high ownership.\n",
      "good at time managing, speed, teamwork, and multitasking.\n",
      "willing to learn, thrive in a fast-paced environment and have a can-do attitude.\n",
      "at least 2-3 years of experiences in planning, supply chain/business/data analytics or similar roles. retail supply chain, e-commerce experience is priority.\n",
      "\n",
      "iii. why you will love joining us?\n",
      "for you to join\n",
      "\n",
      "financial well-being: a competitive salary with 13th month salary, annual performance bonus and a variety of allowances.\n",
      "salary review: annually or on excellent performance.\n",
      "activities: company trips, team-building, and other customized monthly bonding events.\n",
      "annual leaves: 16 days off and 01 birthday leave per year.\n",
      "healthcare: annual health check, insurance according to labor law and extra bao viet insurance package.\n",
      "working environment: dynamic, friendly environments with working time flexibility (mon-fri) and other perks include snacks, coffee, and healthy food provided daily suited for hardworking, fun, and team collaboration.\n",
      "\n",
      "for you to grow\n",
      "\n",
      "ambition: we are now keeping on with our hyper growth to multicategory, multichannel, multimarket, and expanding into the world largest e-commerce enabler. hence, there will continuously be opportunities to challenge yourself, learn new skills and knowledge.\n",
      "challenges: your voice can always be heard as we embrace the eagerness of learning and sharing. you can be your own boss and create your own value with the ability to take initiative and make decisions in all aspects of work.\n",
      "chances: be led and coached by experienced and inspirational leaders and participate in various training courses where you can enlarge your knowledge and experience in the e-commerce and supply chain industry.\n",
      "\n",
      "for you to stay\n",
      "\n",
      "people: having a headquarter in the us and an operation office in vietnam, our team is young and highly motivated. you will be working with and alongside members having experiences from international corporations or high profile from vietnam that share the same passion and dedication.\n",
      "culture: our working environment is humble, collaborative and 100% healthy. we promote exchange & speak out, you can receive transparent and supportive feedback so you can perform the best.\n",
      "career path: provide you a great career path, open to rotating for your better understanding of the company and contribute across many of our functions.\n",
      "\n",
      "and much more, join us and let yourself explore other fantastic things!\n",
      "nan\n",
      "experienced business intelligence engineer/data analyst to join our team. you will generate insights that will guide product (physical and tech) development and operational excellence and for our customers. data analysis will the core of what we do, and your work will have a direct impact on decision making and strategy for our team. you will gather customer data, mine those data, generate insights, and make recommendations to help senior leaders make key business decisions.\n",
      "\n",
      "main responsibilities \n",
      "define\n",
      "•\tinterface with internal business teams to gather analytics & decision-making requirements\n",
      "•\tconduct deep dive analyses of business problems and data issues\n",
      "•\tanalyze customer and product trends to determine drivers of growth and performance\n",
      "•\twork closely with stakeholders to translate business needs into analytical needs, including identifying critical metrics and kpis, and deliver actionable insights to relevant decision-makers\n",
      "•\town the definition, design, and requirements for team’s bi tools and reports\n",
      "design\n",
      "•\tdesign, implement and support a platform that can provide ad-hoc access to large data-sets\n",
      "•\tidentify and investigate new data sources that can be used to build a holistic view for customer engagement. partner with technology teams to define, extract, transform, and load data from many data sources using sql and other tools\n",
      "•\tdefine and implement data acquisition and integration logic, selecting appropriate combination of methods and tools within defined technology stack to ensure optimal scalability and performance of the solution\n",
      "•\tdevelop and maintain databases by defining data schema, acquiring data from primary and secondary sources, and build scripts that will make our data evaluation process more flexible or scalable across data sets\n",
      "deliver\n",
      "•\tmodel data and metadata to support ad-hoc and pre-built reporting\n",
      "•\town the design, implementation, and maintenance of ongoing metrics, reports, analyses, and dashboards, to drive key business decisions.\n",
      "•\tautomate and simplify self-service or reporting pipelines, including improving etl workflows, automatic alarming, prototyping data science models and performance tuning.\n",
      "•\tcreate and maintain rich interactive visualizations through data interpretation and analysis integrating various reporting components from multiple data sources\n",
      "decide\n",
      "•\tparticipate in strategic and tactical planning discussions and provide data insights. challenge business teams to think differently about how they digest and use the data insights to make informed decisions\n",
      "•\tproactively analyze data to answer key questions from stakeholders or out of self-initiated curiosity with an eye for what drives business performance, investigating and communicating areas for improvement in efficiency and productivity\n",
      "                                                                                    \n",
      "xem toàn bộ mô tả công việc\n",
      "nan\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "trình độ học vấn· \n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "+ nam/nữ; tốt nghiệp các trường đại học chuyên ngành cntt hoặc các ngành khác có liên quan+ có từ 6 tháng - 1 năm kinh nghiệm làm việc ở vị trí tương đương+ có kiến thức cơ sở về các thuật toán ai, machine learning+ biết lập trình một trong các ngôn ngữ python, c/c+++ nhanh nhẹn, chủ động và có khả năng làm việc nhóm\n",
      "quyền lợi\n",
      "+ thu nhập 8-20m/tháng, 2-6 tháng xét tăng lương 1 lần\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "yêu cầu công việc\n",
      "các công việc khác được giao bởi project manager và group leader.\n",
      "\n",
      "\n",
      "your skills and experience\n",
      "\n",
      "\n",
      "thành thạo ngôn ngữ python. có từ\n",
      "kinh nghiệm trong lĩnh vực phân tích và trình bày dữ liệu tài chính.\n",
      "• kỹ năng giao tiếp bằng văn bản và bằng lời nói xuất sắc (đặc biệt là bằng tiếng anh), với khả năng truyền đạt rõ ràng thông tin chi tiết về dữ liệu phức tạp cho các bên liên quan phi kỹ thuật.\n",
      "• khả năng làm việc độc lập đã được chứng minh và là một phần của nhóm.\n",
      "• kỹ năng giải quyết vấn đề và tư duy phản biện mạnh mẽ.\n",
      "• kiến thức về sql, python và kho dữ liệu là một lợi thế.\n",
      "• kiến thức về các công cụ báo cáo và trực quan hóa dữ liệu như power point, tableau, powerbi hoặc tương tự là một lợi thế.\n",
      "• có kinh nghiệm tư vấn, tư vấn và nghiên cứu là một lợi thế.\n",
      "• acca/cfa là một lợi thế.\n",
      "chế độ\n",
      "• thu nhập hàng tháng: theo năng lực, có thể thỏa thuận. tháng lương 13.\n",
      "• thưởng năm theo năng lực, thưởng dự án và các mức thưởng khác theo quy chế thu nhập.\n",
      "• các khoản phúc lợi: thưởng lễ, tết, … bằng tiền theo thỏa ước lao động tập thể.\n",
      "• chính sách bhxh, bhyt, bhtn, kpcđ và các phúc lợi khác theo đúng quy định của luật lao động và của công ty.\n",
      "• 14-16 ngày phép/ năm so với trung bình 12 ngày phép/năm trên thị trường.\n",
      "• làm việc trong môi trường năng động, có cơ hội được đào tạo nâng cao nghiệp vụ thường xuyên.\n",
      "• có cơ hội tiếp cận, làm việc trong môi trường tài chính, chứng khoán.\n",
      "• được đào tạo về kỹ năng chuyên môn và kiến thức kinh tế, tài chính, hàng hóa.\n",
      "• trợ cấp internet khi làm việc tại nhà do ảnh hưởng của dịch bệnh covid.\n",
      "• đối với senior: được đóng bảo hiểm y tế của bảo hiểm bưu điện\n",
      "• cơ hội thăng tiến sớm cho cá nhân tiêu biểu.\n",
      "• khung giờ làm việc linh hoạt.\n",
      "• trợ cấp các loại tuỳ theo đối tượng: phụ cấp điện thoại, phụ cấp gửi xe ô tô, trợ cấp kết hôn.\n",
      "gửi cv\n",
      " email liên hệ: talents@fiingroup.vn \n",
      "experiencedesignfinanceglobal affairskey accountslegalmarketingpeopleproductstrategic partnershipsstudentssupplytechnology \n",
      "\n",
      "all locationsbalibangkokbarcelonabeijingberlinboracaybudapestbusancairocancuncape towncebuchiang maichicagocolombodallasdubaifukuokaguangzhougurugramho chi minh cityhong konghonoluluistanbuljakartajeddahkathmandukota kinabalukuala lumpurlas vegaslondonlos angelesmalemanilamumbainew york citynorwalkokinawaorlandoosakapenangphuketsanyasao paulosapporoseoulshanghaisiem reapsingaporesydneytaipeitel avivtokyotorontovientianeyangonyokohama \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "people analytics manager (bangkok based, relocation provided)\n",
      "apply now\n",
      "bangkok, thailand\n",
      "\n",
      "about agoda\n",
      "experience enabled by our own technology ecosystem and operational infrastructure, we are setting the benchmark in online fashion & lifestyle in our markets, and our vision is to be the #1 online destination for fashion & lifestyle in growth markets.\n",
      "kinh nghiệm. xử lý dữ liệu. trực quan hóa các kết quả phân tích dữ liệu.\n",
      "- giải quyết các vấn đề như phát hiện gian lận, cho điểm tín nhiệm, …\n",
      "- kiểm thử hệ thống. xử lý các vấn đề liên quan đến kiểm thử.\n",
      "- phát triển các công cụ tự động hóa cho kiểm thử, kiểm tra xử lý dữ liệu và các công việc liên quan khác.\n",
      "- tham gia các công việc phân tích dữ liệu kinh nghiệm, lập các báo cáo phân tích tài chính, mô hình hóa sản phẩm theo các yêu cầu nghiệp vụ trên hệ thống phần mềm prophet chuyên biệt.\n",
      "- hỗ trợ các công việc phân tích kỹ thuật nghiệp vụ bảo hiểm nhân thọ, thực hiện các công việc liên quan đến xây dựng các tính năng kỹ thuật của sản phẩm trên hệ thống cntt\n",
      "\n",
      "nan\n",
      "experience\n",
      "\n",
      "\n",
      "the ideal candidate should have a degree in computer science, mathematics, or a related field, with a minimum of 3 years of experience in machine learning and deep learning\n",
      "at least 3 years of experience working as an ai engineer, ai researcher, or data scientist position\n",
      "at least 2 years of experience working on 3d computer vision domains such as 3d object detection, depth estimation, or 3d mesh reconstruction\n",
      "experience in 3d data processing such as depth information, point cloud, etc.\n",
      "solid foundation in probability, linear algebra, and space geometry\n",
      "deep understanding of the multi-view geometry of the camera, a variety of matrix factorization algorithms, linear equation solutions, and spatial coordinate transformations in different coordinate systems\n",
      "experience in deploying deep learning models onto real environments such as edge devices\n",
      "proficient in frameworks such as pytorch or tensorflow\n",
      "proficient in python. c/c++ is a plus\n",
      "good logical and critical thinking skills, hard-working and responsible at work\n",
      "able to communicate and work in a team\n",
      "\n",
      "\n",
      "why you'll love working here\n",
      "\n",
      "\n",
      "competitive salary: up to $2500\n",
      "14 months' salary a year\n",
      "opportunity to receive bonus shares.\n",
      "to fully participate in the regimes prescribed by the state such as social insurance, health insurance, unemployment insurance, and annual leave.\n",
      "be trained and work directly with experienced experts in the field of ai.\n",
      "have the opportunity to do challenging things, develop your full potential\n",
      "participate in team building sessions, travel 2-3 times/year, and have fun monthly with the company;\n",
      "enjoy full benefits (happiness, birthday...);\n",
      "young, comfortable working environment, dynamic startup spirit.\n",
      "\n",
      "\n",
      "nan\n",
      "yêu cầu công việc\n",
      "\n",
      "\n",
      "solid knowledge and experience working with relation databases.\n",
      "\n",
      "strong knowledge and experience working with python programming language.\n",
      "experience working with linux/unix, google cloud platform environment.\n",
      "working knowledge of message queue, stream processing, and highly scalable data storage.\n",
      "experience working with celery, elasticsearch or flask is a plus.\n",
      "experience working with git is a plus.\n",
      "\n",
      "\n",
      "tại sao bạn sẽ yêu thích làm việc tại đây\n",
      "\n",
      "\n",
      "opportunity to be onsite in us\n",
      "company-sponsored macbook\n",
      "flexible vacation schedule\n",
      "flexible work hours\n",
      "office happy hours\n",
      "a family of exceptional developers\n",
      "\n",
      "\n",
      "nan\n",
      "yêu cầu công việc\n",
      "\n",
      "\n",
      "university graduate or equivalent\n",
      "fluent in english speaking and writing. good office computer skills and data management.\n",
      "demonstrated strong ability to manage and analyze and interpret complex problems/data gathered from a variety of sources and, through effective decision-making and planning, delivers superior business solutions.\n",
      "understand organizational structure, operating culture, effective work styles, and achieving results in a changing environment.\n",
      "\n",
      "\n",
      "\n",
      "job tags:\n",
      "replenishment analyst\n",
      "replenishment analyst\n",
      "analyst\n",
      "merchandise\n",
      "\n",
      "nan\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "graduated from a regular university, with priority in it, computer science, information systems,economic informatics, finance – banking, ...- have 2+ years of experience in data warehouse construction.- have good knowledge of database management systems and data modeling.\n",
      "quyền lợi\n",
      "salary: negotiable (unlimited)- competitive and fair environment, promoting multi-capacity.- salary review: 02 times/year, fixed in april and october every year; sudden increase in salary...- insurance regime: social insurance, health insurance, unemployment insurance fully according to theregulations of the state- annual health check-up- annual vbi health care insurance.- various bonuses: money saving, 13th month bonus, lunar new year bonus, holiday/tet bonus, lastbusiness bonus years, excellent staff, deep knowledge, initiative....- support for parking, laptop, personal computer....- working time: from monday to friday; saturday morning is not required to go to the timekeepingoffice.- participate in activities: events, conferences, seminars on technology... and internal programs set atthe office.- training mode: to participate in internal training programs, certificates according to demand to serveundertaking work.- tourism and vacation activities: 01 time/year. team building: 02 times/year- free tea, coffee, snacks at the office\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 08/06/2023\n",
      "\n",
      "\n",
      "\n",
      "nan\n",
      "kinh nghiệm làm việc trong lĩnh vực tài chính, ngân hàng tại các tổ chức dịch vụ tài chính liên quan đến xử lý dữ liệu hệ thống, phân tích dữ liệu, lập báo cáo;\n",
      "- tối thiểu 1 năm kinh nghiệm làm việc trong lĩnh vực lập trình vba trên excel: khả năng advance/excellent;\n",
      "- kinh nghiệm lập trình và cấu trúc dữ liệu cơ bản;\n",
      "- kiến thức sql căn bản;\n",
      "- kỹ năng phân tích, quản lý hoạt động và quản lý thời gian tốt; tư duy logic;\n",
      "- kỹ năng tiếng anh cơ bản (ưu tiên).\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "yêu cầu ứng viên\n",
      "- excellent attention to detail and analytical skills.- strong communication and collaboration skills.- ability to work independently and meet deadlines.\n",
      "quyền lợi\n",
      "12 annual days off a year.salary review once a year.birthday party monthly.gifts on international/national holidays. (women's day, valentines,..)annual health check.social security.\n",
      "cách thức ứng tuyển\n",
      "\n",
      "ứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.\n",
      "\n",
      "\n",
      "\n",
      "ứng tuyển ngay\n",
      "\n",
      "lưu tin\n",
      "\n",
      "\n",
      "hạn nộp hồ sơ: 31/07/2023\n",
      "\n",
      "\n",
      "\n",
      "yêu cầu ứng viên\n",
      "● kiến thức:- tốt nghiệp cử nhân chuyên ngành công nghệ thông tin, điện tử viễn thông, tài chính, ngân hàng, kinh tế hoặc tương đương. ưu tiên ứng viên có bằng tốt nghiệp loại giỏi hoặc tốt nghiệp tại nước ngoài- ưu tiên có các chứng chỉ chuyên nghành data engineer, data analytics, data science cho xử lý dữ liệu lớn● kinh nghiệm:- tối thiểu 1.5 năm kinh nghiệm làm việc trực tiếp tại các công ty, dự án về de- có kiến thức về kiến trúc vật lý, kiến trúc logic, thành phần cơ bản của hadoop eco-sys: tầng ingesstion, tầng processing, tầng consumtion- có kiến thức và kinh nghiệm sử dụng spark etl with scala, python trên hadoo eco-sys- có kiến thức và kinh nghiệm tối ưu luồng xử lí data: landing zone, working zone, gold zone, các kỹ thuật thiết kế job tối ưu cho dữ liệu lớn, kỹ thuật orchestration luồng job- có kiến thức và kinh nghiệm về các db sau: sql, nosql, graph- có kiến thức và kinh nghiệm flask, fastapi, gunicorn- có kiến thức và kinh nghiệm tableau/ powerbi- có kiến thức và kinh nghiệm unit testing, integration testing, functional testing, a/b testing, \n",
      "yêu cầu ứng viêntốt nghiệp master ngành computer visionít nhất 2-3 năm kinh nghiệm làm sản phẩm thực tế trong ngành computer visionquen thuộc với pytorch, keras, tensorflowcó kinh nghiệm finetune, tối ưu modeltrung thực, trách nhiệm, có khả năng làm việc độc lập tốt và có tinh thần làm việc nhómquyền lợimức offer upto 3000 usdcontribute vào sản phẩm công nghệ có vision tầm cỡ thế giớiđược quyền quyết định, định hướng công nghệtham gia trực tiếp nghiên cứu, định hướng, phát triển sản phẩmcơ chế đãi ngộ tập trung vào phát triển nhân tài và xây dựng theo concept gia tốc: nhân sự top đầu tăng lương gấp 6 lần nhân sự top dưới.thưởng 4-6 tháng lương 1 năm với nhân sự top đầu.bổ nhiệm ngay khi có chiến công đặc biệt.tham gia đầy đủ các chế độ bhxh, bhyt, bhtn.các gói bảo hiểm ngoài bhxh: bảo hiểm pti, khám sức khỏe định kỳ hàng nămvăn hóa làm việc genz,môi trường làm việc trẻ trung, sáng tạo, dám nghĩ - dám làm, trà đá, bàn tròn, ném đá sếp, áp dụng triệt để văn hóa 6k startup, tsb3c.thực chiến cùng quản lý, chuyên gia từ các tập đoàn lớn: topica, vng, samsung,...du lịch hàng năm, team building, tea break hàng tuầncách thức ứng tuyểnứng viên nộp hồ sơ trực tuyến bằng cách bấm ứng tuyển ngay dưới đây.hạn nộp hồ sơ: 08/05/202\n",
      "yêu cầu công việcuniversity degree in finance, accounting or related disciplines\n",
      "have at least 4 years of experience\n",
      "systematic thinking\n",
      "excellent communication, grasping and problem-solving skills\n",
      "preference will be given to candidates who are proficient at power bi, vba, excel at excel\n",
      "having experience in building process, work management system such as: oracle, sap, base, 1office is an advantageđịa điểm làm việc35/2 nguyễn văn hưởng, phường thảo điền - quận 2 - thành phố thủ đức, hcm\n",
      "experience in web crawling and/or scraping skills with or without a framework\n",
      "– experience in software development life cycle and developing large scale software systems\n",
      "– proficiency in high level language such as python, java or perl\n",
      "– proficiency in a query language and using sql\n",
      "– experience in programming and working in aws infrastructure\n",
      "– excellent verbal and written communication skills in both vietnamese and english\n",
      "– machine learning research and nlp experience is a great plus\n",
      "rewards:\n",
      "– competitive compensation package\n",
      "– collaborating with talented software engineers\n",
      "– formulate and execute projects that will have a real impact\n",
      "– improve your personal and technical skills\n",
      "\n",
      "nan\n",
      "nan\n",
      "yêu cầu ứng viên- proven working experience as a data analyst or business data analyst\n",
      "- technical expertise regarding data models, database design development, data mining and segmentation techniques\n",
      "- strong knowledge of and experience with reporting packages (business objects etc), databases (sql etc), programming (xml, javascript, or etl frameworks)\n",
      "- knowledge of statistics and experience using statistical packages for analyzing datasets (excel, spss, sas etc)\n",
      "- strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy- adept at queries, report writing and presenting findings\n",
      "- bs in mathematics, economics, computer science, information management or statisticsquyền lợi- attractive salary from 1,000 - 2,000$\n",
      "- the remuneration mechanism focuses on talent development and builds on the concept of acceleration: the top employees will have the opportunities to increase their salary 6 times more than the underrated employees.\n",
      "- bonus 4-6 months salary per year for top employees.\n",
      "- promoted as soon as there is a special achievement in work.\n",
      "- fully benefits in social insurance, health insurance and unemployment insurance regimes.\n",
      "- extra insurance packages: pti insurance, annual health check per year\n",
      "- genz working culture: young, creative working environment, dare to think - dare to do, dynamic discussion , round table discussion, completely straight discussion with boss, \n"
     ]
    }
   ],
   "source": [
    "for req in df['Requirements']:\n",
    "    print(req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d3806e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['Requirements'][1])== str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "175b74dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for req in df['Requirements']:\n",
    "#     print(type(req))\n",
    "    if (type(req) == str):\n",
    "        tmp.append(filter_keyword(req,keyword))\n",
    "    else:\n",
    "        tmp.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6c67c0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Keyword'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ecc1b453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp = df['Keyword'].value_counts().index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "155a0b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = df['Keyword'].value_counts().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "29a1b431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "248\n",
      "[]\n",
      "70\n",
      "['analys']\n",
      "16\n",
      "['3year']\n",
      "6\n",
      "['1year']\n",
      "5\n",
      "['excel', 'analys', 'sql']\n",
      "5\n",
      "['statistics']\n",
      "5\n",
      "['excel']\n",
      "4\n",
      "['excel', 'english']\n",
      "3\n",
      "['excel', 'english', 'sql']\n",
      "3\n",
      "['analys', '3year']\n",
      "3\n",
      "['analys', 'sql']\n",
      "3\n",
      "['sql']\n",
      "2\n",
      "['analys', 'statistics', '5year']\n",
      "2\n",
      "['5year']\n",
      "2\n",
      "['excel', 'analys', 'english', 'sql', 'google bigquery', '2year']\n",
      "2\n",
      "['analys', 'spark', 'data mining', 'airflow', 'algorithms', 'oop', '2year']\n",
      "2\n",
      "['sql', '2year']\n",
      "2\n",
      "['oop']\n",
      "2\n",
      "['excel', 'sql']\n",
      "2\n",
      "['analys', 'sql', '1year']\n",
      "2\n",
      "['analys', '2year']\n",
      "2\n",
      "['english']\n",
      "2\n",
      "['azure']\n",
      "2\n",
      "['excel', 'analys', 'english', '1year']\n",
      "2\n",
      "['analys', 'data mining']\n",
      "2\n",
      "['excel', 'analys', 'power bi', 'statistics', '2year']\n",
      "1\n",
      "['sql', '5year']\n",
      "1\n",
      "['excel', 'word', 'analys', 'oop', 'statistics', '3year']\n",
      "1\n",
      "['excel', 'word', 'analys']\n",
      "1\n",
      "['english', 'statistics', '3year']\n",
      "1\n",
      "['excel', 'english', 'sql', 'c++']\n",
      "1\n",
      "['excel', 'power bi', 'english', 'sql', '4year']\n",
      "1\n",
      "['excel', 'word', 'power bi', 'english', 'sql']\n",
      "1\n",
      "['analys', 'sql', 'javascript', 'data warehouse']\n",
      "1\n",
      "['english', 'sql', 'data warehouse', 'data pipeline', '3year']\n",
      "1\n",
      "['excel', 'word', 'analys', 'power bi', 'english', '3year']\n",
      "1\n",
      "['analys', 'spark', 'sql', 'oop']\n",
      "1\n",
      "['analys', 'power bi', 'sql', '2year']\n",
      "1\n",
      "['excel', 'analys', 'english', 'e-commerce', '3year']\n",
      "1\n",
      "['analys', 'e-commerce']\n",
      "1\n",
      "['power bi', 'english', 'sql', '2year']\n",
      "1\n",
      "['sql', '3year']\n",
      "1\n",
      "['excel', 'analys', 'power bi', 'english', 'sql', 'statistics', 'mathematics', '2year']\n",
      "1\n",
      "['power bi', 'sql', 'data warehouse', '2year']\n",
      "1\n",
      "['analys', 'spark', '4year']\n",
      "1\n",
      "['sql', 'linux', 'airflow', 'pytorch', 'c++']\n",
      "1\n",
      "['excel', 'statistics', 'mathematics', '3year']\n",
      "1\n",
      "['excel', 'analys', 'power bi', 'sql', 'e-commerce', 'data warehouse', ' r ', 'statistics', '2year']\n",
      "1\n",
      "['spark', 'sql', 'oop', '1year']\n",
      "1\n",
      "['data mining']\n",
      "1\n",
      "['excel', 'word', 'analys', 'sql']\n",
      "1\n",
      "['excel', 'power bi', 'english', 'spark', 'azure', 'sql', 'data warehouse', 'data pipeline', '5year']\n",
      "1\n",
      "['analys', 'sql', ' r,', '1year']\n",
      "1\n",
      "['excel', 'word', '5year']\n",
      "1\n",
      "['analys', 'sql', ' r,', 'statistics', '3year']\n",
      "1\n",
      "['sql', 'linux', 'bash script', 'data pipeline']\n",
      "1\n",
      "['power bi', 'spark', 'data warehouse', 'oop', '2year']\n",
      "1\n",
      "['excel', 'sql', 'linux', 'bash script', 'c++', 'algorithms']\n",
      "1\n",
      "['excel', 'analys', 'power bi', 'statistics', '3year']\n",
      "1\n",
      "['excel', 'analys', 'english', 'sql', 'e-commerce', '1year']\n",
      "1\n",
      "['analys', 'power bi', 'sql', '5year']\n",
      "1\n",
      "['excel', 'sql', 'data mining', 'segmentation techniques']\n",
      "1\n",
      "['keras', 'tensorflow', 'javascript', 'pytorch', 'algorithms']\n",
      "1\n",
      "['english', 'spark', 'sql', 'data pipeline', 'airflow', 'oop', '3year']\n",
      "1\n",
      "['excel', 'analys', 'statistics']\n",
      "1\n",
      "['sql', 'linux', 'c++', 'algorithms', 'statistics']\n",
      "1\n",
      "['analys', 'sql', 'data pipeline', 'statistics']\n",
      "1\n",
      "['excel', 'analys', 'azure', '5year']\n",
      "1\n",
      "['word', '3year']\n",
      "1\n",
      "['excel', 'analys', 'data mining']\n",
      "1\n",
      "['excel', 'english', '2year']\n",
      "1\n",
      "['excel', 'english', 'linux', 'javascript', 'e-commerce', '5year']\n",
      "1\n",
      "['excel', 'analys', 'power bi']\n",
      "1\n",
      "['excel', 'analys', 'sql', ' r,', 'statistics']\n",
      "1\n",
      "['excel', 'analys', 'sql', '2year']\n",
      "1\n",
      "['excel', 'spark', 'sql', 'airflow', '5year']\n",
      "1\n",
      "['airflow', '5year']\n",
      "1\n",
      "['excel', 'word']\n",
      "1\n",
      "['excel', 'sql', 'e-commerce', '4year']\n",
      "1\n",
      "['c++', 'algorithms', '1year']\n",
      "1\n",
      "['analys', 'sql', '3year']\n",
      "1\n",
      "['tensorflow', 'pytorch', 'c++', 'algorithms', 'mathematics', '3year']\n",
      "1\n",
      "['linux']\n",
      "1\n",
      "['analys', 'english']\n",
      "1\n",
      "['excel', 'data warehouse', '2year']\n",
      "1\n",
      "['excel', 'analys', 'sql', '1year']\n",
      "1\n",
      "['excel', '2year']\n",
      "1\n",
      "['spark', 'sql', 'oop', '5year']\n",
      "1\n",
      "['keras', 'tensorflow', 'pytorch', '3year']\n",
      "1\n",
      "['excel', 'power bi', '4year']\n",
      "1\n",
      "['power bi', 'azure', 'sql', ' r,']\n",
      "1\n",
      "['excel', 'analys', 'power bi', '3year']\n",
      "1\n",
      "['excel', 'analys', 'english', '2year']\n",
      "1\n",
      "['excel', 'word', 'english']\n",
      "1\n",
      "['statistics', 'mathematics']\n",
      "1\n",
      "['english', 'sql', '1year']\n",
      "1\n",
      "['analys', 'data mining', 'statistics']\n",
      "1\n",
      "['excel', 'analys', 'english', 'sql', 'e-commerce', '5year']\n",
      "1\n",
      "['excel', 'power bi', 'sql', ' r ', 'algorithms']\n",
      "1\n",
      "['word', 'analys', 'english', '2year']\n",
      "1\n",
      "['analys', 'power bi', 'azure', 'sql', ' r ', '3year']\n",
      "1\n",
      "['azure', 'sql', 'kubeflow']\n",
      "1\n",
      "['excel', 'analys', 'english', 'statistics', 'mathematics']\n",
      "1\n",
      "['sql', 'data warehouse', '2year']\n",
      "1\n",
      "['excel', 'english', 'sql', 'keras', 'tensorflow', 'pytorch', 'c++']\n",
      "1\n",
      "['analys', 'english', 'flink', 'spark', 'azure', 'sql', 'airflow', 'oop']\n",
      "1\n",
      "['sql', 'linux', '2year']\n",
      "1\n",
      "['analys', '1year']\n",
      "1\n",
      "['excel', 'analys', 'sql', 'data mining', 'segmentation techniques', ' r,', 'statistics', 'mathematics']\n",
      "1\n",
      "['power bi', 'sql', 'data warehouse']\n",
      "1\n",
      "['spark', 'oop']\n",
      "1\n",
      "['tensorflow', 'pytorch', 'c++', 'algorithms', 'mathematics']\n",
      "1\n",
      "['excel', 'power bi', 'sql', '1year']\n",
      "1\n",
      "['spark', 'sql', ' r,', 'oop']\n",
      "1\n",
      "['spark', 'sql', 'oop']\n",
      "1\n",
      "['statistics', '2year']\n",
      "1\n",
      "['excel', 'word', 'analys', 'power bi', '3year']\n",
      "1\n",
      "['spark', 'sql', 'airflow', 'oop', '5year']\n",
      "1\n",
      "['sql', 'e-commerce']\n",
      "1\n",
      "['excel', 'analys', 'power bi', 'statistics']\n",
      "1\n",
      "['excel', 'analys', 'e-commerce']\n",
      "1\n",
      "['analys', 'azure', 'sql', '3year']\n",
      "1\n",
      "['power bi', 'spark', 'data warehouse', 'oop', 'statistics', '3year']\n",
      "1\n",
      "['spark', 'algorithms']\n",
      "1\n",
      "['spark', '3year']\n",
      "1\n",
      "['excel', 'power bi', 'sql', '3year']\n",
      "1\n",
      "['excel', 'azure', 'sql', '4year']\n",
      "1\n",
      "['analys', 'english', 'azure', 'sql', 'data mining', 'segmentation techniques', '3year']\n",
      "1\n",
      "['english', 'sql']\n",
      "1\n",
      "['analys', 'power bi', '4year']\n",
      "1\n",
      "['excel', 'word', 'sql']\n",
      "1\n",
      "['english', 'c++', 'algorithms']\n",
      "1\n",
      "['excel', 'analys', 'power bi', 'sql', ' r,', 'statistics', '1year']\n",
      "1\n",
      "['analys', 'data warehouse', 'data pipeline']\n",
      "1\n",
      "['spark', 'sql', 'airflow', '2year']\n",
      "1\n",
      "['linux', 'bash script', '2year']\n",
      "1\n",
      "['linux', '3year']\n",
      "1\n",
      "['excel', 'power bi', 'english', 'data mining', '4year']\n",
      "1\n",
      "['excel', 'power bi', 'e-commerce']\n",
      "1\n",
      "['excel', 'analys', 'power bi', 'english', 'sql', 'data warehouse', 'mathematics', '5year']\n",
      "1\n",
      "['sql', 'data warehouse', '1year']\n",
      "1\n",
      "['analys', 'power bi', 'sql']\n",
      "1\n",
      "['analys', 'spark', 'sql', '2year']\n",
      "1\n",
      "['c++', 'opencv']\n",
      "1\n",
      "['spring', 'vue', 'angular']\n",
      "1\n",
      "['excel', 'word', 'analys', 'tableau bi', 'power bi']\n",
      "1\n",
      "['excel', 'analys', 'sql', ' r ', 'statistics', '1year']\n",
      "1\n",
      "['analys', 'spark', 'data warehouse', 'data pipeline', 'algorithms', 'google bigquery']\n",
      "1\n",
      "['jetson', 'raspberry', '4year']\n",
      "1\n",
      "['excel', 'english', 'flink', 'spark', 'azure', 'sql', 'keras', 'tensorflow', 'scikit learn', 'oop', '2year']\n",
      "1\n",
      "['english', 'sql', 'linux', 'bash script', 'javascript', 'data mining']\n",
      "1\n",
      "['sql', 'asynchronous programming', '1year']\n",
      "1\n",
      "['data mining', 'segmentation techniques']\n",
      "1\n",
      "['analys', 'spark', 'sql', 'data pipeline', 'airflow', 'c++', 'oop', 'statistics', '2year']\n",
      "1\n",
      "['excel', 'spark', 'sql', 'e-commerce', 'data warehouse', 'data pipeline', 'airflow', 'algorithms', '1year']\n",
      "1\n",
      "['analys', 'data warehouse']\n",
      "1\n",
      "['excel', 'transaction data']\n",
      "1\n",
      "['azure', 'tensorflow', 'pytorch', 'visualisation', ' r ', 'kubeflow', 'vertex']\n",
      "1\n",
      "['data warehouse', 'data pipeline']\n",
      "1\n",
      "['linux', 'reinforcement learning', 'supervised learning', '2year']\n",
      "1\n",
      "['analys', 'power bi', '1year']\n",
      "1\n",
      "['english', 'keras', 'tensorflow', 'pytorch', 'c++', 'algorithms', 'statistics', 'mathematics']\n",
      "1\n",
      "['english', 'sql', 'linux', 'node js', 'data warehouse', 'google bigquery', 'google bigtable']\n",
      "1\n",
      "['tensorflow', 'jetson', 'pytorch', 'c++', '5year']\n",
      "1\n",
      "['tensorflow', 'algorithms', '2year']\n",
      "1\n",
      "['linux', 'c++']\n",
      "1\n",
      "['spark']\n",
      "1\n",
      "['2year']\n",
      "1\n",
      "['spark', 'azure', 'data pipeline', '2year']\n",
      "1\n",
      "['english', 'spark', 'oop', '2year']\n",
      "1\n",
      "['sql', '1year']\n",
      "1\n",
      "['analys', 'sql', 'javascript']\n",
      "1\n",
      "['analys', 'english', 'c++']\n",
      "1\n",
      "['excel', 'sql', 'data warehouse']\n",
      "1\n",
      "['english', '3year']\n",
      "1\n",
      "['excel', 'analys', 'english', 'sql', '3year']\n",
      "1\n",
      "['data warehouse', '2year']\n",
      "1\n",
      "['analys', 'sql', 'statistics', '1year']\n",
      "1\n",
      "['analys', 'power bi', 'sql', ' r,', 'supervised learning', 'statistics']\n",
      "1\n",
      "['excel', 'statistics', '1year']\n",
      "1\n",
      "['analys', 'sql', ' r ', 'statistics']\n",
      "1\n",
      "['analys', 'sql', 'mathematics', '5year']\n",
      "1\n",
      "['analys', 'english', 'azure', 'data pipeline', 'statistics', 'mathematics']\n",
      "1\n",
      "['analys', 'power bi', 'english', '2year']\n",
      "1\n",
      "['excel', 'keras', 'pytorch', 'algorithms', 'statistics', 'mathematics']\n",
      "1\n",
      "['english', 'spark', 'oop']\n",
      "1\n",
      "['excel', 'analys', 'power bi', 'sql', '3year']\n",
      "1\n",
      "['analys', 'english', 'sql', 'data mining', 'segmentation techniques', '3year']\n",
      "1\n",
      "['analys', 'power bi', 'sql', '3year']\n",
      "1\n",
      "['excel', 'sql', 'algorithms', 'statistics', 'mathematics', '3year']\n",
      "1\n",
      "['spark', 'sql', 'bash script', 'airflow']\n",
      "1\n",
      "['analys', 'english', 'azure', 'data warehouse', '3year']\n",
      "1\n",
      "['spark', 'sql', 'linux', 'data mining']\n",
      "1\n",
      "['analys', 'sql', ' r ', 'statistics', '1year']\n",
      "1\n",
      "['tensorflow', 'linux', 'javascript', 'pytorch', 'c++', 'algorithms', 'opencv', '2year']\n",
      "1\n",
      "['english', 'spark', 'sql', 'spring', 'data warehouse', 'data pipeline', 'oop', '3year']\n",
      "1\n",
      "['analys', 'power bi', 'sql', 'airflow', '5year']\n",
      "1\n",
      "['english', 'sql', 'e-commerce', 'data warehouse', 'statistics', '5year']\n",
      "1\n",
      "['sql', 'mathematics']\n",
      "1\n",
      "['excel', 'english', 'tensorflow', 'data mining', '2year']\n",
      "1\n",
      "['english', 'oop']\n",
      "1\n",
      "['english', 'sql', '3year']\n",
      "1\n",
      "['excel', 'spark', 'azure', 'sql', 'data warehouse', 'data pipeline', 'airflow', 'oop', '2year']\n",
      "1\n",
      "['english', 'tensorflow', 'pytorch', ' r,', 'c++', '2year']\n",
      "1\n",
      "['english', 'spring', 'angular', '3year']\n",
      "1\n",
      "['excel', 'analys', 'power bi', 'english']\n",
      "1\n",
      "['excel', 'english', '5year']\n",
      "1\n",
      "['excel', 'analys', 'sql', 'algorithms', 'statistics', '5year']\n",
      "1\n",
      "['spark', 'tensorflow', 'pytorch', 'oop', 'statistics', '5year']\n",
      "1\n",
      "['analys', 'power bi', 'english', 'data bricks', 'azure', 'sql', 'data mining', '2year']\n",
      "1\n",
      "['azure', 'data pipeline']\n",
      "1\n",
      "['analys', '4year']\n",
      "1\n",
      "['excel', 'analys', 'english', 'spark', 'sql', 'data warehouse', 'data pipeline', 'oop', '3year']\n",
      "1\n",
      "['excel', 'analys', 'sql', 'javascript', 'data mining', 'segmentation techniques', 'statistics', 'mathematics']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tmp)):\n",
    "    print(tmp[i])\n",
    "    print(tmp1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "db2ce8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df['Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "74e80320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2121,\n",
       " 2860,\n",
       " 2537,\n",
       " 2727,\n",
       " 860,\n",
       " 2337,\n",
       " 1871,\n",
       " 1670,\n",
       " 3017,\n",
       " 3128,\n",
       " 1589,\n",
       " 2743,\n",
       " 2920,\n",
       " 2990,\n",
       " 3022,\n",
       " 1897,\n",
       " 145,\n",
       " 2758,\n",
       " 767,\n",
       " 1867,\n",
       " 2886,\n",
       " 1710,\n",
       " 2634,\n",
       " 1121,\n",
       " 1160,\n",
       " 720,\n",
       " 2178,\n",
       " 2068,\n",
       " 2381,\n",
       " 2717,\n",
       " 1706,\n",
       " 2261,\n",
       " 703,\n",
       " 3092,\n",
       " 2846,\n",
       " 2212,\n",
       " 1612,\n",
       " 2163,\n",
       " 2605,\n",
       " 858,\n",
       " 1838,\n",
       " 2559,\n",
       " 2828,\n",
       " 789,\n",
       " 2535,\n",
       " 646,\n",
       " 360,\n",
       " 2141,\n",
       " 2722,\n",
       " 2328,\n",
       " 2723,\n",
       " 2954,\n",
       " 1983,\n",
       " 3021,\n",
       " 2397,\n",
       " 2517,\n",
       " 2787,\n",
       " 2589,\n",
       " 1565,\n",
       " 2644,\n",
       " 3122,\n",
       " 1836,\n",
       " 2291,\n",
       " 2380,\n",
       " 612,\n",
       " 2140,\n",
       " 1505,\n",
       " 2562,\n",
       " 2371,\n",
       " 2948,\n",
       " 2896,\n",
       " 2386,\n",
       " 2771,\n",
       " 2640,\n",
       " 768,\n",
       " 2283,\n",
       " 1000,\n",
       " 396,\n",
       " 251,\n",
       " 2910,\n",
       " 2986,\n",
       " 1069,\n",
       " 2187,\n",
       " 2324,\n",
       " 1571,\n",
       " 2590,\n",
       " 2626,\n",
       " 3099,\n",
       " 2339,\n",
       " 1281,\n",
       " 2350,\n",
       " 3078,\n",
       " 2172,\n",
       " 248,\n",
       " 2438,\n",
       " 2428,\n",
       " 3041,\n",
       " 1860,\n",
       " 2587,\n",
       " 654,\n",
       " 1006,\n",
       " 2497,\n",
       " 3077,\n",
       " 770,\n",
       " 2126,\n",
       " 2242,\n",
       " 2750,\n",
       " 2427,\n",
       " 588,\n",
       " 1159,\n",
       " 822,\n",
       " 2647,\n",
       " 2709,\n",
       " 2057,\n",
       " 1412,\n",
       " 2885,\n",
       " 2931,\n",
       " 682,\n",
       " 2543,\n",
       " 143,\n",
       " 2586,\n",
       " 2967,\n",
       " 2461,\n",
       " 845,\n",
       " 2773,\n",
       " 2927,\n",
       " 2755,\n",
       " 1172,\n",
       " 2558,\n",
       " 2792,\n",
       " 2188,\n",
       " 1934,\n",
       " 790,\n",
       " 3044,\n",
       " 2888,\n",
       " 1730,\n",
       " 1954,\n",
       " 1716,\n",
       " 482,\n",
       " 91,\n",
       " 2652,\n",
       " 2715,\n",
       " 3104,\n",
       " 2854,\n",
       " 2545,\n",
       " 884,\n",
       " 2305,\n",
       " 2576,\n",
       " 879,\n",
       " 3110,\n",
       " 424,\n",
       " 1785,\n",
       " 1243,\n",
       " 2240,\n",
       " 2784,\n",
       " 1903,\n",
       " 1773,\n",
       " 1236,\n",
       " 882,\n",
       " 1711,\n",
       " 1192,\n",
       " 672,\n",
       " 2325,\n",
       " 2786,\n",
       " 2486,\n",
       " 1891,\n",
       " 1878,\n",
       " 269,\n",
       " 2762,\n",
       " 2508,\n",
       " 3093,\n",
       " 17,\n",
       " 3130,\n",
       " 2785,\n",
       " 2655,\n",
       " 3109,\n",
       " 1173,\n",
       " 2402,\n",
       " 1456,\n",
       " 1174,\n",
       " 1902,\n",
       " 1883,\n",
       " 2484,\n",
       " 2306,\n",
       " 3057,\n",
       " 2983,\n",
       " 766,\n",
       " 2478,\n",
       " 2657,\n",
       " 581,\n",
       " 2953,\n",
       " 1313,\n",
       " 2840,\n",
       " 3027,\n",
       " 2526,\n",
       " 3079,\n",
       " 1145,\n",
       " 3150,\n",
       " 826,\n",
       " 2524,\n",
       " 2103,\n",
       " 1980,\n",
       " 2334,\n",
       " 777,\n",
       " 2585,\n",
       " 1244,\n",
       " 2206,\n",
       " 674,\n",
       " 2825,\n",
       " 3011,\n",
       " 1818,\n",
       " 3040,\n",
       " 2726,\n",
       " 2520,\n",
       " 2286,\n",
       " 2231,\n",
       " 1743,\n",
       " 2058,\n",
       " 2919,\n",
       " 3072,\n",
       " 1920,\n",
       " 2279,\n",
       " 3064,\n",
       " 2607,\n",
       " 1413,\n",
       " 1579,\n",
       " 2426,\n",
       " 2824,\n",
       " 2578,\n",
       " 2382,\n",
       " 2769,\n",
       " 964,\n",
       " 1982,\n",
       " 2538,\n",
       " 2383,\n",
       " 2506,\n",
       " 2603,\n",
       " 1304,\n",
       " 824,\n",
       " 2029,\n",
       " 2265,\n",
       " 1053,\n",
       " 793,\n",
       " 317,\n",
       " 2388,\n",
       " 2582,\n",
       " 250,\n",
       " 2716,\n",
       " 1677,\n",
       " 2500,\n",
       " 2420,\n",
       " 3000,\n",
       " 2878,\n",
       " 2721,\n",
       " 2719,\n",
       " 2965,\n",
       " 1969,\n",
       " 2555,\n",
       " 2980,\n",
       " 583,\n",
       " 2899,\n",
       " 2813,\n",
       " 2084,\n",
       " 2706,\n",
       " 275,\n",
       " 1309,\n",
       " 2767,\n",
       " 1984,\n",
       " 1523,\n",
       " 1985,\n",
       " 3137,\n",
       " 1558,\n",
       " 2614,\n",
       " 1776,\n",
       " 3129,\n",
       " 2724,\n",
       " 2239,\n",
       " 1714,\n",
       " 2075,\n",
       " 1946,\n",
       " 2791,\n",
       " 1336,\n",
       " 807,\n",
       " 1288,\n",
       " 2796,\n",
       " 2749,\n",
       " 2267,\n",
       " 1289,\n",
       " 795,\n",
       " 775,\n",
       " 3162,\n",
       " 1620,\n",
       " 2547,\n",
       " 3135,\n",
       " 2164,\n",
       " 2768,\n",
       " 3010,\n",
       " 844,\n",
       " 1566,\n",
       " 1084,\n",
       " 2751,\n",
       " 2487,\n",
       " 2117,\n",
       " 3071,\n",
       " 2924,\n",
       " 3023,\n",
       " 2759,\n",
       " 747,\n",
       " 1588,\n",
       " 2574,\n",
       " 2560,\n",
       " 2847,\n",
       " 2400,\n",
       " 705,\n",
       " 2561,\n",
       " 2026,\n",
       " 2710,\n",
       " 2666,\n",
       " 2829,\n",
       " 2588,\n",
       " 2033,\n",
       " 778,\n",
       " 1176,\n",
       " 1198,\n",
       " 2076,\n",
       " 2227,\n",
       " 2454,\n",
       " 2304,\n",
       " 515,\n",
       " 2251,\n",
       " 3115,\n",
       " 2523,\n",
       " 1246,\n",
       " 2849,\n",
       " 2906,\n",
       " 2909,\n",
       " 597,\n",
       " 2679,\n",
       " 2528,\n",
       " 3043,\n",
       " 2083,\n",
       " 142,\n",
       " 2166,\n",
       " 1947,\n",
       " 792,\n",
       " 2534,\n",
       " 890,\n",
       " 3076,\n",
       " 1629,\n",
       " 2599,\n",
       " 2483,\n",
       " 3155,\n",
       " 1555,\n",
       " 2649,\n",
       " 2203,\n",
       " 2918,\n",
       " 2269,\n",
       " 3039,\n",
       " 3042,\n",
       " 2298,\n",
       " 961,\n",
       " 450,\n",
       " 1973,\n",
       " 2937,\n",
       " 2156,\n",
       " 1175,\n",
       " 2708,\n",
       " 1828,\n",
       " 2036,\n",
       " 802,\n",
       " 1007,\n",
       " 2714,\n",
       " 2628,\n",
       " 2266,\n",
       " 2032,\n",
       " 1752,\n",
       " 2568,\n",
       " 806,\n",
       " 2230,\n",
       " 3136,\n",
       " 1240,\n",
       " 1913,\n",
       " 1643,\n",
       " 2035,\n",
       " 2226,\n",
       " 2951,\n",
       " 2259,\n",
       " 2625,\n",
       " 1402,\n",
       " 2964,\n",
       " 2104,\n",
       " 1245,\n",
       " 1839,\n",
       " 2124,\n",
       " 2525,\n",
       " 2575,\n",
       " 2760,\n",
       " 1709,\n",
       " 2347,\n",
       " 1297,\n",
       " 161,\n",
       " 2379,\n",
       " 2485,\n",
       " 2608,\n",
       " 2663,\n",
       " 666,\n",
       " 2139,\n",
       " 3157,\n",
       " 647,\n",
       " 794,\n",
       " 1690,\n",
       " 2646,\n",
       " 2205,\n",
       " 2433,\n",
       " 1990,\n",
       " 965,\n",
       " 1295,\n",
       " 2563,\n",
       " 1834,\n",
       " 2936,\n",
       " 2389,\n",
       " 1550,\n",
       " 2604,\n",
       " 1578,\n",
       " 2826,\n",
       " 3121,\n",
       " 2044,\n",
       " 3158,\n",
       " 683,\n",
       " 733,\n",
       " 1196,\n",
       " 2929,\n",
       " 697,\n",
       " 1086,\n",
       " 3075,\n",
       " 2665,\n",
       " 2877,\n",
       " 2150,\n",
       " 2894,\n",
       " 2686,\n",
       " 198,\n",
       " 2301,\n",
       " 2507,\n",
       " 2815,\n",
       " 1316,\n",
       " 649,\n",
       " 2241,\n",
       " 2938,\n",
       " 2310,\n",
       " 2349,\n",
       " 2557,\n",
       " 974,\n",
       " 2995,\n",
       " 3118,\n",
       " 1347,\n",
       " 2897,\n",
       " 2979,\n",
       " 2435,\n",
       " 1551,\n",
       " 2475,\n",
       " 3159,\n",
       " 2718,\n",
       " 2639,\n",
       " 2355,\n",
       " 2499,\n",
       " 1728,\n",
       " 70,\n",
       " 1139,\n",
       " 796,\n",
       " 659,\n",
       " 2293,\n",
       " 692,\n",
       " 2725,\n",
       " 825,\n",
       " 776,\n",
       " 3113,\n",
       " 2220,\n",
       " 1564,\n",
       " 1603,\n",
       " 430,\n",
       " 2879,\n",
       " 3084,\n",
       " 249,\n",
       " 3013,\n",
       " 3138,\n",
       " 2542,\n",
       " 2823,\n",
       " 2377,\n",
       " 2479,\n",
       " 1799,\n",
       " 273,\n",
       " 2518,\n",
       " 2390,\n",
       " 885,\n",
       " 2529,\n",
       " 2887,\n",
       " 1537,\n",
       " 2766,\n",
       " 3095,\n",
       " 2498,\n",
       " 1033,\n",
       " 2656,\n",
       " 774,\n",
       " 3096,\n",
       " 843,\n",
       " 2570,\n",
       " 2336,\n",
       " 2536,\n",
       " 1832,\n",
       " 90,\n",
       " 1634,\n",
       " 1628,\n",
       " 2120,\n",
       " 3066,\n",
       " 2157,\n",
       " 2391,\n",
       " 2297,\n",
       " 3045,\n",
       " 2858,\n",
       " 2939,\n",
       " 3117,\n",
       " 2369,\n",
       " 3056,\n",
       " 2014,\n",
       " 2597,\n",
       " 1083,\n",
       " 1426,\n",
       " 2522,\n",
       " 2664,\n",
       " 2827,\n",
       " 2908,\n",
       " 2062,\n",
       " 2072,\n",
       " 3116,\n",
       " 1088,\n",
       " 1702,\n",
       " 3083,\n",
       " 2145,\n",
       " 2772,\n",
       " 1938,\n",
       " 805,\n",
       " 2713,\n",
       " 628,\n",
       " 2260,\n",
       " 2921,\n",
       " 2818,\n",
       " 1729,\n",
       " 1807,\n",
       " 734,\n",
       " 59,\n",
       " 1917,\n",
       " 2554,\n",
       " 2987,\n",
       " 3020,\n",
       " 2539,\n",
       " 809,\n",
       " 2527,\n",
       " 1837,\n",
       " 1009,\n",
       " 3107,\n",
       " 2399,\n",
       " 1140,\n",
       " 1784,\n",
       " 2515,\n",
       " 1030,\n",
       " 2122,\n",
       " 2142,\n",
       " 670,\n",
       " 2303,\n",
       " 773,\n",
       " 2268,\n",
       " 1942,\n",
       " 2375,\n",
       " 2237,\n",
       " 2770,\n",
       " 546,\n",
       " 2805,\n",
       " 521,\n",
       " 200,\n",
       " 1700,\n",
       " 3134,\n",
       " 2720,\n",
       " 1899,\n",
       " 2989,\n",
       " 791,\n",
       " 1499,\n",
       " 2573,\n",
       " 1898]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jod_id = []\n",
    "for path in tmp:\n",
    "    path = path[path.find('/')+1:]\n",
    "    path = path[:path.find('/')]\n",
    "    jod_id.append(int(path))\n",
    "jod_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "76b66032",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Job Id'] = jod_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "76683cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reindex(columns=['Job Id', 'Data','Description','Requirements','Keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6d2f46e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job ID</th>\n",
       "      <th>Data</th>\n",
       "      <th>Description</th>\n",
       "      <th>Requirements</th>\n",
       "      <th>Keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2121</td>\n",
       "      <td>data-02-06/2121/data.html</td>\n",
       "      <td>mô tả công việc\\n\\n\\nwork on data collection s...</td>\n",
       "      <td>yêu cầu công việc\\n\\n- education level, certif...</td>\n",
       "      <td>[english, statistics, 3year]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2860</td>\n",
       "      <td>data-02-06/2860/data.html</td>\n",
       "      <td>responsible for driving strategic planning pro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2537</td>\n",
       "      <td>data-02-06/2537/data.html</td>\n",
       "      <td>mô tả công việc\\n- tham gia vào các dự án triể...</td>\n",
       "      <td>yêu cầu ứng viên\\n- tốt nghiệp đại học ngành k...</td>\n",
       "      <td>[excel, word, analys, tableau bi, power bi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2727</td>\n",
       "      <td>data-02-06/2727/data.html</td>\n",
       "      <td>mô tả công việc\\nchịu trách nhiệm trích xuất v...</td>\n",
       "      <td>yêu cầu ứng viên\\n1. trình độ:có kiến thức cơ ...</td>\n",
       "      <td>[excel, analys, sql,  r , statistics, 1year]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>860</td>\n",
       "      <td>data-02-06/860/data.html</td>\n",
       "      <td>descriptionkiotviet wishes to transfer a massi...</td>\n",
       "      <td>experience.what you will do:design the archite...</td>\n",
       "      <td>[analys, spark, data warehouse, data pipeline,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>2989</td>\n",
       "      <td>data-02-06/2989/data.html</td>\n",
       "      <td>mô tả công việc• build financial models to rev...</td>\n",
       "      <td>yêu cầu công việcuniversity degree in finance,...</td>\n",
       "      <td>[excel, power bi, 4year]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>791</td>\n",
       "      <td>data-02-06/791/data.html</td>\n",
       "      <td>description \\n\\njob responsibilities (include,...</td>\n",
       "      <td>experience in web crawling and/or scraping ski...</td>\n",
       "      <td>[excel, english, sql]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>1499</td>\n",
       "      <td>data-02-06/1499/data.html</td>\n",
       "      <td>responsibilities:\\n\\n\\nyou are an</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>2573</td>\n",
       "      <td>data-02-06/2573/data.html</td>\n",
       "      <td>mô tả công việc\\n\\n                           ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>1898</td>\n",
       "      <td>data-02-06/1898/data.html</td>\n",
       "      <td>mô tả công việc- interpret data, analyze resul...</td>\n",
       "      <td>yêu cầu ứng viên- proven working experience as...</td>\n",
       "      <td>[excel, analys, sql, javascript, data mining, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Job ID                       Data  \\\n",
       "0      2121  data-02-06/2121/data.html   \n",
       "1      2860  data-02-06/2860/data.html   \n",
       "2      2537  data-02-06/2537/data.html   \n",
       "3      2727  data-02-06/2727/data.html   \n",
       "4       860   data-02-06/860/data.html   \n",
       "..      ...                        ...   \n",
       "583    2989  data-02-06/2989/data.html   \n",
       "584     791   data-02-06/791/data.html   \n",
       "585    1499  data-02-06/1499/data.html   \n",
       "586    2573  data-02-06/2573/data.html   \n",
       "587    1898  data-02-06/1898/data.html   \n",
       "\n",
       "                                           Description  \\\n",
       "0    mô tả công việc\\n\\n\\nwork on data collection s...   \n",
       "1    responsible for driving strategic planning pro...   \n",
       "2    mô tả công việc\\n- tham gia vào các dự án triể...   \n",
       "3    mô tả công việc\\nchịu trách nhiệm trích xuất v...   \n",
       "4    descriptionkiotviet wishes to transfer a massi...   \n",
       "..                                                 ...   \n",
       "583  mô tả công việc• build financial models to rev...   \n",
       "584  description \\n\\njob responsibilities (include,...   \n",
       "585                 responsibilities:\\n\\n\\nyou are an    \n",
       "586  mô tả công việc\\n\\n                           ...   \n",
       "587  mô tả công việc- interpret data, analyze resul...   \n",
       "\n",
       "                                          Requirements  \\\n",
       "0    yêu cầu công việc\\n\\n- education level, certif...   \n",
       "1                                                  NaN   \n",
       "2    yêu cầu ứng viên\\n- tốt nghiệp đại học ngành k...   \n",
       "3    yêu cầu ứng viên\\n1. trình độ:có kiến thức cơ ...   \n",
       "4    experience.what you will do:design the archite...   \n",
       "..                                                 ...   \n",
       "583  yêu cầu công việcuniversity degree in finance,...   \n",
       "584  experience in web crawling and/or scraping ski...   \n",
       "585                                                NaN   \n",
       "586                                                NaN   \n",
       "587  yêu cầu ứng viên- proven working experience as...   \n",
       "\n",
       "                                               Keyword  \n",
       "0                         [english, statistics, 3year]  \n",
       "1                                                       \n",
       "2          [excel, word, analys, tableau bi, power bi]  \n",
       "3         [excel, analys, sql,  r , statistics, 1year]  \n",
       "4    [analys, spark, data warehouse, data pipeline,...  \n",
       "..                                                 ...  \n",
       "583                           [excel, power bi, 4year]  \n",
       "584                              [excel, english, sql]  \n",
       "585                                                     \n",
       "586                                                     \n",
       "587  [excel, analys, sql, javascript, data mining, ...  \n",
       "\n",
       "[588 rows x 5 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "584c3906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job ID</th>\n",
       "      <th>JD Company</th>\n",
       "      <th>JD Title ( Eng )</th>\n",
       "      <th>JD Level</th>\n",
       "      <th>JD YOE Min</th>\n",
       "      <th>JD Location</th>\n",
       "      <th>JD Gross Salary Max*</th>\n",
       "      <th>JD Due Date</th>\n",
       "      <th>JD Working Hour</th>\n",
       "      <th>JD Note</th>\n",
       "      <th>JD Details</th>\n",
       "      <th>JD Title ( Vie )</th>\n",
       "      <th>check</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3165</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>Leader, Data Engineer</td>\n",
       "      <td>Senior, Lead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tới khi đóng link</td>\n",
       "      <td>Fulltime</td>\n",
       "      <td>Hà Nội tuyển dụng tech leader Data Engineer Go...</td>\n",
       "      <td>https://www.facebook.com/groups/datanalyticsvn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>HTTPSConnectionPool(host='www.trans-cosmos.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3164</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>Market Analyses And Business Intelligence Manager</td>\n",
       "      <td>Manager</td>\n",
       "      <td>8.0</td>\n",
       "      <td>HCM</td>\n",
       "      <td>4</td>\n",
       "      <td>Tới khi đóng link</td>\n",
       "      <td>Fulltime</td>\n",
       "      <td>Minimum 8 years; Proven experience in business...</td>\n",
       "      <td>https://abbott.wd5.myworkdayjobs.com/en-US/abb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>HTTPSConnectionPool(host='www.trans-cosmos.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2839</td>\n",
       "      <td>TEAM DATAJOBS</td>\n",
       "      <td>Data &amp; Domain Mentor</td>\n",
       "      <td>Junior, Senior, Manager, Senior Manager+++</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tới khi đóng link</td>\n",
       "      <td>Part-time, Freelance</td>\n",
       "      <td>- Giờ giấc linh hoạt, tự đề xuất mức phí, 100%...</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1kCr2Pn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>HTTPSConnectionPool(host='www.trans-cosmos.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3163</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>Business Intelligence Analyst</td>\n",
       "      <td>Senior</td>\n",
       "      <td>3.0</td>\n",
       "      <td>HCM</td>\n",
       "      <td>2,2</td>\n",
       "      <td>Tới khi đóng link</td>\n",
       "      <td>Fulltime</td>\n",
       "      <td>At least 3 years of experience as BI Analyst</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/business-in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>HTTPSConnectionPool(host='www.trans-cosmos.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3162</td>\n",
       "      <td>Shinhan Bank Vietnam</td>\n",
       "      <td>Data Analytics Supervisor</td>\n",
       "      <td>Senior, Lead</td>\n",
       "      <td>2.0</td>\n",
       "      <td>HCM</td>\n",
       "      <td>1,06</td>\n",
       "      <td>1-Jul-23</td>\n",
       "      <td>Fulltime</td>\n",
       "      <td>Experience in SQL, PowerBI is compulsory</td>\n",
       "      <td>https://www.topcv.vn/viec-lam/data-analytics-s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>HTTPSConnectionPool(host='www.trans-cosmos.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>91</td>\n",
       "      <td>Ninja Van</td>\n",
       "      <td>Senior Data Analyst ( Fleet )</td>\n",
       "      <td>Senior</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HN</td>\n",
       "      <td>2,5</td>\n",
       "      <td>Tới khi đóng link</td>\n",
       "      <td>Fulltime</td>\n",
       "      <td>At least 6 month of experienced working in an ...</td>\n",
       "      <td>https://jobs.lever.co/ninjavan/329f01c1-aa84-4...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>HTTPSConnectionPool(host='www.trans-cosmos.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>90</td>\n",
       "      <td>Ninja Van</td>\n",
       "      <td>Data Analyst ( Fleet )</td>\n",
       "      <td>Fresher*, Junior, Senior</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HN</td>\n",
       "      <td>1,5</td>\n",
       "      <td>Tới khi đóng link</td>\n",
       "      <td>Fulltime</td>\n",
       "      <td>At least 6 months of experience in the field o...</td>\n",
       "      <td>https://jobs.lever.co/ninjavan/6c9dcb5b-9a2f-4...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>HTTPSConnectionPool(host='www.trans-cosmos.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>70</td>\n",
       "      <td>NIC's Client</td>\n",
       "      <td>Data Solution Consultant</td>\n",
       "      <td>Junior, Senior</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HN</td>\n",
       "      <td>1,36</td>\n",
       "      <td>Tới khi đóng link</td>\n",
       "      <td>Fulltime</td>\n",
       "      <td>Có kinh nghiệm phát triển ETL hoặc báo cáo như...</td>\n",
       "      <td>https://nicvn.com/chuyen-vien-tu-van-giai-phap...</td>\n",
       "      <td>Chuyên viên Tư vấn Giải pháp Dữ liệu</td>\n",
       "      <td>True</td>\n",
       "      <td>HTTPSConnectionPool(host='www.trans-cosmos.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>59</td>\n",
       "      <td>Yes4All</td>\n",
       "      <td>Demand &amp; Supply Planning Associate Manager</td>\n",
       "      <td>Manager</td>\n",
       "      <td>2.0</td>\n",
       "      <td>HCM</td>\n",
       "      <td>2,5</td>\n",
       "      <td>30-Apr-23</td>\n",
       "      <td>Fulltime</td>\n",
       "      <td>At least 2-3 years of experiences in Planning,...</td>\n",
       "      <td>https://yes4all.talent.vn/job/demand-supply-pl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>HTTPSConnectionPool(host='www.trans-cosmos.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>17</td>\n",
       "      <td>EVIZI LLC</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Senior</td>\n",
       "      <td>7.0</td>\n",
       "      <td>HN, Da Nang</td>\n",
       "      <td>4</td>\n",
       "      <td>Tới khi đóng link</td>\n",
       "      <td>Fulltime</td>\n",
       "      <td>BS with 7+ years MS SQL experience.</td>\n",
       "      <td>https://evizi.com/careers/#data-engineer-career-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>HTTPSConnectionPool(host='www.trans-cosmos.com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1596 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Job ID            JD Company  \\\n",
       "0       3165           Undisclosed   \n",
       "1       3164                Abbott   \n",
       "2       2839         TEAM DATAJOBS   \n",
       "3       3163           Undisclosed   \n",
       "4       3162  Shinhan Bank Vietnam   \n",
       "...      ...                   ...   \n",
       "1591      91             Ninja Van   \n",
       "1592      90             Ninja Van   \n",
       "1593      70          NIC's Client   \n",
       "1594      59               Yes4All   \n",
       "1595      17             EVIZI LLC   \n",
       "\n",
       "                                       JD Title ( Eng )  \\\n",
       "0                                 Leader, Data Engineer   \n",
       "1     Market Analyses And Business Intelligence Manager   \n",
       "2                                  Data & Domain Mentor   \n",
       "3                         Business Intelligence Analyst   \n",
       "4                             Data Analytics Supervisor   \n",
       "...                                                 ...   \n",
       "1591                      Senior Data Analyst ( Fleet )   \n",
       "1592                             Data Analyst ( Fleet )   \n",
       "1593                           Data Solution Consultant   \n",
       "1594         Demand & Supply Planning Associate Manager   \n",
       "1595                                      Data Engineer   \n",
       "\n",
       "                                        JD Level  JD YOE Min  JD Location  \\\n",
       "0                                   Senior, Lead         NaN           HN   \n",
       "1                                        Manager         8.0          HCM   \n",
       "2     Junior, Senior, Manager, Senior Manager+++         1.0       Remote   \n",
       "3                                         Senior         3.0          HCM   \n",
       "4                                   Senior, Lead         2.0          HCM   \n",
       "...                                          ...         ...          ...   \n",
       "1591                                      Senior         NaN           HN   \n",
       "1592                    Fresher*, Junior, Senior         NaN           HN   \n",
       "1593                              Junior, Senior         1.0           HN   \n",
       "1594                                     Manager         2.0          HCM   \n",
       "1595                                      Senior         7.0  HN, Da Nang   \n",
       "\n",
       "     JD Gross Salary Max*        JD Due Date       JD Working Hour  \\\n",
       "0                     NaN  Tới khi đóng link              Fulltime   \n",
       "1                       4  Tới khi đóng link              Fulltime   \n",
       "2                     NaN  Tới khi đóng link  Part-time, Freelance   \n",
       "3                     2,2  Tới khi đóng link              Fulltime   \n",
       "4                    1,06           1-Jul-23              Fulltime   \n",
       "...                   ...                ...                   ...   \n",
       "1591                  2,5  Tới khi đóng link              Fulltime   \n",
       "1592                  1,5  Tới khi đóng link              Fulltime   \n",
       "1593                 1,36  Tới khi đóng link              Fulltime   \n",
       "1594                  2,5          30-Apr-23              Fulltime   \n",
       "1595                    4  Tới khi đóng link              Fulltime   \n",
       "\n",
       "                                                JD Note  \\\n",
       "0     Hà Nội tuyển dụng tech leader Data Engineer Go...   \n",
       "1     Minimum 8 years; Proven experience in business...   \n",
       "2     - Giờ giấc linh hoạt, tự đề xuất mức phí, 100%...   \n",
       "3          At least 3 years of experience as BI Analyst   \n",
       "4              Experience in SQL, PowerBI is compulsory   \n",
       "...                                                 ...   \n",
       "1591  At least 6 month of experienced working in an ...   \n",
       "1592  At least 6 months of experience in the field o...   \n",
       "1593  Có kinh nghiệm phát triển ETL hoặc báo cáo như...   \n",
       "1594  At least 2-3 years of experiences in Planning,...   \n",
       "1595                BS with 7+ years MS SQL experience.   \n",
       "\n",
       "                                             JD Details  \\\n",
       "0     https://www.facebook.com/groups/datanalyticsvn...   \n",
       "1     https://abbott.wd5.myworkdayjobs.com/en-US/abb...   \n",
       "2     https://docs.google.com/spreadsheets/d/1kCr2Pn...   \n",
       "3     https://www.linkedin.com/jobs/view/business-in...   \n",
       "4     https://www.topcv.vn/viec-lam/data-analytics-s...   \n",
       "...                                                 ...   \n",
       "1591  https://jobs.lever.co/ninjavan/329f01c1-aa84-4...   \n",
       "1592  https://jobs.lever.co/ninjavan/6c9dcb5b-9a2f-4...   \n",
       "1593  https://nicvn.com/chuyen-vien-tu-van-giai-phap...   \n",
       "1594  https://yes4all.talent.vn/job/demand-supply-pl...   \n",
       "1595  https://evizi.com/careers/#data-engineer-career-5   \n",
       "\n",
       "                          JD Title ( Vie )  check  \\\n",
       "0                                      NaN  False   \n",
       "1                                      NaN   True   \n",
       "2                                      NaN  False   \n",
       "3                                      NaN  False   \n",
       "4                                      NaN   True   \n",
       "...                                    ...    ...   \n",
       "1591                                   NaN   True   \n",
       "1592                                   NaN   True   \n",
       "1593  Chuyên viên Tư vấn Giải pháp Dữ liệu   True   \n",
       "1594                                   NaN   True   \n",
       "1595                                   NaN   True   \n",
       "\n",
       "                                                  error  \n",
       "0     HTTPSConnectionPool(host='www.trans-cosmos.com...  \n",
       "1     HTTPSConnectionPool(host='www.trans-cosmos.com...  \n",
       "2     HTTPSConnectionPool(host='www.trans-cosmos.com...  \n",
       "3     HTTPSConnectionPool(host='www.trans-cosmos.com...  \n",
       "4     HTTPSConnectionPool(host='www.trans-cosmos.com...  \n",
       "...                                                 ...  \n",
       "1591  HTTPSConnectionPool(host='www.trans-cosmos.com...  \n",
       "1592  HTTPSConnectionPool(host='www.trans-cosmos.com...  \n",
       "1593  HTTPSConnectionPool(host='www.trans-cosmos.com...  \n",
       "1594  HTTPSConnectionPool(host='www.trans-cosmos.com...  \n",
       "1595  HTTPSConnectionPool(host='www.trans-cosmos.com...  \n",
       "\n",
       "[1596 rows x 14 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('data-02-06-22_crawl.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a496c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(df2,df, on=\"Job ID\", how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5ca72a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data-02-06-23_keyword.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
